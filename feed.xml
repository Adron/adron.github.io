<?xml version="1.0" encoding="utf-8" ?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adron's Composite Code</title>
    <atom:link href="http://adron.github.io/feed.xml" rel="self" type="application/rss+xml"></atom:link>
    <link>http://adron.github.io</link>
    <description>Coder, Messenger, Recon, Infrastructure, Ops</description>
    <pubDate>Fri, 12 May 2017 06:21:13 -0500</pubDate>
    <generator>Wintersmith - https://github.com/jnordberg/wintersmith</generator>
    <language>en</language>
    <item>
      <title>OSCON 2017 Austin - An Attendance Guide and Review</title>
      <link>http://adron.github.io/articles/OSCON-2017-Austin-Attendance-Guide-Review/</link>
      <pubDate>Fri, 12 May 2017 06:21:13 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/OSCON-2017-Austin-Attendance-Guide-Review/</guid>
      <author></author>
      <description>&lt;p&gt;Another OSCON. I think this makes 6 years I’ve attended OSCON. Each having it’s own unique characteristics while maintaining what makes OSCON, OSCON. But before even diving in I’ll add a few specific observations I’ve made at the Austin OSCON 2017:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OSCON is still one of the largest, if not &lt;em&gt;the&lt;/em&gt; largest open source conference in the world. It still appears to have some seriously concrete influence in the industry.&lt;/li&gt;
&lt;li&gt;Even with its size, OSCON seems to be missing a few key elements to bridge connections within the open source world, which I’ll add detail to in a moment.&lt;/li&gt;
&lt;li&gt;OSCON is a great conference to attend for a deluge of great presentations and related material to advance your knowledge on a wide range of topics.&lt;/li&gt;
&lt;li&gt;The Expo Pass, albeit it’s sold for X amount sometimes, is generally worth a solid $0-$50 bucks in my opinion. One can easily get $50 bucks worth out of the Expo Pass even if its just to attend one session (I believe that’s included) and to get into the conference area to mingle and discuss topics of interest with fellow conference goers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One thing I’ve always noticed, considering words spoke many years ago by the leadership of Microsoft, is how involved they are now in OSCON. I don’t mean in the sense of a predatory, desire to destroy open source or any competitors those words from many years ago would dictate, but instead they’ve actually involved in the open source community and the projects of the community. Sure, some of the projects are effectively just Microsoft projects that paid Microsoft employees work on. But many others are projects you’d still not really expect Microsoft to be working on, such as the Linux Kernel or others.&lt;/p&gt;
&lt;p&gt;Microsoft did release and interesting new feature to augment their Bash on Windows. Instead of just one Bash on Windows subsystem contraption, you can now (or soon, never really sure when a thing is actually released at Microsoft) multiple distros of Bash on Windows.&lt;/p&gt;
&lt;h2 id=&quot;wtf-bash-on-windows-&quot;&gt;WTF? Bash on Windows?&lt;/h2&gt;
&lt;p&gt;Ok, I’ll admit I shifted away from Windows back in 2011 and haven’t had a single issue come up. I dropped all of that trash fire like the oddball hack it was back then. One of the big reasons I dropped it was because I wanted to have systems that more closely resembled the systems I was generally working with, or wanted to work with. Those, 99.9% of the time, were some * nix variant and Windows was definitely not anything remotely close to that. This makes me scratch my head in curiosity of what the long game is, still not entirely sold on switching back or even using Windows as another system within my stable of systems.&lt;/p&gt;
&lt;p&gt;Here’s an article by &lt;a href=&quot;https://twitter.com/richturn_ms&quot;&gt;@richturn_ms&lt;/a&gt;, &lt;a href=&quot;https://blogs.msdn.microsoft.com/commandline/2017/05/11/new-distros-coming-to-bashwsl-via-windows-store/&quot;&gt;“New distro’s coming to Bash/WSL via Windows Store”&lt;/a&gt; for more details on this whole release of distros on Windows.&lt;/p&gt;
&lt;h2 id=&quot;oscon-bridging-gaps-a-suggestion&quot;&gt;OSCON Bridging Gaps, A Suggestion&lt;/h2&gt;
&lt;p&gt;One of the main benefits of OSCON, to me personally, is expanding my network and speaking personally with individuals working on the technology that I use everyday. If it is Kubernetes or Ubuntu or something else, it’s always beneficial to catch up with other members of the community. This year in Austin was no exception. I was able to catch up with a number of coders, media people, and others pushing the industry forward.&lt;/p&gt;
&lt;p&gt;One thing I did notice, and I realize this is the &lt;strong&gt;&lt;em&gt;“Open Source Conference”&lt;/em&gt;&lt;/strong&gt; and not the “Hardware Hackers” or “Makers Conference” or “Open Source Hardware Makers Conference” but that doesn’t matter. I’d like to see more of a bridge for OSCON to other parts of the community. I’d like to see Ubuntu, Elementary, and other projects present in the expo hall. I’d like to see System 76 and other hardware makers specifically invited and attending to show off their hardware alongside the software. I’m not sure how or what OSCON would need to do to make this happen, but it definitely seems like something that is really missing from the overall picture.&lt;/p&gt;
&lt;h2 id=&quot;linux-hardware&quot;&gt;Linux Hardware&lt;/h2&gt;
&lt;p&gt;There was some hardware at the conference. There were open source versions of robots and related creations, and some individuals from System 76. With that I did see some hardware from Dell, System 76, and other manufacturers. However it was by no means a concerted effort, it was merely happenstance that I fumbled into some scenarios that I got to check out this hardware and it’s respective software working together.&lt;/p&gt;
&lt;p&gt;Hopefully in coming years OSCON can bridge this gap and we’ll see more hardware combined with software, intertwined with the community members that are building these technologies together.&lt;/p&gt;
&lt;h2 id=&quot;getting-your-roi-from-oscon&quot;&gt;Getting Your ROI from OSCON&lt;/h2&gt;
&lt;p&gt;If you’ve looked at the pricing for OSCON, it can seem daunting at first without a direct infusion or full coverage of the conference by one’s employer. There are however a number of other ways to attend in some way and gain a solid return on your investment in time and money.&lt;/p&gt;
&lt;h3 id=&quot;full-price-roi-attendance-guide&quot;&gt;Full Price ROI Attendance Guide&lt;/h3&gt;
&lt;p&gt;If you’ve paid full price you’ve contributed the greatest amount to a great OSCON. In this case my suggestion, my strong suggestion, is to follow this attendance guide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Attend and &lt;em&gt;take notes with paper&lt;/em&gt;, &lt;strong&gt;&lt;em&gt;NOT&lt;/em&gt;&lt;/strong&gt; &lt;em&gt;a laptop&lt;/em&gt;, in your selection of presentations throughout the days where presentations occur. There are solid paths of study that can be taken and a vast amount of knowledge, experience, and use case story that you can learn from. But without solid note taking, it will be extremely overwhelming.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Attend as many of the after hours events and parties as possible. Introduce yourself and speak to as many people as you can that meet one of several criteria:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If someone is interested in or studying a similar topic range of interests as what you’re looking into, befriend them and discuss that topic. Hang out with them, exchange contact info, and expand your network beyond that one person to others at the conference.&lt;/li&gt;
&lt;li&gt;If someone is knowledgeable about a topic, but maybe not exactly aligned with the topics you’re aiming to learn about, it still may behoove you to discuss that topic and expand on your topic range a bit.&lt;/li&gt;
&lt;li&gt;If someone is a key person in an industry domain that you’d like to be involved with, introduce yourself and strike up some conversation about their work in said industry domain.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Attend the Expo Hall and give a quick walk through of the space. If there are any companies that you may want to interact with then go up and discuss the technology, but also ask about who’s working on what, the structure of the company, and how it interoperates internally. This can provide insight into how the products or services are built. Maybe, just maybe, you’ll let them scan your badge so they can badger you later. But I’ll leave that as an open ended somewhat nefarious suggestion.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;full-price-training-roi-attendance-guide&quot;&gt;Full Price + Training ROI Attendance Guide&lt;/h3&gt;
&lt;p&gt;This one is easy, you attend the training and you follow the &lt;em&gt;Full Price ROI Attendance Guide&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;expo-hall-roi-attendance-guide&quot;&gt;Expo Hall ROI Attendance Guide&lt;/h3&gt;
&lt;p&gt;Depending on how much you’ve paid the activities and such to get an ROI can vary. If you’ve paid nothing, of course you really don’t need to do much of anything.&lt;/p&gt;
&lt;p&gt;The Expo Hall pass, as far as I understand it, enables; attendance of after parties, one presentation, checking out the expo hall itself, and hanging out and around the general conference spaces and conference study spaces. Merely attending the after parties, a presentation, or meeting people in the conference area easily makes the Expo Hall Pass worth a reasonable prices (let’s say $25-50 bucks). If you’ve paid more (maybe $50+ bucks) then I’d definitely suggest making a point at using the pass to its maximum. Hit up the parties and meet as many people as possible.&lt;/p&gt;
&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;
&lt;p&gt;Well, another OSCON done, and looking forward to the next in Portland! Regardless of the pass you’ve bought, there’s a way to get a solid ROI from OSCON. In the future, I hope to see a great bridge between hardware, software, and the connection and presence of these industry elements. Even in light of this absence, another great OSCON Conference.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Four Quick Git Tips (AKA Things I Always Forget and Have to Look Up)</title>
      <link>http://adron.github.io/articles/git-editors/</link>
      <pubDate>Wed, 03 May 2017 06:02:58 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/git-editors/</guid>
      <author></author>
      <description>&lt;p&gt;Are you ever working in git, then all of a sudden you do a pull or push and boom, you’ve got a request to make a merge text file. Often this pops up as VI or Nano on Linux. But it can depend based on what editor is actually set. Did you know you could set the editor? Obviously you can right? Here’s the details on getting that done in git.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;1&quot;&gt;1&lt;/h2&gt;
&lt;p&gt;Want Atom as your editor to make merge comments and errata in?&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/d86eac58a61b726ea8f1e416a386a32b.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;How about Sublime?&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/296050d3f6dde3e6f7245aa56324230a.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;You get the idea. Basically, whatever editor you want just issue the command to change the git config so it can launch that editor via a CLI call.&lt;/p&gt;
&lt;h2 id=&quot;2&quot;&gt;2&lt;/h2&gt;
&lt;p&gt;Moving beyond the mere merge editor, we can also set the merge IDE or editor. This can help dramatically if you’re digging through merge conflicts regularly or needing to run diffs on code. For instance, let’s set Intellij as the merge and diff tool. Open up the ~/.gitconfig file and add the respective snippets.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/b650ef841453ca676d247105eb684a3b.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;3&quot;&gt;3&lt;/h2&gt;
&lt;p&gt;Another git helper, is setting up autocomplete for your shell.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/5fb1e87e7dd18cf3330ba24671d522f3.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Some of my crew uses zsh, so if you’re one of those users the steps involve a bit more. Add the following to your &lt;code&gt;~/.zshrc&lt;/code&gt; file.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/30d8555ad25c12049e05d899aaea364e.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;4&quot;&gt;4&lt;/h2&gt;
&lt;p&gt;Gah, seriously, type less already. Alias git to the ‘g’ key. Add the following to your .bashrc or .zshrc:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alias g=&amp;#39;git&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To enable Git Autocompletion as previously stated, complete this additional step. Add this to your &lt;code&gt;.bashrc&lt;/code&gt; or &lt;code&gt;.zshrc&lt;/code&gt;.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/c2ccc9b27e165c7d282e4d776a03422f.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;That’s it for my quick tips list. I’d been wanting to put this short list together since these are things I always forgot how to do when setting up git on a new machine and am tired of looking them up. So now, I’ve got em’ all right here!&lt;/p&gt;
&lt;p&gt;Cheers,
Happy git-ing and coding - Adron&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Riding in the Peloton</title>
      <link>http://adron.github.io/articles/peloton/</link>
      <pubDate>Wed, 26 Apr 2017 09:48:05 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/peloton/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://pelotontech.io&quot;&gt;&lt;img src=&quot;/articles/peloton/peloton.png&quot; alt=&quot;Peloton Tech.IO&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Over the past few months I’ve been working, somewhat on the down low, as I get settled into Seattle, the daily flow, and life slightly north of Portland. I’ve gotten a solid footing on things now and am ready to announce what exactly I’m up to. Nothing is hugely surprising to anyone I’ve shared a beer or bike ride with in the last half a year, but for those I haven’t had the pleasure, here’s the details.&lt;/p&gt;
&lt;h2 id=&quot;new-job-new-business&quot;&gt;New Job, New Business&lt;/h2&gt;
&lt;p&gt;I’ve joined &lt;a href=&quot;http://www.pelotontech.io/&quot;&gt;Peloton Tech.IO&lt;/a&gt; (Follow us &lt;a href=&quot;https://twitter.com/PelotonTechIO&quot;&gt;@PelotonTechIO&lt;/a&gt;), a crew of smart, driven, inspired people that know how to live, love hacking, coding, and helping people implement solutions to the problems we all face. This team is exceptional in a lot of ways. The saying “work hard, play hard”, but really it’s more accurate to say we “work smart, play smart, and relax hard”. More on that in a moment however, I want to dive into some specifics of what I’ll be doing.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Technologies&lt;/em&gt; Over the last few months ramping up and working with Peloton I’ve had the chance to dive into a number of new technologies. Some of the most important technologies we’re using right now include;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://rancher.com/rancher/&quot;&gt;Rancher &lt;/a&gt;(&lt;a href=&quot;http://rancher.com/&quot;&gt;Rancher Labs&lt;/a&gt;) - Rancher is a container management platform. It, I must admit, is super slip. It looks good, plays well, and offers some pretty extensive capabilities and a plugin ecosystem to envy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/drone/drone&quot;&gt;Drone.io&lt;/a&gt; - Check out &lt;a href=&quot;https://twitter.com/droneio&quot;&gt;@droneio&lt;/a&gt; on Twitter, &lt;a href=&quot;https://github.com/drone&quot;&gt;@droneio Org on Github&lt;/a&gt;, and &lt;a href=&quot;http://readme.drone.io/&quot;&gt;Docs&lt;/a&gt; are great places to start. Drone.io is a continuous integration system built on containers (Docker) and written in Go. It is a truly slick system that is easily self-hosted or however you want or need to run it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are, of course, many other technologies I’ll be blogging, writing, and working with in the coming weeks and months, but these are two of the key pieces of technology.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Business Development&lt;/em&gt; In the coming months I’ll be keeping an eye out for companies I and the team would like to work with. If you’d like to talk to us about what we do, what we can do for you, or you already know you’d like to work with us - &lt;a href=&quot;http://blog.adron.me/docs/contact/&quot;&gt;contact me here&lt;/a&gt; - we’ll get a conversation started!&lt;/p&gt;
&lt;p&gt;Adding to the idea of business development, we at &lt;a href=&quot;http://www.pelotontech.io/&quot;&gt;Peloton&lt;/a&gt; have also kicked off a &lt;a href=&quot;https://www.meetup.com/Peloton-Technology-Share-Out/&quot;&gt;meetup group&lt;/a&gt; to elaborate, teach, learn, and explore more about the technologies we’re working with day in and day out.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Other things of note…&lt;/em&gt; Stay tuned, subscribe to my &lt;a href=&quot;http://blog.adron.me/feed.xml&quot;&gt;RSS feed&lt;/a&gt; (The full pipeline) or email newsletter, &lt;a href=&quot;http://blog.adron.me/docs/thrashing-code-news/&quot;&gt;Thrashing Code News&lt;/a&gt; (the easier lower volume method), or check out my &lt;a href=&quot;http://blog.adron.me/docs/Speaking-Presentations-Workshops/&quot;&gt;calendar of events&lt;/a&gt;, there are some goodies in there. Over time, I’ll elaborate on specific things we’re doing at Peloton, and fill you in on more ways we can work together, what we’ve got in the works, or you could even possibly join the peloton itself!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Thrashing Code Metal Monday for Week of March 13th 2017</title>
      <link>http://adron.github.io/articles/thrashing-code-metal-monday-03-13-2017/</link>
      <pubDate>Mon, 13 Mar 2017 08:06:16 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/thrashing-code-metal-monday-03-13-2017/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-03-13-2017/assemble-the-charriots-top.jpg&quot; alt=&quot;Assemble the Charriots&quot;&gt;&lt;/p&gt;
&lt;p&gt;Some completely new tunes I’ve been enjoying.&lt;/p&gt;
&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A0dYCExAAfFpFvjYjgiEC0n&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A6MWE8Xn602R4dRfbmJaNRJ&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A1AdrYGYDz4oa9dvW2jfFrG&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/3BiodeWYAV0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/EpkuYxyYM2A&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/req-oDf2ZRc&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-03-13-2017/assemble-the-charriots-bottom.jpg&quot; alt=&quot;Assemble the Charriots&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A Go UUID Solution - Cooking Go - Issue 001</title>
      <link>http://adron.github.io/articles/cooking-golang/</link>
      <pubDate>Sun, 12 Mar 2017 17:16:24 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/cooking-golang/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/cooking-golang/golang-mascot.png&quot; alt=&quot;Go Mascot&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Want a UUID generator for your Go code? It’s likely you’ll need one sometime. Well here’s a short code snippet and a review of one of the available UUID libraries available.&lt;/p&gt;
&lt;p&gt;The library is avaliable at &lt;a href=&quot;https://github.com/satori/go.uuid&quot;&gt;https://github.com/satori/go.uuid&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With test coverage this library supports the following UUID types. I’ll elaborate on what each of these types are after a code snippet or two.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version 1, based on timestamp and MAC address (RFC 4122)&lt;/li&gt;
&lt;li&gt;Version 2, based on timestamp, MAC address and POSIX UID/GID (DCE 1.1)&lt;/li&gt;
&lt;li&gt;Version 3, based on MD5 hashing (RFC 4122)&lt;/li&gt;
&lt;li&gt;Version 4, based on random numbers (RFC 4122)&lt;/li&gt;
&lt;li&gt;Version 5, based on SHA-1 hashing (RFC 4122)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First step. Get the library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go get github.com/satori/go.uuid
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next I whipped up a code file with the example code. I’ve called mine &lt;em&gt;&lt;a href=&quot;http://adron.github.io/articles/cooking-golang/&quot;&gt;uuid_generation.go&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/c7225ebc07058f443482925a4565afee.js&quot;&gt;&lt;/script&gt;


&lt;p&gt;Stepping through the code, the import includes the library being used.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;github.com/satori/go.uuid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then at the very beginning of the code a new UUID v4 is created.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;u1 := uuid.NewV4()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the example, a few lines down, there is also code around parsing a UUID.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;u2, err := uuid.FromString(&amp;quot;6ba7b810-9dad-11d1-80b4-00c04fd430c8&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I wanted to insure the other functions worked for the other versions so I added some code to create and print out each of them. At the same time, I’ve added what each of the versions are as I worked through creating them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Version 1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A version 1 UUID concatenates the 48-bit MAC address of the machine creating the UUID with a 60-bit timestamp. If the process clock does not advance fast enough, there is a 14-bit clock sequence that extends the timestamp to insure uniqueness. Based on these creation parameters there is a maximum of 18 sextrillion version 1 UUIDs that can be generated per node. So ya know, don’t get carried away or anything.  :P&lt;/p&gt;
&lt;p&gt;It’s also important to note, albeit obviously, that this UUID can be tracked back to the MAC Address that was used to create it.&lt;/p&gt;
&lt;p&gt;The code for this UUID creation is shown above in the first example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Version 2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Version 2 is reserved for DCE Security UUIDs. It’s a bit light on details in the RFC (&lt;a href=&quot;https://www.ietf.org/rfc/rfc4122.txt&quot;&gt;4122&lt;/a&gt;). Even though the RFC is light on details, the &lt;a href=&quot;http://pubs.opengroup.org/onlinepubs/9696989899/chap5.htm#tagcjh_08_02_01_01&quot;&gt;DCE 1.1 Authentication and Security Services&lt;/a&gt; specification clarifies a bit more. Overall this UUID is generally similar to a version 1 UUID except the least significant 8 bits of the clock sequence (clock_seq_low) are replaced by local domain numbers. The least significant 32 bits of the timestamp replaced by an integer identifier.&lt;/p&gt;
&lt;p&gt;Updated code with a working example of the specific domains used to create a v2 UUID.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/738b30ce93d5cd0efc02c0a4f43ce8a1.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Version 3 and 5&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Version 3 and 5 are similar UUIDs generated from hashing a namespace identifier and name. Version 5 uses SHA1 and version 3 uses MD5 as the hashing algorithm. The namespace identifier itself is a UUID and is used to represent the namespaces for URLs, fully qualified domain names (FQDNs), object identifiers, and X.500 distinguished names. Other UUIDs could be used as namespace designators, but the aforementioned are usually used.&lt;/p&gt;
&lt;p&gt;To note, RFC 4122 refers version 5 (SHA1) over version 3 (MD5), and suggests against either as security credentials.&lt;/p&gt;
&lt;p&gt;Here’s the added examples of version 3 and 5.&lt;/p&gt;
&lt;script src=&quot;https://gist.github.com/Adron/b8864c5e0d652f8ca14eb154e806a3bd.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Enjoy those UUIDs, happy coding!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Thrashing Code Metal Monday for Week of March 6th 2017, on Tuesday the 7th!</title>
      <link>http://adron.github.io/articles/thrashing-code-metal-monday-03-07-2017/</link>
      <pubDate>Tue, 07 Mar 2017 06:43:48 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/thrashing-code-metal-monday-03-07-2017/</guid>
      <author></author>
      <description>&lt;p&gt;Obviously it isn’t Monday. But sometimes you go to a show on Sunday and you’re recovering on Monday and writing a blog entry just isn’t a priority. But in that vein, here’s the line up for the Bound by the Road Tour I dived into the pit for this last Sunday!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-03-07-2017/dd.jpg&quot; alt=&quot;Devil Driver&quot;&gt;&lt;/p&gt;
&lt;p&gt;K’atun &amp;gt; &lt;a href=&quot;https://www.facebook.com/pg/katunband&quot;&gt;https://www.facebook.com/pg/katunband&lt;/a&gt;&lt;/p&gt;
&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A21XgrFZKhmE6A7U1Om95eU&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A1CToivUVH4hS9CXlYOSFgb&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/XuVibnWHoLA&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/GVYl_hiD1oQ&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/CgR0r94J8EM&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-03-07-2017/agonist.jpg&quot; alt=&quot;The Agonist&quot;&gt;&lt;/p&gt;
&lt;p&gt;Until next, happy thrashing code!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Golang Execution on OS-X vs. Linux</title>
      <link>http://adron.github.io/articles/want-a-what-golang/</link>
      <pubDate>Sun, 26 Feb 2017 06:57:24 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/want-a-what-golang/</guid>
      <author></author>
      <description>&lt;p&gt;Recently I was dorking about with some Go code on OS-X. Just working with it via iTerm 2 and using some basic &lt;code&gt;go run whateverthefile.go&lt;/code&gt; commands and displaying results out the the shell. All was well, and then I dived into some code that used so Go Routines. The code looked something like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
    &lt;span class=&quot;string&quot;&gt;&quot;time&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
)

func say(s string) {
    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i := &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;lt;&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;; i++ {
        time.Sleep(&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; * time.Second)
        fmt.Println(s)
    }
}

func main() {
    go say(&lt;span class=&quot;string&quot;&gt;&quot;1. First thread is running.&quot;&lt;/span&gt;)
    go say(&lt;span class=&quot;string&quot;&gt;&quot;  2. Second thread is running.&quot;&lt;/span&gt;)
    say(&lt;span class=&quot;string&quot;&gt;&quot;    3. Thread is running in main.&quot;&lt;/span&gt;)
    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;Ended.&quot;&lt;/span&gt;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That was fine. I ran the code and the results were as expected.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;OSX$   2. Second thread is running.
    3. Thread is running in main.
1. First thread is running.
1. First thread is running.
  2. Second thread is running.
    3. Thread is running in main.
    3. Thread is running in main.
1. First thread is running.
  2. Second thread is running.
  2. Second thread is running.
    3. Thread is running in main.
1. First thread is running.
1. First thread is running.
  2. Second thread is running.
    3. Thread is running in main.
Ended.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I ran it again. Also these results were expected.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;OSX$     3. Thread is running in main.
  2. Second thread is running.
1. First thread is running.
    3. Thread is running in main.
1. First thread is running.
  2. Second thread is running.
  2. Second thread is running.
    3. Thread is running in main.
1. First thread is running.
1. First thread is running.
    3. Thread is running in main.
  2. Second thread is running.
    3. Thread is running in main.
Ended.
1. First thread is running.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice the slightly out of order response as each thread completes. With the first set of results the last response is “Ended.” and with the second set of results “Ended.” is second to last. This of course is expected as the threads are likely to be executing while the last line of code is executed. But, there’s a catch to this depending where you run this code.&lt;/p&gt;
&lt;p&gt;On the MacOS/OS-X platforms, when you run the shell it runs certain things with an assumed “&amp;amp;” after the command. Now, I’m not sure the specifics of what is happening (I’m looking it up and will happily post a super detailed reference link if you’ve got one, lemme know &lt;a href=&quot;https://twitter.com/adron&quot;&gt;@Adron&lt;/a&gt;.) The “&amp;amp;” is however used on Linux/Unix systems to designate to the shell, &lt;em&gt;run this command on the background so that the user remains in control of the shell&lt;/em&gt;. Specifically, from the &lt;em&gt;man&lt;/em&gt; pages.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If a command is terminated by the control operator &amp;amp;, the shell executes the command in the background in a subshell. The shell does not wait for the command to finish, and the return status is 0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The reason I bring this up, is if I run the same thing and those same results come back on Linux or Unix, you would not see anything after the “Ended.” runs, because the application terminates at that point and none of the background threads are actively connected to the shell. In other words the result where “Ended.” occurs second to last would look like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;LINUX-SHELL$     3. Thread is running in main.
  2. Second thread is running.
1. First thread is running.
    3. Thread is running in main.
1. First thread is running.
  2. Second thread is running.
  2. Second thread is running.
    3. Thread is running in main.
1. First thread is running.
1. First thread is running.
    3. Thread is running in main.
  2. Second thread is running.
    3. Thread is running in main.
Ended.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At first glance, it might seem like the application has run successfully, but look closely and count the number of responses from each thread. In this example, the shell has lost priority when the “Ended.” message appears and there is only four messages that read “1. First thread is running.”. However, after the “Ended.” message there should have been another one, like the second example above that I ran on OS-X. On Linux, the solution to executing this example is actually to add the ampersand at the end of the command.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;go run whateverthefile.go &amp;amp;&lt;/code&gt; and then you’ll see the execution of the program with the correct results.&lt;/p&gt;
&lt;p&gt;Well that’s it for this often overlooked and confusing behavior on Linux versus OS-X. Happy hacking, cheers!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Addition/Correction April 3rd, 2017:&lt;/strong&gt; It was brought to my attention that this is very specifically the shell, not the operating system. This is an important thing to note, and sometimes is easily confused or mistaken outright. The effect can even be different behavior between shell use on the same operating system, regardless of OS-X, Linux, UNIX, or whatever.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Thrashing Code Metal Monday for Week of February 20th, 2017</title>
      <link>http://adron.github.io/articles/thrashing-code-metal-monday-02-20-2017/</link>
      <pubDate>Mon, 20 Feb 2017 07:01:40 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/thrashing-code-metal-monday-02-20-2017/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-02-20-2017/eluveitie.jpeg&quot; alt=&quot;Eluveitie&quot;&gt;&lt;/p&gt;
&lt;p&gt;It’s a holiday, but the thrashing never stops. Here’s some tunes that I’ve had on during my recent &lt;a href=&quot;https://twitter.com/search?q=%23golang&quot;&gt;#golang&lt;/a&gt; experiments.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A52xuvlUvnxqH0xzxGPKXSu&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A4DwtbMRUsK4JVU0Ts7pVwd&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A4tLnmxO1rdlxWcEXXMds8a&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/4I9vnAxCvWY&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/-w2m-TeLi6I&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/UOvZKJlrtk8&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    <item>
      <title>Industry Introspection</title>
      <link>http://adron.github.io/articles/industry-introspection/</link>
      <pubDate>Wed, 15 Feb 2017 04:27:09 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/industry-introspection/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/industry-introspection/farnsworth-in-chair.jpg&quot; alt=&quot;Chillin&amp;#39; like Farnsworth&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Every few days I like to sit down like an old academic professor and just read and ponder what’s going on in the computer hardware and software industries. As of late it’s been interesting to dive into whatever Elon Musk is working on also; electric cars, solar energy, rockets, or even boring machines. Another thing I’ve had a curiosity in and continue to find interesting is machine learning, or as some call it in the mainstream movie media &lt;em&gt;artificial intelligence&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I’ll tackle some of these technologies real quick so we all have a current situational report. Each of these topics seems to be a area of work that could use some extensive clarification. I’ll provide some of my own thoughts along with a few links of reference to dig in deeper, so that one doesn’t fall into the trap of uniformed oblivious media consumer.&lt;/p&gt;
&lt;h2 id=&quot;rockets-i-e-space-&quot;&gt;Rockets (i.e. Space)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;My History:&lt;/em&gt;&lt;/strong&gt; I haven’t always paid attention to this space because I never had intention of working in the area, however who isn’t interested in rockets in some way. Well, considering my desire for other work, I was extremely fortunate where I grew up to be involved in rocketry. I grew up in Picayune, Mississippi which is a mere ~15-20 miles away from John C. Stennis Space Center.&lt;/p&gt;
&lt;p&gt;I had the joy of experiencing rocket tests at John C. Stennis and seeing research into rockets as a child, and on some of my first paid computer related gigs. As one might suspect, they use computers to do rocket research and help with launches. Shocker right!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;My Thoughts:&lt;/em&gt;&lt;/strong&gt; The space we’re in right now is impressive. The market is actually getting involved in launching it’s own rockets, which means we’re likely only years or maybe a decade or two of having an economically sustainable rocket program. Hopefully NASA can work on more focused deep space missions now while Musk’s Space-X and others refine and perfect orbital rockets for satellites and all that mess.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;SITREP:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;India is currently pushing the envelope with &lt;em&gt;&lt;a href=&quot;https://www.nytimes.com/2017/02/15/world/asia/india-satellites-rocket.html&quot;&gt;104 satellites with a rocket&lt;/a&gt;&lt;/em&gt;, which is &lt;a href=&quot;https://www.nytimes.com/2017/02/15/world/asia/india-satellites-rocket.html&quot;&gt;fueling even more of a space race today&lt;/a&gt;. The previous record was held by Russia with &lt;a href=&quot;https://www.nasaspaceflight.com/2014/06/russian-dnepr-rocket-record-launch-37-satellites/&quot;&gt;37 satellites in 2014&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Keep track of launches with the &lt;a href=&quot;http://spaceflightnow.com/launch-schedule/&quot;&gt;launch schedule&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nasaspaceflight.com/&quot;&gt;Nasa Space Flight&lt;/a&gt; is also a great source.&lt;/li&gt;
&lt;li&gt;Related Nasa links; &lt;a href=&quot;https://blogs.nasa.gov/&quot;&gt;Nasa Blog&lt;/a&gt;, &lt;a href=&quot;https://www.nasa.gov/socialmedia&quot;&gt;Nasa Social Media&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/user/NASAtelevision&quot;&gt;Nasa Youtube&lt;/a&gt;. Also check out the forums &lt;a href=&quot;https://forum.nasaspaceflight.com/index.php?board=55.0&quot;&gt;here&lt;/a&gt; per Peter Stephens &lt;a href=&quot;https://twitter.com/peterastephens&quot;&gt;@peterastephens&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;a href=&quot;http://www.spacex.com/&quot;&gt;Space-X&lt;/a&gt; check out; &lt;a href=&quot;http://www.spacex.com/news&quot;&gt;Space-X News&lt;/a&gt;, and the &lt;a href=&quot;https://twitter.com/SpaceX&quot;&gt;@SpaceX&lt;/a&gt; Account for quick tweets.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning&lt;/h2&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/industry-introspection/farnsworth-future-of-ai-ml.gif&quot; alt=&quot;Farnsworth and the future of Artificial Intelligence&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;My History:&lt;/em&gt;&lt;/strong&gt; I’ve toyed with machine learning on and off again, working on pathing algorithms for objects to decide travel patterns to supervised learning algorithms. In the end I’ve generally ended up working on other things in my day to day work but I know this will be changing in the near future (next year or three). It’s an extremely interesting space of work and research.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;My Thoughts:&lt;/em&gt;&lt;/strong&gt; First, getting AI &amp;amp; ML (That’s artificial integlligence and machine learning) conflated, especially in the media, is starting to reflect the popularity of said space in the software industry. However, for the most part these two things are effectively the same thing. It’s just different words describing the industry space where we’re trying to make machines make decisions we deem intelligent based on available data.&lt;/p&gt;
&lt;p&gt;That actually leads to many other discussions. What do we as humans deem intelligent and what happens when available data isn’t enough? But more words on that for another day. I know the questions are burning in the mind of every chief executive of something that wants this mythical AI they keep hearing about and paying voluminous amounts of money to their big data bad ass data science ninja architects to implement but rarely have answers for all of it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;The SITREP:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Even though I’m not a fan of the site, here’s a pretty straight forward no bullshit &lt;a href=&quot;https://elitedatascience.com/learn-machine-learning#what&quot;&gt;description of machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Here is a post that has some material on machine learning titled “&lt;a href=&quot;https://medium.com/@mattfogel/master-the-basics-of-machine-learning-with-these-6-resources-63fea5a21c1c#.35nmxgrw4&quot;&gt;Master the Basics of Machine Learning With These 6 Resources&lt;/a&gt;“ by Matt Fogel &lt;a href=&quot;https://twitter.com/mattfogel&quot;&gt;@mattfogel&lt;/a&gt;, it’s a good list to get started with.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall there’s a ton of material ending up on the web related to AI/ML, and my top suggestion is to start googling so you can pick and choose which aspects you want to read about in this space. One could dive in via the super technical aspect of how systems work that are being used for processing, how the algorithms work, or even working with data to model good decision results from data sets (i.e. diving into training). But it’s really a space that is awash in resources. Dive in!&lt;/p&gt;
&lt;h2 id=&quot;end-words&quot;&gt;End Words&lt;/h2&gt;
&lt;p&gt;That’s it for my industry instrospections for now. If you’re interested in reading about this, programming material, and related topics of this nature follow &lt;a href=&quot;https://twitter.com/PelotonTechio&quot;&gt;@PelotonTechio&lt;/a&gt; as I’ll be taking the site &amp;amp; blog at Peloton live in the coming days!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Thrashing Code Metal Monday for Week of February 13th, 2017</title>
      <link>http://adron.github.io/articles/thrashing-code-metal-monday-02-13-2017/</link>
      <pubDate>Mon, 13 Feb 2017 09:05:41 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/thrashing-code-metal-monday-02-13-2017/</guid>
      <author></author>
      <description>&lt;p&gt;I’ve been getting a fair dose of New Orleans cajun grub lately so I went back to my roots and picked out a few bands from NOLA (That’s New Orleans, Lousiana FYI). Be prepared, NOLA Metal is a special level of sludgy heaviness and growl combined with some slightly psychodelic melodies thrown in. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-02-13-2017/dungeon.jpg&quot; alt=&quot;The Dungeon&quot;&gt;&lt;/p&gt;
&lt;p&gt;With that, enjoy your coding heavy monday metal! &lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Top 3 for Spotify&lt;/p&gt;
&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A3xtIpqzIOfQUxKce8BU4Ka&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A1m0B9ak05G0jqDY4ACLhQu&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A5kuYamMO00pHPdRQcAXWTl&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Top 3 Videos for Youtube&lt;/p&gt;
&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/AxcaIKMAJ3Y&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/_u8rVrUDgRU&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/TPF4vIXpAsA&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-02-13-2017/dungeon2.jpg&quot; alt=&quot;The Dungeon&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Setting up a GCP Container Cluster - Part II</title>
      <link>http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/</link>
      <pubDate>Mon, 06 Feb 2017 07:48:40 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/</guid>
      <author></author>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster/&quot;&gt;Part 1 - Setting up a GCP Container Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/&quot;&gt;Part 2 - Working with a GCP Container Cluster&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Part 3 - Setup of Drone.io on a GCP Container Cluster - Currently being written&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-gcp-container-cluster-part-2/gce-kube-gce.png&quot; alt=&quot;Google Compute &amp;amp; Container Engines together with Kubernetes&quot;&gt;
&lt;/div&gt;

&lt;p&gt;A couple of days I wrote up the experience around getting a Google Container Cluster up and running and adding a Terraform config to automate the process. Today my plan is to dig into getting containers into the Google Container Repository and then using those containers to launch various things within the Google Container Cluster. With my end goal being to get a Drone.io setup for production use.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the last &lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster/&quot;&gt;blog entry of this series&lt;/a&gt; I wrote up, I covered the steps and some of the issues I ran into getting a Google Cloud Container cluster up and running. In this article I’m going to dive into working with that container, specifically via the &lt;code&gt;gcloud&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt; commands. I’m assuming prerequisites at this point include &lt;code&gt;gcloud&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt; being installed. With &lt;code&gt;gcloud&lt;/code&gt; also being setup via the &lt;code&gt;gcloud init&lt;/code&gt; command already.&lt;/p&gt;
&lt;p&gt;I’ve also made a few small changes to the Terraform config file since the previous use. I’ve copied the file contents below. The changes I’ve included below the file contents.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt; resource &lt;span class=&quot;string&quot;&gt;&quot;google_container_cluster&quot;&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;drone&quot;&lt;/span&gt; {
   name = &lt;span class=&quot;string&quot;&gt;&quot;drone&quot;&lt;/span&gt;
   zone = &lt;span class=&quot;string&quot;&gt;&quot;us-west1-b&quot;&lt;/span&gt;
   initial_node_count = &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;

   additional_zones = [
     &lt;span class=&quot;string&quot;&gt;&quot;us-west1-b&quot;&lt;/span&gt;
   ]

   network = &lt;span class=&quot;string&quot;&gt;&quot;developer-space&quot;&lt;/span&gt;
   subnetwork = &lt;span class=&quot;string&quot;&gt;&quot;developer-space-west1&quot;&lt;/span&gt;

   master_auth {
     username = &lt;span class=&quot;string&quot;&gt;&quot;firsttry&quot;&lt;/span&gt;
     password = &lt;span class=&quot;string&quot;&gt;&quot;willchange&quot;&lt;/span&gt;
   }

   node_config {
     oauth_scopes = [
       &lt;span class=&quot;string&quot;&gt;&quot;https://www.googleapis.com/auth/compute&quot;&lt;/span&gt;,
       &lt;span class=&quot;string&quot;&gt;&quot;https://www.googleapis.com/auth/devstorage.read_only&quot;&lt;/span&gt;,
       &lt;span class=&quot;string&quot;&gt;&quot;https://www.googleapis.com/auth/logging.write&quot;&lt;/span&gt;,
       &lt;span class=&quot;string&quot;&gt;&quot;https://www.googleapis.com/auth/monitoring&quot;&lt;/span&gt;
     ]

     machine_type = &lt;span class=&quot;string&quot;&gt;&quot;g1-small&quot;&lt;/span&gt;
   }
 }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;The changes included:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I changed the name of the cluster to &lt;em&gt;drone&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;I’ve added the additional zone, which is the same as the primary zone. Since the additional zone is identical to the primary zone there will only be 3 instances created. This is per the initial node count. If the additional zone were different than the primary zone, it would create 6 instances, 3 in the additional zone and 3 in the primary zone. I’m not particularly concerned about the high availability associated with the additional instances in another zone so I’ve configured it this way to cut down on prospective costs. The other effect of setting the additional zone, is that Terraform won’t re-create the entire cluster every single time it runs.&lt;/li&gt;
&lt;li&gt;I’ve also set network and subnetwork, which if you’re following along you wouldn’t particularly need set, but I have my networks configured in a particular way so I like to designate which network which cluster or set of instances is going to be created in.&lt;/li&gt;
&lt;li&gt;Just a note, not a change, but using a g1-small is about the smallest size you can go and have a working cluster. Anything smaller than that and it tends to choke on itself, which is unfortunate.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Next step is getting connected to this cluster. Here’s a few of the things you’ll do over and over again when working with a container cluster.&lt;/p&gt;
&lt;h2 id=&quot;using-google-container-cluster-via-gcloud-and-kubectl-&quot;&gt;Using Google Container Cluster via &lt;code&gt;gcloud&lt;/code&gt; and &lt;code&gt;kubectl&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;For the next steps of what I need to do (to setup a cluster for use) there are a host of commands that are useful to determine what’s going on, troubleshoot any issues that might come up, and generally get any insight into the cluster. Here’s a run down of those key commands.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;gcloud container clusters describe [NAME]&lt;/code&gt; - where NAME is the name of the cluster to get information from. The results which of which look like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ gcloud container clusters describe drone
clusterIpv4Cidr: 10.132.0.0/14
createTime: &amp;#39;2017-02-07T01:09:42+00:00&amp;#39;
currentMasterVersion: 1.5.2
currentNodeCount: 3
currentNodeVersion: 1.5.2
endpoint: 104.196.239.145
initialClusterVersion: 1.5.2
initialNodeCount: 3
instanceGroupUrls:
- https://www.googleapis.com/compute/v1/projects/that-big-universe/zones/us-west1-b/instanceGroupManagers/gke-drone-default-pool-d9a3b45a-grp
locations:
- us-west1-b
loggingService: logging.googleapis.com
masterAuth:
  clientCertificate: THIS IS WHERE A BUNCH OF AUTH KEY STUFF GOES FOR THE CLIENT CERT
  clientKey: THIS IS WHERE A BUNCH OF CLIENT KEY AUTH STUFF GOES
  clusterCaCertificate: THIS IS WHERE A BUNCH OF CLIENT AUTH CA CERTIFICATE STUFF GOES
  password: THIS SHOWS THE PASSWORD THE CLUSTER IS SETUP WITH - SEE ABOVE TERRAFORM FILE FOR CORRELATION.
  username: THIS SHOWS THE USERNAME THE CLUSTER IS SETUP WITH - SEE ABOVE TERRAFORM FILE FOR CORRELATION.
monitoringService: monitoring.googleapis.com
name: drone
network: developer-space
nodeConfig:
  diskSizeGb: 100
  imageType: GCI
  machineType: g1-small
  oauthScopes:
  - https://www.googleapis.com/auth/compute
  - https://www.googleapis.com/auth/devstorage.read_only
  - https://www.googleapis.com/auth/logging.write
  - https://www.googleapis.com/auth/monitoring
  serviceAccount: default
nodeIpv4CidrSize: 24
nodePools:
- config:
    diskSizeGb: 100
    imageType: GCI
    machineType: g1-small
    oauthScopes:
    - https://www.googleapis.com/auth/compute
    - https://www.googleapis.com/auth/devstorage.read_only
    - https://www.googleapis.com/auth/logging.write
    - https://www.googleapis.com/auth/monitoring
    serviceAccount: default
  initialNodeCount: 3
  instanceGroupUrls:
  - https://www.googleapis.com/compute/v1/projects/that-big-universe/zones/us-west1-b/instanceGroupManagers/gke-drone-default-pool-d9a3b45a-grp
  management: {}
  name: default-pool
  selfLink: https://container.googleapis.com/v1/projects/that-big-universe/zones/us-west1-b/clusters/drone/nodePools/default-pool
  status: RUNNING
  version: 1.5.2
selfLink: https://container.googleapis.com/v1/projects/that-big-universe/zones/us-west1-b/clusters/drone
servicesIpv4Cidr: 10.135.240.0/20
status: RUNNING
subnetwork: developer-space-west1
zone: us-west1-b
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info:  &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/container/clusters/describe&quot;&gt;https://cloud.google.com/sdk/gcloud/reference/container/clusters/describe&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;gcloud container clusters get-credentials [NAME]&lt;/code&gt; - where NAME is the name of the cluster, this command retrieves credentials for the cluster in which work will be done against.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Fetching cluster endpoint and auth data.
kubeconfig entry generated for drone.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/container/clusters/get-credentials&quot;&gt;https://cloud.google.com/sdk/gcloud/reference/container/clusters/get-credentials&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;gcloud container clusters list&lt;/code&gt; This command will provide a listing of the clusters that are in service. This is the first command to run to get the name of the cluster you want to work with. In this case, I’m working with the only cluster that I have named &lt;em&gt;drone&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ gcloud container clusters list
NAME   ZONE        MASTER_VERSION  MASTER_IP        MACHINE_TYPE  NODE_VERSION  NUM_NODES  STATUS
drone  us-west1-b  1.5.2           104.196.239.145  g1-small      1.5.2         3          RUNNING
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/container/clusters/list&quot;&gt;https://cloud.google.com/sdk/gcloud/reference/container/clusters/list&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl config set-cluster [NAME]&lt;/code&gt; - To use &lt;code&gt;kubectl&lt;/code&gt; to manage the cluster, first the cluster to work against must be set. Use set-cluster to get this done. Where NAME is the name of the cluster to work against.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ kubectl config set-cluster drone
Cluster &amp;quot;drone&amp;quot; set.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://kubernetes.io/docs/user-guide/kubectl/kubectl_config_set-cluster/&quot;&gt;https://kubernetes.io/docs/user-guide/kubectl/kubectl_config_set-cluster/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;gcloud container get-server-config&lt;/code&gt; - This &lt;code&gt;gcloud&lt;/code&gt; command gets information about the configuration that is setup for the container cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ gcloud container get-server-config
Fetching server config for us-west1-b
defaultClusterVersion: 1.5.2
defaultImageType: GCI
validImageTypes:
- CONTAINER_VM
- GCI
validMasterVersions:
- 1.5.2
- 1.4.8
validNodeVersions:
- 1.5.2
- 1.5.1
- 1.4.8
- 1.4.7
- 1.4.6
- 1.3.10
- 1.2.7
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/container/get-server-config&quot;&gt;https://cloud.google.com/sdk/gcloud/reference/container/get-server-config&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl config get-clusters&lt;/code&gt; - This command simply lists out the available clusters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl config current-context&lt;/code&gt; - This command prints out the current context in which the &lt;code&gt;kubectl&lt;/code&gt; command is working in.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ kubectl config current-context
gke_that-big-universe_us-west1-b_drone
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://kubernetes.io/docs/user-guide/kubectl/kubectl_config_current-context/&quot;&gt;https://kubernetes.io/docs/user-guide/kubectl/kubectl_config_current-context/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl cluster-info&lt;/code&gt; - This command provides information about the cluster as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ kubectl cluster-info
Kubernetes master is running at https://104.196.239.145
GLBCDefaultBackend is running at https://104.196.239.145/api/v1/proxy/namespaces/kube-system/services/default-http-backend
Heapster is running at https://104.196.239.145/api/v1/proxy/namespaces/kube-system/services/heapster
KubeDNS is running at https://104.196.239.145/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at https://104.196.239.145/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard

To further debug and diagnose cluster problems, use &amp;#39;kubectl cluster-info dump&amp;#39;.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://kubernetes.io/docs/user-guide/kubectl/kubectl_cluster-info/&quot;&gt;https://kubernetes.io/docs/user-guide/kubectl/kubectl_cluster-info/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl describe nodes&lt;/code&gt; - This command provides a lot of information about the actual running nodes in the cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ kubectl describe nodes
Name:            gke-drone-default-pool-d9a3b45a-l082
Role:            
Labels:            beta.kubernetes.io/arch=amd64
            beta.kubernetes.io/instance-type=g1-small
            beta.kubernetes.io/os=linux
            cloud.google.com/gke-nodepool=default-pool
            failure-domain.beta.kubernetes.io/region=us-west1
            failure-domain.beta.kubernetes.io/zone=us-west1-b
            kubernetes.io/hostname=gke-drone-default-pool-d9a3b45a-l082
Taints:            &amp;lt;none&amp;gt;
CreationTimestamp:    Mon, 06 Feb 2017 17:13:11 -0800
Phase:            
Conditions:
  Type            Status    LastHeartbeatTime            LastTransitionTime            Reason                Message
  ----            ------    -----------------            ------------------            ------                -------
  NetworkUnavailable     False     Mon, 06 Feb 2017 17:14:09 -0800     Mon, 06 Feb 2017 17:14:09 -0800     RouteCreated             RouteController created a route
  OutOfDisk         False     Mon, 06 Feb 2017 17:50:06 -0800     Mon, 06 Feb 2017 17:13:11 -0800     KubeletHasSufficientDisk     kubelet has sufficient disk space available
  MemoryPressure     False     Mon, 06 Feb 2017 17:50:06 -0800     Mon, 06 Feb 2017 17:13:11 -0800     KubeletHasSufficientMemory     kubelet has sufficient memory available
  DiskPressure         False     Mon, 06 Feb 2017 17:50:06 -0800     Mon, 06 Feb 2017 17:13:11 -0800     KubeletHasNoDiskPressure     kubelet has no disk pressure
  Ready         True     Mon, 06 Feb 2017 17:50:06 -0800     Mon, 06 Feb 2017 17:13:41 -0800     KubeletReady             kubelet is posting ready status. AppArmor enabled
Addresses:        10.140.0.4,35.185.193.72,gke-drone-default-pool-d9a3b45a-l082
Capacity:
 alpha.kubernetes.io/nvidia-gpu:    0
 cpu:                    1
 memory:                1740088Ki
 pods:                    110
Allocatable:
 alpha.kubernetes.io/nvidia-gpu:    0
 cpu:                    1
 memory:                1740088Ki
 pods:                    110
System Info:
 Machine ID:            9d264f9182ffa64366cd05fda65a9c20
 System UUID:            9D264F91-82FF-A643-66CD-05FDA65A9C20
 Boot ID:            eb0a6a3f-0316-4898-a0a8-03b8207a2125
 Kernel Version:        4.4.21+
 OS Image:            Google Container-VM Image
 Operating System:        linux
 Architecture:            amd64
 Container Runtime Version:    docker://1.11.2
 Kubelet Version:        v1.5.2
 Kube-Proxy Version:        v1.5.2
PodCIDR:            10.132.1.0/24
ExternalID:            7008904420460372122
Non-terminated Pods:        (5 in total)
  Namespace            Name                        CPU Requests    CPU Limits    Memory Requests    Memory Limits
  ---------            ----                        ------------    ----------    ---------------    -------------
  kube-system            fluentd-cloud-logging-gke-drone-default-pool-d9a3b45a-l082        100m (10%)    0 (0%)        200Mi (11%)    200Mi (11%)
  kube-system            heapster-v1.2.0-2168613315-m2sv2        138m (13%)    138m (13%)    301856Ki (17%)    301856Ki (17%)
  kube-system            kube-dns-autoscaler-2715466192-2csx9        20m (2%)    0 (0%)        10Mi (0%)    0 (0%)
  kube-system            kube-proxy-gke-drone-default-pool-d9a3b45a-l082100m (10%)    0 (0%)        0 (0%)        0 (0%)
  kube-system            kubernetes-dashboard-3543765157-17nxs        100m (10%)    100m (10%)    50Mi (2%)    50Mi (2%)
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.
  CPU Requests    CPU Limits    Memory Requests    Memory Limits
  ------------    ----------    ---------------    -------------
  458m (45%)    238m (23%)    568096Ki (32%)    557856Ki (32%)
Events:
  FirstSeen    LastSeen    Count    From                    SubObjectPath    Type        Reason            Message
  ---------    --------    -----    ----                    -------------    --------    ------            -------
  37m        37m        1    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Normal        Starting        Starting kubelet.
  37m        37m        1    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Warning        ImageGCFailed        unable to find data for container /
  37m        37m        1    {kube-proxy gke-drone-default-pool-d9a3b45a-l082}            Normal        Starting        Starting kube-proxy.
  37m        37m        19    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Normal        NodeHasSufficientDisk    Node gke-drone-default-pool-d9a3b45a-l082 status is now: NodeHasSufficientDisk
  37m        37m        19    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Normal        NodeHasSufficientMemory    Node gke-drone-default-pool-d9a3b45a-l082 status is now: NodeHasSufficientMemory
  37m        37m        19    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Normal        NodeHasNoDiskPressure    Node gke-drone-default-pool-d9a3b45a-l082 status is now: NodeHasNoDiskPressure
  36m        36m        1    {kubelet gke-drone-default-pool-d9a3b45a-l082}                Normal        NodeReady        Node gke-drone-default-pool-d9a3b45a-l082 status is now: NodeReady

    ETC ETC ETC EACH NODE WOULD HAVE INFORMATION DISPLAYED HERE
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl describe pods&lt;/code&gt; - This command describes what pods are running. Currently I have none running so this isn’t a super useful command until some pods are actually running in the kubernetes cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl get pods --all-namespaces&lt;/code&gt; - This command actually gives a full list of pod in all the namespaces of the cluster. This would provide insight into what other pods the Kubernetes system itself has put onto the server.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;kubectl config view&lt;/code&gt; - This is another command that provides specific configuration information.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;
&lt;p&gt;That covers the commands that will help us troubleshoot and get things running in the Google Container Engine (i.e. Kubernetes Cluster). Next post I’ll dive into and step through the specifics of getting Drone.io setup. Until then, cheerio and happy hacking.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster/&quot;&gt;Part 1 - Setting up a GCP Container Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/&quot;&gt;Part 2 - Working with a GCP Container Cluster&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Part 3 - Setup of Drone.io on a GCP Container Cluster - Currently being written&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Thrashing Code Metal Monday for Week of February 6th, 2017</title>
      <link>http://adron.github.io/articles/thrashing-code-metal-monday-02-06-2017/</link>
      <pubDate>Mon, 06 Feb 2017 04:33:50 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/thrashing-code-metal-monday-02-06-2017/</guid>
      <author></author>
      <description>&lt;p&gt;This is the first of many of a series that is starting today. Thrashing Code Metal Monday’s picks for heavy tunes to code to. Ya know, if you can handle it.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/thrashing-code-metal-monday-02-06-2017/ep-1.gif&quot; alt=&quot;The Fire of Metal!&quot;&gt;&lt;/p&gt;
&lt;p&gt;With that introduction, may the thrashing code begin!&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Top 3 for Spotify&lt;/p&gt;
&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A5ctFffJBdJe8PZL7W7NeML&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A67ZMMtA88DDO0gTuRrzGjn&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;300&quot; height=&quot;56&quot; src=&quot;https://embed.spotify.com/follow/1/?uri=spotify%3Aartist%3A3dnH7fdVm2X07MK6Fkbhbt&amp;amp;size=detail&amp;amp;theme=dark&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;border:none; overflow:hidden;&quot; allowtransparency=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Top 3 Videos for Youtube&lt;/p&gt;
&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/9VHA0H8peZ0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/CpAcxbtXUgQ&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;853&quot; height=&quot;480&quot; src=&quot;https://www.youtube.com/embed/c-vhrv-1Ctg&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>Data Diluvium Design Ideas</title>
      <link>http://adron.github.io/articles/data-diluvium-design-ideas/</link>
      <pubDate>Sat, 04 Feb 2017 06:44:58 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/data-diluvium-design-ideas/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/data-diluvium-design-ideas/dd-logo.jpg&quot; alt=&quot;Data Diluvium&quot;&gt;
&lt;/div&gt;

&lt;p&gt;This post includes a collection of my thoughts on design and architecture of a data generation service project I’ve started called &lt;a href=&quot;http://datadiluvium.com&quot;&gt;Data Diluvium&lt;/a&gt;. I’m very open to changes, new ideas, or completely different paradigms around these plans altogether. You can jump into the conversation &lt;a href=&quot;https://github.com/Adron/datadiluvium/issues/9&quot;&gt;thread&lt;/a&gt;. What kind of data do you often need? What systems do you want it inserted into?&lt;/p&gt;
&lt;p&gt;Breakdown of Article Ideas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Collected Systems API&lt;/strong&gt; - This API service idea revolves around a request that accepts a schema type for a particular database type, an export source for inserting the data into, and generating an amount of data per the requested amount. The response then initiates that data generation, while responding with a received message and confirmation based on what it has received.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Individual Request API&lt;/strong&gt; - This API service idea (thanks to Dave Curylo for this one, &lt;a href=&quot;https://github.com/Adron/datadiluvium/issues/9#issuecomment-276117856&quot;&gt;posted in the thread&lt;/a&gt;) revolves around the generation of data, requested at end points for a particular type of random data generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alright, time to dive deeper into each of these.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;collected-systems-apis&quot;&gt;Collected Systems APIs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/schema/generate&quot;&gt;https://datadiluvium.com/schema/generate&lt;/a&gt;&lt;/em&gt; - This API end point would take a schema with the various properties needed. For any that aren’t set, a default would be set. The generation process would then randomize, generate, and insert this data into any destination source specified. Here are some prospective examples I’ve created:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;A very basic sample JSON schema&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;[
  {
    &lt;span class=&quot;string&quot;&gt;&quot;schema&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;relational&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;database&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;text&quot;&lt;/span&gt;
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this particular example, I’ve created the simplist schema that could be sent into the service. For this particular situation I’d have (currently not decided yet) defaults that would randomly create a table, with a single column, and generate one element of data in that table. Other properties could be set, which would give control over the structure created in which to insert the data into. An example would be the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;[
  {
    &lt;span class=&quot;string&quot;&gt;&quot;schema&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;relational&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;database&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;postgresql&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;structure&quot;&lt;/span&gt;: [
      {
        &lt;span class=&quot;string&quot;&gt;&quot;table&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Users&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;columns&quot;&lt;/span&gt;: [
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;uuid&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;firstname&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;firstname&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;lastname&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;lastname&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;email_address&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;email&quot;&lt;/span&gt;}
        ]
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;table&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Addresses&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;columns&quot;&lt;/span&gt;: [
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;uuid&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;street&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;address&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;city&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;city&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;state&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;state&quot;&lt;/span&gt;},
          {&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;postalcode&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;zip&quot;&lt;/span&gt;}
        ]
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;table&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Transactions&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;columns&quot;&lt;/span&gt;: [
          { &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;uuid&quot;&lt;/span&gt; },
          { &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;transaction&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;money&quot;&lt;/span&gt; },
          { &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;stamp&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;date&quot;&lt;/span&gt; }
        ]
      }
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the properties included are three tables; &lt;em&gt;Users&lt;/em&gt;, &lt;em&gt;Addresses&lt;/em&gt;, and &lt;em&gt;Transactions&lt;/em&gt;. In the first table, &lt;em&gt;Users&lt;/em&gt;, the columsn would be; &lt;em&gt;id&lt;/em&gt;, &lt;em&gt;firstname&lt;/em&gt;, &lt;em&gt;lastname&lt;/em&gt;, and &lt;em&gt;email_address&lt;/em&gt;. Each of these then have a &lt;em&gt;type&lt;/em&gt; property which sets the type of data to be generated for the columns. The same type of set of properties is then included for the &lt;em&gt;Addresses&lt;/em&gt; and &lt;em&gt;Transactions&lt;/em&gt; tables and their respective columns.&lt;/p&gt;
&lt;p&gt;Some additional questions remain, such as if the tables exist in the database, would the insertion build SQL to create the tables? Should it be assumed that the tables exist already and have the appropriate settings set to insert the data into the tables? Again, a great thing to discuss on the &lt;a href=&quot;https://github.com/Adron/datadiluvium/issues/9&quot;&gt;thread here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/schema/validate&quot;&gt;https://datadiluvium.com/schema/validate&lt;/a&gt;&lt;/em&gt; - This could be used to validate a schema request body. Simply submit a schema and a validation response would be returned with “Valid” or “Invalid”. In the case of an invalid response, a list of prospective and known errors would be returned.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two API end points focus around building out large data to test systemic environments and the respective construction of those environments. The actual generation of the data is assumed for this API service and the individual generation of data is discussed below in the individual request APIs.&lt;/p&gt;
&lt;h2 id=&quot;individual-request-apis&quot;&gt;Individual Request APIs&lt;/h2&gt;
&lt;p&gt;The following API calls could be implemented with fairly straight forward random data generation. A number can easily be randomized and returned, a word can be chosen from a dictionary, and a city returned from a list of cities. The following are prospective API calls to return data of this type.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/number/&quot;&gt;https://datadiluvium.com/random/number/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/word/&quot;&gt;https://datadiluvium.com/random/word/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/city/&quot;&gt;https://datadiluvium.com/random/city/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next level of complexity for data generation would be the slightly structured data generation. Instead of having an arbitrary list of addresses, we could or would prospectively generate one. But on the other hand, maybe we should just randomly create actual addresses that can be validated against an actual real address? That seems to have the possiblity of issues in the real world in spite of the fact all the addresses out there in the world are basically publicly accessible data. But questioning how or what the data would or could actually represent will be a great thing to discuss in the &lt;a href=&quot;https://github.com/Adron/datadiluvium/issues/9&quot;&gt;thread&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/address/&quot;&gt;https://datadiluvium.com/random/address/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/name/&quot;&gt;https://datadiluvium.com/random/name/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next level of data generation complexity would be to generate sentences and other related data. This could be done a number of ways. If we wanted to have it generate intelligent sentences that made sense, it would take a little bit more work then for example generating lorum ipsum.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://datadiluvium.com/random/sentence/&quot;&gt;https://datadiluvium.com/random/sentence/&lt;/a&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;tldr-&quot;&gt;TLDR;&lt;/h3&gt;
&lt;p&gt;This blog entry just details the starting point of features for the &lt;a href=&quot;http://datadiluvium.com/&quot;&gt;Data Diluvium Project&lt;/a&gt;. If you’d like to jump into the project too, let me know. I’m generally working on the project during the weekends and a little during the week. There’s already a &lt;a href=&quot;https://github.com/Adron/datadiluvium&quot;&gt;building project base&lt;/a&gt; that I’m starting with. If you’re interested in writing some F#, check out the work Dave Curylo has done &lt;a href=&quot;http://adron.github.io/articles/data-diluvium-design-ideas/&quot;&gt;here&lt;/a&gt;. I’ve been pondering breaking it out to another project and sticking to the idea of microservice but with F# for the work he put in. Anyway if you’ve got ideas on how to generate data, how you’d like to use it in your applications, or other related ideas please dive into the conversation on the &lt;a href=&quot;https://github.com/Adron/datadiluvium/issues/9&quot;&gt;Github Thread here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Setting up a GCP Container Cluster - Part I</title>
      <link>http://adron.github.io/articles/setting-up-gcp-container-cluster/</link>
      <pubDate>Tue, 31 Jan 2017 06:27:09 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/setting-up-gcp-container-cluster/</guid>
      <author></author>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster/&quot;&gt;Part 1 - Setting up a GCP Container Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/&quot;&gt;Part 2 - Working with a GCP Container Cluster&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Part 3 - Setup of Drone.io on a GCP Container Cluster - Currently being written&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I set out to create a container cluster to work with in Google Cloud. These are the notes of that effort I undertook. On the heels of this article I’m putting together the notes also on getting Drone.io fully setup with an appropriate domain name and the like for use in full production grade work. For now, here’s the lowdown on the steps I took to get educated on and informed about setup and use of the Google Container Cluster.&lt;/p&gt;
&lt;p&gt;First exploratory script I ran based on instructions &lt;a href=&quot;https://cloud.google.com/container-engine/docs/clusters/operations&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud container clusters create working-space \
  --zone us-central1-a \
  --additional-zones us-central1-b,us-central1-c
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s the container cluster listing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-gcp-container-cluster/gcp-01.png&quot; alt=&quot;Google Cloud&quot;&gt;&lt;/p&gt;
&lt;p&gt;This is the list of instances running providing the nodes for the cluster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-gcp-container-cluster/gcp-02.png&quot; alt=&quot;Google Cloud&quot;&gt;&lt;/p&gt;
&lt;p&gt;I deleted that after I confirmed it did what I expected. Which was mostly true.&lt;/p&gt;
&lt;p&gt;Observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This command did execute and launch 9 instances. This I assumed is what it would do since I had selected a default &lt;code&gt;--zone&lt;/code&gt; but also selected two additional with &lt;code&gt;--additional-zones&lt;/code&gt;. This spooled up 3 instances in each zone for us within the cluster.&lt;/li&gt;
&lt;li&gt;In the container clusters listing in the Google Cloud Console, there’s a button now that prompts with the gcloud container cluster get-credentials command and the kubectl command to connect. This is helpful, as the last time I was testing out this one had to go and dig into.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I went ahead and deleted that cluster via the Google Cloud Console. The next command I tried out was as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud container clusters create secondary-delete \
  --network worker-space
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Since this was done on a freshly installed gcloud install on a new machine, I’d missed that I had not installed kubectl. However gcloud kindly informed me.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create secondary-delete \
&amp;gt;   --network worker-space
WARNING: Accessing a Container Engine cluster requires the kubernetes commandline
client [kubectl]. To install, run
  $ gcloud components install kubectl

ERROR: (gcloud.container.clusters.create) ResponseError: code=400, message=Subnetwork must be provided for manual-subnet Network &amp;quot;worker-space&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A quick &lt;code&gt;gcloud components install kubectl&lt;/code&gt; fixed that. I ran the command again and oops, I needed to designate the subnetwork, not particularly the network.&lt;/p&gt;
&lt;p&gt;I wanted to bake this into a Terraform config, so the next thing I wired together was exactly that. A quick change and reran the command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create secondary-delete   --network worker-space --subnetwork worker-space-default
ERROR: (gcloud.container.clusters.create) ResponseError: code=400, message=Subnetwork &amp;quot;projects/that-big-universe/regions/us-west1/subnetworks/worker-space-default&amp;quot; is not valid for Network &amp;quot;worker-space&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Dammit, error central. I went and did some RTFMing at this point. The section for network and subnetwork read as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;–network=NETWORK
The Compute Engine Network that the cluster will connect to. Google Container Engine will use this network when creating routes and firewalls for the clusters. Defaults to the ‘default’ network.&lt;/p&gt;
&lt;p&gt;–subnetwork=SUBNETWORK
The name of the Google Compute Engine subnetwork (&lt;a href=&quot;https://cloud.google.com/compute/docs/subnetworks&quot;&gt;https://cloud.google.com/compute/docs/subnetworks&lt;/a&gt;) to which the cluster is connected. If specified, the cluster’s network must be a “custom subnet” network.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ok, seems like &lt;code&gt;gcloud container clusters create secondary-delete --network worker-space --subnetwork worker-space-default&lt;/code&gt; should have worked. I tried out a few more ideas to see what the issue could actually be.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud compute networks subnets list
NAME                      REGION           NETWORK       RANGE
...default networks were listed here...
worker-space-default      us-central1      worker-space  10.128.0.0/20
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So even &lt;code&gt;gcloud&lt;/code&gt; finds that the network name is &lt;em&gt;worker-space-default&lt;/em&gt; and the network is &lt;em&gt;worker-space&lt;/em&gt;? Is that right? That’s actually a little confusing. In the interface it looks like this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-gcp-container-cluster/gcp-03.png&quot; alt=&quot;Google Cloud Console&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ah, I try this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create secondary-delete --network worker-space --subnetwork us-central1
ERROR: (gcloud.container.clusters.create) ResponseError: code=400, message=Subnetwork &amp;quot;projects/that-big-universe/regions/us-west1/subnetworks/us-central1&amp;quot; is not valid for Network &amp;quot;worker-space&amp;quot;.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then I realize that it’s injecting &lt;em&gt;us-west1&lt;/em&gt; into that string for the subnetwork. But that’s not true. My worker-space and its subnetwork is in central1 not in west1. So a quick RTFM again and realized that maybe adding the zone back, with these network and subnetwork parameters set, I might get a successful cluster creation. I tried this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create secondary-delete --network worker-space --subnetwork worker-space-default --zone us-central1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This also didn’t work, so I went with a zone of &lt;code&gt;us-central1a&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters create secondary-delete --network worker-space --subnetwork worker-space-default --zone us-central1b
ERROR: (gcloud.container.clusters.create) ResponseError: code=400, message=zone &amp;quot;us-central1b&amp;quot; does not exist.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, WTF?! RTFMing doesn’t really help at this point either. Now I’m just getting frustrated. I’m doubtfully going to use &lt;code&gt;gcloud&lt;/code&gt; to build this in production anyway, so I’ll go ahead and try to get Terraform building it.&lt;/p&gt;
&lt;h2 id=&quot;terraform-for-google-cloud-container-cluster&quot;&gt;Terraform for Google Cloud Container Cluster&lt;/h2&gt;
&lt;p&gt;I added this to the script in the &lt;em&gt;adron-infrastructure&lt;/em&gt; branch of my repo &lt;a href=&quot;https://github.com/Adron/adron.github.io/tree/adron-infrastructure&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_container_cluster&amp;quot; &amp;quot;development&amp;quot; {
  name = &amp;quot;development-systems&amp;quot;
  zone = &amp;quot;us-west1-b&amp;quot;
  initial_node_count = 3

  master_auth {
    username = &amp;quot;someusername&amp;quot;
    password = &amp;quot;willchange&amp;quot;
  }

  node_config {
    oauth_scopes = [
      &amp;quot;https://www.googleapis.com/auth/compute&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/logging.write&amp;quot;,
      &amp;quot;https://www.googleapis.com/auth/monitoring&amp;quot;
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The console container cluster display once it completes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-gcp-container-cluster/gcp-04.png&quot; alt=&quot;Google Cloud Console&quot;&gt;&lt;/p&gt;
&lt;p&gt;The console instances listed again. This time of course, just like the node count in the config above and the zone being only set to west1-b, I’ve got 3 instances.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-gcp-container-cluster/gcp-04.png&quot; alt=&quot;Google Cloud Console&quot;&gt;&lt;/p&gt;
&lt;p&gt;Alright, that worked beautifully. If anybody has any idea what the issue is with my aforementioned attempts to create a cluster using gcloud and the network and subnetwork please ping me via &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; and we’ll DM or email if you would. (Also, for more info on getting started with GCP with Terraform, check out my article “&lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too) &lt;/a&gt;“)&lt;/p&gt;
&lt;p&gt;Next step I needed to connect kubectl to the cluster. This is one of the spaces where a lot of Google documentation is lacking since it also assumes you’ve followed some pre-baked route to gain credentials. For instance, int he interface the thing I pointed to earlier, just uses kubectl and gcloud does some crazy black magic in the background that require tertiary RTFMing in order to figure out what is actually going on, retrace those steps, and connect yourself. The first thing I tried was to set the cluster.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl config set-cluster development-systems
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then did a quick &lt;code&gt;kubectl config view&lt;/code&gt; which showed that things were set correctly. Then I tried to run &lt;code&gt;kubectl cluster-info&lt;/code&gt; just to see what’s up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl cluster-info
error: google: could not find default credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So no go. Default credentials… another thing I’m not really sure. I tried to run &lt;code&gt;gcloud container clusters get-credentials development-systems  --zone us-west1-b --project that-big-universe&lt;/code&gt; and it failed. Grumble grumble come on. I tried again however, because something seemed odd with the network before, and this time I got some results! Win!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcloud container clusters get-credentials development-systems \
&amp;gt;     --zone us-west1-b --project that-big-universe
Fetching cluster endpoint and auth data.
kubeconfig entry generated for development-systems.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I then try to get a &lt;code&gt;kubectl cluster-info&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl cluster-info
error: google: could not find default credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nope. Oh yeah, I gotta set kube’s proxy!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl proxy
error: google: could not find default credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;No. Alright, what then? At this point I’m pretty frustrated, but whatevs, this is gonna work so I keep researching. A quick search for default credentials leads to &lt;a href=&quot;https://developers.google.com/identity/protocols/application-default-credentials&quot;&gt;this&lt;/a&gt;. I read through it and this whole GOOGLE_APPLICATION_CREDENTIALS needs to be set. Ok, that’s cool. So I set it. It needs to be a credentials file for the service account used. Which actually makes sense but only because I’ve used Google Cloud before, but for somebody just diving into using the container service on Google this is kind of a whole derailment to go read up on a bunch of other topics. Albeit, it is necessary reading. Anyway…  back to setting the credentials file. For more info on how to set this up and working with GCP, check out my previous article “&lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too)&lt;/a&gt;“.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export GOOGLE_APPLICATION_CREDENTIALS=~/thepathtosecrets/account.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I added this to my bash_profile and sourced that file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then I ran &lt;code&gt;kubectl cluster-info&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl cluster-info
Kubernetes master is running at https://104.196.234.30
GLBCDefaultBackend is running at https://104.196.234.30/api/v1/proxy/namespaces/kube-system/services/default-http-backend
Heapster is running at https://104.196.234.30/api/v1/proxy/namespaces/kube-system/services/heapster
KubeDNS is running at https://104.196.234.30/api/v1/proxy/namespaces/kube-system/services/kube-dns
kubernetes-dashboard is running at https://104.196.234.30/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ah, magic! It’s working! So a few other commands just to verify and determine what the state of things are.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ kubectl top node
NAME                                                 CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%
gke-development-systems-default-pool-f30f476e-gtnj   34m          3%        1529Mi          41%
gke-development-systems-default-pool-f30f476e-ncln   47m          4%        1879Mi          50%
gke-development-systems-default-pool-f30f476e-s5pc   38m          3%        1691Mi          45%
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That looks good. So on to getting some containers launched.&lt;/p&gt;
&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;
&lt;p&gt;At this point I’ve learned a number of things. One, is that using Terraform I lose a few of the other credentials that are auto-magically available if you setup the cluster via the &lt;code&gt;gcloud&lt;/code&gt; commands. Using &lt;code&gt;gcloud&lt;/code&gt; generally handles a lot of the management of ssh keys, credentials, and related security stuff so that you don’t have to. There are of course positives and negatives around this, for instance, if I go and created a cluster via Terraform my credentials are out of sync with what &lt;code&gt;gcloud&lt;/code&gt; is actually using. At least in the scenario above I had to go set the credentials manually and add them to the ~/.bash_profile. Overall, once familiar with, I know this all will be super easy to dig through, but it definitely takes some exploration and lots of breaking things before getting it all figured out and mapped in one’s brain. For part II I’m digging into running containers in the cluster and also getting container images stored in Google’s image container registry. Hopefully I can get the network and subnetwork confusion sorted out too and get that implemented.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster/&quot;&gt;Part 1 - Setting up a GCP Container Cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://adron.github.io/articles/setting-up-gcp-container-cluster-part-2/&quot;&gt;Part 2 - Working with a GCP Container Cluster&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Part 3 - Setup of Drone.io on a GCP Container Cluster - Currently being written&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Talking Through Managed or Baked In House Continuous Integration (CI) and Delivery (CD)</title>
      <link>http://adron.github.io/articles/talking-through-ci-cd/</link>
      <pubDate>Thu, 26 Jan 2017 08:45:46 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/talking-through-ci-cd/</guid>
      <author></author>
      <description>&lt;p&gt;Ok, we have several different scenarios and let’s say you’re the boss. In each of these scenarios we can assume that CI &amp;amp; CD are going to be mandatory to achieve the team’s greatest potential to deliver. So the question I’ll be attacking is, do we roll our own with Drone.io, TeamCity, continuous integration and delivery or do we get more advantage from utilizing a managed solution like CircleCI, Codeship, or related offerings. The following are the scenarios in relation to team size and project that you’re heading up:&lt;/p&gt;
&lt;h2 id=&quot;scenarios&quot;&gt;Scenarios&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 1:&lt;/em&gt;&lt;/strong&gt; You have team of 4 people. All developers by trade and experienced. The team may, about 20% chance in the coming 3-6 months, grow to ~8 people, with 1-2 of those being automation experts that could prospectively manage CI/CD systems. Currently the project is just starting, and the decision on what language and tech stack has been determined and initial coding will be starting in the coming week. Currently, there is no CI/CD setup for this project.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 2:&lt;/em&gt;&lt;/strong&gt; Another team has 33 developers, 4 are site reliability with 2 more working with them frequently on systems automation. No real growth for the team in the next 2-3 years. The application these developers work on has new feature development and maintenance, lot’s of ongoing maintenance. Currently there is also a fair amount of technical debt associated with the code base that needs paid off for each new feature implemented, or any significant changes during maintenance of the software. This team currently has no CI or CD of the application setup.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 3:&lt;/em&gt;&lt;/strong&gt; The third team is 4 people, pairing, and they have the highest output and quality of the rest of the teams. Largely because they work well together but also they have minimal technical debt and can move quickly. The application has been under development for about 3 months and they currently have a CI process setup with Drone.io. No deployment is setup yet nor is any infrastructure or other tooling setup beyond what they’ve already setup with the Drone.io solution.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 4:&lt;/em&gt;&lt;/strong&gt; Fourth scenario is a large team of 232 people. There are 9 organizations with multiple people in each of those organizations, split out to developers, project management, product development leads, and a core architecture team. Among the 232 there are also 17 people dedicated to automation and infrastructure management. This team manages one huge monolithic application that currently is built with manual build processes that are partially scripted. Of these build processes there are 11 of them, which then must be combined via some more scripts and more manual processes that are then pushed to a &lt;em&gt;test development&lt;/em&gt; environment, where a subsequent 4 people work full time testing the &lt;em&gt;test development&lt;/em&gt; environment.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each of these scenarios has a clear and present need for continuous integration and delivery setup. Just for context, when I write continuous integration or continuous delivery I define these like this:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Continuous Integration&lt;/strong&gt; - &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuous_integration&quot;&gt;Wikipedia&lt;/a&gt; - &lt;a href=&quot;https://www.thoughtworks.com/continuous-integration&quot;&gt;Thoughtworks&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…is the process of bringing together the assets of an application or service project to compile that code into a binary. In the case of JavaScript or other non-compiled language this process would include any transpiling or gathering of assets that are needed in order to execute the code via the integration process. In most cases I include unit testing, and sometimes certain types of or styles of behavior tests in a project to be included under the process of continuous integration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Continuous Delivery&lt;/strong&gt; -  &lt;a href=&quot;https://en.wikipedia.org/wiki/Continuous_delivery&quot;&gt;Wikipedia&lt;/a&gt; - &lt;a href=&quot;https://www.thoughtworks.com/continuous-delivery&quot;&gt;Thoughtworks&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…is the process of events that must be completed, in an automated fashion, after the continuous integration process to take code or a binary from the transpiled or binary state into a production environment in which it will be used or executed. This is fairly easy to outline with a services or web application, since there is an obvious way in which this code needs to be called (via http/https in a browser) but some other applications, like a CLI or desktop application are slightly more diverse in the way they may be delivered. These later applications we can safely assume have a continuous delivery process that would vary widely but be something like being packaged into an installer (in the case of OS-X a .pkg file or in the case of Windows into a .exe or .msi file.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Also an excellent resource is available &lt;a href=&quot;https://continuousdelivery.com/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;solutions-discussion-for-scenarios&quot;&gt;Solutions &amp;amp; Discussion for Scenarios&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 1:&lt;/em&gt;&lt;/strong&gt; Considering there are 4 people, prospectively 8 at the most over the next 6 months, the team really should not spend time on putting together, automating, and building out systems they don’t absolutely need to. The emphasis with a small team needs to be lean, mean, and focused on the mission at hand. Continuous integration and delivery will help delivery that, but putting it together isn’t directly related to business value.&lt;/p&gt;
&lt;p&gt;  What to do? Well, the quickest and simplest way to get started and enable a core focus on the mission is to use a managed continuous integration and delivery provider. This is a great case to use Codeship, CircleCI, AppVeyor, or a host of providers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 2:&lt;/em&gt;&lt;/strong&gt; This is an interesting scenario in that there are people tasked with automation and what would be the effort of continuous integration and delivery. However, there are questions to ask. There are three questions that immediately come to mind. These would likely have the most weight on a managed or self-hosted CI &amp;amp; CD solution would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Would running our own CI and CD save the company money?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Does the team need specific features or capabilities inherent in self-hosted CI and CD solutions?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Would the self-hosted capabilities versus the managed enable the team to deliver more effectively?&lt;/p&gt;
&lt;p&gt;Let’s dig through each question.&lt;/p&gt;
&lt;p&gt;The first, is the cost question. If the team had enough demand for builds or other integration and delivery automation it is feasible that costs could be fairly huge. I myself have seen price tags in the $40-50k a month range, which more than validates self-hosting build and delivery solutions to more finely manage or even decrease costs. However, I’ll add that $40-50k does only pay for work equating to a part time effort on this work. That doesn’t go that far either. By proxy, the cost is a valid question, but it isn’t all that it’s cracked up to be. I tend to lean heavily toward using a hosted solution even if it costs 10-40% more as that cost is usually worth it to refocus efforts on business value instead of CI and CD management. Let’s say, for this 33+ person team in scenario 2, that CI and CD costs will be around $40k per month via hosted offerings and about $25k if it’s self-hosted.&lt;/p&gt;
&lt;p&gt;The second is likely the most important that would be asked of the three. Case in point the market has provided very few .NET build solutions that are managed. This has limited the ability to gain CI and CD advantages for startups that choose .NET. This has likely been one of many reasons .NET has taken a massive nose dive in popularity over the last decade among startups. Even among the more popular build service one can use, there are certain limitations that can stop a project cold. In these cases, a team can be forced into a self-hosted option. Let’s say, for scenario 2 however there isn’t a legitimate need for self-hosted control, but some of the team think it would be a nice to have.&lt;/p&gt;
&lt;p&gt;The third question, is more inclusive of the aforementioned other two questions plus other criteria. But just as I mentioned the team thinks it would be a &lt;em&gt;nice to have&lt;/em&gt; that begs another question. If the team had the extra control would that give them a boost or assistance with certain CI or CD automation, or will they get into situations where someone will end up with managing or spending significant time toying about with capabilities? Would that time be worth it in the end, or be lost time sunk into something that could work without the investment? Let’s say that having full control in this situation, as if we were so fortunate to get a % of productivity increase, would give the team a 5% speed to delivery boost and 2% less bugs.&lt;/p&gt;
&lt;p&gt;Alright, I’ve conjured up those few thougths about each of those questions. Based on the posed end statements of each questions what would you do as the boss? What would I do? Since this is a team that is largely maintaining existing software and building some features, I’d also ponder what would keep them happier. Maintaining a CI and CD system in hours or gettinga  self-hosted service, then I’d look at the over under of $40k cost per month hosted or $25k self-hosted, then &lt;em&gt;nice to have&lt;/em&gt; thought behind self-hosted, and the upside of 5% speed to deliver and 2% bugs boost. In the end here, it would come down to developer happiness, and anything, I may even mix usage. For instance a bit of Codeship and Drone.io together. Both have a similar usage style so the learning curve would be huge, but similar giving the team a conjoined experience. I’ll leave this solution in the democratic vote of the developer team.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 3:&lt;/em&gt;&lt;/strong&gt; This scenario is easy for me. If someone is spending more than 30 minutes a week dealing with Drone.io management, I’d push a shift to a managed provider. However since the Drone.io solution is already in place, if the only thing people are doing is committing code, getting builds, and have their code delivered then I’m a happy camper. Drone.io would stay as the CI and CD tooling for the team.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Scenario 4:&lt;/em&gt;&lt;/strong&gt; Ok, wow, this is a big team to implement for. My immediate reaction is everything will be dependent on individual teams within the big team vote. There’s no reason to force a large team of this size to use a single solution, but there’s also many downsides to using to many different technologies to implement CI and CD. Let’s say the code this 200+ person team is working on is a single language, single stack, and singular deployment path, with just a few builds occurring per hour. If that’s the case then that would change my response toward a managed and hosted solution. But with this size, it’s likely that costs are much higher, build demand is dramatically higher, and the various internal security, admin, and related management of users, individual features, and the like lend to a self-hosted internal solution to give more control over customization specific to needs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Summary: These are just a few of the thoughts, notions, and issues that need reflected upon to make a useful and effective decision about CI and CD tooling. These scenarios I posed are merely from the perspective of team size, organization, costs, and these higher level notions are CI and CD. In a future article I’ll dive into the specifics of how CI and CD are implemented on various platforms, and we can dig even deeper into why, what, who, where, and when to implement CI and CD for your team(s). Whatever the case, CI and CD are a fundamentally and vitally important first step or ongoing step of any project. If you’d like to discuss more, feel free to reach out to me on Twitter &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; or &lt;a href=&quot;http://blog.adron.me/docs/contact/&quot;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Introduction to Drone.io</title>
      <link>http://adron.github.io/articles/drone-io/</link>
      <pubDate>Wed, 25 Jan 2017 00:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/drone-io/</guid>
      <author></author>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Research &amp;amp; Learn&lt;/strong&gt;: &lt;a href=&quot;https://github.com/drone/drone&quot;&gt;Drone.io Github Repo&lt;/a&gt;, &lt;a href=&quot;http://try.drone.io/&quot;&gt;Trying Drone.io&lt;/a&gt;, and &lt;a href=&quot;http://readme.drone.io/&quot;&gt;Drone.io Docs&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: What Drone.io is and getting started.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve dived into a new effort to figure out &lt;a href=&quot;http://try.drone.io/&quot;&gt;Drone.io&lt;/a&gt;, get it running, and if plausible contribute in some way to the project. This was kick started yesterday while I was speaking with Joachim (T &lt;a href=&quot;https://twitter.com/lindyhop&quot;&gt;@lindyhop&lt;/a&gt; &amp;amp;&amp;amp; G &lt;a href=&quot;https://github.com/josmo&quot;&gt;@josmo&lt;/a&gt;) about some projects we’re working on. We discussed the design of Drone.io, how we’re using it on some projects internally here &lt;a href=&quot;https://twitter.com/PelotonTechio&quot;&gt;@PelotonTechio&lt;/a&gt;. I will, and others will be posting more on what we’re doing with Drone.io later, but for now, I’ve put together this introduction to what Drone.io is, and getting started with it.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;my-first-steps&quot;&gt;My First Steps&lt;/h2&gt;
&lt;p&gt;I was fortunate to join Joachim a few weeks ago for a Share-out &lt;a href=&quot;https://twitter.com/PelotonTechio&quot;&gt;@PelotonTechio&lt;/a&gt; where someone from the team shares information they’ve recently gained while working on a project, toying around with a personal project, or other research they’ve been doing. From this, I had a little head start of what Drone.io is about, but still dug in from the very start. Which in my case, that meant grabbing the code and looking directly into things.&lt;/p&gt;
&lt;h2 id=&quot;what-is-drone-io-&quot;&gt;What is Drone.io?&lt;/h2&gt;
&lt;p&gt;In simple terms, Drone is a continuous integration platform using containers, primarily Docker based containers. These containers provide complete control over each build environment with the obvious isolation that containers provide. The goal of Drone is to help ship code similar to the way Github does, as per the stated objective in the README.md. Check out more on that specific &lt;a href=&quot;https://github.com/blog/1241-deploying-at-github#always-be-shipping&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’re curious about what Github does, and it’s TLDR; and you don’t want to click through, here’s the synopsis in one graph:&lt;/p&gt;
&lt;p&gt;Always be shipping:
&lt;a href=&quot;https://github.com/blog/1241-deploying-at-github#always-be-shipping&quot;&gt;&lt;img src=&quot;/articles/drone-io/abs-graph.png&quot; alt=&quot;Always Be Shipping&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A secondary goal is to replace Jenkins as an industry wide integration tool. We’ll all get to see how that goes as time rolls onward.&lt;/p&gt;
&lt;h2 id=&quot;getting-a-build-started&quot;&gt;Getting a Build Started&lt;/h2&gt;
&lt;p&gt;The first step, if you’ve got a build environment already, is simply to create a .drone.yml file. This file is a subset of the &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt; style format. This yaml file describes the services and the container image that will be used. For instance, here’s an example from the docs.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;pipeline:
  build:
    image: golang
    commands:
      - go get
      - go build
      - go test

services:
  postgres:
    image: postgres:9.4.5
    environment:
      - POSTGRES_USER=myapp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a simple service running postgres using the postgres 9.4.5 docker image and the pipeline is based on the golang image. The first pipeline step is to build using the commands &lt;code&gt;go get&lt;/code&gt;, &lt;code&gt;go build&lt;/code&gt;, and &lt;code&gt;go test&lt;/code&gt;. The service in this situation would likely be available for that build to use for integration tests with the database server.&lt;/p&gt;
&lt;p&gt;This also points to how the architecture works for this particular process. Drone starts these containers up based on the specified images. That image acts as the starting point for the container point which will be used to put code on that will eventually be built, tested, or otherwise used for this processing.&lt;/p&gt;
&lt;p&gt;Once the image is pulled, Drone automatically clones the repository you specify onto a locally mounted volume, called a workspace, on the running container. The clone process is parallel to executing a command similar to the following (from the docs &lt;a href=&quot;http://readme.drone.io/usage/getting-started/&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;git clone --depth=50 --recusive=true \
    https://github.com/octocat/hello-world.git \
    /drone/src/github.com/octocat/hello-world
git checkout 7fd1a60
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That the basic steps and idea for getting a build setup. It’s one seriously clean, smooth, and seamless way to setup a build. In the coming weeks I’ll have more information about builds for specific stacks, but for now, let’s take a look at some other elements beyond setting up a simple build.&lt;/p&gt;
&lt;h2 id=&quot;setting-up-some-drone-s-&quot;&gt;Setting up Some Drone(s)&lt;/h2&gt;
&lt;p&gt;Alright, so after digging through a bit I realized I just needed to dig in and get a Drone service running for myself. So this was my first attempt at getting Drone up and running. I saw the “&lt;em&gt;click this one cool button to make it work on Azure&lt;/em&gt;“ button but I have two issues with this: 1. I’m not actually learning anything about what is being done, and if it breaks I’m up the proverbial creek without a paddle 2. I currently, among all clients and people I cohack with, have zero need to know how it works on Azure. But hey, maybe in the future. For now, I just want to get something working locally, as it seems like this would be reasonable.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Prerequisite Knowledge&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Digging through the documentation it is immediately clear that it behooves the admin of Drone to know a thing or three about Docker Compose, in addition to merely Docker. The first sample file that is in the docs &lt;a href=&quot;http://readme.drone.io/admin/installation-guide/&quot;&gt;here&lt;/a&gt; in the &lt;a href=&quot;http://readme.drone.io/admin/installation-guide/&quot;&gt;installation guide&lt;/a&gt; is simply a Docker Compose yaml file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;#39;2&amp;#39;

services:
  drone-server:
    image: drone/drone:0.5
    ports:
      - 80:8000
    volumes:
      - ./drone:/var/lib/drone/
    restart: always
    environment:
      - DRONE_OPEN=true
      - DRONE_GITHUB=true
      - DRONE_GITHUB_CLIENT=${DRONE_GITHUB_CLIENT}
      - DRONE_GITHUB_SECRET=${DRONE_GITHUB_SECRET}
      - DRONE_SECRET=${DRONE_SECRET}

  drone-agent:
    image: drone/drone:0.5
    command: agent
    restart: always
    depends_on: [ drone-server ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - DRONE_SERVER=ws://drone-server:8000/ws/broker
      - DRONE_SECRET=${DRONE_SECRET}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The installation guide generally follows the setup with the assumption of hosting it with a public access URI so that Github OAUTH can be setup. I simply wanted to get some basic elements tested out so I just thought I’d give it a go without any of that setup. Just run the basic service and get the UI setup first.&lt;/p&gt;
&lt;p&gt;With that, I thought I’d just try to copy and paste the Docker Compose file into a &lt;em&gt;docker-compose.yaml&lt;/em&gt; and just &lt;code&gt;docker-compose up&lt;/code&gt; the thing. Theoretically it &lt;em&gt;shouldn’t&lt;/em&gt; hurt anything right? Well, without even setting the environment variables I kicked off the command.&lt;/p&gt;
&lt;p&gt;Well, that was kind of useless. But you know, I immediately learned a few things just from observation of this attempt. Obviously it would, it should fail considering. So for attempt two I set the environment variables. It was a bit LOLz…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker-compose up
WARNING: The DRONE_SECRET variable is not set. Defaulting to a blank string.
WARNING: The DRONE_GITHUB_CLIENT variable is not set. Defaulting to a blank string.
WARNING: The DRONE_GITHUB_SECRET variable is not set. Defaulting to a blank string.
Creating network &amp;quot;drone_default&amp;quot; with the default driver
Pulling drone-server (drone/drone:0.5)...
0.5: Pulling from drone/drone
a3ed95caeb02: Pull complete
802d894958a2: Pull complete
f294f54a4453: Pull complete
Digest: sha256:f04adc8fd1097671af6d74dd809eefea6e5062a881912322d3d908e167253a97
Status: Downloaded newer image for drone/drone:0.5
Creating drone_drone-server_1
Creating drone_drone-agent_1
Attaching to drone_drone-server_1, drone_drone-agent_1
drone-server_1  | time=&amp;quot;2017-01-25T18:59:14Z&amp;quot; level=fatal msg=&amp;quot;failed to generate token from DRONE_AGENT_SECRET&amp;quot;
drone-agent_1   | 1:M 25 Jan 18:59:15.243 * connecting to server ws://drone-server:8000/ws/broker
drone-agent_1   | 1:M 25 Jan 18:59:15.283 # connection failed, retry in 15s. websocket.Dial ws://drone-server:8000/ws/broker: dial tcp: lookup drone-server on 127.0.0.11:53: no such host
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So even without the environment variables set it attempted to go about launching a &lt;em&gt;drone-server_1&lt;/em&gt; and go through various steps. I quickly killed the efforts of the executing Docker Compose with Ctrl+C and then a quick call to &lt;code&gt;docker-compose down&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker-compose down
WARNING: The DRONE_SECRET variable is not set. Defaulting to a blank string.
WARNING: The DRONE_GITHUB_CLIENT variable is not set. Defaulting to a blank string.
WARNING: The DRONE_GITHUB_SECRET variable is not set. Defaulting to a blank string.
Removing drone_drone-agent_1 ... done
Removing drone_drone-server_1 ... done
Removing network drone_default
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It appears at this point that it stopped and cleaned up appropriately. Also I wanted to see if I could get things going without the Github integration. I removed those environment variables form the list. That included deleting these lines.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- DRONE_GITHUB=true
- DRONE_GITHUB_CLIENT=${DRONE_GITHUB_CLIENT}
- DRONE_GITHUB_SECRET=${DRONE_GITHUB_SECRET}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also made a change for the DRONE_SERVER, set the variables remaining. My yaml looked like this when completed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;#39;2&amp;#39;

services:
  drone-server:
    image: drone/drone:0.5
    ports:
      - 80:8000
    volumes:
      - ./drone:/var/lib/drone/
    restart: always
    environment:
      - DRONE_OPEN=true
      - DRONE_SECRET=${DRONE_SECRET}

  drone-agent:
    image: drone/drone:0.5
    command: agent
    restart: always
    depends_on: [ drone-server ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - DRONE_SERVER=ws://localhost:8000/ws/broker
      - DRONE_SECRET=${DRONE_SECRET}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To run this I setup a .env file, which can be used beside a docker-compose.yaml file to store environment variables. Since I didn’t want to clutter up my actual environment variables on my machine while testing this out, this seemed a better route. The initial .env file had the following content.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DRONE_SECRET=&amp;#39;thesecret&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After running &lt;code&gt;docker-compose&lt;/code&gt; this time, I got the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker-compose up
Creating network &amp;quot;drone_default&amp;quot; with the default driver
Creating drone_drone-server_1
Creating drone_drone-agent_1
Attaching to drone_drone-server_1, drone_drone-agent_1
drone-server_1  | time=&amp;quot;2017-01-25T19:11:53Z&amp;quot; level=fatal msg=&amp;quot;version control system not configured&amp;quot;
drone-agent_1   | 1:M 25 Jan 19:11:53.770 * connecting to server ws://localhost:8000/ws/broker
drone-agent_1   | 1:M 25 Jan 19:11:53.772 # connection failed, retry in 15s. websocket.Dial ws://localhost:8000/ws/broker: dial tcp [::1]:8000: getsockopt: connection refused
drone_drone-server_1 exited with code 1
drone-server_1  | time=&amp;quot;2017-01-25T19:11:53Z&amp;quot; level=fatal msg=&amp;quot;version control system not configured&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Well that escalated quickly to hostility! Egads! No version control system configured! Ugh. Ok, I guess I’ve got to have that as a default. I was hoping that it would present some type of default setup for this and just let me get running, especially since I want to host this locally, not out in internet land where I’d have a valid URI to use. With a quick change I added a few things back to the file with the following changes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &amp;#39;2&amp;#39;

services:
  drone-server:
    image: drone/drone:0.5
    ports:
      - 80:8000
    volumes:
      - ./drone:/var/lib/drone/
    restart: always
    environment:
      - DRONE_OPEN=true
      - DRONE_GITHUB=true
      - DRONE_GITHUB_CLIENT=${DRONE_GITHUB_CLIENT}
      - DRONE_GITHUB_SECRET=${DRONE_GITHUB_SECRET}
      - DRONE_SECRET=${DRONE_SECRET}

  drone-agent:
    image: drone/drone:0.5
    command: agent
    restart: always
    depends_on: [ drone-server ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - DRONE_SERVER=ws://drone-server:8000/ws/broker
      - DRONE_SECRET=${DRONE_SECRET}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then I navigated out to &lt;em&gt;&lt;a href=&quot;https://github.com/settings/applications/new&quot;&gt;https://github.com/settings/applications/new&lt;/a&gt;&lt;/em&gt; and created an application for my &lt;em&gt;localhost&lt;/em&gt;, guessing what it would prospectively be.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/drone-io/New_OAuth_Application.png&quot; alt=&quot;New OAuth Application&quot;&gt;&lt;/p&gt;
&lt;p&gt;(Made a screenshot, then realized I had to take off the port numbers. No need for those)&lt;/p&gt;
&lt;p&gt;Next accepted the permissions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/drone-io/Authorize_Adron_s_Drone_io.png&quot; alt=&quot;Authorized Adron&amp;#39;s Drone.io Application&quot;&gt;&lt;/p&gt;
&lt;p&gt;The screen upon confirmation has the appropriate secret and client info for the application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/drone-io/github-oauth.png&quot; alt=&quot;OAuth Application Information&quot;&gt;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;.env&lt;/em&gt; file then included the following changes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DRONE_SECRET=&amp;#39;thesecret&amp;#39;
DRONE_GITHUB_CLIENT=30clientbclient8d
DRONE_GITHUB_SECRET=8csecret09fesecret3be1a2427b80easecretcf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I then spooled up with &lt;code&gt;docker-compose up&lt;/code&gt; again and progress was made!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker-compose up
Recreating drone_drone-server_1
Recreating drone_drone-agent_1
Attaching to drone_drone-server_1, drone_drone-agent_1
drone-server_1  | time=&amp;quot;2017-01-25T21:03:20Z&amp;quot; level=warning msg=&amp;quot;agents can connect with token eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiJ3RoZXNlY3JldCciLCJ0eXBlIjoiYWdlbnQifQ.q8qhOlPLQePSxKfnTe-uURfMOKSQznA2iaLQZnuOYgE&amp;quot;
drone-server_1  | [GIN-debug] [WARNING] Running in &amp;quot;debug&amp;quot; mode. Switch to &amp;quot;release&amp;quot; mode in production.
drone-agent_1   | 1:M 25 Jan 21:03:21.763 * connecting to server ws://drone-server:8000/ws/broker
drone-server_1  |  - using env:    export GIN_MODE=release
drone-server_1  |  - using code:    gin.SetMode(gin.ReleaseMode)
drone-server_1  |
drone-server_1  | [GIN-debug] GET    /static/*filepath         --&amp;gt; github.com/drone/drone/router.Load.func1 (2 handlers)
drone-server_1  | [GIN-debug] GET    /login                    --&amp;gt; github.com/drone/drone/server.ShowLogin (15 handlers)
drone-server_1  | [GIN-debug] GET    /login/form               --&amp;gt; github.com/drone/drone/server.ShowLoginForm (15 handlers)
drone-server_1  | [GIN-debug] GET    /logout                   --&amp;gt; github.com/drone/drone/server.GetLogout (15 handlers)
drone-server_1  | [GIN-debug] GET    /api/user                 --&amp;gt; github.com/drone/drone/server.GetSelf (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/user/feed            --&amp;gt; github.com/drone/drone/server.GetFeed (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/user/repos           --&amp;gt; github.com/drone/drone/server.GetRepos (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/user/repos/remote    --&amp;gt; github.com/drone/drone/server.GetRemoteRepos (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/user/token           --&amp;gt; github.com/drone/drone/server.PostToken (16 handlers)
drone-server_1  | [GIN-debug] DELETE /api/user/token           --&amp;gt; github.com/drone/drone/server.DeleteToken (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/users                --&amp;gt; github.com/drone/drone/server.GetUsers (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/users                --&amp;gt; github.com/drone/drone/server.PostUser (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/users/:login         --&amp;gt; github.com/drone/drone/server.GetUser (16 handlers)
drone-server_1  | [GIN-debug] PATCH  /api/users/:login         --&amp;gt; github.com/drone/drone/server.PatchUser (16 handlers)
drone-server_1  | [GIN-debug] DELETE /api/users/:login         --&amp;gt; github.com/drone/drone/server.DeleteUser (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/teams/:team/secrets  --&amp;gt; github.com/drone/drone/server.GetTeamSecrets (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/teams/:team/secrets  --&amp;gt; github.com/drone/drone/server.PostTeamSecret (16 handlers)
drone-server_1  | [GIN-debug] DELETE /api/teams/:team/secrets/:secret --&amp;gt; github.com/drone/drone/server.DeleteTeamSecret (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/global/secrets       --&amp;gt; github.com/drone/drone/server.GetGlobalSecrets (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/global/secrets       --&amp;gt; github.com/drone/drone/server.PostGlobalSecret (16 handlers)
drone-server_1  | [GIN-debug] DELETE /api/global/secrets/:secret --&amp;gt; github.com/drone/drone/server.DeleteGlobalSecret (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/repos/:owner/:name   --&amp;gt; github.com/drone/drone/server.PostRepo (15 handlers)
drone-server_1  | [GIN-debug] GET    /api/repos/:owner/:name   --&amp;gt; github.com/drone/drone/server.GetRepo (18 handlers)
drone-server_1  | [GIN-debug] GET    /api/repos/:owner/:name/builds --&amp;gt; github.com/drone/drone/server.GetBuilds (18 handlers)
drone-server_1  | [GIN-debug] GET    /api/repos/:owner/:name/builds/:number --&amp;gt; github.com/drone/drone/server.GetBuild (18 handlers)
drone-server_1  | [GIN-debug] GET    /api/repos/:owner/:name/logs/:number/:job --&amp;gt; github.com/drone/drone/server.GetBuildLogs (18 handlers)
drone-server_1  | [GIN-debug] POST   /api/repos/:owner/:name/sign --&amp;gt; github.com/drone/drone/server.Sign (19 handlers)
drone-server_1  | [GIN-debug] GET    /api/repos/:owner/:name/secrets --&amp;gt; github.com/drone/drone/server.GetSecrets (19 handlers)
drone-server_1  | [GIN-debug] POST   /api/repos/:owner/:name/secrets --&amp;gt; github.com/drone/drone/server.PostSecret (19 handlers)
drone-server_1  | [GIN-debug] DELETE /api/repos/:owner/:name/secrets/:secret --&amp;gt; github.com/drone/drone/server.DeleteSecret (19 handlers)
drone-server_1  | [GIN-debug] PATCH  /api/repos/:owner/:name   --&amp;gt; github.com/drone/drone/server.PatchRepo (19 handlers)
drone-server_1  | [GIN-debug] DELETE /api/repos/:owner/:name   --&amp;gt; github.com/drone/drone/server.DeleteRepo (19 handlers)
drone-server_1  | [GIN-debug] POST   /api/repos/:owner/:name/chown --&amp;gt; github.com/drone/drone/server.ChownRepo (19 handlers)
drone-server_1  | [GIN-debug] POST   /api/repos/:owner/:name/builds/:number --&amp;gt; github.com/drone/drone/server.PostBuild (19 handlers)
drone-server_1  | [GIN-debug] DELETE /api/repos/:owner/:name/builds/:number/:job --&amp;gt; github.com/drone/drone/server.DeleteBuild (19 handlers)
drone-server_1  | [GIN-debug] GET    /api/badges/:owner/:name/status.svg --&amp;gt; github.com/drone/drone/server.GetBadge (15 handlers)
drone-server_1  | [GIN-debug] GET    /api/badges/:owner/:name/cc.xml --&amp;gt; github.com/drone/drone/server.GetCC (15 handlers)
drone-server_1  | [GIN-debug] POST   /hook                     --&amp;gt; github.com/drone/drone/server.PostHook (15 handlers)
drone-server_1  | [GIN-debug] POST   /api/hook                 --&amp;gt; github.com/drone/drone/server.PostHook (15 handlers)
drone-server_1  | [GIN-debug] GET    /ws/broker                --&amp;gt; github.com/drone/drone/server.Broker (15 handlers)
drone-server_1  | [GIN-debug] GET    /ws/feed                  --&amp;gt; github.com/drone/drone/server.EventStream (15 handlers)
drone-server_1  | [GIN-debug] GET    /ws/logs/:owner/:name/:build/:number --&amp;gt; github.com/drone/drone/server.LogStream (18 handlers)
drone-server_1  | [GIN-debug] GET    /authorize                --&amp;gt; github.com/drone/drone/server.GetLogin (15 handlers)
drone-server_1  | [GIN-debug] POST   /authorize                --&amp;gt; github.com/drone/drone/server.GetLogin (15 handlers)
drone-server_1  | [GIN-debug] POST   /authorize/token          --&amp;gt; github.com/drone/drone/server.GetLoginToken (15 handlers)
drone-server_1  | [GIN-debug] GET    /api/builds               --&amp;gt; github.com/drone/drone/server.GetBuildQueue (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/agents               --&amp;gt; github.com/drone/drone/server.GetAgents (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/         --&amp;gt; github.com/drone/drone/server.IndexHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/heap     --&amp;gt; github.com/drone/drone/server.HeapHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/goroutine --&amp;gt; github.com/drone/drone/server.GoroutineHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/block    --&amp;gt; github.com/drone/drone/server.BlockHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/threadcreate --&amp;gt; github.com/drone/drone/server.ThreadCreateHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/cmdline  --&amp;gt; github.com/drone/drone/server.CmdlineHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/profile  --&amp;gt; github.com/drone/drone/server.ProfileHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/symbol   --&amp;gt; github.com/drone/drone/server.SymbolHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] POST   /api/debug/pprof/symbol   --&amp;gt; github.com/drone/drone/server.SymbolHandler.func1 (16 handlers)
drone-server_1  | [GIN-debug] GET    /api/debug/pprof/trace    --&amp;gt; github.com/drone/drone/server.TraceHandler.func1 (16 handlers)
drone-agent_1   | 1:M 25 Jan 21:03:21.966 * connection established, ready to process builds.
drone-agent_1   | 1:M 25 Jan 21:03:51.766 - stomp: send heart-beat.
drone-agent_1   | 1:M 25 Jan 21:03:51.866 - stomp: received heart-beat
drone-agent_1   | 1:M 25 Jan 21:04:21.770 - stomp: send heart-beat.
drone-agent_1   | 1:M 25 Jan 21:04:21.870 - stomp: received heart-beat
drone-agent_1   | 1:M 25 Jan 21:04:51.765 - stomp: send heart-beat.
drone-agent_1   | 1:M 25 Jan 21:04:51.867 - stomp: received heart-beat
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Alright. So that actually gave me something useful. From this point I opened up Kitematic, just to see the instances and have an easy to navigate to the UI.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/drone-io/kitematic.png&quot; alt=&quot;Kitematic Display&quot;&gt;&lt;/p&gt;
&lt;p&gt;There were the running instances. I clicked on the link for the UI on the server and immediately it served up my request.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/drone-io/welcome_drone.png&quot; alt=&quot;Welcome Drone!&quot;&gt;&lt;/p&gt;
&lt;p&gt;At this point I’m ready to get going on some builds. More on that in a coming article, for now I’m gonna go enjoy good talk on machine learning and a beer with the &lt;a href=&quot;https://twitter.com/search?q=%23seascale&quot;&gt;#SEASCALE&lt;/a&gt; crew. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Data Diluvium, Getting Started</title>
      <link>http://adron.github.io/articles/data-diluvium-getting-started/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/data-diluvium-getting-started/</guid>
      <author></author>
      <description>&lt;p&gt;Welcome to the first of more than a few blog entries on Data Diluvium. Data Diluvium is a project I’ve started focused around generating data for the purposes of testing, capacity, or whatever other needs might arise.&lt;/p&gt;
&lt;p&gt;Definition of &lt;strong&gt;&lt;em&gt;data&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;:  factual information (as measurements or statistics) used as a basis for reasoning, discussion, or calculation &lt;the data is plentiful and easily available — H. A. Gleason, Jr.&gt; &lt;comprehensive data on economic growth have been published — N. H. Jacoby&gt;&lt;/li&gt;
&lt;li&gt;:  information output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful&lt;/li&gt;
&lt;li&gt;:  information in numerical form that can be digitally transmitted or processed&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Definition of &lt;strong&gt;&lt;em&gt;deluge&lt;/em&gt;&lt;/strong&gt; which is the English version of the latin &lt;strong&gt;&lt;em&gt;diluvium&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;a :  an overflowing of the land by water. b :  a drenching rain “a deluge causing mudslides in the area”.&lt;/li&gt;
&lt;li&gt;:  an overwhelming amount or number &lt;received a deluge of angry phone calls&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;…thus &lt;strong&gt;&lt;em&gt;Data Diluvium&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The idea is to build a data generation service. Something that will generate random data in usable chunks; name generation, addresses, and related data. To get a wide range of use out of this capability I needed to build a web service application and a respective CLI (Command Line Interface) to go along with the web application.&lt;/p&gt;
&lt;h2 id=&quot;a-microservice-is-born-&quot;&gt;A Microservice is Born!&lt;/h2&gt;
&lt;p&gt;The web service is going to generate pseudo-random data around name, addresses, phone numbers, and location. Over the course of this series I’ll add more data generation types and implement a schema for the actual data generation. This web service will be created based on microservice architectural and design ideas. However in the early stages of this effort I’ll keep it simple and will stick to implementing a minimally viable product (MVP). From here on out I’ll refer to this project as the &lt;em&gt;Data
Diluvium&lt;/em&gt; project.&lt;/p&gt;
&lt;h2 id=&quot;microservice-client-cli&quot;&gt;Microservice Client CLI&lt;/h2&gt;
&lt;p&gt;For the client side, I want to provide a CLI in which to interface with the microservice itself. With this CLI I want to be able to provide basic configuration or passed parameters that will allow me to take the generated data and pass it directly into terminal output, out to a file, or prospectively as things develop directly into databases of various kinds themselves.&lt;/p&gt;
&lt;h2 id=&quot;the-tooling-language&quot;&gt;The Tooling &amp;amp; Language&lt;/h2&gt;
&lt;p&gt;Overall this could be built in a number of technology stacks. I could use Node.js, .NET, Java, Erlang, or Go to build both the CLI and the microservice. With the multitude of choices it can be somewhat difficult picking the right stack to get things done as quickly, efficiently, well organized, and cleanly as possible. For this particular effort I’m going to go with Go to implement the microservice and the CLI.&lt;/p&gt;
&lt;p&gt;Why Go you might ask? For the CLI, I’d want a cleanly built, fast, and responsive CLI that I can setup on any machine with minimal fuss. For Node.js for instance, one doesn’t get a built executable, but instead a kind of morass of tooling, and preinstallation software required. For Java and .NET one ends up with a great array of tooling to build a microservice and CLI, but the knowledge and time just to setup the initial development environments leads me away from those. With Erlang, maybe a day in the future, since it is indeed hugely and almost mystically powerful (yes, I just wrote mystically, it sounds appropriate).&lt;/p&gt;
&lt;h2 id=&quot;kick-off&quot;&gt;Kick Off&lt;/h2&gt;
&lt;p&gt;First things first, I need the projects themselves. Here are the steps I took to get some basic parts building together for the two projects. The first step was simply to create two directories for each of these projects, one I named &lt;em&gt;Data
Diluvium&lt;/em&gt; and one &lt;em&gt;Colligere&lt;/em&gt;. Inside both of those directories I put together a basic structure for each of these folders.&lt;/p&gt;
&lt;h3 id=&quot;basic-project-files&quot;&gt;Basic Project Files&lt;/h3&gt;
&lt;p&gt;The frame of each included the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I created a folder titled &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/tree/master/.github&quot;&gt;.github&lt;/a&gt;&lt;/em&gt; and placed the following files: &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/.github/CONTRIBUTING.md&quot;&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/em&gt;, &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/.github/ISSUE_TEMPLATE.md&quot;&gt;ISSUE_TEMPLATE.md&lt;/a&gt;&lt;/em&gt;, and &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/.github/PULL_REQUEST_TEMPLATE.md&quot;&gt;PULL_REQUEST.md&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next the standard &lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/.gitignore&quot;&gt;.gitignore&lt;/a&gt; file with the following contents. This is the basic file Github starts a Go project with if selected during the creation of the repository. It has the minor addition of &lt;em&gt;.DS_Store&lt;/em&gt; to keep that OS-X file out of the repository and the &lt;em&gt;.idea&lt;/em&gt; director to keep out the IntelliJ, WebStorm, or Goland IDE (or any Jetbrains IDE) settings directory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;# Compiled Object files, Static and Dynamic libs (Shared Objects)
*.o
*.a
*.so

# Folders
_obj
_test

# Architecture specific extensions/prefixes
*.[568vq]
[568vq].out

*.cgo1.go
*.cgo2.c
_cgo_defun.c
_cgo_gotypes.go
_cgo_export.*

_testmain.go

*.exe
*.test
*.prof

.DS_Store
.idea
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I added the &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/LICENSE&quot;&gt;LICENSE&lt;/a&gt;&lt;/em&gt; file with the standard Apache 2.0 license legalese.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally the &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/README.md&quot;&gt;README.md&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;build-files&quot;&gt;Build Files&lt;/h3&gt;
&lt;p&gt;It is important at this stage to create a build and get that build passing with some basic element of code. At this point I need some basic executing code and the respective build configuration files. For this I’ll create three files and name them respectively: &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/main.go&quot;&gt;main.go&lt;/a&gt;&lt;/em&gt;, &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/codeship-steps.yml&quot;&gt;codeship-steps.yml&lt;/a&gt;&lt;/em&gt;, and &lt;em&gt;&lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/codeship-services.yml&quot;&gt;codeship-services.yml&lt;/a&gt;&lt;/em&gt;. In addition to the code, since I was going to be pulling in dependencies I’d need something to handle that, which I went ahead and chose &lt;a href=&quot;https://github.com/Masterminds/glide&quot;&gt;glide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I installed glide with the following commands on my OS-X machine, but since I am doing a lot of development on my new &lt;a href=&quot;http://adron.github.io/articles/data-diluvium-getting-started/&quot;&gt;Leopard WS&lt;/a&gt; machine I installed glide with the curl command below.&lt;/p&gt;
&lt;p&gt;Install with brew.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;brew update
brew install glide
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The curl installation step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl https://glide.sh/get | sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With glide installed I ran the default initialization command &lt;code&gt;glide create&lt;/code&gt; to get a &lt;code&gt;glide.yaml&lt;/code&gt; and &lt;code&gt;glide.lock&lt;/code&gt; file setup. Running this command will display the following via the CLI.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ glide create
[INFO]  Generating a YAML configuration file and guessing the dependencies
[INFO]  Attempting to import from other package managers (use --skip-import to skip)
[INFO]  Scanning code to look for dependencies
[INFO]  --&amp;gt; Found reference to github.com/Masterminds/semver
[INFO]  --&amp;gt; Found reference to github.com/Masterminds/vcs
[INFO]  --&amp;gt; Found reference to github.com/codegangsta/cli
[INFO]  --&amp;gt; Found reference to gopkg.in/yaml.v2
[INFO]  Writing configuration file (glide.yaml)
[INFO]  Would you like Glide to help you find ways to improve your glide.yaml configuration?
[INFO]  If you want to revisit this step you can use the config-wizard command at any time.
[INFO]  Yes (Y) or No (N)?
n
[INFO]  You can now edit the glide.yaml file. Consider:
[INFO]  --&amp;gt; Using versions and ranges. See https://glide.sh/docs/versions/
[INFO]  --&amp;gt; Adding additional metadata. See https://glide.sh/docs/glide.yaml/
[INFO]  --&amp;gt; Running the config-wizard command to improve the versions in your configuration
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then ran &lt;code&gt;glide get github.com/icrowley/fake&lt;/code&gt; to get the fake library I would need. The &lt;code&gt;glide.yaml&lt;/code&gt; and &lt;code&gt;glide.lock&lt;/code&gt; looked like this after I pulled in this library.&lt;/p&gt;
&lt;p&gt;glide.yaml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-yaml&quot;&gt;&lt;span class=&quot;attr&quot;&gt;package:&lt;/span&gt; github.com/adron/datadiluvium
&lt;span class=&quot;attr&quot;&gt;import:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;- package:&lt;/span&gt; github.com/icrowley/fake
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;glide.lock&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-yaml&quot;&gt;&lt;span class=&quot;attr&quot;&gt;hash:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;fd78ca8369405d5998e65ea4cfce94c6599e878c36fec39b85fd385552392d7
&lt;span class=&quot;attr&quot;&gt;updated:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;2017&lt;/span&gt;&lt;span class=&quot;bullet&quot;&gt;-01&lt;/span&gt;&lt;span class=&quot;bullet&quot;&gt;-09&lt;/span&gt;T01:&lt;span class=&quot;number&quot;&gt;04&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;18.134993358&lt;/span&gt;&lt;span class=&quot;bullet&quot;&gt;-08&lt;/span&gt;:&lt;span class=&quot;number&quot;&gt;00&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;imports:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;- name:&lt;/span&gt; github.com/icrowley/fake
&lt;span class=&quot;attr&quot;&gt;  version:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;84&lt;/span&gt;bff6d01560fb0b5a396ba29534e93fd00d09c6
&lt;span class=&quot;attr&quot;&gt;testImports:&lt;/span&gt; []
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re curious about the hash, and related properties of this file check out the glide &lt;a href=&quot;https://github.com/Masterminds/glide/blob/master/README.md&quot;&gt;README.md&lt;/a&gt;, it’s useful in understanding what’s stored here.&lt;/p&gt;
&lt;p&gt;At this point, it was time to actually sling some Go code! At this point, I do indeed mean sling some too. Splat!&lt;/p&gt;
&lt;h3 id=&quot;some-go-code&quot;&gt;Some Go Code&lt;/h3&gt;
&lt;p&gt;In the main.go file I wrote some basic Go code just to have something to build. I wanted a little bit more than just a &lt;em&gt;Hello World!&lt;/em&gt; code sample so I added a little bit more. I did some research and found the &lt;a href=&quot;https://github.com/icrowley/fake&quot;&gt;Fake&lt;/a&gt; library written by Dmitry Afanasyev from Ulyanovsk, Russia. I used &lt;code&gt;Go get&lt;/code&gt; to pull that into the project and then added an &lt;code&gt;import&lt;/code&gt; after &lt;code&gt;package main&lt;/code&gt; with the various bits of code I’d want for my getting started code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
    &lt;span class=&quot;string&quot;&gt;&quot;encoding/json&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;io/ioutil&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;os&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;github.com/icrowley/fake&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;time&quot;&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The other libraries I knew I would need for various other output, date stamps, and other library features I’d want. Then I went to coding, my first sample of working code to prove out key functionality of the libraries looked like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;type Page struct {
    Title string &lt;span class=&quot;string&quot;&gt;`json:&quot;title&quot;`&lt;/span&gt;
    Schema   string &lt;span class=&quot;string&quot;&gt;`json:&quot;schema&quot;`&lt;/span&gt;
}

func (p Page) toString() string {
    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; toJson(p)
}

func toJson(p interface{}) string {
    bytes, &lt;span class=&quot;attr&quot;&gt;err&lt;/span&gt; := json.Marshal(p)
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != nil {
        fmt.Println(err.Error())
        os.Exit(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)
    }
    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; string(bytes)
}

func main() {
    &lt;span class=&quot;attr&quot;&gt;pages&lt;/span&gt; := getPages()
    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; _, &lt;span class=&quot;attr&quot;&gt;p&lt;/span&gt; := range pages {
        fmt.Println(p.toString())
    }

    fmt.Println(toJson(pages))

    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;\nSome Russian Random Data&quot;&lt;/span&gt;)
    fake.SetLang(&lt;span class=&quot;string&quot;&gt;&quot;ru&quot;&lt;/span&gt;)
    fmt.Println(fake.FirstName())
    fmt.Println(fake.FullName())

    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;\n\n\nSome English Random Data&quot;&lt;/span&gt;)
    fake.SetLang(&lt;span class=&quot;string&quot;&gt;&quot;en&quot;&lt;/span&gt;)
    fmt.Println(fake.FirstName())
    fmt.Println(fake.FullName())

    thisMany := &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;
    counter := &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;
    t := time.Now().Format(time.RFC850)

    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;\n\n\nPrinting&quot;&lt;/span&gt;, thisMany)

      &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i := &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i &amp;lt; thisMany; i++ {
      fmt.Println(counter, fake.FirstName())
      counter += &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;
      fake.FirstName()
      }

    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;Start Time: &quot;&lt;/span&gt;, t)
    t = time.Now().Format(time.RFC850)
    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;End Time: &quot;&lt;/span&gt;, t)
}

func getPages() []Page {
    raw, &lt;span class=&quot;attr&quot;&gt;err&lt;/span&gt; := ioutil.ReadFile(&lt;span class=&quot;string&quot;&gt;&quot;./deluge.json&quot;&lt;/span&gt;)
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != nil {
        fmt.Println(err.Error())
        os.Exit(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)
    }

    &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; c []Page
    json.Unmarshal(raw, &amp;amp;c)
    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; c
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, this all was a small mess at this point. I know I needed to get it cleaned up. However the &lt;em&gt;priority&lt;/em&gt; at this point is to get a build working that will provide a trusted basis to continue work from. Since I intend to use this to teach, for everyday testing, and hopefully to gain contributors (want to help?) it needs to have a good build, end of story.&lt;/p&gt;
&lt;h2 id=&quot;continuous-integration-build&quot;&gt;Continuous Integration Build&lt;/h2&gt;
&lt;p&gt;At this point I have the main.go file executing with some Go code that pulls together some functionality on random data generation, file I/O (at least reading) with a JSON file for config, and displaying this out the console. So far, so good.&lt;/p&gt;
&lt;p&gt;I’ve decided to use &lt;a href=&quot;https://codeship.com&quot;&gt;Codeship&lt;/a&gt; for this particular project. They’re a service provider the specializes in continuous integration and delivery services, and I might add that they’re good at it (* Also note declarations, etc at the bottom of this blog entry).&lt;/p&gt;
&lt;p&gt;Two significant reasons I like to use Codeship are: remote builds &amp;amp; deploys with Docker and local builds with Docker. Having that combination is very effective, providing the capability to effectively to builds that include systemic deployments to my own local machine in addition to combining efforts with a prospective team together via the remote build.&lt;/p&gt;
&lt;h3 id=&quot;ci-service-setup-at-codeship&quot;&gt;CI Service Setup at Codeship&lt;/h3&gt;
&lt;p&gt;To setup the repository on Codeship for &lt;em&gt;Docker&lt;/em&gt; support I went through these steps.&lt;/p&gt;
&lt;p&gt;First select create new project. This is up on the Select Project bar or if you’ve just signed up it is available as the default screen when navigating to builds. Codeship just added &lt;a href=&quot;https://about.gitlab.com/&quot;&gt;Gitlab&lt;/a&gt; as a repository option recently, which I opted for the Data Diluvium Client, &lt;a href=&quot;https://gitlab.com/adron/colligere&quot;&gt;Colligere&lt;/a&gt;, using Gitlab just to test it out. At this time I really like my experience with Gitlab, but that’s for another blog entry, for now, onward!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/data-diluvium-getting-started/codeship01.png&quot; alt=&quot;Codeship Docker Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next enter the path for the git repo.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/data-diluvium-getting-started/codeship02.png&quot; alt=&quot;Codeship Docker Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Select pro infrastructure. This will provide Docker capabilities.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/data-diluvium-getting-started/codeship03.png&quot; alt=&quot;Codeship Docker Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Then it is time to setup the Docker configuration and yaml files for the build. The page at this point on Codeship has some links and such, for the two yaml files needed, but I’ll describe them here in detail a bit. In the image below a quick review of each element of the page: (1), the project settings, which will navigate to an area to setup notification, configure and add team members, repository details or reconnecting to a different repository, and general settings, which can be navigated to via (2), and (3) lists the current project the settings are displaying and available for changing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/data-diluvium-getting-started/codeship.png&quot; alt=&quot;Codeship Docker Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once the build project is setup in Codeship there are two files that are needed in the repository itself. Both of these files are simple yaml files. Each are given a default name of &lt;code&gt;codeship-steps.yaml&lt;/code&gt; and &lt;code&gt;codeship-services.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;codeship-steps.yaml&lt;/code&gt; file has the following steps listed for this project. I’ve associated these to a service called &lt;em&gt;deluge_svc&lt;/em&gt; which will be defined in the &lt;code&gt;codeship-services.yaml&lt;/code&gt; file. Then the commands, in order, are &lt;code&gt;go clean&lt;/code&gt;, &lt;code&gt;go test ./...&lt;/code&gt;, and &lt;code&gt;go build&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;- name: deluge
  service: deluge_svc
  command: go clean
- name: deluge_tests
  service: deluge_svc
  command: go test ./...
- name: deluge_build
  service: deluge_svc
  command: go build
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next file is &lt;code&gt;codeship-services.yaml&lt;/code&gt; and has the following contents.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;deluge_svc:
  build:
    image: deluge
    dockerfile_path: Dockerfile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This simply gives the service a name, which in this case is &lt;code&gt;deluge_svc&lt;/code&gt; and then points to which Docker image will be used and which Dockerfile will build that image. Here I’ve just placed Dockerfile as the file, and next will put together the Dockerfile.&lt;/p&gt;
&lt;h3 id=&quot;dockerfile&quot;&gt;Dockerfile&lt;/h3&gt;
&lt;p&gt;The Dockerfile I put together is based off of the official golang image, with the tag specific for the 1.7.4-alpine build. The Alpine build is basically a Linux image that is about ~10MB, maybe a little more or a little less depending on what needs to be added to the image to run the service.&lt;/p&gt;
&lt;p&gt;In the case of the Data Diluvium App I’ve added a few things that will be needed in order to get the build working. The complete Dockerfile is below, but below that I’ll break out what is going on and what I needed to do to implement this Docker image to run as a container for the build (and by proxy any production use of the same image).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-docker&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; golang:&lt;span class=&quot;number&quot;&gt;1.7&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;-alpine

&lt;span class=&quot;keyword&quot;&gt;ENV&lt;/span&gt; GOPATH /go

&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; mkdir /app &amp;amp;&amp;amp; \
    apk add --update curl &amp;amp;&amp;amp; \
    rm -rf /var/cache/apk/*
&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;ADD&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; . /app/
&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; /app
&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; apk update &amp;amp;&amp;amp; apk upgrade &amp;amp;&amp;amp; \
  apk add --no-cache git &amp;amp;&amp;amp; \
  curl https://glide.sh/get | sh
&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; glide up &amp;amp;&amp;amp; go get github.com/icrowley/fake &amp;amp;&amp;amp; \
  go build
&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; [&lt;span class=&quot;string&quot;&gt;&quot;/app/datadiluvium&quot;&lt;/span&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first part of the file sets the official golang image and immediately after that I set the actual $GOPATH environment variable on the image.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-docker&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; golang:&lt;span class=&quot;number&quot;&gt;1.7&lt;/span&gt;.&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;-alpine

&lt;span class=&quot;keyword&quot;&gt;ENV&lt;/span&gt; GOPATH /go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I install curl with Alpine’s apk and clear out the apk cache.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-docker&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; mkdir /app &amp;amp;&amp;amp; \
    apk add --update curl &amp;amp;&amp;amp; \
    rm -rf /var/cache/apk/*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next are some very specific steps, which I’m not sure really meet a good practice, but it’s what I needed to do in the moment to get things working. The first steps here is simply adding the app directory, then setting it as the WORKDIR. Next I update apk again and upgrade the cache before installing glide. I’m not sure if this is absolutely necessary but I was running into errors and things not executing until I broke apart this section from the aforementioned section.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-docker&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ADD&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; . /app/
&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;WORKDIR&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; /app
&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;RUN&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; apk update &amp;amp;&amp;amp; apk upgrade &amp;amp;&amp;amp; \
  apk add --no-cache git &amp;amp;&amp;amp; \
  curl https://glide.sh/get | sh&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With glide installed it was time to grab the dependencies for the Docker image with &lt;code&gt;glide up&lt;/code&gt; and for some reason, even though it’s in the glide yaml file I still had to specifically call out the &lt;code&gt;go get github.com/icrowley/fake&lt;/code&gt; library before executing the &lt;code&gt;go build&lt;/code&gt; step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-docker&quot;&gt;UN glide up &amp;amp;&amp;amp; go get github.com/icrowley/fake &amp;amp;&amp;amp; \
  go build
&lt;span class=&quot;keyword&quot;&gt;CMD&lt;/span&gt;&lt;span class=&quot;bash&quot;&gt; [&lt;span class=&quot;string&quot;&gt;&quot;/app/datadiluvium&quot;&lt;/span&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that done, I could then finally run a build that encompassed all elements of what I’ve built so far. I did this simple with a &lt;code&gt;jet steps&lt;/code&gt; command and realized I’d missed the steps needed to actually &lt;a href=&quot;https://documentation.codeship.com/pro/getting-started/installation/#jet&quot;&gt;install the jet CLI&lt;/a&gt;. Since this first build I was working on, was actually on Ubuntu Linux, I followed these steps for getting the Jet CLI installed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl -SLO &amp;quot;https://s3.amazonaws.com/codeship-jet-releases/1.15.4/jet-linux_amd64_1.15.4.tar.gz&amp;quot;
sudo tar -xaC /usr/local/bin -f jet-linux_amd64_1.15.4.tar.gz
sudo chmod +x /usr/local/bin/jet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However there is a brew cask that can be used to install jet with too. It’s a one line command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew cask install jet
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, that should get those following along with a running build too. There is of course the prereq of having git and docker installed too, I’ll admit I keep making the mistake of assuming those things are installed everywhere. So if you hit a hiccup at this point, it may be because those two things need installed - which likely will have caused errors far before this.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;jet steps&lt;/code&gt; running the build locally, I can now navigate to Codeship and check out the build when I commit all of this work.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;git add -A
git commit -m &amp;#39;First code all wrapped up.&amp;#39;
git push origin master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…and that’s it for this entry. Hope that’s useful for getting your own Go project started. If you’re interested, definitely ping me if you’d like to work on Data Diluvium some too. I’m looking for help.&lt;/p&gt;
&lt;p&gt;Cheers!  -Adron&lt;/p&gt;
&lt;h4 id=&quot;declarations-references&quot;&gt;Declarations &amp;amp; References&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Codeship - I’ve worked for Codeship providing technical writing and good coding fun with the crew there. They’re not currently paying me, but I will likely do more work for them, so take that into account when judging my judgement of their products. As always, I’m not into any shill work and wanted you dear reader, to have full clarity into my use of the tech. Cheerio!&lt;/li&gt;
&lt;li&gt;Collected Links - &lt;a href=&quot;https://codeship.com/&quot;&gt;Codeship&lt;/a&gt;, &lt;a href=&quot;http://datadiluvium.com/&quot;&gt;Data Diluvium&lt;/a&gt;, &lt;a href=&quot;https://github.com/Adron/datadiluvium&quot;&gt;Data Diluvium Github Project&lt;/a&gt;, &lt;a href=&quot;https://gitlab.com/adron/colligere&quot;&gt;Colligere&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Autodidact Learning, For the Hacker at Heart</title>
      <link>http://adron.github.io/articles/autodidact-learning/</link>
      <pubDate>Sun, 22 Jan 2017 00:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/autodidact-learning/</guid>
      <author></author>
      <description>&lt;p&gt;I always aim to be a good a student and teacher. To be a proficient and effective student and teacher, I’ve realized long ago I must strive to be good at both. Without this effort, I’d never truly understand or gain proficiency in either position.&lt;/p&gt;
&lt;p&gt;In addition to striving to improve myself as a student or teacher, I always finds myself continuously learning. There is never a known end, as I’m always searching for a new best, a new level of proficiency, or even a new definition of what these things are. As such, I work diligently to take mental notes during my own efforts to become a better teacher or to improve my study as a student. It’s hard work, as most things that are worthwhile in life are. This hard work however, is definitely one of the top things I enjoy in life. Learning to me is something I cherish in the extreme!&lt;/p&gt;
&lt;p&gt;On that note, here’s a few of the things that I’ve found that have helped me to learn effectively. I offer them as is, and everybody’s use may vary in effectiveness. If you’ve got any suggestions or practices of your own, please email, tweet (&lt;a href=&quot;https://twitter.com/adron&quot;&gt;@Adron&lt;/a&gt;), or message me with them. I’m always happy to discuss new ways two to better my learning and teaching.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-notes-note-taking-in-projects&quot;&gt;1. Notes / Note Taking in Projects&lt;/h2&gt;
&lt;p&gt;One thing I’ve found very useful in software projects is to find a way to take parallel notes. These could be perceived as &lt;em&gt;comments&lt;/em&gt; except I’ve made a few slight modifications. Instead of adding these in code files, they’re more project or project folder specific comments, so I don’t place the files in comments in actual code files. The following is a list of characteristics of where I put these notes and the practices I follow to create them.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://github.com/adron/datadiluvium&quot;&gt;&lt;img src=&quot;/articles/autodidact-learning/notesmd-files.png&quot; alt=&quot;NOTES.md&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Where&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’ve found, when working through a project I like to have two specific spaces where notes go. One is in the root and any directories of the project where there are additional snippets of information needed. I usually just title these files &lt;em&gt;NOTES.md&lt;/em&gt; and encourage anybody involved in the project to add their own personal notes for anybody to read. This adds context of what is going on and helps provide insight for anybody working in a project.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I tend to write notes as quick blurbs of what is in the directory or project, notes that wouldn’t particularly be in a README.md file. They’re more of a &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Stream_of_consciousness_(narrative_mode&quot;&gt;stream of consciousness&lt;/a&gt;)&lt;/em&gt; style. The primary focus is to write them concise, but quicly, for future reference. Helping to prevent one from forgetting what and why certain things are in a directory, specifically a directory in which is manually created for documentation or something somewhat outside of the normal application code flow, similar to &lt;a href=&quot;https://github.com/Adron/datadiluvium/blob/master/docs/hugo/NOTES.md&quot;&gt;this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In a Go, C#, Java, C, C++, or related compilable language these files don’t get built into the final binary. However in something like JavaScript the files may get included when zipped up to be deployed or may increase the likelihood of secrets or other information that should not be public becoming public. By association be sure that these files won’t cause an actual problem later on in the project. Generally there’s a small chance compared to the advantage of actually having some relevant project notes inside the actual project. But one has to keep these responsibilities in mind.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Take notes in projects (even trash projects, as I write about below). Write from a &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Stream_of_consciousness_(narrative_mode&quot;&gt;stream of consciousness&lt;/a&gt;)&lt;/em&gt; style and it will work to reinforce what you’re observing and learning in the projects as well as working to provide a path to understanding for prospective maintainers in ongoing projects!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;2-trash-projects&quot;&gt;2. Trash Projects&lt;/h2&gt;
&lt;p&gt;When learning, one of the best ways to get used to how parts of a language and respective technology stack perform and behave is to actually build things with the language and respective tech stack. For instance, when learning JavaScript I wrote a lot of completely garbage code just to try out the language. Sure, I had read things like &lt;em&gt;&lt;a href=&quot;http://shop.oreilly.com/product/9780596517748.do&quot;&gt;JavaScript: The Good Parts&lt;/a&gt;&lt;/em&gt; and even the gargantuan &lt;em&gt;&lt;a href=&quot;http://shop.oreilly.com/product/9780596805531.do&quot;&gt;JavaScript: The Definitive Guide&lt;/a&gt;&lt;/em&gt;, but I really had not set certain things into memory until I started writing code.&lt;/p&gt;
&lt;p&gt;One example, if I check for the type of NaN (Not a Number) I get ‘number’. That does’t really make logical sense based on what NaN stands for. But alright, what about NaN equaling NaN? That’s false, even though it clearly appears as if it is the same thing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&amp;gt; &lt;span class=&quot;keyword&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;NaN&lt;/span&gt;
&lt;span class=&quot;string&quot;&gt;'number'&lt;/span&gt;
&amp;gt; &lt;span class=&quot;literal&quot;&gt;NaN&lt;/span&gt;==&lt;span class=&quot;literal&quot;&gt;NaN&lt;/span&gt;
&lt;span class=&quot;literal&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are side effects, while reading the guides and good parts books I wouldn’t have realized without actually testing the code and realizing these oddities exist. Of course when I stop and think, having read the material in the books, I realize that NaN does not equal NaN because these are two different actual objects, part of the crux of mutable imperative object creation eh!&lt;/p&gt;
&lt;p&gt;So building tons of throwaway trash projects is hugely important. I have to fight against the urge to “build a cool working project that does X and open source it” syndrome and just focus on testing out bits of code a time until I can effectively and proficiently write are large degree of functionality using the features and concepts inherent to a language and the underlying technology stack. The best and quickest way isn’t to fight building a larger projet but instead build many small &lt;em&gt;trash projects&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Build lots and lots of trash projects to focus in on the behavior and features of a language or technology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;3-when-beginning-skip-videos&quot;&gt;3. When Beginning, Skip Videos&lt;/h2&gt;
&lt;p&gt;I suppose it depends on what one’s learning style really is and it is also odd coming from me that I’d say skip videos (because of &lt;a href=&quot;https://www.pluralsight.com/authors/adron-hall&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://vimeo.com/channels/thrashingcode&quot;&gt;this&lt;/a&gt;). Even though I produce Videos and find they can be used to learn things, there’s a catch. Video content is generally horrible at providing large amounts of information with specific detail in the time it takes to watch a video. There are certain nuances that video is good at, but overall they just don’t work for effective, quick, and intensive deep dives into particular technology.&lt;/p&gt;
&lt;p&gt;In that vein, videos are horrible as stand alone learning mediums, skip them. Focus on written material, with details about things and going back to &lt;em&gt;trash projects&lt;/em&gt; create and work with hands on implementation of code and technologies. If a video is a small complement or has lots of written collateral, testing, and other mediums used in conjunction with the video it might work out ok, but otherwise focus on other things and skip the videos when starting in on a new language or tech.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Skip videos when starting out and gain some proficiency around actual implementation first, this has worked excellently for me and I’ve found it tends to work well for gaining productiveness quickly with a language or technology.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;4-mixing-theory-implementation&quot;&gt;4. Mixing Theory &amp;amp; Implementation&lt;/h2&gt;
&lt;p&gt;As above I mentioned focusing on implementation of code, referring to it as &lt;em&gt;trash projects&lt;/em&gt;, which is a great way to really dig into the nuances of things. However at a certain point the theory of particular design practices and languages must be understood or a solid proficiency just isn’t going to be attained. That’s where mixing theory and implementation becomes fundamental. I’ve found that I need to do more reading on the why and what for of a language or technology once I’ve gotten fairly fluent in implementing things with a language or technology.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When learning, once proficient with a language, be sure to dive deep into why and how the language actually works to gain even more proficiency with the language.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    <item>
      <title>Buying a Leopard!</title>
      <link>http://adron.github.io/articles/system76-ubuntu-leopard-workstation/</link>
      <pubDate>Thu, 19 Jan 2017 00:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/system76-ubuntu-leopard-workstation/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-small.png&quot; alt=&quot;System76&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;em&gt;January 24th, 2017 UPDATE: After I wrote this, I spoke with the System 76 team and I’m getting the chance to go out and tour their Denver Headquarters. This happened well after I made my purchase, which all of the following was written after. But just for full transparency, I’ve added this note. Also, I’m aiming to get a full write up of my System76 trip put together with Denver tidbits and more! Until then, here’s the review…&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the trailing days of 2016, after having moved to Redmond, Washington I sat working at my desktop workstation. This workstation, which still exists, is a iMac with an i7, 16GB RAM, 256 GB SSD, and a 1GB Video Card with a 1TB secondary drive. The machine is a 27” all in one style design, and the screen is rather beautiful. But as I did a build and tried to run Transport Tycoon at the same time in the background the machine sputtered a bit. It was definitely maxed out doing this Go code build, putting together a Docker image build, and spinning it up for go live at the same time my game ran in the background. I thought, this machine has served me extremely well, at over 5 years old it had surpassed the standard 5 year lifespan of peak Apple oomf. At the moment, I thought, maybe it’s time to dig into a serious machine with some premium hardware again.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In that moment I thought about the last dedicated, custom built, super powerful workstation machine I had. It was a powerful machine, nice form factor, and easily drove two giant 27” screens. However this machine had lived and finished it’s useful life over 6 years before 2016 had even started. But it was a sweet machine, that offered a lot of productive gaming and code writing efficiencies. It was thus, time to get in gear and get a machine again.&lt;/p&gt;
&lt;p&gt;Immediately I thought through a few of the key features I wanted and other prerequisites of purchase.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Enough RAM and processor power to drive my aforementioned gaming, docker, and code building scenario with ease.&lt;/li&gt;
&lt;li&gt;SSD drive of at least 1TB with at least a beefy 8GB Video Card.&lt;/li&gt;
&lt;li&gt;It needed to run, with full support, not-Windows. Ubuntu would be fine, but if any Linux was installed from factory or at least fully supported on the hardware I put together, that would suffice.&lt;/li&gt;
&lt;li&gt;If I were to buy it from a company, it had to be a company that wasn’t some myopic afterthought of 50s era suburbia (i.e. I didn’t really want to deal with Dell or Alienware again after the XPS 13 situation). This definitely narrowed down the options.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I started digging into hardware specifications and looking into form factors, cases, and all the various parts I’d need for a solid machine. In parallel I started checking out several companies.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://system76.com/&quot;&gt;System76&lt;/a&gt; - Located in Denver, I was curious about this company and had been following them for some time. I had seen a few of the laptops over the years but had never seen or used any of their desktops.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://lacpdx.com&quot;&gt;Los Alamos Computers&lt;/a&gt; which is now &lt;a href=&quot;https://lacpdx.com&quot;&gt;LAC Portland&lt;/a&gt;! - Holy smokes, I had not realized this company moved. They definitely meet the 4th criteria above.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.pugetsystems.com/&quot;&gt;Puget Systems&lt;/a&gt; is a company located somewhere in the Puget Sound area and used to be called Puget Sound Systems. After digging I found they are located in a suburb of Seattle, in a town called Auburn. I didn’t want to rule them out so I kept them on the list and started researching.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.penguincomputing.com/&quot;&gt;Penguin Computing&lt;/a&gt; is another one of the companies, and kidn of a mainstay of Linux machines. They were a must have in the run up.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.thinkpenguin.com/&quot;&gt;Think Penguin&lt;/a&gt; is another I dove into.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://emperorlinux.com/&quot;&gt;Emperor Linux&lt;/a&gt; is another company I found specializing in Linux machines.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://zareason.com/&quot;&gt;Zareason&lt;/a&gt; was another, that specialized in Linux machines.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;first-decision-build-or-buy-&quot;&gt;First Decision &amp;gt; Build or Buy?&lt;/h2&gt;
&lt;p&gt;I wrangled hardware specifications and the idea of building my own machine for some time. I came to the conclusion that the time versus money investment for me was on the side of buying a built machine. This first decision was pretty easy, but educating myself on the latest hardware was eye opening and a lot of fun. In the end however, better to let a builder get it done right instead of me creating a catastrophe for myself and nuking a whole weekend!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Decision&lt;/strong&gt; Buy!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;second-decision-who-should-i-buy-from-&quot;&gt;Second Decision &amp;gt; Who should I buy from?&lt;/h2&gt;
&lt;p&gt;I dug through each of the computer builders previously mentioned. I scouted out where they were located, what the general process was they used to build the machines, what testing, what involvement in the community they have, and finally a cost and parts review.&lt;/p&gt;
&lt;p&gt;Each of the builders has a lot of positives in regards to Linux, the only one that I was hesitant about at first in regards to Linux was Puget Computing. Because by default the machines come with Windows 10. However after asking around and reviewing other reviews online, I came to find they do have Linux and a solid skill set around Linux. Puget remained a leader in the selection process.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/pugetsystems.png&quot; alt=&quot;Puget Systems&quot;&gt;&lt;/p&gt;
&lt;p&gt;I went through Los Alamos Computers, which I realized are now LAC Portland (Win for Portland!), then Penguin, Think Penguin, and Emperor Linux. All had great skills and ethos around Linux. LAC definitely had the preeminently preferable choice in physical location (I mean, I do love Portland!), but each were short in either their customer facing desktop options. Albeit for a company or other reason, I’d likely buy a Thinkpad or other computing platform running Linux from them. But for this scenario each were disqualified for my personal workstation.&lt;/p&gt;
&lt;p&gt;The last two I started checking out were Zareason and System76. I had been following what System76 for a while and a few things had caught my eye on their site. It led me to realize that they’re located out of Denver. Being a transit nerd, one of their website video photo coffee shop scenes had the RTD Light Rail passing in the background. But all things aside I started checking out cases and hardware that each builder puts in a box.&lt;/p&gt;
&lt;ul class=&quot;faq js-faq&quot; id=&quot;my-faq&quot;&gt;
  &lt;li class=&quot;faq-item&quot;&gt;
    &lt;h4 class=&quot;faq-question&quot;&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/berkely-bart.jpg&quot; alt=&quot;Berkely BART&quot;&gt;&lt;a href=&quot;http://zareason.com&quot;&gt;Zareason&lt;/a&gt; had several cases as shown below. With each of these I checked out the hardware options. (open for details)&lt;/h4&gt;
    &lt;div class=&quot;faq-answer&quot;&gt;
      One of the other side notes of the Zareason site is that you can navigate directly to it at the http address, and they don’t for https. I just found this a bit odd. But here’s the machines that I reviewed.
      &lt;table&gt;
        &lt;tr&gt;
        &lt;/tr&gt;
      &lt;/table&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
        &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/zareason1.jpg&quot; alt=&quot;Zareason Zeto&quot;&gt;
        &lt;a href=&quot;http://zareason.com/shop/Zeto.html&quot;&gt;Zeto&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
        &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/zareason2.jpg&quot; alt=&quot;Zareason Limbo 560&quot;&gt;
        &lt;a href=&quot;http://zareason.com/shop/Limbo-560.html&quot;&gt;Limbo 560&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
        &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/zareason3.jpg&quot; alt=&quot;Zareason Valta X99i&quot;&gt;
        &lt;a href=&quot;http://zareason.com/shop/Valta-X99i.html&quot;&gt;Valta X99i&lt;/a&gt;
      &lt;/div&gt;
      &lt;!-- ![Berkely BART](berkely-bart-.jpg) --&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li class=&quot;faq-item&quot;&gt;
    &lt;h4 class=&quot;faq-question&quot;&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/sounder.jpg&quot; alt=&quot;Sounder&quot;&gt;Next up I checked out a number of &lt;a href=&quot;https://www.pugetsystems.com&quot;&gt;Puget Systems&lt;/a&gt;. (open for details)&lt;/h4&gt;
    &lt;div class=&quot;faq-answer&quot;&gt;
      The religious reference names were a bit strange. But whatever, to each their own.
      &lt;div class=&quot;image float-left&quot;&gt;
          &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/puget3.jpg&quot; alt=&quot;Puget Systems&quot;&gt;
          &lt;a href=&quot;https://www.pugetsystems.com/deluge.php&quot;&gt;Deluge&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
          &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/puget2.jpg&quot; alt=&quot;Puget Systems&quot;&gt;
          &lt;a href=&quot;https://www.pugetsystems.com/spirit.php&quot;&gt;Spirit&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
          &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/puget1.jpg&quot; alt=&quot;Puget Systems&quot;&gt;
          &lt;a href=&quot;https://www.pugetsystems.com/genesis.php&quot;&gt;Genensis II&lt;/a&gt;
      &lt;/div&gt;
      &lt;!-- ![Sounder](sounder-.jpg) --&gt;
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li class=&quot;faq-item&quot;&gt;
    &lt;h4 class=&quot;faq-question&quot;&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/rtd1.jpg&quot; alt=&quot;RTD Light Rail&quot;&gt;Next I started looking at &lt;a href=&quot;https://www.pugetsystems.com&quot;&gt;System76&lt;/a&gt; machines. (open for details)&lt;/h4&gt;
    &lt;div class=&quot;faq-answer&quot;&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
          &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/leopardws.jpg&quot; alt=&quot;Leopard WS&quot;&gt;
          &lt;a href=&quot;https://system76.com/desktops/leopard&quot;&gt;Leopard Workstation&lt;/a&gt;
      &lt;/div&gt;
      &lt;div class=&quot;image float-left&quot;&gt;
          &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/silverback.jpg&quot; alt=&quot;Silverback WS&quot;&gt;
          &lt;a href=&quot;https://system76.com/desktops/silverback&quot;&gt;Silverback Workstation&lt;/a&gt;
      &lt;/div&gt;
      &lt;!-- ![RTD Light Rail](rtd1-.jpg) --&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After working through and reviewing prices, features, hardware, and options things were close. I started reviewing location and what I could derive about each company’s community involvement in Linux, how they’re involved locally, and what the word is about those companies in their respective communities. Out of the three, I ended up not finding any customers to talk to about Zareason. For Puget, I found one friend that had a box purchased from a few years ago, and for System76 I actually found 2 different feedback bits from users within an hour or so of diffing around.&lt;/p&gt;
&lt;p&gt;Kenny Spence &lt;a href=&quot;https://twitter.com/tekjava&quot;&gt;@tekjava&lt;/a&gt; - Kenny and I have known each other for more years than I’m going to count. We got to meetup here in Seattle recently and he showed me his System76 laptop. The build quality was good and the overall review he gave me was a &lt;em&gt;+1&lt;/em&gt;. Before this he’d mentioned in Twitter DM convo that this was the case, and I’d taken his word for it back then.&lt;/p&gt;
&lt;p&gt;Dev Shop X - A group of individuals I reached out to I had met 3 years ago at the Portland &lt;a href=&quot;https://twitter.com/osbridge&quot;&gt;@OSBridge&lt;/a&gt; Conference. I spoke to them again and found they were still using the System76 machines with no real complaints. They’d also bought the XPS 13 laptops well before the model I did and had a few complaints. With a short conversation we ended with them offering a &lt;em&gt;+1&lt;/em&gt; for System76.&lt;/p&gt;
&lt;p&gt;With the reviews from trusted sources, seeing the involvement and related culture of System76 I decided that they would be the builder of choice.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Decision&lt;/strong&gt; &lt;a href=&quot;https://system76.com&quot;&gt;System76&lt;/a&gt; &lt;a href=&quot;https://system76.com/desktops/leopard&quot;&gt;Leopard WS&lt;/a&gt;!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;leopard-workstation&quot;&gt;Leopard Workstation&lt;/h2&gt;
&lt;p&gt;With the decision made, I pulled the trigger on the purchase. In spite of the holiday season, I still received the machine in short order. It arrived at my door via UPS in a box, ya know, like a computer does when its shipped somewhere.  ;-)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-01.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;I cleared off the desk next, and dug into the box.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-02.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-03.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;The computer was packaged cleanly and neatly with minimal waste compared to some I’ve seen. So far so good. I pulled pieces gently from the box. The first thing I extracted was the static bag which had all of the extra cords and respective attachments that had come with various parts of the computer hardware that were unnecessary. Another plus in my opinion, as many would likely not notice this having not built computers themselves, nor even cared, but I’m glad to have the extra pieces for this or other things I might need them for.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-04.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next thing I pulled out of the box was a thank you letter envelope with cool sticker and related swag.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-05.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Stickers!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-07.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;That was it for peripheral things just floating around in the box. Next, out came the computer itself.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-06.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;It was wrapped in a static free bag itself. As it should be. I did notice a strange ink like bit of dusted debris in and around the box. I’m not really sure, and still am not sure today what exactly it was. I cleaned it up immediately. It wasn’t excessive, but was leaving slight marks on the white table which required a little scrubbing to remove.&lt;/p&gt;
&lt;p&gt;After all things were removed from the box I removed them from envelopes and static free bags and placed them on the desk for a simple shot of all the parts in the box.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-08.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next I went through the steps of desk cleanup again and then connected my 28 port USB Hub, Razor Mouse, and a keyboard to the machine. It was finally time to boot this machine up!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-09.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;As for the screen which you see, it’s an LG 34” Extra Wide Screen monitor with slight curved view to it. Yes, it’s awesome, and yes it actually makes it relatively easy to not need dual monitors.&lt;/p&gt;
&lt;p&gt;BOOTING!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-10.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ubuntu started, monitor fussing.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-11.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;I toyed around and had for whatever reason plugged in the HDMI, when I should have used the other monitor connection. It immediately provided more resolution options when I changed the connection and the monitor and related elements detected appropriately!&lt;/p&gt;
&lt;p&gt;On the side of the machine is a clear window cut through the case to view the internals. The cords were managed well and overall build was very clean. Upon boot up the graphics card immediately lit up too. The nice blue tone provided a nice light within the room.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-12.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Ubuntu booted up cleanly, and I might crazy bloody fast.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-13.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here’s a non-flash shot of the machine and monitor side by side.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-14.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;I then changed the respective positioning and the lighting, as you can see actually changed dramatically just by repositioning the hardware and the rear light I was shooting with.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-15.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;Lights off shot. The widow is beautiful!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-16.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;p&gt;A slightly closer shot of the GTX 1080 humming away inside.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/system76-leopard-17.jpg&quot; alt=&quot;System 76 Leopard&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;the-ubuntu-on-leopard-ws-review&quot;&gt;The Ubuntu on Leopard WS Review&lt;/h3&gt;
&lt;p&gt;So far I’ve done a ton of coding &amp;amp; game playing on the machine. Here’s a break down of some specifics and some respective comments with a full read on the specifications of the machine.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 16.10 (64-bit)&lt;/li&gt;
&lt;li&gt;4.0 GHz i7-6850K (3.6 up to 4.0 GHz – 15 MB Cache – 6 Cores – 12 threads)&lt;/li&gt;
&lt;li&gt;High Performance Self-Contained Liquid Cooler&lt;/li&gt;
&lt;li&gt;32 GB Quad Channel DDR4 at 2400MHz (2× 16 GB)&lt;/li&gt;
&lt;li&gt;8 GB GTX 1080 with 2560 CUDA Cores&lt;/li&gt;
&lt;li&gt;Chipset Intel® X99&lt;/li&gt;
&lt;li&gt;Front: 2× USB 3.0 Type-A, 1× USB 2.0 Type-A, 1× eSATA&lt;/li&gt;
&lt;li&gt;Rear: 3× USB 3.0 Type-A, 1× USB 3.1 Type-A, 1× USB 3.1 Type-C, 4× USB 2.0, Type-A, 1× PS/2&lt;/li&gt;
&lt;li&gt;Gigabit Ethernet, optional Intel® Wireless-AC (a/b/g/n/ac)&lt;/li&gt;
&lt;li&gt;GTX 1080: DVI-D, HDMI, 3× Display Port&lt;/li&gt;
&lt;li&gt;Audio Front: Headphone Jack, Mic Jack&lt;/li&gt;
&lt;li&gt;Audio Rear: 8 channel (HDMI, S/PDIF), Mic Jack, Line In, Line Out&lt;/li&gt;
&lt;li&gt;Power Supply 750 W 80+ Certified (80% or greater power efficiency)&lt;/li&gt;
&lt;li&gt;Dimensions 15.8″ × 8.3″ × 19.5″ (40.13 × 21.08 × 49.53cm)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;gaming&quot;&gt;Gaming&lt;/h4&gt;
&lt;p&gt;Using Steam I downloaded several games including my latest addiction Transport Tycoon. The others included Warhammer 40k: Dawn of War, Stronghold 3, Stellaris, Sid Meier’s Civ V, Master of Orion, and Cities: Skylines. Each of these games I loaded up and played for at least 20-30 minutes, with every graphics detail maxed out and full audio feature enabled. Where the option existed to run it at full resolution of     3440x1440 I ran the game at that resolution.&lt;/p&gt;
&lt;p&gt;Not a blip, stir, or flake out of any sort. The color was solid (which obviously is also largely the monitor) and being able to move around these games in their respective 3d worlds was exception. All the while the speed of elapsed time in games like Transport Tycoon and Cities: Skylines barely slowed at all no matter how massive the city or layout was.&lt;/p&gt;
&lt;p&gt;At this point I’ve also added about 16 hours of Transport Tycoon play to this, and I’ve built absurdly extensive layouts (100s of trains plus massively grown cities) and this processor and video card handles it. The aforementioned previous desktop easily choked to 1/10th the speed of this beast while running the game.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;More on the gaming elements of this machine in the coming days.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;coding&quot;&gt;Coding&lt;/h4&gt;
&lt;p&gt;I used &lt;a href=&quot;https://www.jetbrains.com/toolbox/&quot;&gt;Jetbrains Toolbox&lt;/a&gt; to download &lt;a href=&quot;https://www.jetbrains.com/idea/&quot;&gt;IntelliJ&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/webstorm/&quot;&gt;Webstorm&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/clion/&quot;&gt;CLion&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/datagrip/&quot;&gt;DataGrip&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/rider/&quot;&gt;Project Rider&lt;/a&gt;, and &lt;a href=&quot;https://www.jetbrains.com/ruby/&quot;&gt;RubyMine&lt;/a&gt;. I dug around for some sample projects and slung together some basic “hello world!” apps to build with each of the IDEs. All built at absurd rates, but nothing real specific as I didn’t load any large projects just yet.&lt;/p&gt;
&lt;p&gt;One of the things I did do was load Go so that I could continue work on the &lt;a href=&quot;http://datadiluvium.com/&quot;&gt;Data Diluvium&lt;/a&gt; Project that I’ve started (&lt;a href=&quot;https://github.com/Adron/datadiluvium&quot;&gt;Repo on Github&lt;/a&gt;). To hack around with Go I also installed &lt;a href=&quot;https://atom.io/&quot;&gt;Atom&lt;/a&gt; and &lt;a href=&quot;https://code.visualstudio.com/&quot;&gt;Visual Studio Code&lt;/a&gt;. Both editors on this particular machine were screaming fast and with the 34” display, I could easily have both to test out features side by side. Albeit, that makes shortcut combos a nightmare! DON’T DO THIS AT HOME!&lt;/p&gt;
&lt;p&gt;Build time for the C, Go, and C# Projects I tried out were all crazy fast, but I’m holding off posting any results as I want to get some more apples to apples comparisons put together before posting. I’m also aiming to post versus some other hardware just so there are some baselines in which to compare the build times against.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;More on the coding and related projects in the coming days too.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;important-software&quot;&gt;Important Software&lt;/h4&gt;
&lt;p&gt;You may think, if you’re not an Ubuntu or Linux user, what about all the other stuff like office software and … &lt;em&gt;big long list goes here&lt;/em&gt;. Well, &lt;strong&gt;&lt;em&gt;most&lt;/em&gt;&lt;/strong&gt; of the software that we use is either available or a comparable product is available on Linux these days. There’s really not many things that keep me - or would keep anybody tied to - OS-X/MacOS or Windows. Here are a few that I’ve tried out and am using regularly that are 1 to 1 across Windows, OS-X, and Linux.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jetbrains - as mentioned before these work across all the platforms. They’re excellent developer tools.&lt;/li&gt;
&lt;li&gt;Spotify - even though it states that there hasn’t been support or what not for the app for many months, it still works seemlessly on Linux. That’s what you get when you build an app for a solid platform - one doesn’t have to &lt;em&gt;fix&lt;/em&gt; shit every week like on OS-X or Windows.&lt;/li&gt;
&lt;li&gt;Slack - Slack is available on Linux too. After all the native app (or pseudo native) is built on Electron, which at its core runs on Node.js. So thus, feature parity is pretty much 100%. If you’re going to use slack, it’s not an excuse to be stuck on Windows or OS-X. The choice of platform is yours.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/system76-ubuntu-leopard-workstation/me-horns-up.jpg&quot; alt=&quot;Me, Adron&quot;&gt;
&lt;/div&gt;

&lt;p&gt;NOTE: Nobody paid me a damned penny to write any of this btw, I reviewed all of these things because I love writing about my nerd adventures. No shill shit here. With that stated…&lt;/p&gt;
&lt;p&gt;I have more things to review across all of these platforms and much more to write about this mean machine from System76. However, this review has gotten long enough. The TLDR; of this is, if you’re looking for a machine then System76 definitely gets the horns from me! Highly recommended!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Microsoft's Scorched Earth History and The Current Crossroads</title>
      <link>http://adron.github.io/articles/microsoft-at-the-crossroads/</link>
      <pubDate>Fri, 06 Jan 2017 10:17:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/microsoft-at-the-crossroads/</guid>
      <author></author>
      <description>&lt;p&gt;Microsoft is at a crossroads. If you’re not familiar with Microsoft at all, then just go ahead and skip this blog entry. It won’t matter to you anyway, at least not in the grand scheme of things. Only read forward if you’re curious about the conflict, the inner battles, and perverse juxtaposition that Microsoft exists within.&lt;/p&gt;
&lt;p&gt;In this article I’ll break out various key points and call them out in quotes as an &lt;em&gt;“assertion”&lt;/em&gt;. Such as this&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Assertion: this is the assertion I’m making.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The article is also broken out with the historical context, then I’ll dig into the actual dichotomy of the juxtapositions that are in evidence.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/microsoft-at-the-crossroads/microsoft1975.png&quot; alt=&quot;First Microsoft Logo from 1975&quot;&gt;
    This is the first logo for Microsoft dating from 1975.
&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;the-history-and-context&quot;&gt;The History and Context&lt;/h2&gt;
&lt;p&gt;Many people are aware that at one time Microsoft was brought to court on monopoly charges by the United States of America. That court battle is simply known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/United_States_v._Microsoft_Corp.&quot;&gt;United State vs. Microsoft Corporation&lt;/a&gt; Case. It effectively became moot with the meteoric rise of the iPhone (and mobile in general) and subsequent irrelevancy of their operating system through the course of many events. However Microsoft still paid out about $750 million to Netscape for damages. It’s slightly difficult to find specific information on the payout, but some google-fu tends to still pull up the information on the settlement.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/microsoft-at-the-crossroads/microsoft-80s-logo.jpg&quot; alt=&quot;Microsoft during the 1980s&quot;&gt;
    This is the logo used for much of the 1980’s.
&lt;/div&gt;

&lt;p&gt;Some people might not know where most of Microsoft’s &lt;em&gt;innovations&lt;/em&gt; have come from. The history is pretty clear however, that Microsoft has resoundingly been fairly poor at innovations that come forward and stick. Not to detract from the positives they did bring; a computer in every home, every school, etc was their mission for years, and largely successful. For a clear grasp of Microsoft’s &lt;em&gt;innovations&lt;/em&gt; however, let’s take a look at some of the big ones.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/MS-DOS&quot;&gt;MS-DOS&lt;/a&gt; - This was the operating system of default for the vast majority of business in the 80s. This was when computers or &lt;em&gt;desktops&lt;/em&gt; were kind of a new thing and &lt;a href=&quot;https://en.wikipedia.org/wiki/History_of_laptops&quot;&gt;the laptop was still a &lt;em&gt;laptop&lt;/em&gt;&lt;/a&gt; in the literal sense.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
&lt;img src=&quot;/articles/microsoft-at-the-crossroads/Macintosh_Portable.jpg&quot; alt=&quot;Macintosh Portable&quot;&gt;
&lt;img src=&quot;/articles/microsoft-at-the-crossroads/Osborne_1_open.jpg&quot; alt=&quot;Osborne&quot;&gt;
&lt;/div&gt;

&lt;p&gt;MS-DOS was created by Tim Paterson and in May of 81’ he wrote 86-DOS for Microsoft for $75,000. This was what was renamed to MS-DOS and licensed by Microsoft to computer manufacturers like IBM. Externally created, customized and purchased by Microsoft.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “Microsoft bought a product, often gets credited with it’s invention, which was Tim Paterson and his small company, furthering the notion laid out in &lt;a href=&quot;http://www.claytonchristensen.com/books/the-innovators-dilemma/&quot;&gt;Innovator’s Dilemma&lt;/a&gt;.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Microsoft_Windows&quot;&gt;Windows 1 to 3.11 to 95 to 2000 to 10 etc.&lt;/a&gt; - Windows was largely inspired by, with some slight customizations, from the work done at &lt;a href=&quot;https://en.wikipedia.org/wiki/PARC_(company&quot;&gt;Xerox PARC&lt;/a&gt;), a research and development company. Things Xerox PARC actually invented include; Laser Printers, Graphical User Interfaces (GUI) with Windows &amp;amp; Icons, the Mouse pointing device, WYSIWIG Text Editor, Ethernet, Smalltalk (Object Oriented Programming Language), and Model View Controller software architecture (MVC). As an aside, massive kudos and thanks to PARC for being an amazing innovator and developer what led to the core of over 30 years of software and computer technology!&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; Microsoft, Apple, or whoever at the time (Remember Deskmate? Yeah there were many others) simply were not the &lt;em&gt;innovators&lt;/em&gt; or &lt;em&gt;creators&lt;/em&gt; of the GUI or related windows technology, they were merely following the industry along a previously developed path.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com&quot;&gt;Azure&lt;/a&gt; - Nothing really original in this space at all, it’s almost entirely derived from &lt;a href=&quot;http://aws.amazon.com/&quot;&gt;Amazon Web Services (AWS)&lt;/a&gt; and related cloud computing technologies. The first release of Azure was a complete and utter failure and purposely glossed over by anybody involved in cloud computing at the time. The original Microsoft attempt was a Platform as a Service (PaaS) similar to Google’s AppEngine, but it failed to gain much traction at all. Eventually they worked and worked on reliability (because it was catastrophically unreliable in the early days). At some point in time Scott Guthrie was put in charge of it and other Microsoft projects and it finally became something. Largely the effort changed to follow a more modern cloud computing focused path, it came to mimic AWS’s efforts around compute, storage, networking, and related items being independent, individual, but centrally managed via API services.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; Does this one really need tackled? Microsoft was years late to this game (don’t even get me started on the laggard luddite beast that Oracle is!). It’s really cool that Microsoft is there now, but by no means did they lead and it is arguable whether they have any technological lead today.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, not to distract from the accomplishments of the company by pulling these technologies together. It was and continues to be the way large corporations &lt;em&gt;innovate&lt;/em&gt; or &lt;em&gt;invent&lt;/em&gt; new things. I put italics around innovate in this and most writing about large corporations and innovation because of a simple premise. This is laid out very well in &lt;a href=&quot;http://www.claytonchristensen.com/books/the-innovators-dilemma/&quot;&gt;Innovator’s Dilemma&lt;/a&gt;. If you haven’t read Innovator’s Dilemma, I highly recommend it in the sense that it is a fundamental reference point that anybody even slightly involved in this industry should have the knowledge of. The basic premise is, big companies simply do not innovate or invent without either creating small breakaway companies (i.e. like startups), research entities, or some other organization that can operate almost entirely outside of the large parent corporation. Microsoft is no exception to this premise, being almost all of the innovation or inventions that Microsoft has attained or can even take credit for primarily come from external or externally organized sources. More on this later in this article, but suffice to say, the &lt;em&gt;core&lt;/em&gt; corporate entity Microsoft is itself no innovator or inventive company.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “…almost all of the innovation or inventions that Microsoft has attained or can even take credit for primarily come from external or externally organized sources.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’ll write more about Microsoft’s &lt;em&gt;innovation&lt;/em&gt; and &lt;em&gt;inventions&lt;/em&gt; later. However, the caveat to what I’ve written above is that Microsoft has &lt;em&gt;traditionally&lt;/em&gt; not innovated, but simply purchased their new technology and otherwise maintained or slowly iterated it forward over time with their own internal resources. The company has spent most of its history creating this “&lt;em&gt;maintain the status quo&lt;/em&gt;“ type of ecosystem and employee base, in spite of the employee’s efforts sometimes to push forward the company into a leader instead of a massive monolithic follower. But again, this is simply an observation of Microsoft’s history, not their current actions.&lt;/p&gt;
&lt;p&gt;With this being the case, Microsoft has also provided a vast benefit to humanity by providing a central operating system platform. One can argue the merits of the ethical issues of the monopolization (or arguable the lack there of) but having an operating system that was provided gave society a cohesive means for the market (and respectively the &lt;em&gt;people&lt;/em&gt;) to come together behind a way to interact with computers. One could even argue that if Microsoft had not taken actions in such a brutally anti-competitive way, open source would have become relevant sooner, or that Microsoft stymied the open source movement originally, but I assert this just from the perspective that Microsoft was what we had. On the flip side of that coin Microsoft could also be attributed with being such a central point of hatred for its anti-competitive ideals that it drew together open source advocates into a powerful ideal. But otherwise nothing might have happened in this space. That leads to another assertion, that Microsoft has arguably created a societal benefit over the years and has made a ton of cash in the process.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “Microsoft has arguably created a societal benefit over the years and has made a ton of cash in the process.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now we get to the real meat of the subject, here stand the crossroads. It’s a dustbowl field to the left, and a razed field the right. Just beyond a wisp of trees swaying in the breeze. It’s hot, humid, and a hellish sting in the air. The crossroads has but one entity standing alone watching our path, sitting there to collect the soul. Shall Microsoft go left, shall we go right, shall we go together or is it best to shun the effort? Whatever the case, there is no path back, it’s only forward onward, to the left or to the right. The devil is in the details, and let’s talk about those details shall we.&lt;/p&gt;
&lt;h1 id=&quot;the-crossroads&quot;&gt;The Crossroads&lt;/h1&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/microsoft-at-the-crossroads/Microsoft-1987.png&quot; alt=&quot;Microsoft Logo in 1987&quot;&gt;
    Microsoft Logo of 1987
&lt;/div&gt;

&lt;p&gt;Alright, we’re finally at the crossroads now, hot as hell as it is (or has it frozen over and it’s burning hot as with dry ice?). Microsoft has shown us several key market spaces they’re going after that really draw us to these crossroads. These are the battles that exist in Microsoft itself and not just among its competition. In the following I’ll hit on these key market spaces and break them down into bullet points.&lt;/p&gt;
&lt;h2 id=&quot;key-market-space-cloud-computing&quot;&gt;Key Market Space: Cloud computing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Azure vs. AWS/GCP&lt;/strong&gt; - Microsoft’s Azure still has some significant features to overcome to be best of breed. However it isn’t always Microsoft’s forte to be best of breed, just to impose enough marketing pressure to disparagingly edge corporate entities into usage. They did it with Office through loss leader tactics, and pushing their way in through control with active directory and other resources. Even amid Word, Excel, and the other tools being lackluster products compared to WordPerfect or Quattro Pro (even until in just the recent few years, when these tools finally gained parity with the features and capabilities of WordPerfect and Quattro Pro in 1998). It could be a strategy that I hope Microsoft doesn’t pursue to gain dominance in cloud computing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accounting &amp;amp; Market Trickery&lt;/strong&gt; - What counts as “cloud” to Azure is a bit confusing. I generally don’t care how Microsoft manages its accounting books, it shouldn’t alter the technology right? Well, considering that Microsoft counts its “cloud customers” or “cloud market” in a very different way than AWS or GCP it can be used to mislead CIOs or other IT leaders into thinking Azure is dramatically larger and more used than it is. This might not, at face value, seem like a big deal but you can rest assured that the board rooms are made to make decisions of folly on a regular basis. This type of misleading information is used to push specifically these types of decisions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Microsoft vs. Microsoft’s “Developers, Developers, Developers!”&lt;/strong&gt; - Microsoft has a loyal following of developers, not all of which have even pushed toward Azure or cloud computing, but they’re a large contingent of people. Microsoft is using that to their advantage as much as possible. However the patterns, practices, and acumen doesn’t always follow the capabilities, intent, or design elements fundamental to cloud computing among their development community compared to say almost any other cohesive development community. Rarely is there a well designed distributed anything coming out of the Microsoft oriented landscape (Orleans is an exception, and Akka.NET is at it’s core still a Java thing that now is ported to .NET) - among the company or the company’s constituents. I hope this improves in the near future with more focus on well designed applications that are focused around &lt;em&gt;microservices&lt;/em&gt;, &lt;em&gt;containerized applications&lt;/em&gt;, &lt;em&gt;modular, dare I say the “unix way” style CLIs&lt;/em&gt;, and the like. Overall the developer’s world within Azure is one of a continuously improving state. I can’t bring myself for it to be a first choice among clouds, but it is dramatically improved and I’m happy when I do have to use it for something.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ops in Azure&lt;/strong&gt; - Azure is not known as a great space for operations. Whatever one calls it; DevOps, Operations, Ops, IT, or whatnot, the team is often better off with AWS or GCP unless there is some very specific reasons to be using Azure. This could be changing in the coming months as they’re closing the gap on many of Azure’s usability issues.&lt;/p&gt;
&lt;p&gt;The SRE specifically and the tooling is focused more and more on how to do things right vs. the traditional old style Microsoft way - which inherently is severely broken in the world of cloud computing (&lt;em&gt;and honestly, the Internet itself was nothing more than a fad for Microsoft for so long it’s been a late comer of competence for the company&lt;/em&gt;). One notable thing however, that is holding back the platform, is the strange notion of the Azure interface being a side scrolling mobile application oriented sewer of user interface elements shafted via a skewer of a pseudo tab interface shoved on the top and sides. The user experience is horrible in that regard, and it’s a damned good thing that they’re pushing more and more with the APIs. Please more APIs Microsoft and less of this scandalous thing called a user interface.&lt;/p&gt;
&lt;p&gt;Azure recently, closing that gap has had tooling introduced around &lt;a href=&quot;https://www.hashicorp.com/&quot;&gt;Hashicorp&lt;/a&gt;‘s Tools, more tooling in Go (more on this at a later date), and a host of other advancements. These things have really been given me some hope that they’ll clean this space up.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “Microsoft at this time, January of 2017, is still the weak player in the cloud space versus Amazon Web Services or Google Cloud Platform. They have a lot of ground to cover still to solidify the platform, but that ground is nowhere near as vast as when Azure started. They have caught up so significantly that apps can at least be developed in a one-to-one similar way as apps for AWS or GCP, and that is a very good thing.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;key-market-space-gaming&quot;&gt;Key Market Space: Gaming&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Playstation &amp;amp; Nintendo&lt;/strong&gt; - Microsoft really doesn’t have all that much competition in this space. Sure the Playstation product and Nintendo product exists, but the Xbox and PC Gaming is still almost entirely the domain of Microsoft. I’m cool with that, and it seems the market is happy with this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Frameworks &amp;amp; Game Coding&lt;/strong&gt; Not only is Microsoft still dominating much (most?) of the gaming industries hardware and end product, they’ve also been doing a fairly solid job building and maintaining gaming frameworks. Albeit again, as mentioned with their Office product, the frameworks aren’t always the best of breed. In spite of this they often introduce easier and more focused ways to build games for whatever system.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “Microsoft is still kicking some ass in the gaming space. I can even play a number of games I play that are built on frameworks and libs that are rooted in Microsoft tech on Linux (thanks to Steam). This is one of the most kick ass events of the decade for me. End of story.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;key-market-space-computers-i-e-be-like-apple-&quot;&gt;Key Market Space: Computers (i.e. Be Like Apple)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;SURFACE ALL THE THINGS&lt;/strong&gt; - Surface This, Surface That - Ok, years ago when Microsoft came out with the small car size table top computer, it inspired chuckles and laughter that it cost as much as a small new car and was the size of one too. However the technology and notions derived from it are coming to play in positive ways. The Surface Book, Surface Desktop, Surface Pro, and Surface (&lt;em&gt;are these all the names, I always feel like I might be missing one of the surfaces&lt;/em&gt;). These are truly beautiful machines that show some actual creativity, (&lt;em&gt;are you ready for this&lt;/em&gt;) innovation, and inventive leadership in the market. As of late, they’re even appearing to one up Apple at the hardware game. I’m much impressed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Microsoft vs. Google&lt;/strong&gt; - The Google Computers honestly aren’t even showing on the radar. The Google computers are basically in the same space as Microsoft’s phones are. Albeit neither of these things are bad, the Google Computers do what they do and the Microsoft phones are actually good phones with a cool mobile operating system. But alas, nobody is buying the things. This in turn is an unfortunate failure for Google, Microsoft, and the lot of us consumers.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “I’ve always liked Microsoft hardware devices like their keyboards. Well, basically just their keyboards. However this new breed of hardware and computing devices they’re producing are spot one excellent devices. I’m a fan, again similar to Azure these aren’t my first choice devices but I’d be perfectly happy using them without a complaint.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;key-market-space-software-open-source-&quot;&gt;Key Market Space: Software? Open Source?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Azure vs. AWS/GCP (OpenStack?)&lt;/strong&gt; - This is a strange space compared to the clean cut Linux vs. Windows fight. One was entirely closed source and the other open to the world. In the cloud space some of this and some of that is open, some is partially open, and yet other stuff is entirely closed. Some hardware stuff is open and some is closed, it’s entirely different for every single little piece of the cloud space.&lt;/p&gt;
&lt;p&gt;Amidst all the confusion Microsoft has it’s positives and negatives just as GCP and AWS do. AWS is probably one of the least involved in actually contributing back to the open source software community, where as GCP contributes back at a regular pace. Microsoft probably leans towards the not open approach but it’s confusing, it appears and seem almost like they’re not open because of mere obfuscation of their efforts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Microsoft vs. Microsoft’s “Developers, Developers, Developers!”&lt;/strong&gt; - Two events occurred recently that kind of insured that hell was indeed frozen over. One was that Microsoft contributed to and got one of their pull requests accepted to the Linux Kernel. The other was that they surpassed any other entity on github for commits/pull requests. The later is a bit hard to measure as succinctly as the simple fact they contributed to the Linux Kernel, but they’re both huge accomplishments for the company.&lt;/p&gt;
&lt;p&gt;This is all great, these events and Microsoft’s newfound efforts and new attempts to improve their culture. Their previously built developer community culture of insular and myopic viewpoints has been and still continues to take a toll upon the technology community however and that is another issue that Microsoft has to deal with. The community could just ignore the “softies” and fanbois of yesteryear but Microsoft actually needs to get these individuals to update their viewpoints, get with the program, and step out of the ways they were previously taught in order for Microsoft to actually get ahead of itself. It’s a kind of perverse irony, which I’ll elaborate on more in just a moment.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “Dramatically better and simply awesome in this space now. Good job Microsoft!”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;microsoft-s-lingering-issues&quot;&gt;Microsoft’s Lingering Issues&lt;/h1&gt;
&lt;h2 id=&quot;the-insular-cultural-mort&quot;&gt;The Insular Cultural Mort&lt;/h2&gt;
&lt;p&gt;(For more on what a “&lt;a href=&quot;http://www.urbandictionary.com/define.php?term=Mort&quot;&gt;Mort&lt;/a&gt;“ is check out the &lt;a href=&quot;http://www.urbandictionary.com/define.php?term=Mort&quot;&gt;Urban Dictionary&lt;/a&gt; or these other great blog entries “&lt;a href=&quot;https://blog.codinghorror.com/mort-elvis-einstein-and-you/&quot;&gt;Mort, Elivs, Einstein, and You&lt;/a&gt;“, “&lt;a href=&quot;https://blogs.msdn.microsoft.com/ericwhite/2006/05/11/who-are-mort-elvis-and-einstein/&quot;&gt;Who are Mort, Evlis, and Einstein&lt;/a&gt;“, “&lt;a href=&quot;https://www.cnet.com/news/microsofts-mort-we-hardly-knew-you/&quot;&gt;Microsoft’s Mort: we hardly knew you&lt;/a&gt;“, and &lt;a href=&quot;http://www.hanselman.com/&quot;&gt;Scott Hanselman&lt;/a&gt;‘s awesome “&lt;a href=&quot;http://www.hanselman.com/blog/BeyondElvisEinsteinAndMortNewProgrammingStereotypesForWeb20.aspx&quot;&gt;Beyond Elivs, Einstein and Mort: New Programming Stereotypes for Web 2.0&lt;/a&gt;“).&lt;/p&gt;
&lt;p&gt;During the 80s and 90s Microsoft built itself into a huge powerhouse and built a massive cultural programmer community around this. It was however a community of closed doors, insular viewpoints, notions of &lt;em&gt;“open source is communism”&lt;/em&gt;, and other such nonsense notions. Microsoft taught one brand of things, their brand, dictated often by copying the competition or rewriting ideas from the community for their own and pawning them off on their fanbois as an alternate to the rest of … well the rest of anything or whatever existed in opposition of Microsoft and The Microsoft Way™. (is it trademarked? Seemed fitting. meh?) This Microsoft Way™ way introduced much of the computer scientist community to a new form of software developers that was dubbed the &lt;em&gt;mort&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Microsoft loved to act like it had the best programmers programming applications for their platform, while in reality Microsoft had made huge strides in dumbing down programming into Visual Basic [&amp;amp;&amp;amp;.NET] (and hey, I wrote some amazeballs stuff with Visual Basic too, shoutout to SCP Pool Corp!) and other tools. For many, this was great and I’ll be the first to say, entry of any sort brought more to the industry as a whole than less. I’ll also must say that Microsoft - purposely or inadvertently - creating the notion of a lesser programmer through the &lt;em&gt;mort&lt;/em&gt; casting was not helpful overall.&lt;/p&gt;
&lt;p&gt;There’s a lot of argument that has occurred around this dubbing and segmentation of developer types, and I’m &lt;em&gt;not&lt;/em&gt; arguing there are not types of developers, but mort is a rather denigrative adjective to use to describe the sort. But it is extremely telling about some of the very serious issues still facing Microsoft. I bring up the &lt;em&gt;mort&lt;/em&gt; designator for a simple example, and only one of many examples, of how Microsoft has burned itself in the tech industry over the years.&lt;/p&gt;
&lt;h2 id=&quot;microsoft-building-the-90s-corporation&quot;&gt;Microsoft Building the 90s Corporation&lt;/h2&gt;
&lt;p&gt;Microsoft unfortunately has a lot of developers that fall under its communities’ designators of Elvis, Einstein, and Mort. The problem with this is Microsoft has also built up a huge number of developers outside of Microsoft inside corporations that latch onto the Microsoft Way™. They use Windows Server, SQL Server, .NET 2.x, and maybe even Microsoft Bob. They are the hard core fanbois and they’ve sold their respective companies short by pushing a simpleton, singular, myopic view of the world on the companies they work for. They’ve shoved every possible Microsoft solution down their respective company’s throats and now they’re where they are. This poses a very serious threat to Microsoft itself, since Microsoft has taken a very direct about face to its whole preached Microsoft Way™.&lt;/p&gt;
&lt;p&gt;In the 00s and 10s of the 21st Century Microsoft has put huge efforts, which are starting to work finally, into changing vast amounts of their insular culture, legal attack activities, patent trolling, and other ethical issues. This is wonderful news for anybody and everybody using their tooling directly or even standard consumers out there. Is it good for Microsoft’s bottom line? So far, it doesn’t seem bad, as they’re still raking in billions.&lt;/p&gt;
&lt;p&gt;This conflict is large between Microsoft’s aged mort, Einstein, Elvis, and fanbois programmers and their new desired demographic of &lt;em&gt;everybody&lt;/em&gt;. This conflict is vast and difficult and Microsoft has made some intelligent moves, but faces many extremely difficult hurdles. Their relevancy, what Microsoft had, has mostly been lost in software development circles and entirely lost in the world of startups and new business. They’ve taken huge hits from any number of technologies: Ruby on Rails, Java, Node.js, JavaScript, Cloud, etc. Almost all point at the root of one uprising against Microsoft and that uprising won out over Microsoft. In other words, open source won, whatever open source is, and Microsoft is now working diligently to join the actually technology industry and community instead of being a stand alone myopic, stand alone insular company.&lt;/p&gt;
&lt;p&gt;In this Microsoft has tried to regain relevancy and has done a wonderful job of involving itself in open source. It has even, mostly, kind of, sort of, almost figured out how to use and work with open source effectively. This is a huge plus.&lt;/p&gt;
&lt;p&gt;They still have a huge problem with their internal and external demographics. It’s almost entirely older males, and often from only one subset of society. Contrary to this the industry itself (also in spite of itself) is slowly but surely becoming more diverse: from men and women to cultural differences to age ranges. But Microsoft’s minions and fans have stayed one small demographic of the overall - and that subset has shrunken and lost many of its ardent advocates even. The insular viewpoints and ideas of this group need broken and made larger, which Microsoft itself has a difficult road to bring this notion to their demographic.&lt;/p&gt;
&lt;h2 id=&quot;the-root-culture-issue&quot;&gt;The Root Culture Issue&lt;/h2&gt;
&lt;p&gt;The cultural issue goes deep and I honestly have a hard time writing or even speaking about the issue. Microsoft has shorted its adopted community (Seattle) which hasn’t exactly adopted it (Softies often just piss off the locals, including the transplant locals) and they’re largely uninvolved in the actual tech scene in Seattle. Until of course they leave Microsoft.&lt;/p&gt;
&lt;p&gt;I got an email from a recruiter who thought I worked or had started working at Microsoft. It went like this, &lt;em&gt;“Has it sucked your soul dry yet?”&lt;/em&gt; which I thought was a bit hyperbolic. But I understand the sentiment and their attempt at catching one’s eye. They probably start letters to Amazonians this way too, but it hit me that this isn’t all that hyperbolic. This is kind of a summary for many and that culture runs deep. It’s a culture of ingrained apathy that needs eliminated. It doesn’t matter if its top down leadership and grass roots changes, or layoffs with a mix of hires, something needs to change this and upheave the “&lt;em&gt;I’m working until I die or retire and don’t care&lt;/em&gt;“ mindset of the Microsoft office these days. This attitude doesn’t help the community or the company.&lt;/p&gt;
&lt;p&gt;This is the reason why startups have their pick of top tier talent before Microsoft (and often before Amazon or Google) even though they offer slim chances at riches and very little stability. But people, top tier people, tend to be attracted to challenge, opportunity, and even just the chance at being with the next big startup. They want to change the world in some way for the better, and Microsoft just isn’t seen as that entity. Albeit the perception is wrong (they can change the world for the better) but perception is more important in attracting talent then reality.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Assertion:&lt;/strong&gt; “They want to change the world in some way for the better, and Microsoft just isn’t seen as that entity. Albeit the perception is wrong (they can change the world for the better) but perception is more important in attracting talent then reality.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;thoughts-and-solutions&quot;&gt;Thoughts and Solutions&lt;/h2&gt;
&lt;p&gt;Here’s some of my key ideas, the top 4 for now, for Microsoft’s leadership. Maybe they’re already working on some of these, maybe not. Either way, here they are for free!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Microsoft should get serious about downtown Seattle office real estate and becoming a real prominent &lt;em&gt;SEATTLE&lt;/em&gt; company. Ideally they ought to build a tower, instead of their sleepy, faux forrest, suburbian, divided, lonely campus away from everything they could instead have a presence among the city life and music, art, and the relevancy of urban life. Not that they should give up their surburban myopia, but just give the options a fair shake. The singular small offices that exist in Seattle that are mostly empty really don’t help much, something more, large, and concrete needs done.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Keep pushing the open source angle. Do NOT dictate, which Microsoft hasn’t been doing much of this for years now, but don’t start and get rid of any notions that the company should dictate how a thing should be. In the past Microsoft tried this with development methods like Agile, and other things that they weren’t responsible for creating nor should they have pushed until they understood it better. The same goes for renaming and dictating design patterns. This has happened with MVVM and some others, and it would behoove Microsoft not to regurgitate existing things without it being community rooted, not “company proprietary” (or heaven forbid pre-existing and effectively plagiarized!).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Build software and tooling as stand alone entities. Stop trying to build software to lock one into other software. I know a lot of the time this isn’t even intentional, but it would help Microsoft in a big way if they quelled that reaction of internal employees to hook up to “All the Microsoft Things” when it should be “Connect it to all the Used Web Tools &amp;amp; Internets”. A case in point, Dev Tool A is integrated into TFS, Visual Studio, and some other nonsense. It’s only used by Softies, when it could have been incorporated in a cleaner way into &lt;em&gt;source control&lt;/em&gt; and &lt;em&gt;plugins for editors&lt;/em&gt; (like Atom, Code, or what not). This doesn’t happen as much as it used to at Microsoft but still enough that it needs to stop.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This is super abstract and kind of out there, but seriously Microsoft needs to figure out marketing. A large part of this will be to relocate and kill off the &lt;em&gt;suburban 80s&lt;/em&gt; design motif and &lt;em&gt;50s lifestyle&lt;/em&gt; mindset that Microsoft often perpetuates. Part of the problem is the company exists in a &lt;em&gt;suburban 80s&lt;/em&gt; and &lt;em&gt;50s lifestyle&lt;/em&gt; myopia in Redmond, if they want to attract new, creative, inspiring, and adventurous marketing internally to the company it’s in the city, the urban space, not the outlying boring suburbs. Never was and never will be. Dive into lifestyles outside of that singular demographic mentioned earlier and the marketing will come to the company. Individuals will stand up and come to work for Microsoft when these issues, as massive as they are, are resolved. Until then I expect to see the same marketing trash come from Microsoft and that’s unfortunate.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;dystopian-myopia-no-more&quot;&gt;Dystopian Myopia No More&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Summary: “If Microsoft can pull off these few changes, albeit huge, there are even larger upsides to accomplishing these. The downside is they continue to trudge along with small wins and minor, but unfortunately forgettable things like Surface Desktop, Windows Phone, and similar technologies. In the end, I wish the company well and best wishes to Satya and crew on continuing to change the direction and sailing of the Microsoft ship. Cheers!”&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>December Coding &amp; Hacking Projects | Top 5 Priorities</title>
      <link>http://adron.github.io/articles/december-projects-and-coding/</link>
      <pubDate>Tue, 29 Nov 2016 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/december-projects-and-coding/</guid>
      <author></author>
      <description>&lt;p&gt;As of today I’ve made a few specific decisions that I’ll announce on January 1st of 2017. But for now I’ve got a slew of other things I’m going to attempt to knock out in the coming days. Hopefully I can make them useful and fun to read, if not, that’s cool too since I’ll make use of it!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If you’re a regular reader you’ll get a few pieces of my opinion in the next 31 days.&lt;/li&gt;
&lt;li&gt;The plan is to produce one blog entry per week related to Go around the language, toolchain, and hacking around in IDEs and related tooling.&lt;/li&gt;
&lt;li&gt;I will be wrapping up several blog entries that you’ll see going live over on &lt;a href=&quot;https://blog.codeship.com&quot;&gt;Codeship’s Blog&lt;/a&gt;. Topics include a bit o’ Jenkins, Go, and what you can get out of Codeship and their respective toolchain and services!&lt;/li&gt;
&lt;li&gt;Put together a sick new machine for myself and order by X-mas (no expectation of delivery, just ordering it! - also, blog it!!)&lt;/li&gt;
&lt;li&gt;I am putting together some other project work for some un-named companies (primarily because I’m unsure if they’d want me to mention what they’re working on at this time, so I’ll keep that on the down low). But by proxy I will have some reviews of several technologies.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So mark, and go. We’ll all see if I can knock these five things out by the end of December!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Notes on Go / Future Writings</title>
      <link>http://adron.github.io/articles/golang-notes-upcoming-writings/</link>
      <pubDate>Sat, 19 Nov 2016 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/golang-notes-upcoming-writings/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/golang-notes-upcoming-writings/golang-mascot.png&quot; alt=&quot;Go Language Mascot&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Notes &amp;amp; Thoughts on Go:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So far I like Go. Primarily because it is just simple. Simply RTFMing it gets one pretty far without any fuss. The hardest part of the language to grasp seems to be the same things I often have issue with, which is the ecosystem has it’s own conventions are related things one just simply doesn’t &lt;em&gt;know&lt;/em&gt;. It involves going through the docs and just remembering where the GOPATH is, where the build files go, what the go commands do with the toolset, and related things.&lt;/p&gt;
&lt;p&gt;One thing that required a bit of fiddling around with to get figured out was writing tests for Go. The convention to mark tests and have them executed is actually super easy once you know the specifics of the toolchain.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The first thing one does is create a file or add tests to the file that has the code you want to test. For example, here’s a simple sample I created in an existing project I’m working on.&lt;/p&gt;
&lt;p&gt;I created a file called &lt;code&gt;main_test.go&lt;/code&gt;. The convention follows that any file with &lt;em&gt;test&lt;/em&gt; at the end of the filename and before the extension will be processed as a file that includes tests. This by its very nature makes it necessary to place tests in the code with the functions that are being tested specifically. This could cause issue for some that are used to writing tests another way, but it also makes a lot of sense. But I’m not debating that in this write up, so onward.&lt;/p&gt;
&lt;p&gt;I created the file &lt;code&gt;main_test.go&lt;/code&gt; in the root of the project directory. Once I created the file I added the following code. The package is part of the &lt;em&gt;main&lt;/em&gt; package, and I’d need the &lt;em&gt;test&lt;/em&gt; library imported.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;testing&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I added a struct to use for test data. Below that I created variable with the test data that I would use to test my average function. Then below that I wrote a test that would assert that the function averages numbers appropriately. In the &lt;em&gt;Error&lt;/em&gt; I’ve followed the &lt;em&gt;for&lt;/em&gt;, &lt;em&gt;expected&lt;/em&gt;, &lt;em&gt;got&lt;/em&gt; testing flow to asset the expectation of the result of the function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;type testpair struct {
  values []float64
  result float64
}

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; testAverages = []testpair{
  { []float64{&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;}, &lt;span class=&quot;number&quot;&gt;1.5&lt;/span&gt; },
  { []float64{&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;}, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; },
  { []float64{&lt;span class=&quot;number&quot;&gt;-2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;}, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; },
}

func TestAverage(t *testing.T) {
  &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; _, &lt;span class=&quot;attr&quot;&gt;pair&lt;/span&gt; := range testAverages {
    &lt;span class=&quot;attr&quot;&gt;v&lt;/span&gt; := Average(pair.values)
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; v != pair.result {
      t.Error(
        &lt;span class=&quot;string&quot;&gt;&quot;For&quot;&lt;/span&gt;, pair.values,
        &lt;span class=&quot;string&quot;&gt;&quot;expected&quot;&lt;/span&gt;, pair.result,
        &lt;span class=&quot;string&quot;&gt;&quot;got&quot;&lt;/span&gt;, v,
      )
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, following this TDD style approach, the build fails without the &lt;code&gt;Average&lt;/code&gt; func implemented. I continued forward and implement the function as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func Average(xs []float64) float64 {
  &lt;span class=&quot;attr&quot;&gt;total&lt;/span&gt; := float64(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)
  &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; _, &lt;span class=&quot;attr&quot;&gt;x&lt;/span&gt; := range xs {
    total += x
  }
  &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; total / float64(len(xs))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I execute the test with the Go toolchain command. When executing this command it needs to be called from the root of the Go project code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that I get a nice clean execution and shown that the test passes. More on this later. For now on to other news about myself and Go.&lt;/p&gt;
&lt;h2 id=&quot;go-projects-&quot;&gt;Go Projects!&lt;/h2&gt;
&lt;p&gt;Over the last few weeks I’ve been speaking with the crew at Codeship. If you’re not familiar with this company and its products you should check them out ASAP. They’re easily producing some of the best material on continuous integration, delivery, and related conversations and implementations of immutable infrastructure, immutable deployments, and related container based development practices and patterns. I’m super stoked to announce that I’ve started working with them on some material that you’ll see in the coming days related to just that.&lt;/p&gt;
&lt;p&gt;Some of my first contributions to their blog will be step by step details on setting up Go projects within Codeship, stepping all the way through to continuous delivery, local development with Codeship Pro capabilities and container technology, and onward to more complex deployments including things like Terraform, Packer, Kubernetes, and other toolchains. Keep an eye out here and on their blog (&lt;a href=&quot;https://blog.codeship.com&quot;&gt;https://blog.codeship.com&lt;/a&gt;) and I’ll be sure to let you know when the posts are going live ASAP.&lt;/p&gt;
&lt;p&gt;Also, for a less regular bombardment of posts than my &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; or &lt;a href=&quot;https://twitter.com/ThrashingCode&quot;&gt;@ThrashingCode&lt;/a&gt; Twitter accounts, you can also sign up for my very low volume email newsletter &lt;a href=&quot;http://adron.github.io/docs/thrashing-code-news/&quot;&gt;Thrashing Code News&lt;/a&gt; to get rolled up release notes and links.&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>I Want an Organized Go Project</title>
      <link>http://adron.github.io/articles/want-organized-golang/</link>
      <pubDate>Thu, 03 Nov 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/want-organized-golang/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://www.pelotonseattle.com/&quot;&gt;&lt;img src=&quot;/articles/want-organized-golang/peloton.jpg&quot; alt=&quot;Hacking @ Peloton&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After the last two cookbook style blog entries on a &lt;a href=&quot;http://adron.github.io/articles/want-a-golang-cli/&quot;&gt;basic CLI&lt;/a&gt; with a &lt;a href=&quot;http://adron.github.io/articles/want-a-golang-service/&quot;&gt;simple service&lt;/a&gt; with Go there needed to be some organization around the projects. Here’s the next steps on getting those projects organized.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-workspace-directory&quot;&gt;1. Workspace Directory&lt;/h2&gt;
&lt;p&gt;Workspaces in Go are a simple structure of directories within a root. They include the following three directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;src - Used to store the Go source files.&lt;/li&gt;
&lt;li&gt;pkg - This contains the package objects.&lt;/li&gt;
&lt;li&gt;bin - As in so many other projects with compilable code, this contains the binary executable commands.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Go tool specifically uses this directory structure to place the respective files in the respective directories. One thing that isn’t entirely obvious is that the &lt;code&gt;src&lt;/code&gt; directory is the only directory that should be put in source control.&lt;/p&gt;
&lt;p&gt;Let’s setup one of the existing projects, I’ll take the &lt;a href=&quot;https://github.com/Adron/golang-cli&quot;&gt;golang-cli&lt;/a&gt; that I wrote about here and set it up according to the actual workspace configuration that go tool expects.&lt;/p&gt;
&lt;p&gt;Create a directory to use as the workspace and then create the three directories. I’m going to create this workspace directory within my own code project directory that I call &lt;code&gt;Codez&lt;/code&gt;. It’s a directory I put all of my code projects of varying sorts in, be it C++, Erlang, or F# they all are somewhere in this directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;mkdir GOLANG_WORK
cd GOLANG_WORK
mkdir src bin pkg
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;2-gopath-environment-variable&quot;&gt;2. GOPATH Environment Variable&lt;/h2&gt;
&lt;p&gt;The GOPATH environment variable specifies the location of the working area for Go coding. It’s setup, and in this particular situation it would point to the &lt;code&gt;GOLANG_WORK&lt;/code&gt; directory that I just created previously.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ export GOPATH=$HOME/Codez/GOLANG_WORK
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wanted to have this upon restart, so I added an appropriate append to the $PATH variable by adding this to my &lt;code&gt;~/.bash_profile&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# GO Path Workspace
export GOPATH=~/Codez/GOLANG_WORK
export PATH=$PATH:$GOPATH/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a simple sourcing of the file the new path variables were ready for use.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I pulled in the previous projects. I’ll use these projects to show how the various Go tools work. I simply cloned both of them into the &lt;code&gt;src&lt;/code&gt; path.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;git clone
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;3-import-paths&quot;&gt;3. Import Paths&lt;/h2&gt;
&lt;p&gt;Now, the import path is something that isn’t always immediately intuitive. I had to dive in and RTFM before I realized what was going on here. It also isn’t something that isn’t regularly discussed as a “first step” when learning Go. It isn’t, after all, part of the actual code syntax, it’s part of the ecosystem around the language and tooling. Ya know, the part that often is somewhat neglected as a first step in the learning process.&lt;/p&gt;
&lt;p&gt;The import path is basically the path where the code goes within the &lt;code&gt;src&lt;/code&gt; directory as relating to where it would be publicly shared. For a standard &lt;a href=&quot;https://github.com&quot;&gt;Github&lt;/a&gt; account such as mine I should use github.com/Adron as the base path. To straighten out the organization here, from a Go perspective I changed the name of the folders in which I just cloned to the following.&lt;/p&gt;
&lt;p&gt;These two folders within &lt;code&gt;$HOME/src/&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;golang-cli
golang-service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I moved to.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;github.com/adron/golang-cli
github.com/adron/golang-service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Important to note, is that I moved these folders into a multi-level deep directory structure. I created a github.com directory instide the src directory and inside that I created the adron directory and then moved the golang-cli and golang-service projects respectively. I note this because if one navigates into &lt;code&gt;src&lt;/code&gt; with finder, some other manager, or uses the command to move and attempts to &lt;em&gt;move&lt;/em&gt; the directory like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;mv src golang-cli github.com/adron/golang-cli
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many of the managers or otherwise will attempt to, and by default will create a folder called &lt;em&gt;github.com/adron/golang-cli&lt;/em&gt; NOT a folder called &lt;em&gt;golang-cli&lt;/em&gt; inside of a folder called &lt;em&gt;adron&lt;/em&gt; inside of a folder called &lt;em&gt;github.com&lt;/em&gt;. This is a pretty basic thing, but often can lead even the most experienced to mistakenly moving files around incorrectly.&lt;/p&gt;
&lt;h2 id=&quot;4-go-install-making-a-program-&quot;&gt;4. Go Install (Making a Program)&lt;/h2&gt;
&lt;p&gt;Now using the two existing Go Programs that I’ve just cloned, I can execute either of those via the command line by using the &lt;code&gt;go install&lt;/code&gt; command. Navigating in the terminal to the root of the golang-cli program I then execute this at the root of that project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The other option, which can be typed in a terminal regardless of location.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go install github.com/adron/golang-cli
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, for this particular application, with it installed I can now use the command &lt;code&gt;golang-cli&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ golang-cli
Hello, Person With No Name, please enter some text: Heather
Heather

word:  the-word
numb:  42012
fork:  true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here I’ve entered the command and followed the prompt. Again, for reference check out the &lt;a href=&quot;http://blog.adron.me/articles/want-a-golang-cli/&quot;&gt;quick CLI I put together previously&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the the golang-service project it’s a little trickier because of how I setup the code. I had written the code to show a quick example of creating a service and then running that service via the command &lt;code&gt;go run service.go&lt;/code&gt; or &lt;code&gt;go run service-twosi.go&lt;/code&gt;. If I were to try to install the project via the &lt;code&gt;go install&lt;/code&gt; command I’d get the following results.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go install github.com/adron/golang-service
# github.com/adron/golang-service
Codez/GOLANG_WORK/src/github.com/adron/golang-service/service.go:9: handler redeclared in this block
    previous declaration at Codez/GOLANG_WORK/src/github.com/adron/golang-service/service-twosi.go:10
Codez/GOLANG_WORK/src/github.com/adron/golang-service/service.go:13: main redeclared in this block
    previous declaration at Codez/GOLANG_WORK/src/github.com/adron/golang-service/service-twosi.go:30
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package &lt;code&gt;main&lt;/code&gt; and the &lt;em&gt;handler&lt;/em&gt; is declared twice. This causes a problem since the compiler doesn’t have a way to inform which one to build. For this example, what I would need to do is remove one of the handlers and one of the packages and just keep a singular one. With that I did a quick replace of the &lt;em&gt;service.go&lt;/em&gt; file and replaced it with the contents of the &lt;em&gt;service-twosi.go&lt;/em&gt;  example code. At this point my &lt;em&gt;service.go&lt;/em&gt; code file looks like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
   &lt;span class=&quot;string&quot;&gt;&quot;encoding/json&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;net/http&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;log&quot;&lt;/span&gt;
)

func handler(w http.ResponseWriter, r *http.Request) {
   fmt.Fprintf(w, &lt;span class=&quot;string&quot;&gt;&quot;Welcome to the early morning Amtrak Cascades, %s!&quot;&lt;/span&gt;, r.URL.Path[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;:])
}

type Message struct {
   Text string
}

func about (w http.ResponseWriter, r *http.Request) {

   &lt;span class=&quot;attr&quot;&gt;m&lt;/span&gt; := Message{&lt;span class=&quot;string&quot;&gt;&quot;Welcome to the Twosi API, build v0.0.001.&quot;&lt;/span&gt;}
   b, &lt;span class=&quot;attr&quot;&gt;err&lt;/span&gt; := json.Marshal(m)

   &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != nil {
       panic(err)
   }

    w.Write(b)
}

func main() {
   http.HandleFunc(&lt;span class=&quot;string&quot;&gt;&quot;/&quot;&lt;/span&gt;, handler)
   http.HandleFunc(&lt;span class=&quot;string&quot;&gt;&quot;/about/&quot;&lt;/span&gt;, about)
   log.Fatal(http.ListenAndServe(&lt;span class=&quot;string&quot;&gt;&quot;:8080&quot;&lt;/span&gt;, nil))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can run &lt;code&gt;go install&lt;/code&gt; and run the service via the command line, from anywhere on machine. Just to test it out I issue the &lt;code&gt;golang-service&lt;/code&gt; command and navigate in the browser to the &lt;a href=&quot;http://localhost:8080/about/&quot;&gt;http://localhost:8080/about/&lt;/a&gt; path. Sure enough, the JSON appears.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
&lt;span class=&quot;string&quot;&gt;&quot;Text&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Welcome to the Twosi API, build v0.0.001.&quot;&lt;/span&gt;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;5-project-collateral&quot;&gt;5. Project Collateral&lt;/h2&gt;
&lt;p&gt;It’s all nice and groovy that I have a Go project and some code, but if I really want to make something out of it I should be a good open source citizen. This is where a few other pieces of the repository come together for the project. Now, one might say, “but that’s not part of the Go ecosystem/tooling/whatyamakallit” but that’s not being very respectable about your intent. I’ll admit, I make a mess of a repo now and again too, but these are some good things to include so your repository isn’t a confusing mess of code trash waiting to be set on fire.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;.github Directory and &lt;em&gt;gasp&lt;/em&gt; some basic instructions and documentation. Inside the .github directory there are three key files that ought to be included with some notion of useful information. For these two projects I’ve added some basic contribution information &lt;a href=&quot;http://adron.github.io/articles/want-a-golang-cli/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://adron.github.io/articles/want-a-golang-service/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;README.md with some simple instructions on getting started, installing, etc. This file also should always describe what a project is and what it is for. Another way to put it, the README.md should have some sort of mission description.&lt;/li&gt;
&lt;li&gt;Badges &amp;amp; Status should be shown in the README.md or in some way somewhere on or in the project. A popular way is using badges to show the status of the build, license, dependencies status, and related information about the project. I don’t have those displayed as of this blog entry, but will dive into that and continuous integration and delivery of Go in subsequent blog entries.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s it for this write up. More to come and more news about these projects, paths to production, and related patterns and deployment techniques in the coming weeks. Stay tuned and if you’d like blog entry summaries and other updates delivered to your mailbox, check out &lt;a href=&quot;http://adron.github.io/docs/thrashing-code-news/&quot;&gt;Thrashing Code News&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Peloton Seattle - This is the image at the top of this blog entry, and where I wrote 90% and put together 90% of the code. Per their website, “Peloton is a different approach to the traditional bike shop.  In addition to being a full service repair shop, our cafe offers meals made from ingredients sourced from local farms, coffee made from locally roasted beans, and beer brewed in Washington.  Peloton is your destination whether you’re craving a morning coffee and snack, you need bicycle maintenance and advice, or you want to grab a beer with your riding buddies.  Peloton provides delicious healthy food, professional bicycle service, and a variety of beverages for any time of the day.  We’d love to share our passions with you.”&lt;/li&gt;
&lt;li&gt;The &lt;a href=&quot;https://github.com/Adron/golang-cli&quot;&gt;Go CLI Sample App&lt;/a&gt; and &lt;a href=&quot;https://github.com/Adron/golang-service&quot;&gt;Go Service Sample&lt;/a&gt; Repositories.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>I Want a Go Service</title>
      <link>http://adron.github.io/articles/want-a-golang-service/</link>
      <pubDate>Mon, 31 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/want-a-golang-service/</guid>
      <author></author>
      <description>&lt;p&gt;In the last post, I put together a quick Go CLI that took some flags and acted upon each of the flags. So today, instead of a Bowing 777 I’m aboard Amtrak Cascade’s service to Portland (from Seattle) aboard a &lt;em&gt;Tren Articulado Ligero Goicoechea Oriol&lt;/em&gt;, or &lt;em&gt;Talgo&lt;/em&gt; Train.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/want-a-golang-service/american-talgo.jpg&quot; alt=&quot;Amtrak Cascades Talgo&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Traveling in comfort is an unbelievably great way to get some coding done. It’s easy to disconnect form interruptions (albeit there is internet access, but just enough, not to much) and just get some coding done. &lt;strong&gt;Mission:&lt;/strong&gt; &lt;em&gt;Put together a service that has a basic response for a request, with some message. There needs to be a root response of the service, but also a response from one or more URI end points.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The first thing I did was get the basic package designated and added the imports I’d need for the libraries I’d use for this. I created a file called &lt;code&gt;service.go&lt;/code&gt; to add this code to.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
  &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
  &lt;span class=&quot;string&quot;&gt;&quot;log&quot;&lt;/span&gt;
  &lt;span class=&quot;string&quot;&gt;&quot;net/http&quot;&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I added a little trip specific message for the hello world aspect of the service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func handler(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintf(w, &lt;span class=&quot;string&quot;&gt;&quot;Welcome to the early morning Amtrak Cascades, %s!&quot;&lt;/span&gt;, r.URL.Path[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;:])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a super simple handler that works to handle the request and response by returning a message. Note the parameter &lt;code&gt;r.URL.Path[1:]&lt;/code&gt; that is passed in via the &lt;code&gt;%s&lt;/code&gt; if it is available.&lt;/p&gt;
&lt;p&gt;For the last bit of this sample I added the necessary main function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func main() {
    http.HandleFunc(&lt;span class=&quot;string&quot;&gt;&quot;/&quot;&lt;/span&gt;, handler)
    log.Fatal(http.ListenAndServe(&lt;span class=&quot;string&quot;&gt;&quot;:8080&quot;&lt;/span&gt;, nil))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here I call the http function &lt;code&gt;HandleFunc&lt;/code&gt; and pass in the necessary parameters, including the handler. Next I pass to the log function &lt;code&gt;Fatal&lt;/code&gt; the http &lt;code&gt;ListenAndServe&lt;/code&gt; function and pass it the port 8080 to listen on.&lt;/p&gt;
&lt;p&gt;Now I built the code and run it to prove it out. To build I executed the standard go build command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go build service.go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then executing the service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;19:47 $ ./service
_
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If for some reason you have something using that port already, the following error displays.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;19:48 $ ./service
2016/11/03 19:48:15 listen tcp :8080: bind: address already in use
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This happened to me routinely since I was running the &lt;code&gt;wintersmith preview&lt;/code&gt; instance on port 8080 while I write this very blog entry. I try to prevent port conflicts, but one knows how that goes, sometimes you just gotta lock horns with all the ports.&lt;/p&gt;
&lt;p&gt;If everything runs accordingly however, I get the following when I browser to &lt;a href=&quot;http://localhost:8080&quot;&gt;http://localhost:8080&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-service/localhost-01.png&quot; alt=&quot;Browser Results&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;add-features&quot;&gt;Add Features&lt;/h2&gt;
&lt;p&gt;What I did so far didn’t really meet the mission statement to the extent I wanted to. I decided to add a few more things, so I went ahead and created another file in the repo called &lt;code&gt;service-twosi.go&lt;/code&gt;. No, I don’t know why I named it that other than naming is hard and this is the second services example.&lt;/p&gt;
&lt;p&gt;Again, added the package and imports, which were almost the same as before.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
   &lt;span class=&quot;string&quot;&gt;&quot;encoding/json&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;net/http&quot;&lt;/span&gt;
   &lt;span class=&quot;string&quot;&gt;&quot;log&quot;&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wanted to get some json action into place, thus the addition of the encoding/json library.&lt;/p&gt;
&lt;p&gt;Next I basically kept the previous response writer handler function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func handler(w http.ResponseWriter, r *http.Request) {
   fmt.Fprintf(w, &lt;span class=&quot;string&quot;&gt;&quot;Welcome to the early morning Amtrak Cascades, %s!&quot;&lt;/span&gt;, r.URL.Path[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;:])
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I added a simple struct message type.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;type Message struct {
   Text string
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would be for the message and json manipulation. Next I added a function called about, which would eventually be an API call directly to &lt;a href=&quot;http://localhost:8080/about&quot;&gt;http://localhost:8080/about&lt;/a&gt;. Note I’ve assigned m the Message, which is parsed into json via the json Marshal function call.&lt;/p&gt;
&lt;p&gt;I then added a little error catch in case the json blows up for whatever reason. Then I write it out via this function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func about (w http.ResponseWriter, r *http.Request) {

   &lt;span class=&quot;attr&quot;&gt;m&lt;/span&gt; := Message{&lt;span class=&quot;string&quot;&gt;&quot;Welcome to the Twosi API, build v0.0.001.&quot;&lt;/span&gt;}
   b, &lt;span class=&quot;attr&quot;&gt;err&lt;/span&gt; := json.Marshal(m)

   &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; err != nil {
       panic(err)
   }

    w.Write(b)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, it’s main function time again.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func main() {
   http.HandleFunc(&lt;span class=&quot;string&quot;&gt;&quot;/&quot;&lt;/span&gt;, handler)
   http.HandleFunc(&lt;span class=&quot;string&quot;&gt;&quot;/about/&quot;&lt;/span&gt;, about)
   log.Fatal(http.ListenAndServe(&lt;span class=&quot;string&quot;&gt;&quot;:8080&quot;&lt;/span&gt;, nil))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick build.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go build service-twosi.go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then execution.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;./service-twosi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gives me this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;20:09 $ go run service-twosi.go
_
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now if I navigate to &lt;a href=&quot;http://localhost:8080/&quot;&gt;http://localhost:8080/&lt;/a&gt; I get this.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-service/localhost-02.png&quot; alt=&quot;Browser Results&quot;&gt;&lt;/p&gt;
&lt;p&gt;If I pass in a name as part of the URI like &lt;a href=&quot;http://localhost:8080/John&quot;&gt;http://localhost:8080/John&lt;/a&gt; I get the following.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-service/localhost-03.png&quot; alt=&quot;Browser Results&quot;&gt;&lt;/p&gt;
&lt;p&gt;Of course the last URI to try out is the about URI path of &lt;a href=&quot;http://localhost:8080/about&quot;&gt;http://localhost:8080/about&lt;/a&gt; which provides some nice json data returned in the browser.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-service/localhost-04.png&quot; alt=&quot;Browser Results&quot;&gt;&lt;/p&gt;
&lt;p&gt;That covers this mission, features implemented and done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/golang-service&quot;&gt;Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://golang.org/&quot;&gt;Go language site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>I Want a Go CLI</title>
      <link>http://adron.github.io/articles/want-a-golang-cli/</link>
      <pubDate>Mon, 24 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/want-a-golang-cli/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/want-a-golang-cli/united-airlines-boeing-777.jpg&quot; alt=&quot;United Airlines Boeing 777&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I sat in seat 20B on United Airlines Flight UA 949, enjoying the roominess of the Boeing 777 in service on this route between London (LHR) and San Francisco (SFO). At this time I decided it was time to hack together a &lt;a href=&quot;https://golang.org/&quot;&gt;Go&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Command-line_interface&quot;&gt;CLI&lt;/a&gt; Project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mission:&lt;/strong&gt; Create a Command Line Interface (CLI) that takes some flags, basic user input, and prints out something.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/want-a-golang-cli/golang-mascot.png&quot; alt=&quot;Go Language Mascot&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I quickly threw together just a simple “hi” CLI App.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;

func main() {
    fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;Hi&quot;&lt;/span&gt;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I ran that just to make sure I had Go installed properly and all that.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;go run hi-cli.go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s super boring, so first things first, let’s take some input from the command line and print it back out to the screen. I’ll start by passing a few parameters along with the hi-cli call.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;package main

&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; (
    &lt;span class=&quot;string&quot;&gt;&quot;bufio&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;fmt&quot;&lt;/span&gt;
    &lt;span class=&quot;string&quot;&gt;&quot;os&quot;&lt;/span&gt;
)

func main() {
    &lt;span class=&quot;attr&quot;&gt;reader&lt;/span&gt; := bufio.NewReader(os.Stdin)
    fmt.Print(&lt;span class=&quot;string&quot;&gt;&quot;Enter text: &quot;&lt;/span&gt;)
    text, &lt;span class=&quot;attr&quot;&gt;_&lt;/span&gt; := reader.ReadString(&lt;span class=&quot;string&quot;&gt;'\n'&lt;/span&gt;)
    fmt.Println(text)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What this bit of code gives me looks like this when I execute it now.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-cli/hi-cli-01.png&quot; alt=&quot;Running hi-cli.go&quot;&gt;&lt;/p&gt;
&lt;p&gt;A quick few notes if you’re not familiar with Go. The := is a reassignment (or assignment) and declaration operator. It’s actually equivalent to the following statement.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; reader = bufio.NewReader(os.Stdin)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So that’s the notion behind the := syntax.&lt;/p&gt;
&lt;p&gt;Ok, so now I wanted some other features to the cli. The first is the ability to pass in some flags. There is a library for that, simply called &lt;em&gt;flag&lt;/em&gt; which I’ll add. I added that to the import list.&lt;/p&gt;
&lt;p&gt;One of the really cool features of the flag library is that it will auto-generate flag help documentation. To display the flag documentation pass the -h flag. For instance, to see the flag documentation type in &lt;code&gt;go run hi-cli.go -h&lt;/code&gt;. However, I need to actually add some flags with their appropriate descriptions and actually use them somewhere. So I’ve edited my go code file as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;func main() {
  &lt;span class=&quot;attr&quot;&gt;wordFlag&lt;/span&gt; := flag.String(&lt;span class=&quot;string&quot;&gt;&quot;wordly&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;the-word&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;A string value.&quot;&lt;/span&gt;)
  numberFlag := flag.Int(&lt;span class=&quot;string&quot;&gt;&quot;numeraly&quot;&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;42012&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;An integer value.&quot;&lt;/span&gt;)
  booleanFlag := flag.Bool(&lt;span class=&quot;string&quot;&gt;&quot;booly&quot;&lt;/span&gt;, &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;A boolean value.&quot;&lt;/span&gt;)
  nameFlag := flag.String(&lt;span class=&quot;string&quot;&gt;&quot;yourname&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;Person With No Name&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;Put your name here.&quot;&lt;/span&gt;)

  flag.Parse()

  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; reader = bufio.NewReader(os.Stdin)
  fmt.Print(&lt;span class=&quot;string&quot;&gt;&quot;Hello, &quot;&lt;/span&gt; + *nameFlag + &lt;span class=&quot;string&quot;&gt;&quot;, please enter some text: &quot;&lt;/span&gt;)
  text, &lt;span class=&quot;attr&quot;&gt;_&lt;/span&gt; := reader.ReadString(&lt;span class=&quot;string&quot;&gt;'\n'&lt;/span&gt;)
  fmt.Println(text)

  fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;word: &quot;&lt;/span&gt;, *wordFlag)
  fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;numb: &quot;&lt;/span&gt;, *numberFlag)
  fmt.Println(&lt;span class=&quot;string&quot;&gt;&quot;fork: &quot;&lt;/span&gt;, *booleanFlag)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I can ask for help with the &lt;code&gt;go run hi-cli.go -h&lt;/code&gt; and I get the following.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-cli/hi-cli-02.png&quot; alt=&quot;Running hi-cli.go&quot;&gt;&lt;/p&gt;
&lt;p&gt;That’s what I expected, so now I’m going to test out the different flags I set. So I go ahead and set each of the flags just to see. My command reads nice and long as &lt;code&gt;go run hi-cli.go -booly=false -wordly=testing -numeraly=909 -yourname=&amp;quot;Adron Hall&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/want-a-golang-cli/hi-cli-03.png&quot; alt=&quot;Running hi-cli.go&quot;&gt;&lt;/p&gt;
&lt;p&gt;Again, everything I expected. Based on the mission I set out at the beginning of this entry, mission is accomplished. So until next time, happy hacking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/golang-cli&quot;&gt;Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://golang.org/&quot;&gt;Go language site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Marketing Obliviousness of DevOps, WTF is Site Reliability</title>
      <link>http://adron.github.io/articles/devops-obliviousness-site-reliability-wtf/</link>
      <pubDate>Sun, 23 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/devops-obliviousness-site-reliability-wtf/</guid>
      <author></author>
      <description>&lt;p&gt;Recently I started researching what people think DevOps means. What it was originally intended to mean and how ridiculous it is to actually see it in a job title. On the flip of that, since one of my titles was actually “Site Reliability Engineer” I started looking into what is perceived to be the roles of that job. This article is my findings, in full unconstrained wording, about the absurdity of one as a title and the specifics of the other.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://adron.github.io/articles/devops-obliviousness-site-reliability-wtf/syntax%20error.gif&quot; alt=&quot;Syntax Error Explosion&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;part-i-devops-is-nope&quot;&gt;Part I - DevOps is… Nope&lt;/h2&gt;
&lt;p&gt;In linguistics the word DevOps is generally considered a &lt;em&gt;blend word&lt;/em&gt; or a &lt;em&gt;portmanteau&lt;/em&gt;. It’s the combination of developer or development and operations. Meanwhile, Google actually understands what it is. But hey, we know Google is basically a smarter than humanity AI at this point right? Well, ok, maybe Google’s definition of DevOps isn’t 100% spot on, but it’s fairly close to its perceived meaning.&lt;/p&gt;
&lt;p&gt;Google’s definition reads, “DevOps (a clipped compound of development and operations) is a culture, movement or practice that emphasizes the collaboration and communication of both software developers and other information-technology (IT) professionals while automating the process of software delivery and infrastructure changes.”&lt;/p&gt;
&lt;p&gt;Part of that definition also takes it into account that some companies have no clue what they’re doing. Hiring a “DevOps Engineer” and then they end up throwing that person into the fire of systems administration menial servitude or the absurdity of &lt;em&gt;cluster fucked crossed wires&lt;/em&gt; network administration. So often a DevOps Engineer is hired without a company, human resources department, or management having any idea that DevOps was and is mostly focused around an idea more than any practice or notion. Sure, some of the practices we undertake are specific, but the idea is more important. It’s the combination of development and operations into a focused effort instead of being two battling organizations.&lt;/p&gt;
&lt;p&gt;But has that even really happened? In most offices DevOps has grown into another segmented, broken, and often dysfunctional group autonomous of both operations and development. Where the DevOps engineers may be creating automation or who knows, maybe just off drinking in the corner, ops doesn’t know because they’re fighting fires and development doesn’t have any idea because they’re building flame throwers to put the fires out (ya know, fighting fire with fire and all).&lt;/p&gt;
&lt;p&gt;If you want to get super pedantic about DevOps and what it might mean, check out the Wikipedia or go get your google-fu karate ninja chops going and make up your own definition from the various sources. I’m sure it would be super entertaining! …or not?&lt;/p&gt;
&lt;p&gt;Suffice to say, DevOps hit full buzzword bingo status a few years ago now. Now it exists in that strange limbo of &lt;em&gt;worthless buzzword&lt;/em&gt; and &lt;em&gt;relatively useful in a relative way&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;devops-damage-an-aside&quot;&gt;DevOps Damage - An Aside&lt;/h3&gt;
&lt;p&gt;During one of my efforts researching DevOps I stumbled into Pete Cheslock’s blog post, “&lt;a href=&quot;https://pete.wtf/2013/05/03/devops-in-your-job-title-is-doing-you-harm/&quot;&gt;DevOps in Your job Title is Doing You Harm&lt;/a&gt;“. He points out it is better to title yourself something like&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Site Reliability Engineer&lt;/li&gt;
&lt;li&gt;Automation Engineer&lt;/li&gt;
&lt;li&gt;Release Engineer&lt;/li&gt;
&lt;li&gt;DevTools Engineer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll add, if you see titles like…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DevOps Hadoop Cloud Engineer&lt;/li&gt;
&lt;li&gt;DevOps Ninja&lt;/li&gt;
&lt;li&gt;DevOps Programmer&lt;/li&gt;
&lt;li&gt;Operations DevOps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…it’s ok to respond with a &lt;em&gt;“WTF did I just read?”&lt;/em&gt; and then just go ahead and fire that company. The company obviously hasn’t invested even the 10-30 minutes into figuring out what they’re trying to do. The risk is huge, everything is just gonna be a giant tire fire, &lt;em&gt;leave before you even apply to a job with a title like one of these.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pete actually goes on to mention,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don’t know why recently there is a need to move away from the same job titles we’ve used in the past, as if there is some negative connotation towards them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To which my research into what exactly a Site Reliability Engineer differs versus titles like&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System Administrator&lt;/li&gt;
&lt;li&gt;Operations Engineer&lt;/li&gt;
&lt;li&gt;Network Engineer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These notes aren’t the only gem of smarts in this post of Pete’s. Go read the blog entry, it’s &lt;a href=&quot;https://pete.wtf/2013/05/03/devops-in-your-job-title-is-doing-you-harm/&quot;&gt;here&lt;/a&gt;, I’ll wait as you should have the context. One more solid blog entry, check out Jez Humble’s “&lt;a href=&quot;https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/&quot;&gt;There’s No Such Thing as a DevOps Team&lt;/a&gt;“. Again, I’ll wait so go ahead and read it.&lt;/p&gt;
&lt;p&gt;Well, it’s time I dove into role of Site Reliability Engineer.&lt;/p&gt;
&lt;h2 id=&quot;site-reliability-engineer&quot;&gt;Site Reliability Engineer&lt;/h2&gt;
&lt;p&gt;I’ve gotten a few mixed results around what people think this role and title encompasses, but unlike DevOps which has unfortunately become a buzzword with oodles of overloaded context and meaning. What is generally sought out in the role of a site reliability engineer can be described best by what Ben Traynor stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Fundamentally, it’s what happens when you ask a software engineer to design an operations function.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I see SRE individuals and teams as the people who are actually moving us past the dark past inferred with the mystic past associated with the strange black magic mysticism of systems administration, operations, and network engineering of the past. It’s setting the practices involved in running those systems into a known manner of operation, that is repeatable, and in many ways more importantly able to be automated.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Enterprise Open Source Anti-patterns</title>
      <link>http://adron.github.io/articles/enterprise-open-source-anti-patterns/</link>
      <pubDate>Wed, 19 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-open-source-anti-patterns/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV (That’s this article)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;first part&lt;/a&gt; of this series I kicked off writing about how we created a manifesto at &lt;a href=&quot;http://www.homedepot.com&quot;&gt;Home Depot&lt;/a&gt;. This is something I’d strongly urge anybody that is helping to lead an enterprise toward open source efforts. The &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;second part&lt;/a&gt; focused on tactical tools used with open source software development. I’ll be adding more to the tools conversation a bit later in this series. Then in &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;part three&lt;/a&gt; I delved into some of the positive cultural characteristics of a team working on open source projects.&lt;/p&gt;
&lt;p&gt;In this part of the series I want to share a few thoughts on some of the anti-patterns that came up in the process. These are specific hurdles that continue to afflict the efforts, and range from a general disturbance or an outright conflict with efforts.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As I was creating these, I did a quick search to see what prospective open source anti-patterns existing with or without the context of enterprise open source. Not surprisingly there were a few, and the few that I found via the search I’ve attributed to who I found had written about them just under each description.&lt;/p&gt;
&lt;h2 id=&quot;1-insular-anti-pattern&quot;&gt;1. Insular Anti-Pattern&lt;/h2&gt;
&lt;p&gt;This is the idea that a group is so used to interacting behind closed doors, only among each other, that they fail to message, market, or even discuss the actual open source project with prospective contributors or others that are interested in public. This makes for code repositories that are starkly devoid of any conversation or information about what is being developed or why. It’s also a pretty sure fire way of killing your project, or insuring that the only group that uses it and develops the code for the project are those that started it.&lt;/p&gt;
&lt;h2 id=&quot;2-no-source-anti-pattern&quot;&gt;2. No Source Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is when a project is announced, usually by upper management that has somehow failed to determine where, who, or who they’re going to create or get the source code written. Companies that do this look embarrassingly absurd and out of touch with their actual employees that do the actual work at the company. Do NOT be this company.&lt;/p&gt;
&lt;h2 id=&quot;3-wishful-thinking-anti-pattern&quot;&gt;3. Wishful Thinking Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is the broken idea that because a project is brought into the open (new or existing) someone else will join in and do the work. If you’re not ready to do the work yourself, then don’t expect others to want to jump in and help you.&lt;/p&gt;
&lt;h2 id=&quot;4-extroverted-anti-pattern&quot;&gt;4. Extroverted Anti-pattern&lt;/h2&gt;
&lt;p&gt;This is similar to the No Source Anti-pattern. The pattern here is that a group - not particularly management - has gotten so excited preaching the idea of the project even when the project may or may not be moving forward. They see talk of the project as the means to an end even more than the actual code and project itself. This is most identifiable when a marketing or recruitment team sees the project as a means to market or recruit people but don’t have any vested interest in the actual code or project itself.&lt;/p&gt;
&lt;h2 id=&quot;5-forkaphobia-anti-pattern&quot;&gt;5. Forkaphobia Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is one of the craziest anti-patterns. The juxtoposition of this anti-pattern is the &lt;em&gt;forking paradox&lt;/em&gt;. The forking paradox is stated as &lt;em&gt;the easier it is to fork the software, the more difficult it is to the fork the community. If forking is easy, experimentation with ideas is persued while still remaining safely downstream. If forking is difficult, experimenters are reduced to dissenters - resulting in endless arguments (best case) or divorce (worst case).&lt;/em&gt; Bryan summarizes this one well with “Corporate Entities must therefore encourage forking - open source that cannot be forked has no vitality”.&lt;/p&gt;
&lt;h2 id=&quot;6-governance-anti-pattern&quot;&gt;6. Governance Anti-pattern&lt;/h2&gt;
&lt;p&gt;This is best seen in governance of real things, like people. The massive and complex ordeal of maintaining governance around a software project can become so large and unwieldy to to enforce an order and dictate on the future progress of the project. Necessitating a governance body or board is often a sign the project has become unwieldy with to many influencers who can’t agree on the direction. At this point, to maintain health and vitality it’s often best to fork the solution to break the stranglehold of the Governance Anti-pattern.&lt;/p&gt;
&lt;h2 id=&quot;7-eschewing-leadership-anti-pattern&quot;&gt;7. Eschewing Leadership Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Good open source have good leadership. When consensus isn’t available, good leadership turns that into positive direction and inspires people to move forward regardless. Projects that are started but nobody wants to take a leading role, even among people who generally decide on the direction, leads to a project that quickly spirals out of control into branches and forks and gets lost.&lt;/p&gt;
&lt;h2 id=&quot;8-demanding-assignment-anti-pattern&quot;&gt;8. Demanding Assignment Anti-pattern&lt;/h2&gt;
&lt;p&gt;Demanding assignment relies on a community trusting a commercial entity. Bad actors in open source (a notorious example is Oracle) however have destroyed that trust. To prevent this anti-pattern a contributor agreement to protect the source base from 3rd party claims of copyright and patent infringement. Copyright assignment still may make sense, but should be used only as a social contract.&lt;/p&gt;
&lt;h2 id=&quot;9-apathy-anti-pattern&quot;&gt;9. Apathy Anti-pattern&lt;/h2&gt;
&lt;p&gt;This anti-pattern is a combination of things like the Extroverted, Wishful Thinking, or No Source Anti-patterns. When this occurs a group simply throws their source code into a public repository but then does nothing else with it in the public repository. If active development isn’t done in the public repository, or a very effective story and information is provided as to why it’s a read-only kind of copy, there is an immediate threat that the project won’t just have apathetic developers that created it but worse, an apathetic audience who simply just won’t use it.&lt;/p&gt;
&lt;h2 id=&quot;10-opaque-anti-pattern&quot;&gt;10. Opaque Anti-pattern&lt;/h2&gt;
&lt;p&gt;In this anti-pattern a tool, set of tools, or other medium in which communication about the project is done almost entirely in a closed and invisible way. There are Github repositories for instance that the issues and wiki are turned off, and nobody communicates around the repository itself. Sometimes the communiation occurs in a closed email thread or other medium, like a closed Slack channel that is invite only. This isn’t to say that some communication could and should be kept in private, because there is some that should, but the bulk of the community’s communication should be available via public means. This is needed for others to use, understand, and work with the project. Otherwise the trust to make the project effective and move forward is simply not there. Don’t make your open source project efforts opaque!&lt;/p&gt;
&lt;p&gt;That’s my list of anti-patterns to watch out for when starting or moving an enterprise project into an open source model. There are probably more, and as usual, it’s an open invite to add more. Just let me know via twitter &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; and I’ll get them added right away.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;For more on Bryan’s talk on the anti-patterns he discusses, here is a video of the talk: &lt;iframe width=&quot;960&quot; height=&quot;540&quot; src=&quot;https://www.youtube.com/embed/NhgXQFk9noI?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Here’s what I believe is the &lt;a href=&quot;http://www.slideshare.net/bcantrill/corporate-open-source-antipatterns&quot;&gt;slide deck&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV (That’s this article)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Enterprise Open Source Cultural Characteristics</title>
      <link>http://adron.github.io/articles/enterprise-cultural-characteristics/</link>
      <pubDate>Sun, 16 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-cultural-characteristics/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III (That’s this article)&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My friend Glenn Block &lt;a href=&quot;https://twitter.com/gblock&quot;&gt;@gblock&lt;/a&gt; contacted me via Twitter and we discussed some of what I had discussed in the previous post. He brought up some good points and I realized there were a few points I ought to bring up regarding what I’d previously written about.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;atlassian-tools-good-stuff&quot;&gt;Atlassian Tools, Good Stuff&lt;/h3&gt;
&lt;p&gt;Most of the fight I’ve had undertake has been what appears to be against the aforementioned Atlassian Tools: JIRA, Confluence, and Stash. I think it is important to clarify my position however, the tools are perfectly capable of and well suited for any closed source internal development, and even being used for open source if they’re paired with the appropriate practices and usage patterns. If they’re not, their use can amplify the difficulty in creating open source solutions - but that amplification is merely the amplification of those cultural practices that make it difficult to change to a process that helps build useful and effective open source projects.&lt;/p&gt;
&lt;p&gt;The other thing I mentioned, was the price tag of the Atlassian tools. I failed to mention that for open source, Github pricing for Enterprise efforts just like anybody else’s is free. I believe that’s the same for Bitbucket, so the comparison was rather disingenous on my behalf. The comparison and migration path before me, to get solutions into the open, was the free utilization of Github. JIRA, Confluence, and Stash on the other hand required practices that were costly and time consuming on our behalf. Such things as maintaining the servers running the software, management of security needs (SSL/TLS/HTTPS, etc), and the whole host of managing the entirety of these servers when all we really needed for open source work was repo + wiki + issues.&lt;/p&gt;
&lt;p&gt;But I do digress, I’m ready to move from tools to practices and how those have to change. Moving from internal software development that is hidden from prying eyes to open source development, beyond tools or manifestos, has it’s largest barriers simply in cultural change that is necessary.&lt;/p&gt;
&lt;h3 id=&quot;enterprise-open-source-cultural-characteristics&quot;&gt;Enterprise Open Source Cultural Characteristics&lt;/h3&gt;
&lt;p&gt;The section of this part of the series could have been named “The Hard Part”. Cultural change is something that moves at a glacial pace in an enterprise and must be a top down and bottom up effort. If it isn’t supported by management, it’ll likely fail, and if it isn’t supported by the contributors themselves, it will surely fail.&lt;/p&gt;
&lt;p&gt;First, here are some of the positive characteristics that always help. Whether it is a brand new greenfield project or an existing project that will be started or moved to be developed in the open, these are the characteristics that are invaluable.&lt;/p&gt;
&lt;h3 id=&quot;my-current-top-5&quot;&gt;My Current Top 5&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;…key culteral characteristics for enterprise open source development.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Self-Organizing - Leaders that lead and followers that follow. Don’t be the person that won’t get out of the way. Open source projects need followers that want to dive in, prospectively lead on parts, cut out corners to build, and projects need leaders to insure that the project stays true to its intent.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Decisive - We’re talking about the internet, the wild wide open internet, being decisive in an intelligent way is vital to help an open source project grow into what it is deemed to be.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aware - It’s important when working on company projects in the open, as mention in the entry where I layed out the &lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Home Depot Manifesto&lt;/a&gt; which includes important awareness around trade secrets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inclusive - The project needs to be aware of it’s particular cultural characteristics, but it’s also important to pick up new traits and characteristics to improve development practices over time. Encourage others to join the project and actually provide some type of outreach and support for anybody that wants to help out with the project. This alone I have found is one of the most difficult features that Enterprise Open Source projects need to build and encourage. Usually enterprise projects are simply insular because of their internal facing needs. Often they don’t even realize when they could have things easier or expanded to help all involved - until it happens.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Learning - The members of the project team on an Enterprise Open Source Project need to encourage learning new ways, practices, tools, and capabilities for the project. Encouraging some to always learn puts a project on a trajectory with continued innovation, improved practices, and perpetuating a healthy balance of progress into the future. Getting a project stuck on X set of tools and such doesn’t help anyone in the long run, just take a look at the past of so many infrastructure open source projects like Cloud Foundry, HashiCorp tools, etc that were once Ruby but have migrated almost entirely to Go. In this particularly situation, learning and keeping up on the new technology has helped those platforms move forward.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are more, but these are the top 5 at the moment. If you think I’ve missed any really important trait that should be mentioned, tweet at me &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; and it’s possible we could get the top 6.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III (That’s this article)&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Let's Talk Tactical Tools for Enterprise Open Source</title>
      <link>http://adron.github.io/articles/enterprise-open-source-tactical/</link>
      <pubDate>Sat, 15 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-open-source-tactical/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the first part I wrote about the Enterprise Open Source Manifesto that was written up for Home Depot’s open source efforts. In this part I’m going to tactical some of tooling &amp;amp; cultural characteristics that came into play.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;enterprise-open-source-tooling&quot;&gt;Enterprise Open Source Tooling&lt;/h3&gt;
&lt;p&gt;Every team had a number of tools in use upon the beginning of these efforts. I’m going to dive into a few of the tools we used and how those helped and hurt us all at the same time. After that Iv’e got a discussion on future tool choices, current tool migrations, and goals.&lt;/p&gt;
&lt;h3 id=&quot;existing-pre-oss-efforts&quot;&gt;Existing Pre-OSS Efforts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;JIRA&lt;/li&gt;
&lt;li&gt;Confluence&lt;/li&gt;
&lt;li&gt;Stash&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;jira-stash-and-confluence&quot;&gt;JIRA, Stash, and Confluence&lt;/h4&gt;
&lt;p&gt;JIRA has a lot of pluses and negatives, and I do mean a lot! I’m going to start with the pain points and then move onto the positives.&lt;/p&gt;
&lt;p&gt;Access - One of the major pain points was that JIRA had harbored a completely closed communication practice. What I mean by this was that all communications, as one would assume, were being done in a very insular way. Since the tool had traditionally been used only for closed source development, it was by it’s very nature configured to be exclusionary to any and all possible open source efforts.&lt;/p&gt;
&lt;p&gt;User Limits - The way JIRA is configured, one doesn’t merely get added or become a contributor in any general sense. One needs to fall under a particular user paradigm like Active Directory, controlled auth SSO style accounts, or something of that sort. This leaves JIRA very limited for public access and contributions from an organizational perspective.&lt;/p&gt;
&lt;p&gt;JIRA is extremely heavy and many open source efforts are super lean. I realize for a project with a lot of pull requests and interactions there needs some way to oganize all the interactions, but for small projects or even reasonably sized projects JIRA is overkill.&lt;/p&gt;
&lt;p&gt;Another issue is that JIRA becomes a practice that dictates effort versus effort and results that dictate practice. This in turn makes it even more difficult to break certain practices and dogma to move toward lighter weight practices. More seamless open source projects and the practices that would and can move an open source project forward are disregarded because X, Y, and Z activities must be performed because of the “JIRA”.&lt;/p&gt;
&lt;p&gt;Confluence is actually a great wiki tool. Albeit again, it’s a matter of overkill. Often the wiki that is needed is just a simple tool that can provide absolutely minimalistic wiki features. Maybe markdown is the standard mechanism to markup wiki pages with even. Whatever the case it needs to be simple.&lt;/p&gt;
&lt;p&gt;However, again just like with JIRA, these tools work great for dramatically larger and more complex projects. They can and do provide a great ability to cohesively bring together larger teams of people to work together in a more effective manner.&lt;/p&gt;
&lt;p&gt;Stash is useful in some ways, but again just like with JIRA, Confluence and related tooling it tends to be used to provide a way to hide away the source code internally. This in turn, just as with JIRA and Confluence work toward hiding software and not toward bringing it forward in an open and transparent way for others to work with.&lt;/p&gt;
&lt;h3 id=&quot;new-tools-for-enterprise-oss-efforts&quot;&gt;New Tools for Enterprise OSS Efforts&lt;/h3&gt;
&lt;h4 id=&quot;github&quot;&gt;Github&lt;/h4&gt;
&lt;p&gt;So Github comes to the rescue. For the most part there is a simple reason that it is the defacto go-to place for open source. It’s in the open, millions already use it, their git intergration is good, they have pretty straight forward minimalist focused interfaces and features, and it gets the job done.&lt;/p&gt;
&lt;p&gt;Does Github miss key features for some? Absolutely. Do issues get cumbersome and out of control after moderate conversation. Of course they do, especially with their single depth style of forum comments. Even with whatever disadvantages it has, Github was the go-to for us when we wanted to open source software too. It provided many of the key features we need; wiki, issues, and simple ways to track for simple projects.&lt;/p&gt;
&lt;p&gt;Now, with all the negatives pointed out, one could actually use JIRA, Stash, and Confluence for open source work. You just need to open up all of the software to the public. They’ve be perfectly capable from a technical point of view to accomplish the mission, albeit it’d probably cost a ton of cash.&lt;/p&gt;
&lt;h4 id=&quot;jell&quot;&gt;Jell&lt;/h4&gt;
&lt;p&gt;Need a quick tool for managing the daily punch list, or more simply, what I generally call the &lt;em&gt;My GSD for Today&lt;/em&gt; items? Jell is a great tool for this. Others that come to mind are Trello or even just plain old Google Docs (I guess that’s G-suite now). Whatever the case, it helps members to have a punch list if it’s a day-to-day, regularly worked on project. This helps with that communication across any contributors, even if contributors are all in a single office.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That’s it for part II. More to come for this series real soon, and I’ll update the post with a link right here to Part III as soon as it’s published.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Holy Shit Watch Out for That Enterprise Open Source!</title>
      <link>http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/</link>
      <pubDate>Tue, 11 Oct 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This blog entry is going to be the conjoined events of open source work at Home Depot, enterprise open source in general, and the ideas and punch lists for a talk I have coming up in London on open source enterprise practices. So this will be a hard drifting whirlwind, buckle up!&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the last year there’s been several specific projects I’ve led and consulted on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My work at Home Depot included efforts to bring various closed sourced solutions into the open, some which have been and others that have not been - but may be on their way! Read to the end to see how you might be able to help with this.&lt;/li&gt;
&lt;li&gt;I’ve provided consulting to several enterprise efforts over the last year as they’ve looked toward bolstering their experience and effort providing a coordinated participation within the open source community.&lt;/li&gt;
&lt;li&gt;Putting together a talk related specifically to helping enterprises bridge the gap between insular, closed source, limiting internal development to a inclusive, open source, community oriented contributor and user of software solutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;enterprise-software&quot;&gt;Enterprise software&lt;/h2&gt;
&lt;p&gt;First let’s talk a little bit about enterprise software in general. There is an extremely wide range of disparity in Enterprise software. Some software turns out pretty good, others are complete catastrophes to the point the projects are cancelled and the software is deleted without remorse.&lt;/p&gt;
&lt;p&gt;Just recently this disparity in quality was brought up on via some tweets.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I don&amp;#39;t understand how huge companies with major $$$ can release software that&amp;#39;s such a shit-show - don&amp;#39;t they test it, dogfood, etc.?&lt;/p&gt;&amp;mdash; Dave Glick (@daveaglick) &lt;a href=&quot;https://twitter.com/daveaglick/status/786247215660621824&quot;&gt;October 12, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Dave Glick stated this and it spiraled into a conversation about how big companies, with seemingly endless budgets still produce such horrible applications sometimes. It reminds me of this article I read on the Pivatol Blog by Stacey Schneider (&lt;a href=&quot;https://twitter.com/sparkystacey&quot;&gt;@sparkystacey&lt;/a&gt; ), “Quiz Your Company: How Well Are You Setup to Develop Great Software?”&lt;/p&gt;
&lt;p&gt;Over time this horrible disparity can be narrowed, and the band of good to bad can move toward the “good software” end of the spectrum for enterprises. One of the key steps that helps to produce a better culture around good software for enterprises is moving the effort toward a more open practice with transparent communications, public involvement, and of course actual open source code and licensing.&lt;/p&gt;
&lt;h2 id=&quot;enterprise-open-source&quot;&gt;Enterprise Open Source&lt;/h2&gt;
&lt;p&gt;Let’s take a look at one of the best examples of an open source enterprise. Let’s talk about &lt;a href=&quot;https://www.netflix.com&quot;&gt;Netflix&lt;/a&gt;. Ok, you may be screaming in your head that Netflix doesn’t count, but at 19 years old (August 29th, of 1997 it was founded), $6.78 billion in 2015 revenue, $10.2 billion in assets, 83 million worldwide users, and 3,500 employees Netflix absolutely counts as a large enterprise.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://netflix.github.io/&quot;&gt;&lt;img src=&quot;/articles/holy-shit-watch-out-for-that-enterprise-open-source/netflix-oss-logo.png&quot; alt=&quot;Netflix OSS&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Netflix has gone hard core into the OSS realm. They’ve &lt;a href=&quot;http://techblog.netflix.com/2015/10/evolution-of-open-source-at-netflix.html&quot;&gt;written about it&lt;/a&gt; on their &lt;a href=&quot;http://techblog.netflix.com/&quot;&gt;Netflix Tech Blog&lt;/a&gt;. They’ve even gone so far as to create a &lt;a href=&quot;https://netflix.github.io/&quot;&gt;Netflix Open Source Software Center&lt;/a&gt; too. Of course all of this is is rolled together in the repositories on Github under the &lt;a href=&quot;https://github.com/Netflix&quot;&gt;Netflix Organization&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This has given Netflix massive credibility within the world of developers, providing a true resource and partner to the developer community. But what does that give Netflix from a more tactical point of view? I’ll list a few things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;More eyes on their code that they use to run production. Which translates into more ideas on improvements, catching issues faster, bug fixes inside and outside of the company, and more from this angle.&lt;/li&gt;
&lt;li&gt;Credibility in the industry translates to gaining the eye of the top tier people that Netflix wants and needs for their organization.&lt;/li&gt;
&lt;li&gt;Massive clout as a leader in innovation and technological change, which provides even more of both 1 and 2.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;home-depot-open-source-enterprise&quot;&gt;Home Depot, Open Source Enterprise&lt;/h1&gt;
&lt;p&gt;Ok, so Netflix is a big enterprise that has done it right. They’ve also been reaping the rewards in a huge way, and they’ve set a kind of guidance to others trying to tread that path. At Home Depot it’s been a bit work, but the effort has started with some tangible progress. Since software development and computer tech things is not the focus point at Home Depot, it is a logical path for the company to shift with it’s IT and related resources. As you probably know very well dear reader, Home Depot is a large brick and mortar storefront operation, and it’s best for Home Depot to focus on this, where their customers are!&lt;/p&gt;
&lt;p&gt;With that in mind, the idea for Home Depot to begin using more open source was super easy. But to start providing open source of their own and to get involved has been a dramatically larger challenge. The leadership has a very smart view of the matter, they want to be part of the community and provide and gain the advantages of going open source. Just like Netflix, there’s a lot to be gained.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/holy-shit-watch-out-for-that-enterprise-open-source/homedepot-contributors.png&quot; alt=&quot;Home Depot Contributors&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;getting-things-started&quot;&gt;Getting Things Started&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://allspark-thd.github.io/manifesto/&quot;&gt;Home Depot’s OSS Manifesto&lt;/a&gt; reads with the intent of the efforts and a break out of six specific tenets:&lt;/p&gt;
&lt;h3 id=&quot;we-value&quot;&gt;We Value&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Giving Back&lt;ul&gt;
&lt;li&gt;As developers we use tools provided by the wider community – it’s our responsibility to pay it forward&lt;/li&gt;
&lt;li&gt;Beyond the ethics, as we contribute, so will others – which improves the software we use&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Excellent Customer Server&lt;ul&gt;
&lt;li&gt;By using and improving open source, the software we provide to our associates and customers is of higher quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Creating shareholder value&lt;ul&gt;
&lt;li&gt;Making use of open source makes us more productive and efficient&lt;/li&gt;
&lt;li&gt;As we contribute software, we get the benefit of improvements from the entire community&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Entrepreneurial Spirit&lt;ul&gt;
&lt;li&gt;Encouraging associates to develop the software that interests them provides a creative outlet&lt;/li&gt;
&lt;li&gt;Many key software components we rely on were created as side projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Taking care of our people&lt;ul&gt;
&lt;li&gt;Allows associates to contribute, gives them a public showcase for their talents&lt;/li&gt;
&lt;li&gt;Participating in open source is a fantastic forum for learning from industry experts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Respect for all people&lt;ul&gt;
&lt;li&gt;Open source is one of the most diverse communities available&lt;/li&gt;
&lt;li&gt;Great feedback and communication skills can be developed working on large open source efforts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Doing the right thing&lt;ul&gt;
&lt;li&gt;Making code public is the best way to ensure that you take pride in your work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building strong relationships&lt;ul&gt;
&lt;li&gt;Open source allows developers to build relationships beyond their team&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;we-believe&quot;&gt;We Believe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Have a readme file&lt;/li&gt;
&lt;li&gt;Have a contributing file&lt;/li&gt;
&lt;li&gt;Have a license file&lt;/li&gt;
&lt;li&gt;Follow semantic versioning&lt;/li&gt;
&lt;li&gt;Have easily visible CI&lt;/li&gt;
&lt;li&gt;Tag all releases&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;have-an-idea-&quot;&gt;Have an Idea?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Could my code be helpful for other devs, and is it something that doesn’t already exist?&lt;/li&gt;
&lt;li&gt;Do I feel comfortable that work I’m doing does not include trade secrets?&lt;/li&gt;
&lt;li&gt;Do I have CI setup, and is it publically visible?&lt;/li&gt;
&lt;li&gt;Why are you still asking questions, push some code!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;readme-file&quot;&gt;Readme file&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The readme is the first thing will people will see about your project. This should provide an explanation for why it exists, and why anyone would care about it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;What are my rights?
You also should include license information, so they understand how to use it. Our default license is Apache 2
How can I help?
If you’re open sourcing something, you are hopefully open to outside contributions. Make sure your expectations and process are clearly laid out for people who want to help. You should tell them how to make the thing run and how to test it – in simple, easy to follow steps.&lt;/li&gt;
&lt;li&gt;Does this thing even work?
A sign of a high quality project is well written tests, that are continuously run. By having CI setup and publicly shown, visitors to your repo can have confidence in the code. This could include badges or a link to an example of the live application&lt;/li&gt;
&lt;li&gt;Is anyone maintaining this and/or what just changed?
As you update the project, you should provide semantic versioning to allow consumers to understand the types of changes made, and allow them to use the project with security. You should include release notes that detail any important features or bug fixes, and specifics on any breaking changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;trade-secrets-what-shouldn-t-be-open-sourced-&quot;&gt;Trade Secrets - What shouldn’t be open sourced?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Code that includes work that is licensed by someone else&lt;/li&gt;
&lt;li&gt;Work that provides a significant competetive advantage over other retailers&lt;/li&gt;
&lt;li&gt;Projects that are dependent on THD specific environment&lt;ul&gt;
&lt;li&gt;This should be only true in rare cases&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code that does not have CI or automated unit tests&lt;ul&gt;
&lt;li&gt;Please don’t do this, even if you aren’t open sourcing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code that is essentially the same as other open source projects&lt;ul&gt;
&lt;li&gt;Could you contribute to those projects instead?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;tactical-process&quot;&gt;Tactical Process&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure your manage/team lead approves the effort&lt;/li&gt;
&lt;li&gt;Request open source submission approval&lt;/li&gt;
&lt;li&gt;Push the code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is of course our version of the OSS Manifesto as detailed at &lt;a href=&quot;http://ossmanifesto.org/&quot;&gt;http://ossmanifesto.org/&lt;/a&gt; (after I posted, realized this site is dead!  :( But here’s the &lt;a href=&quot;https://github.com/allspark-thd/manifesto&quot;&gt;repo of the HD Manifesto&lt;/a&gt;). This is one piece I highly suggest any group of individuals at an enterprise to give a read to, and create their own manifesto per their enterprise they work for. It’s good for many reasons to write this out and provide it.&lt;/p&gt;
&lt;p&gt;The main two reasons I really like the OSS Manifesto include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The transparency it provides to users of the project(s) of a particular enterprise.&lt;/li&gt;
&lt;li&gt;The other thing is that it provides a much needed brain storming session to identify and define the groups intent and efforts on a more metaphsycial level, which is hugely needed to understand how a team working on a project and it’s prospective contributors would interact with each other. Defining these core tenants is fundamental to a smooth workflow between contributors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.netflix.com&quot;&gt;Netflix&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Netflix&quot;&gt;Netflix Wikipedia&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.homedepot.com&quot;&gt;Home Depot&lt;/a&gt; and &lt;a href=&quot;https://github.com/homedepot&quot;&gt;Home Depot Github Org&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>The Curse of Windows Server &amp; Windows Server 2016 Salvation</title>
      <link>http://adron.github.io/articles/the-curse-of-windows-server-windows-server-2016-salvation/</link>
      <pubDate>Fri, 07 Oct 2016 14:38:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/the-curse-of-windows-server-windows-server-2016-salvation/</guid>
      <author></author>
      <description>&lt;p&gt;Over the last year I’ve worked with &lt;a href=&quot;https://homedepot.com&quot;&gt;Home Depot&lt;/a&gt;, specifically the &lt;a href=&quot;http://www.quotecenter.com/&quot;&gt;Quote Center&lt;/a&gt; Group, strive forward toward a better future. Yeah, that sounds a bit campy, but seriously. I started with &lt;a href=&quot;http://blog.adron.me/articles/after-816-days-taking-a-job/&quot;&gt;three core objectives, which I wrote about previously&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Community Contributions&lt;/li&gt;
&lt;li&gt;Site Reliability&lt;/li&gt;
&lt;li&gt;Talent Recon&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve been able to help with each of those things over the last year, with more progress being made on some than others. Right now, I want to delve a bit into the adventure of &lt;a href=&quot;https://landing.google.com/sre/interview/ben-treynor.html&quot;&gt;site reliability&lt;/a&gt; at Quote Center. First off, I had the honor of being first guard for Quote Center in the realm of site reliability. I had a lot to do just to set some groundwork on what that position really meant. In addition to the other two &lt;em&gt;roles&lt;/em&gt;, err, &lt;em&gt;priorities&lt;/em&gt;, it was like taking a job that would have three roles rolled into one. For this article though, I’m going to write about specifically the site reliability and what I did to get some practice and culture around the notion of site reliability at Quote Center.&lt;/p&gt;
&lt;p&gt;The first thing, was simply to write out some ideas about what this would involve. Here are a few of my original questions that I scribbled on the matter.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Servers/Instances - Need to figure out where and what servers are magical black magic servers versus fully automated instances? Where be the goodies?&lt;/li&gt;
&lt;li&gt;Networking - What’s where and who’s doing this?&lt;/li&gt;
&lt;li&gt;Monitoring - What do we know exists, where, and how are we alerted when something goes down? How many things are there? How many could go down?&lt;/li&gt;
&lt;li&gt;How does site reliability measure up versus systems admin, network opes, or what not? Who says what?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was working entirely from a blank slate, it appeared the first step would be to get a better definition of what exactly this should cover. One thing I did do was read up on what the notion of Site Reliability Engineer was. I wanted to have a good industry definition of the role. That led to a quick set of resources via Google. Google seems to be the creator of said position, whether they are or not doesn’t matter, because the material they have on the role is excellent. To paraphrase a summary, what an SRE is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An SRE is basically a software engineer that is responsible for designing operations functions. This includes interacting with production environments, automation, high availability improvements, monitoring, and more. All approached from a programmatic perspective versus the more traditional notion of hands on systems administration or network administration. Other terms most commonly associated with and responsibilities of SREs include; availability, latency, performance, efficiency, change management, monitoring, emergency response, and capacity planning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As I dove into this work, amid all the other priorities, I was spending about ~15-20 hours a week on the efforts under this priority (or role). This was ok to get things off the ground. Here are a few other key things I put together within the first 6 months.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We needed action ASAP to modernize and build on modern cloud infrastructure. I went through working with various partners in the organization to insure that our decisions would work with, or align with, or utilize software, services, and solutions that would jive with corporate. Even though I’d started down the route with Amazon Web Services (AWS), Home Depot made a &lt;a href=&quot;http://www.reuters.com/article/us-google-home-depot-cloud-idUSKCN0WO380&quot;&gt;higher level decision to move forward with Google Cloud Platform&lt;/a&gt;. This was an easy switch to make, because I’d also started a trial with various &lt;a href=&quot;https://www.hashicorp.com/&quot;&gt;HashiCorp&lt;/a&gt; tools (Atlas, Terraform, and Packer specifically) that made it a breeze to swap out anything already done.&lt;/li&gt;
&lt;li&gt;The next thing was to get some practices put into place to handle change management of infrastructure. I started working on this in the subsequent 3 months but made very little movement forward. This was because my other priorities took precedence during this time - the Talent Recon &amp;amp; Community Contributions priorities. During this time I worked with Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37/&quot;&gt;@thoward37&lt;/a&gt;) to put on two conferences we’d co-founded: &lt;a href=&quot;http://dotnetfringe.org/&quot;&gt;.NET Fringe 2016&lt;/a&gt; and &lt;a href=&quot;http://nodepdx.org/&quot;&gt;Node PDX 2016&lt;/a&gt;. However, even in spite of all those work, I was able to implement another major HashiCorp Server with Atlas. This helped to start shaping our workflow in a tremendous way.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This was great, and in that first 6 months I was able to get a lot of traction on those efforts. Then the Windows Server battle started…&lt;/p&gt;
&lt;h2 id=&quot;the-windows-server-nightmares&quot;&gt;The Windows Server Nightmares&lt;/h2&gt;
&lt;p&gt;More than a few things we wanted to get deployed using container technology. But because of the limitations of Windows Server around its complete lack of container capabilities and the limited support of drivers within .NET, our container hopes were dashed for the time being. Even with this in our way of moving forward with containers, we knew it would eventually be the future. So what did we do in the meantime to move forward and build out our microservices now?&lt;/p&gt;
&lt;p&gt;The team delved into deployment per Windows Server using a Windows Services Service based approach. In other words, the services you see when you pull up the MMC on Windows Server? Yeah, that’s what we used in the meantime to deal wtih the lack of container support. This gave our microservices the ability to get deployed with many of the feature notions we wanted and will eventually use with container tech. This however didn’t bode well for immutable deployments or clean continuous integraiton and deployment to Windows Server, and we continued to look forward to a container option in the near future with excitement.&lt;/p&gt;
&lt;h2 id=&quot;yay-windows-server-2016-to-the-rescue-&quot;&gt;Yay Windows Server 2016 to the Rescue!&lt;/h2&gt;
&lt;p&gt;Then, enter Windows Server 2016. The news that Windows Server 2016 would have container support was huge. We would absolutely move onto that to gain the advantage of containers if, and only if .NET Core didn’t gain enough driver and related capabilities that we didn’t get to move to Linux first. You see, if we had our druthers, we’d just move to Linux and forgo Windows Server altogether. But Windows Server 2016 at least provided us a path forward if .NET Core drivers and such weren’t ported before it’s release.&lt;/p&gt;
&lt;p&gt;On the flip of all this, you might ask, “&lt;em&gt;why would you deploy .NET stuff to&lt;/em&gt; Linux &lt;em&gt;instead of&lt;/em&gt; Windows Server?” There are a host of reasons, and the first that always pops into my mind wasn’t one of our actual concerns, but it is routinely for others. That would be pricing. Holy bajeezuz the licensing costs adds a lot to running Windows Server instances. It makes many multi-VM solutions cost prohibitive for many solutions, and hopefully containers may change this paradigm more effectively.&lt;/p&gt;
&lt;p&gt;If you are in the search for server tech for microservice hosting, suffice it to say, Windows Server is &lt;strong&gt;&lt;em&gt;NOT&lt;/em&gt;&lt;/strong&gt; particularly the way to move forward unless you have tons of Windows proprietary code base or IIS demands of some other proprietary demand for Windows Server. There is an extreme minimum of reasons to use Windows Server if you’re trying to deploy and efficiently manage microservices and the related infrastructure, practices, and advantages. The ecosystem, market, and industry as a whole has generally moved onto or has just been using &lt;em&gt;JVM + Cloud Provider + Automation Toolchain&lt;/em&gt;. This usually equates to &lt;em&gt;JVM + AWS + HashiCorp Tools&lt;/em&gt; or &lt;em&gt;JVM + GCP + Chef&lt;/em&gt; or &lt;em&gt;JVM + Azure + Puppet&lt;/em&gt;. Most of the future looks something like that. These tools are all dramatically better places to start than using a Windows OS based environment. But alas, back to the pending salvation of Windows Server 2016.&lt;/p&gt;
&lt;h2 id=&quot;the-other-fix-x-plat-net-core&quot;&gt;The Other Fix, X-Plat .NET Core&lt;/h2&gt;
&lt;p&gt;The other solution, post Windows Server 2016, which I look forward to with even more excitement is the ability to run .NET Core Apps on Linux. The reason, is that the operational characteristics for Linux, especially in a high availability, highly scalable, cloud environment (etc., etc., etc.) are years ahead of the Windows Server solutions at this time. On a cost per server and cost per unit of compute, Linux is easily the winner - and of course that is if you are even dealing with an OS yourself - if you’re in the vmless or serverless game then prices get even cheaper prospectively. However, as is obvious, Windows Server isn’t even in that game, it’s a purely cloud play really.&lt;/p&gt;
&lt;p&gt;If you are a Windows Server advocate and you do have legitimate needs to use Windows Server, but still want all the good bits that come along with container technology, Windows Server 2016 is going to be your salvation! Maybe. Soon it’ll even be available in Google Cloud (I hope REAL soon) and I can spool up a few examples of said OS with said .NET Core bits and then migrate said .NET Core bits directly to Linux! At least, I’m looking forward to doing just that.&lt;/p&gt;
&lt;h2 id=&quot;summary-how-you-could-help&quot;&gt;Summary &amp;amp; How You Could Help&lt;/h2&gt;
&lt;p&gt;As you know, from my article “&lt;a href=&quot;http://blog.adron.me/articles/sitrep-home-depot-wrap-up-next-talks-next-job/&quot;&gt;Home Depot Wrap Up and Job Talk&lt;/a&gt;“, I’ve moved to Seattle and am working on a transition. Quote Center is looking for people who would love to dive into the world of site reliability, working with not just Windows but also Linux, Node.js, and a host of other systems. If you’re keen on joining the team, feel free to &lt;a href=&quot;http://blog.adron.me/docs/contact/&quot;&gt;reach out to me&lt;/a&gt; and I can put you in touch with the right people to get the conversation rolling. Otherwise you can also just check out the &lt;a href=&quot;http://quotecenter.com/#openpositions&quot;&gt;job descriptions here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Home Depot Wrap Up and Job Talk</title>
      <link>http://adron.github.io/articles/sitrep-home-depot-wrap-up-next-talks-next-job/</link>
      <pubDate>Thu, 29 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/sitrep-home-depot-wrap-up-next-talks-next-job/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/home-depot.png&quot; alt=&quot;Home Depot&quot;&gt;
&lt;/div&gt;

&lt;p&gt;First, I will be available with a possible start date of November the 28th. I’m currently wrapping up some big projects and completing training for the Home Depot Team and the great progress we’ve made over the last year. If your company is looking for someone with my mixed array of technical skills and soft skills, you can &lt;a href=&quot;http://adron.github.io/docs/about&quot;&gt;check out my resume &amp;amp; details&lt;/a&gt; and initiate &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;job talk with me here&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;On to the rest of the news. If you’ve seen me speak lately I’ve mentioned the open source efforts we’ve had going on at &lt;a href=&quot;http://www.homedepot.com/&quot;&gt;Home Depot&lt;/a&gt; and related efforts I was working on. Some I’m working dilligently to release via the &lt;a href=&quot;https://github.com/homedepot/&quot;&gt;Home Depot OSS Organization on Github&lt;/a&gt; and I’ll still be releasing others soon via my Github account (&lt;a href=&quot;https://github.com/Adron&quot;&gt;@Adron&lt;/a&gt;) and blogging about it here on &lt;a href=&quot;http://blog.adron.me&quot;&gt;Composite Code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since this is one of those rare times in my career where I’m not 100% sold on what I’ll do next, I’m open to fielding prospects and seeing what is out there. This is a different approach for me, as I usually determine a company, particular work that needs done and go after that gap. But I’d like to get a feel for what companies feel they need at this particular time. Since I have a wide range of skills, I can step into a number of positions and immediately start to contribute to projects within a company.&lt;/p&gt;
&lt;p&gt;Here are some positions I’d find attractive and could provide value for (or build) a team immediately!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Building or Expanding a Team&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Need someone to hire, build, and create a cohesive, diverse, and powerful culture of core contributors (developers, designers, advocates, evangelists, or similar). I can knock this one out of the park for the right company. Yes, I’m a bit particular, but I’m not just going to whimsically work for any company (the best people won’t work for just any old company anyway). If you are looking to put a team together and want somebody that can do that for you, I’d like to sit down to a conversation soon. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Coding Architect&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Have some architecture problems, that seem a bit unique or problematic? If you need someone to come in and push forward on design, patterns, practices, and actual implementation then this would also be a conversation I’d be interested in having. I’d be happy to dive into whatever the stack might be (or help decide on the stack): Java (Scala/Kotlin), Golang, Node.js or even .NET (C#/F#) for the right company. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Development &amp;amp; Operations Architect&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Have some architecture that needs to go along with an application and want to build or insure a solid continuous integration and delivery pipeline (or messaging based queue for delivery to production)? This is another possibility I’d be happy to talk about. I really love working with systems to build out reliable immutable infrastructure, data storage mechanisms (distributed, RDBMS, whatever the need calls for) and insure development can continue forward with extremely high confidence levels. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Developer Advocate/OSS Project Lead&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you have an open source project I’d love to take lead on it and also provide advocacy for that project. This role is not to be confused with evangelist, as that’s a fine role for other people, but I want to be in the code and advocating from a position with the team. I’ve done this before with projects like the Iron Foundry for Cloud Foundry and others, and loved it. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Mergers &amp;amp; Acquisition Technical Evaluations&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is not something one sees everyday, but I’ve worked in a consulting role and have assisted others with this work before. I find it really interesting looking at prospective ROI, current run rates, but also at the specific details of whehter a product or service can even be incorporated and integrated into the acquiring company. In the case of merging, this differs from acquisition in that both entities and both companies’ products and services will both need to polymorph into a new whole. If you’re company is looking to get into some M &amp;amp; A’s, &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;let’s talk about how I can help&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If any of these sound like a need you have, please &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;reach out with additional information&lt;/a&gt; and I will be in contact ASAP.&lt;/p&gt;
&lt;p&gt;Besides the above theoretical jobs above, here are a few other things that I would like in a job. Things that just make it all worthwhile, here’s a list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Work Environ / Soft Skills / Culture&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flexible hours remote or remote (out of office). Whatever the case, I’d like to work with a company that has the ability and acumen to manage the workflow and efforts among team members remotely. If you’re a company that wants to upgrade the development and operational characteristics of the culture, I can also help your company incorporate highly effective remote capabilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/cascadia-bioregion.png&quot; alt=&quot;Cascadia&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;If there is travel, I prefer to keep it to a productively effective 10-15% of the time. Traveling dramatically decreases overall ability to contribute to actual work in an effective way. I do love to travel, speak, and get involved with the worldwide community but I always like to make sure that this involvement doesn’t stymie me from contributing to actual coding, design, and related efforts.  NOTE: If travel is within the Cascadian Bioregion (see image: includes YVR, PDX, SEA, etc) it’s easy to increase my travel to 15-25% of the time as travel within the region is so easy. I probably should include SFO too, it’s super easy to get there and doesn’t cause disruption to daily workflow. (i.e. &amp;lt; 2 hr trip)&lt;/li&gt;
&lt;li&gt;Design, build, and communicate. These are the things I like to do. I like to create what will work for high volume or high speed systems, then build prototypes and communicate how these work. Maybe I would be the one deploying to production, maybe the system is production that I’m deploying, but whatever the case is I’m happy to lead efforts on architecture and work with teams to build that architecture.&lt;/li&gt;
&lt;li&gt;I love to provide leadership for teams, I love to build teams, and I like working with teams. Albeit I’m particular about team diversity and culture, I can bring my own skills and the ability to bring people together on a team and expand teams. If the culture is off kilter, I can help with that. If the culture is spot on, I can work effectively with that. Whatever the case, I’m a high communication, GSD type of guy provided the right environment and reigns removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/gcp.png&quot; alt=&quot;Google Cloud Platform&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Technical Skills&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I’ve found Google Cloud Platform (GCP) a pleasure to work with lately. That combined with Terraform, Packer, and related HashiCorp tooling has been a lot of fun and provided an extremely high value for us at Home Depot.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/hashicorp.png&quot; alt=&quot;HashiCorp&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;AWS has been another I’ve worked with that has been of stellar value, not particularly at Home Depot but at multitudes of startups and during consulting. AWS is still for many things my go to cloud provider option.&lt;/li&gt;
&lt;li&gt;Azure is another I’ve used that would be an interesting service to use again. It’s been well over 2 years since I worked with or provided Azure support or consulting. I’ve got a soft spot in my heart for this cloud provider since I led teams back in 2010 writing some of the first &lt;em&gt;white papers&lt;/em&gt; for the service!&lt;/li&gt;
&lt;li&gt;I’m comfortable with C#, JavaScript, Java (mostly), and am looking forward to writing more Golang and happily will dive into Scala, Erlang, F#, and a whole host of other languages.&lt;/li&gt;
&lt;li&gt;I’m happy to work with container tech (Rocket/CoreOS) or Docker and I’ll also help keep your company grounded that it might not be the panacea you’re looking for. But they definitely have lots of awesome uses!&lt;/li&gt;
&lt;li&gt;I’d prefer a Unix/Linux environment to work in, but I’ll happily help remove Windows Servers from deployment requirements!  ;-)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/docs/&quot;&gt;Contact me&lt;/a&gt; or let’s &lt;a href=&quot;http://adron.github.io/docs/&quot;&gt;talk jobs&lt;/a&gt;, cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 4 - Conference Day 2 - A Short Summary</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-4/</link>
      <pubDate>Sun, 11 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-4/</guid>
      <author></author>
      <description>&lt;p&gt;I’m working on getting back in the saddle after a great week at HashiConf and a weekend away at Seaside on the Oregon Coast. With that, I haven’t had a lot of time to write up day 4, which involved a lot of great talks and conversations. Those topics will come up in some subsequent articles, in the meantime please enjoy these videos I made of my HashiConf Adventures.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/182234514?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234580?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234602?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234619?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Autopilot Pattern Application Organization</title>
      <link>http://adron.github.io/articles/autopilot-pattern-application-organization/</link>
      <pubDate>Thu, 08 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/autopilot-pattern-application-organization/</guid>
      <author></author>
      <description>&lt;p&gt;Context: What is the &lt;a href=&quot;http://autopilotpattern.io/#how-do-we-do-it&quot;&gt;Autopilot Pattern&lt;/a&gt;?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The autopilot pattern automates the lifecycle of each component of the application. Whether we architect our application as a single container, in tiers, or as microservices, each container that makes up the application has its own lifecycle, and its own set of actions that are necessary during that lifecycle. Each of these application components are often applications in themselves, like a database server, in-memory cache, or the reverse proxy that fronts our application, in addition to the Node.js, Python, Ruby, or other code that makes the set of components a complete application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The only caveat I would add here is that &lt;em&gt;containers&lt;/em&gt; are largely irrelevant as long as your infrastructure virtualization is programmatic controlled. Of course, hyper-visor based virtualization can be more troublesome or simplify things when building out infrastructure programmatically or from a configuration based perspective. Whatever the case, use what works for your situation. The larger point of all this is to automate things for consistency, reliability, and repeatability.&lt;/p&gt;
&lt;p&gt;The way I have started to break out applications into the autopilot pattern is based on what I’ve dubbed three eras:&lt;/p&gt;
&lt;h2 id=&quot;iron-throne-era&quot;&gt;Iron Throne Era&lt;/h2&gt;
&lt;p&gt;In this era has a deluge of nightmarish problems. You might as well as just give up the quest for the throne during this era. Hardware that isn’t programmatic plagues this era. Networking that needs manually configured or applications that don’t even understand basic TCP/IP Networking or related communications throw a massive barrier into full automation in this era.&lt;/p&gt;
&lt;h2 id=&quot;renaissance-era&quot;&gt;Renaissance Era&lt;/h2&gt;
&lt;p&gt;This era is when things started getting good. I like to think of this era as starting right around 2007, when automation started to take a much bigger step forward with all sorts of things we could actually automate. AWS launched in 07’ and from there, more networking automation, tooling, and application tooling exploded with the first semblances of real PaaS coming to fruition.&lt;/p&gt;
&lt;h2 id=&quot;iron-man-era&quot;&gt;Iron Man Era&lt;/h2&gt;
&lt;p&gt;This era is where we are now. With a plethora of methods to automate networks, applications, deployments, integration, and whatever else that comes up. We’ve gotten to a stage where having viable technology options aren’t the problem anymore. Our question now just lie around how and in which way do we organize, use, and get sorted our various fully automated application deployments.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s take a look at the applications from each of the eras.&lt;/p&gt;
&lt;h1 id=&quot;iron-throne-era-application&quot;&gt;Iron Throne Era Application&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/iron-throne-era.gif&quot; alt=&quot;Iron Throne Era Application&quot;&gt;&lt;/p&gt;
&lt;p&gt;Yup, so done with that era’s app. It’s best left in the past.&lt;/p&gt;
&lt;h1 id=&quot;renaissance-era&quot;&gt;Renaissance Era&lt;/h1&gt;
&lt;p&gt;So let’s talk about this era in respect to the autopilot pattern. There’s still likely to be one or two little pieces here or there that &lt;em&gt;might&lt;/em&gt; not be automated, but it should be an extreme rarity in this era.&lt;/p&gt;
&lt;p&gt;In this era we might have an ASP.NET MVC Application with a front end using Node.js to build the UI components for deployment. To specifically distinct build operations need to occur. Often this part of the over solution would at least be in one project repository or working directory. Often, and this is where we run into one of the most common plights of today’s devops or developer team. The application is in one directory but the server instances are deployed either manually or in a way that requires regular interaction and manipulation.&lt;/p&gt;
&lt;p&gt;Working through this application working toward deployment often looks like this for this application.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Application Build Starts&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;-&amp;gt; Continuous Integration (passes)&lt;/p&gt;
&lt;p&gt;-&amp;gt; Pipeline Checks Pass&lt;/p&gt;
&lt;p&gt;-&amp;gt; Existing Infrastructure Receives Executing Code&lt;/p&gt;
&lt;p&gt;In this era, the infrastructure is autonomous - almost entirely - of the application that actually runs on the infrastructure. The process for deployment of the infrastructure generally follows an approach like this.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;OS Installed or Image Created/Started&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;-&amp;gt; Server installed (Apache, Nginx, IIS, Etc)&lt;/p&gt;
&lt;p&gt;-&amp;gt; Networking setup appropriately for DNS/Routing/Etc.&lt;/p&gt;
&lt;p&gt;-&amp;gt; Structure setup and built/deployment code is placed on server&lt;/p&gt;
&lt;p&gt;Of course each of these flows are simplified. What I’m drawing an emphasis to is that they’re autonomous but must work in conjunction form the perspective of either repositories (folders or wherever they’re stored). Another thing to think about, is that the application cant’ actually deploy itself, nor can the infrastructure do anything without the application. This is obvious, but if you think about it for a moment, this is actually how we commonly store and organize our applications today. The code is in one repository and the infrastructure bits are shoved off in some other folder or repository somewhere else. This type of organization defines the very essence of the disconnected nature of this era’s efforts to automate application deployment and infrastructure.&lt;/p&gt;
&lt;h1 id=&quot;iron-man-era&quot;&gt;Iron Man Era&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;and onward to the Jarvis Era&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alright, this is the era we’re at now. This is the era I’m really looking forward to speaking with people about and coming up with today and tomorrow’s solutions!&lt;/p&gt;
&lt;p&gt;Forget the disparate nature of the renaissance era. Think of the core principles behind the &lt;a href=&quot;http://autopilotpattern.io/&quot;&gt;Autopilot Pattern&lt;/a&gt;. This is the era where things start to come together. Things are still somewhat in distinct repositories but sometimes might not be (more on that later). But things in this era are brought together via a systemic delivery mechanism, commonly referred to as continuous delivery. The organization of these applications, infrastructure, and related projects are more unclear then some of the limited, vertically developed applications of the renaissance era apps. Why not add the infrastructure markup, code, networking, or other related elements to the code repository? Isn’t that the idea behind devops originally anyway? Whatever the intent, here’s my proposals for this below, using a Node.js Application.&lt;/p&gt;
&lt;h1 id=&quot;iron-man-era-autopilot-pattern-application-structural-organization&quot;&gt;Iron Man Era Autopilot Pattern Application Structural Organization&lt;/h1&gt;
&lt;p&gt;Wow, that was a heckuva section title eh!&lt;/p&gt;
&lt;p&gt;First thing I always do is create a directory, change into that directory and run git init and create an ignore file. I generally go ahead and throw in the most important file of all to ignore at this point, the nefarious .DS_Store file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;mkdir whatever-the-app-is
git init
touch .gitignore
nano .gitignore
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;…add stuff and save it…&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;git add -A
git commit -m &amp;#39;First commit!&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/first-steps.gif&quot; alt=&quot;First Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;After that, I create three directories: terraform, packer, and nodejs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/second-steps.gif&quot; alt=&quot;Second Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;From here I create the application project that I’ll develop from.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/third-steps.gif&quot; alt=&quot;Third Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;Then the final step is to setup the infrastructure parts of the application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/fourth-steps.gif&quot; alt=&quot;Fourth Steps&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;a-few-of-the-key-advantages&quot;&gt;A Few of the Key Advantages&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;With all of the core elements of the application combined; infrastructure, application code, configuration, and others combined there isn’t the confusion about where X or Y repo is located in relation to the overal project. Everything that is needed for the application, for it’s deployment, for it’s development, and for the future of the application is included in the repository.&lt;/li&gt;
&lt;li&gt;When working on this code repository, it is in essence practicing what is preached with regard to the ideals of &lt;em&gt;DevOps&lt;/em&gt;. Having the infrastructure and application code together truly does bring together development and operations.&lt;/li&gt;
&lt;li&gt;Communication, pending of course source control practices and workflow are followed, is drawn together even more among the individuals who would be working on the code for the application or infrastructure or whatever element of the solution.&lt;/li&gt;
&lt;li&gt;The continuous integration (CI) and delivery (CD) services now don’t need multiple authentication credentials or keys to go out and pull together the code, infrastructure, and related elements. Instead we’re down to one repository that then can be deployed via CD to whatever would host the infrastructure.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;the-conversation&quot;&gt;The Conversation&lt;/h2&gt;
&lt;p&gt;So is setting up directories and tossing the respective elements into the project the best way to do this? It may be, it may not be, but it’s one possible solution. The idea however to bring these things together in a way where they seamlessly work together demands some type of way to connect the architectural elements. Putting them in one repository is one distinctive solution. Another possible solution might be to have a parent repository that collects other repositories together that would have the respective infrastructure, application, and related glue code.&lt;/p&gt;
&lt;p&gt;Recently with the talk “&lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;Organizing Infrastructure Configuration and Workflow&lt;/a&gt;“ at HashiConf, Evan, myself and many others have started to discuss additional ways to put together the meat and potato basics of these applications. I believe I might even have to dub it something new, as it appears the collection of these things could bring together a truly better way to build and deploy applications consistently, reliably, with higher levels of quality.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 3 - Conference Day 1 - Presentation Time</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-3/</link>
      <pubDate>Wed, 07 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-3/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-3/01-hallway-hacking.jpg&quot; alt=&quot;Hallway Hacking&quot;&gt;&lt;/p&gt;
&lt;p&gt;Day 3 of my trip, and day 1 of the conference kicked off calmly. I made a cup of coffee with my &lt;a href=&quot;http://www.aerobie.com/product/aeropress/&quot;&gt;Aeropress&lt;/a&gt; &amp;amp; props to &lt;a href=&quot;https://twitter.com/aneel&quot;&gt;Aneel&lt;/a&gt; for planting the idea a bunch of months ago by showing me how he uses it.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Good morning &lt;a href=&quot;https://twitter.com/hashtag/HashiConf?src=hash&quot;&gt;#HashiConf&lt;/a&gt;. Cheers! &lt;a href=&quot;https://t.co/TxfqtBVmCS&quot;&gt;pic.twitter.com/TxfqtBVmCS&lt;/a&gt;&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/773545481704124417&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-3/02-repping-devopsday-pdx.jpg&quot; alt=&quot;Representing for Devops Day PDX&quot;&gt;
&lt;/div&gt;

&lt;p&gt;While picking up some breakfast, I realized, how one could create a conference of just hallway activity. I always find myself hacking in a hallway at every conference I’ve ever been to.&lt;/p&gt;
&lt;p&gt;For my respective tshirt of the day, I had to give some love and rep for Devops Day PDX. It was also an excellent conference that a number of organizers did a great job with.&lt;/p&gt;
&lt;p&gt;After breakfast all of the speakers, attendees, and everybody went into the main room for the keynote. We gathered, two big screens displayed beside the podium. Once everyone got seated &lt;a href=&quot;https://twitter.com/sethvargo&quot;&gt;Seth Vargo&lt;/a&gt; came out to kick off they keynote and introduce the speakers.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
&lt;img src=&quot;/articles/hashiconf-trip-day-3/03-ready-for-the-keynote.jpg&quot; alt=&quot;Ready for the Keynote&quot;&gt;
&lt;/div&gt;

&lt;p&gt;After the keynote I chatted about some thoughts on Vault and related security technology.&lt;/p&gt;
&lt;p&gt;I started to walk onward toward the speakers room again but ran into Bryan Cantrill (CTO @ Joyent, lover of Oracle) and James Nugent. They discussed a number of things, one being certain failings of Go. This was interesting to me as I’m just starting to hack around with the language and now have a list of things I will ensure I look into within the toolchain itself. I also wish I could have recorded this conversation for you dear reader, because let me tell ya, Bryan has more overheards (you know, OH on twitter) that need to be published on Twitter than I could even hope to record. We’re talking about 10-20 notable overheard quotes per second, he’s boss on phrasing.&lt;/p&gt;
&lt;p&gt;I’ll have more on Vault, some of the topics that came up in conversation, and more in subsequent blog entries. But for now I was happy with the simple things in life, like tweeting via paper. :-o  #shocks #muchsmartass&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Paper &lt;a href=&quot;https://t.co/vFBkijD8Io&quot;&gt;pic.twitter.com/vFBkijD8Io&lt;/a&gt;&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/773594438195027968&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;As scheduled (thanks for wrangling us speakers Kristen, you did an excellent job!) Evan and I were setup and ready precisely on time. We kicked off our presentation at exactly 3:35pm. More details (slide deck, code, links, etc) on the talk can be found on the page I’ve created for the talk &lt;a href=&quot;http://adron.github.io/articles/hashiconf-trip-day-3/&quot;&gt;here&lt;/a&gt; and whenever the video of the talk is available I’ll post a link there and update with a link here.&lt;/p&gt;
&lt;p&gt;The talk went exceptionally. Both Evan and I were happy with how things turned out. Namely, here are a few high points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code was committed live on Github for features related to create GCP Projects with Terraform. The respective resources will be available soon as they’re ready for a subsequent build.&lt;/li&gt;
&lt;li&gt;Evan did not suffer any consequences from the heat of standing behind the curtain, as wizards sometimes do.&lt;/li&gt;
&lt;li&gt;Our key points of conversation topics came across well, funny parts delivered with laughs, but more importantly there were more than a few people after the talk that also wanted to contribute and discuss further these ideas. The notion of bridging together one’s autopilot pattern based, 12-factor app style, intelligently monitored systems style architectures into application projects was something that is on more than a few people’s minds. I’ll have more on this as conversations continue, and hope you dear reader may want to jump into that conversation too.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Literally hiding behind the curtains at &lt;a href=&quot;https://twitter.com/hashtag/hashiconf?src=hash&quot;&gt;#hashiconf&lt;/a&gt; as &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@adron&lt;/a&gt; does his part of the talk. &lt;a href=&quot;https://twitter.com/hashtag/spooky?src=hash&quot;&gt;#spooky&lt;/a&gt; &lt;a href=&quot;https://t.co/9w65aQ916T&quot;&gt;pic.twitter.com/9w65aQ916T&lt;/a&gt;&lt;/p&gt;&amp;mdash; Evan Brown (@evandbrown) &lt;a href=&quot;https://twitter.com/evandbrown/status/773664064333492224&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;After the presentation conversations went on for another 2 hours or so. But after that a number of Googlers and myself headed off for Oxford Market, Pliny the Elder, and adventure in Napa.&lt;/p&gt;
&lt;p&gt;If you’d like to dive into the conversations around application organization, configuration, maintenance, and management of said projects, do sign up to &lt;a href=&quot;http://blog.adron.me/thrashingcodenews.html&quot;&gt;Thrashing Code&lt;/a&gt; and I’ll be pushing forward that conversation and herding all of us cats into a medium in which we can discuss these things further.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 2 - Part II - Reception and Speakers Dinner</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-2-part-II/</link>
      <pubDate>Tue, 06 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-2-part-II/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/03-up-the-hill.jpg&quot; alt=&quot;Up the Hill&quot;&gt;&lt;/p&gt;
&lt;p&gt;Before diving in to day 3 of my trip, I need to do justice to the awesome reception, speakers dinner, and conversations of the night before.&lt;/p&gt;
&lt;p&gt;After arriving and synching up with Evan on our presentation, I wandered around the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt; for a little while and just explored what was around. The resort had several bars, a bowling alley, coffee shop, and a host of other amenities along with their endless supply of wine. The views around the vineyard, up on the view point atop the hill next to the resort was very nice.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/04-looking-back.jpg&quot; alt=&quot;Looking Back&quot;&gt;&lt;/p&gt;
&lt;p&gt;I walked up toward where the reception would be to take the picture above. About two thirds of the way to the top I turned around and took this panoramic shot. Then I walked back down to the mid-point and got this panoramic shot of the Meritage itself.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/04-the-wide-angle-meritage.jpg&quot; alt=&quot;The Wide Angle Meritage&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/02-mary.jpg&quot; alt=&quot;Mary&quot;&gt;
&lt;/div&gt;

&lt;p&gt;While standing there taking the panoramic I turned around and saw a statue of Mary covered in rosaries. I guess that’s a thing, one I’ve never really understood not being Catholic and all. But I digress, I continued onward.&lt;/p&gt;
&lt;p&gt;Eventually I returned to my room, finished up a few tweaks to my latest Terraform Project and then headed back out for the reception. I walked back up the hill and strolled into the reception area. There were about 100+ people there already hangout out, enjoying a glass or three of vino, and musicians were playing on the raised section of the patio area.&lt;/p&gt;
&lt;p&gt;I didn’t really chat to much with anybody at first as I really needed to wind down after the trip. So for the first 20 minutes of the reception I just kind of zoned out. Taking a few pictures and listening to the music was perfect for this. Eventually I walked around a bit and end up chatting with a number of people.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/05-the-reception.jpg&quot; alt=&quot;The Reception&quot;&gt;&lt;/p&gt;
&lt;p&gt;Evan was out, and we found some of his fellow Googlers &lt;a href=&quot;https://twitter.com/kelseyhightower/&quot;&gt;Kelsey Hightower&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/erjohnso/&quot;&gt;Eric Johnson&lt;/a&gt;, and eventually were joined by a number of others. We all talked shop, containers, some wine, the view, and all sundry of topics.&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/182030548?title=0&amp;byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;I stopped and took a short video of them playing and the overall view. It was super chill, easy to talk, and a nice breeze was blowing over the hill. A perfect match to the warm day.&lt;/p&gt;
&lt;p&gt;After the reception the speakers dinner kicked off inside the very hill we had just been atop. Entering the cave, as it was logically called, we were greeted by an epic HashiCorp Logo as we speakers walked in.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/06-entering-the-cave-hashicorp.jpg&quot; alt=&quot;HashiCorp&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/07-the-cave.jpg&quot; alt=&quot;The Cave&quot;&gt;
&lt;/div&gt;

&lt;p&gt;There we entered a grand room with a number of tables. Enjoyed a round or two of wine, then all took seats at round tables. Conversations were excellent, and we all continued enjoying the evening with a richly and perfectly prepared filet mignon and lobster, surf and turf indeed.&lt;/p&gt;
&lt;p&gt;After the dinner I walked out the entrance and conversation continued among &lt;a href=&quot;https://twitter.com/joshkodroff&quot;&gt;Josh Kodroff&lt;/a&gt;, several other people, and myself. After a while I bid all goodnight and headed off to get some sleep before conference day one!&lt;/p&gt;
&lt;p&gt;A most excellent day, and here the conference hasn’t even started yet. I’ve got to say, this is definitely the way to get ready for any conference though! Good food, good drinks, good conversation, among an excellent atmosphere.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/08-the-cave-wide-pano.jpg&quot; alt=&quot;The Cave&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 2 - A Bus Ride, Napa Valley City Center, Italian, Coffee, and Terraform Notes</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-2/</link>
      <pubDate>Mon, 05 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-2/</guid>
      <author></author>
      <description>&lt;p&gt;Almost to Napa, but not yet. The train pulled in and I detrained. I will admit, I know of nothing about Martinez, California except for two things: It’s a stop on the way to Jack London Square (AKA Oakland) and thus San Francisco and it’s got a lot of knarly looking industrial plants spewing stuff into the air. Poisonous, I’ve no idea, but I know the one’s just west of the city (or town?) are. I enjoyed the ghost fleet at mooring, the sun rising from the east, and the smooth roll of the train. Now I was standing here ready to be on my way to Napa.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/napa-valley.jpg&quot; alt=&quot;Napa Valley&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However I have a 2 hour layover (is it a layover, transfer, or something else in train-speak-ese?). So I decided I was going to learn a thing or three about Martinez, California. I walked a few blocks into town and found a Starbucks. I felt like such a filthy tourist walking into a Starbucks in Martinez, hoping they’ve got the local joint somewhere nearby, I gave in and enjoyed the Seattle sugar drink anyway.&lt;/p&gt;
&lt;p&gt;There I noticed three police officers, somewhat jubilant about whatever day they were going to have. I chatted with them a bit and it seemed there was some easy work they’d be doing at a fair or festival type event. Another few people sat down and enjoyed the fact I’d brought my standard 3 prong adapter along for the ride. Ya see, shockingly, there wasn’t enough outlets for the phones, laptops, and other devices everybody wanted plugged in. So the strip was a welcome addition.&lt;/p&gt;
&lt;p&gt;I sat down and dorked out on some Terraform templates and started reading up on some blog entries about Terraform Modules. I was pleasantly surprised to find solid material on page 2 of the google results (where I look every other year or so). I found blog entries by &lt;a href=&quot;https://twitter.com/serialseb&quot;&gt;@serialseb&lt;/a&gt;, &lt;a href=&quot;https://github.com/bobtfish&quot;&gt;Tom&lt;/a&gt;, and &lt;a href=&quot;https://opencredo.com/author/bart/&quot;&gt;Bart Spaans&lt;/a&gt; (&lt;em&gt;links below in references&lt;/em&gt;). Those along with a host of other materials I started to get more of a picture around how, what, where, when, and why Terraform Modules. Stay tuned in a subsequent blog entry I’ll have thoughts, hacks, and other collections of things on what I learned and hacked together.&lt;/p&gt;
&lt;h3 id=&quot;word-absurdities-over-triple-grande-caramel-macchiatos&quot;&gt;Word Absurdities Over Triple Grande Caramel Macchiatos&lt;/h3&gt;
&lt;p&gt;I penned this blog entry while sipping at my &lt;em&gt;triple grande caramel macchiato&lt;/em&gt;. All the while pondering the absurdity of how English is constructed to identify such a thing as triple grande caramel macchiato and for the millionth time thought about the desecration in re-defining the word macchiato that Starbucks committed. A macchiato is not this strange sugared perverse creation that they serve, but whatever, it tastes good. It’s just a disingenuous and deceitful disrespect, combined with adding confusion to the naive, to taint a word that has existed for over a century which means something entirely different.&lt;/p&gt;
&lt;p&gt;But whatever, it’s almost time for the final 45 minute ride to Napa.&lt;/p&gt;
&lt;p&gt;I boarded the bus. The driver greeted me, scanned my ticket, and we discussed shortly the logistics of getting to Napa from Martinez. A timely departure and barely any traffic had me arriving on time.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/soscol-transit-center.jpg&quot; alt=&quot;Soscol Transit Center&quot;&gt;&lt;/p&gt;
&lt;p&gt;Since the Soscol Transit Center was located just a few blocks from downtown Napa Valley I decided to spend lunch there and take a walk around.&lt;/p&gt;
&lt;h3 id=&quot;oh-lunch-&quot;&gt;Oh Lunch!&lt;/h3&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2/caprese.jpg&quot; alt=&quot;Caprese&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2/gnocchi.jpg&quot; alt=&quot;Gnocchi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Lunch was awesome. Caprese with heirloom tomatoes, actual fresh mozzarella and a thick, sweet, and rich balsamic reduction. Simply, caprese done right! I followed that with some gnocchi and a glass of white wine. It was time after all, being in Napa Valley, that I had some wine.&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;a href=&quot;http://www.ridethevine.com/vine&quot;&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/vine-logo.png&quot; alt=&quot;Vine Transit&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;I hung out downtown for a short time after lunch and then boarded the &lt;a href=&quot;http://www.ridethevine.com/vine&quot;&gt;Vine&lt;/a&gt; Route 11 Bus from downtown Napa out to the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt;. I arrived and walked up to the front desk and checked in. Lo and behold there stood &lt;a href=&quot;https://twitter.com/evandbrown/&quot;&gt;Evan&lt;/a&gt;, a most fortuitous timing indeed.&lt;/p&gt;
&lt;h3 id=&quot;synching-up&quot;&gt;Synching Up&lt;/h3&gt;
&lt;p&gt;We immediately introduced ourselves to some of the great staff handling HashiConf and plotted to meet and synch up our talk. The deck of course being basically done (and available &lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;here&lt;/a&gt;) but we needed to insure some of the surprises that we have are ready. Yes, that’s right, there are surprises we’ll have at the talk itself. So it’s worth tuning in if you’re working with HashiCorp’s Terraform and Google Cloud Platform.&lt;/p&gt;
&lt;p&gt;For now, I bid adieu, I have conference activities to participate in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Those I referred above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://serialseb.com/blog/2016/05/11/terraform-working-around-no-count-on-module/&quot;&gt;Working Around the Lack of Count in Terraform Modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bobtfish.github.io/blog/2015/03/29/terraform-from-the-ground-up/&quot;&gt;Terraform from the Ground Up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://opencredo.com/terraform-infrastructure-design-patterns/&quot;&gt;Terraform Infrastructure Design Patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other Good Entries on Terraform Modules &amp;amp; Related Material:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.davekonopka.com/2016/terraform-conditionals.html&quot;&gt;Terraform Conditionals, Sort of&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/davekonopka&quot;&gt;Dave Konopka&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/apn/terraform-beyond-the-basics-with-aws/&quot;&gt;Terraform: Beyond the Basics with AWS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 1 - Coast Starlight and Terraform</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-1/</link>
      <pubDate>Sun, 04 Sep 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-1/</guid>
      <author></author>
      <description>&lt;p&gt;This week, my trip to &lt;a href=&quot;https://hashiconf.com&quot;&gt;HashiConf&lt;/a&gt; kicked off officially at 2:25pm, when the Amtrak Coast Starlight departed Portland.&lt;/p&gt;
&lt;p&gt;I had more than a few goals for the trip down to Napa Valley for HashiConf. By priority, the top 5 goals:&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/gate-5.jpg&quot; alt=&quot;Gate 5&quot;&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Give a talk with Evan and respectively get a conversation started around organizing immutable infrastructure projects along the lines of 12-factor apps and the autopilot pattern.&lt;/li&gt;
&lt;li&gt;Meet as many of the HashiConf Team as I can.&lt;/li&gt;
&lt;li&gt;Make something like a documentary video short of the trip, the conference, and whatever else might be pertinent. It’s an experiment, it’ll work or it won’t.&lt;/li&gt;
&lt;li&gt;Blog the event. Maybe just a couple entries, or three, or more.&lt;/li&gt;
&lt;li&gt;Have a relaxing, chill, introspective, educational, and laid back trip while enjoying some wine at the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt; (this is where the conference is being held).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;-organizing-infrastructure-config-and-workflow-http-blog-adron-me-talks-organizing-infrastructure-config-and-workflow-&quot;&gt;&lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;Organizing Infrastructure Config and Workflow&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I wrapped up a few more things for the talk, which are now 98% done. I just have a 1% review with my co-presenter &lt;a href=&quot;https://twitter.com/evandbrown/&quot;&gt;Evan&lt;/a&gt;, and then the other 1% a few tweaks to the repositories I’ll be showing and speaking from. You can already find the slide deck and material for the talk &lt;a href=&quot;http://adron.github.io/articles/hashiconf-trip-day-1/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;here&lt;/a&gt;. There will however be more information and details once the talk is over.&lt;/p&gt;
&lt;p&gt;After that I headed down with &lt;a href=&quot;https://twitter.com/lenadroid&quot;&gt;Lena&lt;/a&gt; and discussed a few things, including giving her the first rough presentation via iPad with the v1 of the Retina Display. This reminded, hot damn that version of the iPad is ridiculously heavy, don’t give presentations with it. Afterwards she gave me a critique of things I ought not to forget. With that done, I finished packing up, and we both headed toward the train station.&lt;/p&gt;
&lt;p&gt;I detrained at Union Station and went in to wait for my train. At this point I have a little aside for this blog entry. It’s just a philosophy I have about things which makes the way I approach life very different than the way much of humanity seems to approach life.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/metropolitan-lounge.jpg&quot; alt=&quot;Metropolitan Lounge&quot;&gt;
&lt;/div&gt;

&lt;h2 id=&quot;approaching-life-on-my-terms&quot;&gt;Approaching Life on My Terms&lt;/h2&gt;
&lt;p&gt;One of the things I’m very particular about is how, when, where, and in which way I travel to places. I do everything I can to follow a few principle ideals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Don’t hurry. Otherwise I miss the important moments.&lt;/li&gt;
&lt;li&gt;Enjoy those moments. They only happen once.&lt;/li&gt;
&lt;li&gt;Live my life, there’s only this one I have.&lt;/li&gt;
&lt;li&gt;Demand respect for my time, if others don’t, fire them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sometimes I get stuck in the rat race of airports, but I try to travel by train whenever possible. The experiences I’ve had are too amazing to outline here, but suffice it to say, train travel has been very rewarding for me and a dramatically more human experience than the meat-tubes of the modern airliner.&lt;/p&gt;
&lt;h2 id=&quot;onto-the-flanged-wheel&quot;&gt;Onto The Flanged Wheel&lt;/h2&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/train-one-way.jpg&quot; alt=&quot;Train One Way&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/train-another-way.jpg&quot; alt=&quot;Train Another Way&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Flanged wheels are what train use btw, it’s that lip on the wheel keeps them on the tracks. At 2:25 pm the south bound Amtrak Coast Starlight pulled out of Portland’s Union Station on time. Something this train does about 94% of the time these days. A marked improvement over the abysmal 40% on-time arrival and 6% non-arrivals that were happening back in 2010 and before. Union Pacific straightened it’s grumpy-ass out and started running the trains better, but I digress.&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/sleeping-car-only.jpg&quot; alt=&quot;Roomette&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/roomette.jpg&quot; alt=&quot;Roomette&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I got comfortable and settled into an evening of blog writing, reading further on Go, enjoy the views, and review the talk. Dinner was served at a punctual 6:00pm reservation I’d attained, and by then I’d accomplished almost every one of these things. In addition to these a &lt;em&gt;fire&lt;/em&gt; occurred at work where our Stash Git Server went to shit on us. It’s a bit difficult to manage a &lt;em&gt;fire&lt;/em&gt; when one is between Klamath Eugene, Oregon and Mount Shasta, where the mountain isn’t really kind to one’s internet connectivity. But I did what I could and recovered from some server images. With that up and running I settled in for the night by re-watching Captain America Civil War, ya know, primarily for the hilarious comments Peter Parker makes. Until tomorrow… adieu.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Generate or Regenerate gcloud ssh Keys - How Ya Linux Series - 0001</title>
      <link>http://adron.github.io/articles/how-ya-linux-0001-generate-regenerate-ssh-key/</link>
      <pubDate>Thu, 25  Aug 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/how-ya-linux-0001-generate-regenerate-ssh-key/</guid>
      <author></author>
      <description>&lt;p&gt;Sometimes while working with the various ssh keys you have you might need to regenerate them. Specifically I ran into this need while working with some Google Cloud Platform (GCP) instances with Terraform and GCP’s &lt;em&gt;gcloud&lt;/em&gt; CLI tool. Generally, when you start working with the &lt;em&gt;gcloud&lt;/em&gt; CLI it will, upon need if it doesn’t exist, create a key for you. When it does so it sticks the key it generates in the &lt;code&gt;~/.ssh/&lt;/code&gt; directory and names the key &lt;code&gt;google_compute_engine&lt;/code&gt;. To create a new ssh key pair here, navigate to the &lt;code&gt;~/.ssh/&lt;/code&gt; directory and issue the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo ssh-keygen -t rsa -f ~/.ssh/google_compute_engine -C you_fancy_username@whatever.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that is command is executed, a few moments later and a few prompts later you’ll have a new key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;13:16 $ sudo ssh-keygen -t rsa -f ~/.ssh/google_compute_engine -C adron_hall@homedepot.comPassword:
Generating public/private rsa key pair.
/Users/axh6454/.ssh/google_compute_engine already exists.
Overwrite (y/n)? y
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /Users/axh6454/.ssh/google_compute_engine.
Your public key has been saved in /Users/axh6454/.ssh/google_compute_engine.pub.
The key fingerprint is:
SHA256:8xHVr19EdgPxLr2nWAkuZa8exMdEqbHNzoBxlHhFkZM adron_hall@ataplace.com
The key&amp;#39;s randomart image is:
+---[RSA 2048]----+
|           ooBB= |
|          o.=.E.+|
|          .= *.*o|
|          .o+o= o|
|        S . *=o= |
|         o * +=.o|
|          o o +oo|
|           . = .o|
|           .+ .  |
+----[SHA256]-----+
✔ ~/.ssh
13:16 $
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it. Sort of. For GCP be sure to check out the docs on managing ssh keys. There are docs on &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh&quot;&gt;&lt;code&gt;gcloud compute config-ssh&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys&quot;&gt;Adding and Removing SSH keys&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Visual Studio Code (an intro with snark!) and Hashicorp Configuration Language</title>
      <link>http://adron.github.io/articles/visual-studio-code-and-hcl/</link>
      <pubDate>Mon, 22  Aug 2016 18:21:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/visual-studio-code-and-hcl/</guid>
      <author></author>
      <description>&lt;p&gt;I sat down to setup Visual Studio Code for some Go coding. That is, #golang or “golang” on Google, because heaven forbid a language is named something that isn’t ubiquitous like the word “go”. But anyway, I digress, because this blog entry isn’t even about golang. It’s about HCL. You see, I sat down to toy about with golang but then I had to knock out a few tasks with Terraform, Packer, and such. To do that I needed the HCL support that Visual Studio Code has. I knew there was a plugin for Hashicorp Configuration Language (i.e. HCL). So I decided to do that work in Visual Studio Code and try out the HCL Plugin. Maybe next blog entry I’ll get around to writing some golang in Visual Studio Code?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-00.png&quot; alt=&quot;The Site&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The first thing I needed to do though, was download and get Visual Studio Code. I’d neglected to learn much about it or use Code (I’ll just call it that from now on, Visual Studio Code is way to much to write, plus it’s not really got much in familial relation to Visual Studio). That download, it all started &lt;a href=&quot;https://code.visualstudio.com&quot;&gt;here&lt;/a&gt;. I opened it upon finishing installation to a brand new Visual Studio Code Window.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-01.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;I toyed about a moment looking at the Visual Studio Code website, then toyed around with the editor, and noticed three things immediately.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;When I navigated to &lt;code&gt;https://code.visualstudio.com&lt;/code&gt; I noticed I was redirected or someway navigated to a link that immediately shoved some type of session mess into the URI. My link of &lt;code&gt;https://code.visualstudio.com&lt;/code&gt; turned into &lt;code&gt;https://code.visualstudio.com/b?utm_expid=101350005-27.GqBWbOBuSRqlazQC_nNSRg.1&lt;/code&gt;. Now I’m not sure about you but that type of behavior on a website actually pisses me off and makes me paranoid. I went through various things to determine what was going on, but suffice it to say I determined it was just an annoying contrivance that the site managers make the site do. Whatever…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The second thing I noticed was that I had no idea what to do to install plugins. Was it the same as Atom as I’d heard? Was it some other command? I assumed since I’d used Code a few times before, it was likely the command line I tried a few based on other tooling. First &lt;code&gt;⌘ + space&lt;/code&gt;, nope, that was dumb. I have that mapped to &lt;a href=&quot;https://en.wikipedia.org/wiki/Spotlight_(software&quot;&gt;Spotlight&lt;/a&gt;). Ok, so then I tried &lt;code&gt;⌥ + space&lt;/code&gt;, nope. &lt;code&gt;⌘ + ⌥ + ^ + F12&lt;/code&gt;, naw. Ok, dammit, I guess it’s &lt;code&gt;⌘&lt;/code&gt; key plus something I’ll bet. Then I tried a whole slew and sure enough, &lt;strong&gt;&lt;code&gt;⌘ + p&lt;/code&gt;&lt;/strong&gt; was the magic sauce. But wait, it wasn’t. At this point I thought “maybe I should look this up” but I decide to stay stubborn and try some other things I &lt;em&gt;think&lt;/em&gt; I remember about Code. I try the &lt;code&gt;fn + F1&lt;/code&gt;, or what might be just &lt;code&gt;F1&lt;/code&gt; if you have your keyboard setup for function keys instead of the other OS-X uses. Sure enough, that was the command dialog I wanted.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I opened up another Code window so that I could also use the editor to write this very blog entry. I use &lt;a href=&quot;http://wintersmith.io/&quot;&gt;Wintersmith&lt;/a&gt; and have even written about it in the past &lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt; and &lt;a href=&quot;http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting&quot;&gt;Working in -34c Wintersmith Customization and Github Hosting&lt;/a&gt;. It’s a great Node.js static site generator. I immediately noticed as I started typing that Visual Stuido Code supports basic markdown on the basic installation! Holy shit, that’s super rad!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, on with the meat of all this.&lt;/p&gt;
&lt;p&gt;With the opened Code Window, I hit &lt;code&gt;fn + F1&lt;/code&gt; (again, that’s just &lt;code&gt;f1&lt;/code&gt; if you’ve got your function keys turned on for OS-X) and typed in &lt;code&gt;ext&lt;/code&gt;. That gave me the following dialog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-02.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;The list that displays, I then hit the down arrow key and selected &lt;em&gt;Extensions: Install Extensions&lt;/em&gt;. With that selected I hit enter and down the left hand side of Code I got the extensions list. The focus changes to that, so no need for the mouse still.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-03.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;I pressed the down arrow to select the HCL extension, but realized that was taking a minute, so shifted focus to the search box and just typed HCL. That immediately brought up the display of the extension once I hit the down arrow and then enter.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-04.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now I wasn’t sure how to install this, since I wanted to avoid using the mouse if possible. I just hit enter again and it worked! Since that worked, I hit enter again with the premise that it would now &lt;em&gt;enable&lt;/em&gt; the extension, which it did indeed do with a simple prompt to restart Code. I clicked on &lt;em&gt;ok&lt;/em&gt; and on to the restart of Code.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-05.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;When Code restarted and came back up, I had one Code Windows with the default empty document, with no directory opened, and I opened up another using &lt;em&gt;File -&amp;gt; New Window&lt;/em&gt; and then used it to open the directory in which I was editing this blog entry. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-06.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;To get the word wrap back (which I’d manually clicked before) I recalled the shortcut key is &lt;code&gt;⌥ + Z&lt;/code&gt;. This is super useful when editing markdown like this, so it’s a keyboard shortcut to set to memory.&lt;/p&gt;
&lt;p&gt;Now at this point I should have some HCL. I kick of my pulling down an existing project that I’m working on. I opened it by using the &lt;code&gt;⌘ + O&lt;/code&gt; keys. The project opened up and I immediately opened one of the /*.json files that I have for a Packer image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-07.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;That looked good so far. Let’s see about intellisense and Terraform. I used &lt;code&gt;ctrl + shift + E&lt;/code&gt; to get into the Explorer part of the editor. Then scrolled with the down arrow to the &lt;em&gt;dns-records.tf&lt;/em&gt; file. I atttempted to select the file with the &lt;code&gt;return&lt;/code&gt; button, but that invoked the &lt;em&gt;rename&lt;/em&gt; functionality. I tried a few other things, the &lt;em&gt;space bar&lt;/em&gt;, other unusable combinations, and then &lt;code&gt;ctrl + return&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Nothing&lt;/em&gt;. This was a bit frustrating, to get this far and stumble because I need to use the bloody mouse. Whatever, I clicked on the mouse to open the &lt;em&gt;dns-records.tf&lt;/em&gt; file. I then clicked into the file and tried out something around the intellisense (or is it autocomplete in Code?).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-08.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;This test I found rather interesting. The options, once I started typing &lt;em&gt;goog&lt;/em&gt; immediately showed as &lt;em&gt;google_compute_instance&lt;/em&gt;, &lt;em&gt;google_dns_managed_zone&lt;/em&gt;, and &lt;em&gt;google_dns_record_set&lt;/em&gt;. A somewhat odd selection indeed of these resources. You see, there are many other HCL resources for Google Compute Engine besides these three. But these specific three displayed in the dropdown. I looked throughout the file, and assumed that these three were retrieved from words in the file. Maybe the intellisense is more autocomplete then intellisense. Whatever the case however as I’m happy with just autocomplete. I don’t particularly need intellisense, especially since I haven’t used it now for about 6 years.&lt;/p&gt;
&lt;p&gt;So that’s my first tour of Visual Studio Code and HCL. My next tour and test is going to be finding some more of these bloody shortcuts I haven’t been able to find and to actually write some golang in the editor too.&lt;/p&gt;
&lt;p&gt;For now, I’ve got some HCL to put together for the coming &lt;a href=&quot;https://www.meetup.com/The-Portland-Elasticsearch-Meetup-Group/events/228010912/&quot;&gt;Monday night Elastic UG meetup&lt;/a&gt; on &lt;a href=&quot;http://blog.adron.me/talks/elastic-with-terraform-packer-and-immutability-magic/&quot;&gt;Elastic w/ Terraform, Packer, &amp;amp; That Immutability Magic&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>DevOps Thoughts, Fixing Culture Roadblocks, and Cultural Anti-Pattern Practices</title>
      <link>http://adron.github.io/articles/devops-thoughts/</link>
      <pubDate>Wed, 10  Aug 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/devops-thoughts/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/devops-thoughts/artisanal.jpg&quot; alt=&quot;Artisanal&quot;&gt;
&lt;/div&gt;

&lt;p&gt;DevOps Days PDX just wrapped up and I’m at home, working remotely today, digging into some deployment work around building Elasticsearch Clusters for monitoring with Beats. It’s a tricky beast at this point but I’m getting all the nuances figured out.&lt;/p&gt;
&lt;p&gt;I have a host of tools at my disposal that help tremendously with this endeavor. There is Packer, to help build the base images I need that have Elasticsearch, Beats, or whatever else needs to be on an image. There is Terraform that helps me to get the images deployed and start the final configuration process. Then there is the configuration process, which is a mix of bash, go, and other things to insure that the configuration of and services around Elasticsearch are started appropriately.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;devops-tooling-vs-culture&quot;&gt;DevOps Tooling vs. Culture&lt;/h2&gt;
&lt;p&gt;It’s a cool thing to have all this tooling at my disposal. For me to be able to whip together these solutions for myself and any clients or cohort that needs these solutions. But there’s so much more to the premise of &lt;em&gt;DevOps&lt;/em&gt; (or lack of premise, more on that in the future), or at least that of an efficient and forward thinking &lt;em&gt;DevOps&lt;/em&gt; culture that the tooling is almost irrelevant. Without effective cultural change in an organization all the fancy tooling is for naught.&lt;/p&gt;
&lt;p&gt;A momentary reflection I’ve had as I hack deeper into &lt;strong&gt;DevOps&lt;/strong&gt; idealism and ideas with these notions of &lt;a href=&quot;http://blog.adron.me/articles/immutable-infrastructure-some-reads-clarification-what-it-is/&quot;&gt;immutable infrastructure&lt;/a&gt;, &lt;a href=&quot;http://autopilotpattern.io/&quot;&gt;autopilot pattern applications&lt;/a&gt;, &lt;a href=&quot;http://12factor.net/&quot;&gt;12-factor apps&lt;/a&gt;, and related ideas, the more I find myself between a rock and a hard place with any existing system and existing development cultures.&lt;/p&gt;
&lt;p&gt;This is where I fight with the world, with existing cultures, and fight to make changes. You see, I grew up with more than a few dogs. Many people always said, “you can’t teach an old dog new tricks” to which I retort, “bullshit, you just suck at teaching your fellow dogs new tricks”. Ok, that’s my reactionary activist style response to someone saying I can’t do something, but it’s well founded. Because you see, every dog I ever grew up with would learn new tricks until the day that dog was laid to rest. I &lt;em&gt;respect&lt;/em&gt; dogs in that way and I &lt;em&gt;sure as hell expect more from humans&lt;/em&gt;, even though we humans can be such an enthusiastic let down sometimes.&lt;/p&gt;
&lt;h2 id=&quot;cultural-road-blocks-to-technology-solutions&quot;&gt;Cultural Road Blocks to Technology Solutions&lt;/h2&gt;
&lt;p&gt;So how does culture create an environment that makes all the tools for naught and encourages me to write articles where it takes me 3-5 paragraphs to get to the meat. Here’s a list of the key parts of culture that I’ve fought with over the years. These are greater roadblocks than any processor limit, bad code, or other simple technical limitation. The cultural roadblocks are far more of an issue than any code or technical roadblock in the vast majority of places. Suffice it to say, if you aren’t working on rockets and jets with Nasa, Space-X, or fighting some disease or cancer, it’s a cultural roadblock not a technical one that will stop you from progressing.&lt;/p&gt;
&lt;p&gt;With all that said, here’s my list of cultural problems along with a few suggestions on fixing them. These could also be called “cultural anti-pattern practices”.&lt;/p&gt;
&lt;h2 id=&quot;cultural-anti-pattern-practices&quot;&gt;Cultural Anti-Pattern Practices&lt;/h2&gt;
&lt;h3 id=&quot;-we-always-did-it-this-way-&quot;&gt;&lt;em&gt;“We always did it this way”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This practice basically defines the insanity of always repeating a practice without ever checking to see if it should still be done, if it’s still needed, or if there might be a better way to do things. Someone might respond with, “If it aint broke, don’t fix it!”, but this goes far beyond an refuses to even check it its broke, needs fixing, or otherwise. This cultural characteristic of an organization crosses into so many other ways of thinking and other practices it’s too hard to enumerate how damaging it truly is to any project or effort. It’s definitely a major anti-pattern in technology in general, and a massive cultural roadblock in any group that wants a more “DevOps” Culture of forward progress.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;-fire-fight-while-you-research-&quot;&gt;&lt;em&gt;“Fire Fight While you Research”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;We all know task-switching kills productivity (re: &lt;a href=&quot;https://blog.todoist.com/2014/05/13/how-multitasking-slows-your-brain-and-kills-your-productivity/&quot;&gt;this&lt;/a&gt;, &lt;a href=&quot;https://www.wrike.com/blog/high-cost-of-multitasking-for-productivity/&quot;&gt;this&lt;/a&gt;, &lt;a href=&quot;http://www.umich.edu/~bcalab/multitasking.html&quot;&gt;this&lt;/a&gt;, and &lt;a href=&quot;https://www.psychologytoday.com/blog/brain-wise/201209/the-true-cost-multi-tasking&quot;&gt;this&lt;/a&gt; for example) and the mother load of task switching is going from researching &amp;amp; testing out an idea to being thrown into the hot seat to fight a fire. In this type of task-switch, which is effectively the definition of opposing activities, the mental energy is more than merely exhausting. This type of task switch is a 10 foot thick brick wall of research &amp;amp; learn destruction. There is no way to recover after a fire-fight and immediately dive back into calm, thoughtful, and concentrated creative effort. This type of cultural characteristic will turn any week long project into something that has a delivery date somewhere next to infinity. You think I say that hyperbolically, but it’s basically true. Have regular fires and put a team on those that needs to develop a solution for tomorrow, and you’ll never have a solution for tomorrow. Simply put, DevOps shouldn’t be your “quick fire fight this emergency over here” or the “why is this unique artisanal, hand made, oven baked, organic, custom configured spice rack of a server on fire?” team. This should and needs to be handled in an entirely different way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;-always-silo-for-the-work-&quot;&gt;&lt;em&gt;“Always Silo for the Work”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This is not what Adam Smith meant by &lt;a href=&quot;https://en.wikipedia.org/wiki/Division_of_labour&quot;&gt;division of labor&lt;/a&gt;. This is a serious problem that I see continuing in so many places. If you want to get some more ideas about why not to silo work, go read up on the research and work of &lt;a href=&quot;https://en.wikipedia.org/wiki/W._Edwards_Deming&quot;&gt;W. Edwards Deming&lt;/a&gt; and for some semantic breakdown of the problem &lt;a href=&quot;https://www.infoq.com/articles/break-silos-ventilators&quot;&gt;Don’t Break Your Silos - Push Out the Silo Mentality&lt;/a&gt; is a great article. Creating a silo that creates walls around it and prevents communication or cross-training of necessary knowledge throughout an organization is a surefire way to squander any hopes of a DevOps Culture. The very words pulled together to for DevOps (ya know, Development and Operations) is the breaking down of barriers and silos and bringing together the skills and teamwork necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These are the top three practices that I see and have experienced for a few years. In a subsequent article I’ll take these and others and write about some solutions. As discussed previously, the solutions are hard because it involves people changing their practices. At a core level that is difficult, but again, teaching old dogs new tricks isn’t so hard, it just takes persistence. Keep at it and happy hacking.&lt;/p&gt;
&lt;p&gt;Got comments, thoughts, or some other thing to ramble on about? Ping me via the Twitters &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; or via wherever you saw this posted. Always happy to discuss, argue, chat, or otherwise work toward finding new solutions!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp; Packer - Part 2</title>
      <link>http://adron.github.io/articles/nginx-notes-from-the-url-redirect-part-two/</link>
      <pubDate>Sun, 31 Jul 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/nginx-notes-from-the-url-redirect-part-two/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/google-cloud-platform.png&quot; alt=&quot;Google Cloud Platform&quot;&gt;
&lt;/div&gt;

&lt;p&gt;In the &lt;a href=&quot;http://blog.adron.me/articles/nginx-notes-from-the-url-redirect/&quot;&gt;first blog entry, “NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp;amp; Packer - Part 1”&lt;/a&gt; I covered getting a basic Nginx URL Redirector setup and running. Now it’s time to dig into some of the next steps.&lt;/p&gt;
&lt;p&gt;Since we have an operative server running that we want to automate, I’ll actually just wipe out the server we built in the first part of this series. Albeit I will refer back to it when I get to the process of recreating this server with Packer and Terraform. So first things first, let’s actually setup the networking elements needed to put the server into action.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;infrastructure-the-first-terraform-resources&quot;&gt;Infrastructure : The first Terraform Resources&lt;/h2&gt;
&lt;p&gt;The first thing I need is an IP and an A Record in DNS to map to the server that’ll be in charge of the redirection. With Terraform, I can automate this, and for a quick review of how to get started with Google Cloud and Terraform, check out my post “&lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too)&lt;/a&gt;“. With that, I’ll add the following files to this project including the following Terraform resources. The way I do this is simply create a directory and run &lt;code&gt;git init&lt;/code&gt; to make that a repo, then just push it up to Github or wherever the remote needs to be stored. I’ll work based on that from here on out with this series. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;connections.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file will simply host the connection for the provider I’ll be building the infrastructure resources against. In this case, I’ll be working against Google Cloud. The &lt;code&gt;credentials&lt;/code&gt; section in the file has the interpolated local file &lt;code&gt;account.json&lt;/code&gt; that I have my secret key in. It’s one of the multiple ways you can setup your Google Cloud key to use with Packer, Terraform, or other tools. For more information or for specific directions on getting an account.json file just read my previous post on using &lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Google Cloud &amp;amp; Terraform&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;../secrets/account.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;that-big-universe&amp;quot;
  region      = &amp;quot;us-central1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;addresses.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file will include the resources for the static IPs for use with the server and assigning a subdomain within the DNS Zone to redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_compute_address&amp;quot; &amp;quot;nginx-server&amp;quot; {
  name = &amp;quot;nginx-server&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;zone-adronme.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file has more than the entries below, such as for this very blog. But I’ve just included the specifics of what are needed to provide the subdomain that will direct to the server, which will then provide the redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_dns_managed_zone&amp;quot; &amp;quot;adronme&amp;quot; {
    name = &amp;quot;adronme&amp;quot;
    dns_name = &amp;quot;adron.me.&amp;quot;
    description = &amp;quot;Production http://adron.me Domain.&amp;quot;
}

resource &amp;quot;google_dns_record_set&amp;quot; &amp;quot;data&amp;quot; {
    managed_zone = &amp;quot;${google_dns_managed_zone.adronme.name}&amp;quot;
    name = &amp;quot;data.${google_dns_managed_zone.adronme.dns_name}&amp;quot;
    type = &amp;quot;CNAME&amp;quot;
    ttl = 5
    rrdatas = [&amp;quot;${google_compute_address.nginx-server.address}&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that the rrdatas value of &lt;code&gt;google_compute_address.nginx-server.address&lt;/code&gt; references whatever static IP is created in the &lt;code&gt;addresses.tf&lt;/code&gt; file resource.&lt;/p&gt;
&lt;p&gt;That will give me the DNS entries needed to get any requests sent to the actual server from within Google Cloud using their respective DNS Server &amp;amp; static IP assigned for their network.&lt;/p&gt;
&lt;p&gt;The next thing I want now is the actual server that Nginx will be installed on. I don’t want Terraform just to whimsically make this Nginx Server from scratch though (which it could through scripts, etc). I know what needs to be on the server, namely Nginx, but also how it should be configured by default. I already have my actual redirect, so I want to just have the data baked into the image. The easiest way to insure Terraform builds a Virtual Machine in a repeatable way is to simply create an image in Google Cloud first. That way I can use that as the base of the virtual machine whenever it needs created. The way I generally manage this, is I simply create a folder within the repository called &lt;em&gt;packer&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In the packer directory I’ll now have three specific files: install-nginx.sh, nginx.conf, and redirector.json. The install-nginx.sh will be for installing nginx, but will also include installing and opeing up the appropriate connections to the local firewall. The nginx.conf file will be the custom nginx file used for our nginx server that includes the URL redirection. This file will also be copied into the appropriate directory during creation of the image by the install-nginx.sh file. Last, the redirector.json file is the actual packer template that will be used to create the image. Below are the three files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;install-nginx.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This starts out by running the apt-get update, then installing UFW. UFW stands for &lt;strong&gt;U&lt;/strong&gt;ncomplicated &lt;strong&gt;F&lt;/strong&gt;ire&lt;strong&gt;W&lt;/strong&gt;all. After that is done, two allowances are added to the firewall for 22 (ssh) and 80 (http) traffic. Then it is enabled by passing in “y” to the command execution of &lt;code&gt;sudo ufw enable&lt;/code&gt;. After that is setup, nginx is installed and the service stopped. The service doesn’t really need stopped, but I’ll have to start it or restart it again in a moment so I stop it anyway. Then I’ve got the &lt;code&gt;sudo update-rc.d nginx defaults&lt;/code&gt; to set nginx to start upon reboots of the instance, finally the nginx.conf file from the repo is moved to replace the default nginx.conf file included with the original installation. Then finally a command to start nginx back up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env bash

# Install the UFW (Uncomplicated Firewall), setup tcp 22 and 80 for ssh and http. Then enable the firewall.
sudo apt-get update
sudo apt-get install ufw
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
echo &amp;quot;y&amp;quot; | sudo ufw enable

# Install nginx, stop, start, and restart the server for verification. Then set startup defaults.
sudo apt-get -y install nginx
sudo service nginx stop
sudo update-rc.d nginx defaults

sudo mv nginx.conf /etc/nginx/nginx.conf

sudo service nginx start
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;nginx.conf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the simple nginx.conf file, trimmed down to the bare necessities to accomplish the goal of redirecting this singular subdomain of &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; to the URL in the file. Everything else in the file is default from the original installation. The key part with the URL redirection is toward the bottom of the file in the &lt;code&gt;server&lt;/code&gt; block. For now, until I make the redirect permanent, I’ve set it up simply as a 302 redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user www-data;
worker_processes 4;
pid /run/nginx.pid;

events {
    worker_connections 768;
}

http {

    ##
    # Basic Settings
    ##

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # server_names_hash_bucket_size 64;
    # server_name_in_redirect off;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    ##
    # SSL Settings
    ##

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
    ssl_prefer_server_ciphers on;

    ##
    # Logging Settings
    ##

    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    ##
    # Gzip Settings
    ##

    gzip on;
    gzip_disable &amp;quot;msie6&amp;quot;;

    ##
    # Virtual Host Configs
    ##

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;

    server {
        server_name data.adron.me;
        return 302 http://api.compositecode.com/dataservices/information.html;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;redirector.json&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This final file, the redirector.json file, is the packer template itself. The first section holds two variables, which I didn’t technically need, but when I expand on usage it comes in handy. Also, this way any names or such that I might want to change are at the top of the file. It makes it a little simpler to find the parts I change regularly during troubleshooting and getting everything to work.&lt;/p&gt;
&lt;p&gt;After the two variables is the &lt;code&gt;builders&lt;/code&gt; section of the template. It includes what type of of builder it is (googlecompute), where that security file is (which I mentioned in the connection above for the terraform files, but this is connecting the packer template to the appropriate security key file), project id, zone, instance name, image name, and a few other values. A few of these values are very important to understand what they’re for and why I’ve put them here. The three I need to point out are &lt;code&gt;instance_name&lt;/code&gt;, &lt;code&gt;image_name&lt;/code&gt;, and &lt;code&gt;ssh_username&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The instance name is exactly what you might think, it’s the name of the instance that runs in Google Cloud Engine. However, this is the instance name of the instance that will be used temporarily to build the image from. That’s where the next value comes into place, the &lt;code&gt;image_name&lt;/code&gt;. The instance is deleted once it’s done being created, disconnected form the image that was created to build the instance, and that image is named whatever value is in the &lt;code&gt;image_name&lt;/code&gt;. So you’ll never really see the &lt;code&gt;instance_name&lt;/code&gt; except for a few moments during creation.&lt;/p&gt;
&lt;p&gt;The third value, the &lt;code&gt;ssh_username&lt;/code&gt; is actually the username of the account created to run the shell scripts and do the installations and such. For some of the operating system types, this is necessary and others it is not. For the debian-8-jessie-v20160803 image I’ve set as the &lt;code&gt;source_image&lt;/code&gt;, it seems to be necessary based on my testing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;instance_name&amp;quot;: &amp;quot;redirector-{{timestamp}}&amp;quot;,
    &amp;quot;image_name&amp;quot;: &amp;quot;redirector-{{timestamp}}&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [
    {
      &amp;quot;type&amp;quot;: &amp;quot;googlecompute&amp;quot;,
      &amp;quot;account_file&amp;quot;: &amp;quot;../../secrets/account.json&amp;quot;,
      &amp;quot;project_id&amp;quot;: &amp;quot;that-big-universe&amp;quot;,
      &amp;quot;source_image&amp;quot;: &amp;quot;debian-8-jessie-v20160803&amp;quot;,
      &amp;quot;zone&amp;quot;: &amp;quot;us-central1-a&amp;quot;,
      &amp;quot;instance_name&amp;quot;: &amp;quot;{{user `instance_name`}}&amp;quot;,
      &amp;quot;image_name&amp;quot;: &amp;quot;{{user `image_name`}}&amp;quot;,
      &amp;quot;image_description&amp;quot;: &amp;quot;Nginx Server.&amp;quot;,
      &amp;quot;communicator&amp;quot;: &amp;quot;ssh&amp;quot;,
      &amp;quot;ssh_username&amp;quot;: &amp;quot;nginxadmin&amp;quot;
    }
  ],
  &amp;quot;provisioners&amp;quot;: [
    {
      &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;inline&amp;quot;: [
        &amp;quot;sleep 3&amp;quot;,
        &amp;quot;echo \&amp;quot;slept for 3 seconds.\&amp;quot;&amp;quot;
      ]
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;source&amp;quot;: &amp;quot;nginx.conf&amp;quot;,
      &amp;quot;destination&amp;quot;: &amp;quot;nginx.conf&amp;quot;
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;source&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;,
      &amp;quot;destination&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;script&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;,
      &amp;quot;pause_before&amp;quot;: &amp;quot;10s&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;where-we-re-at-&quot;&gt;Where we’re at…&lt;/h2&gt;
&lt;p&gt;At this point I’ve got the key elements ready for deploy to Terraform and I’ve got the core pieces to build the image with my template for Packer. But I’ve got neither of these tools actually installed just yet. Well, I’m in luck, I’ve created two scripts just for this purpose for &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/adron-infrastructure/terraform-packer-install-scripts/install-terraform-packer-os-x.sh&quot;&gt;OS-X&lt;/a&gt; and &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/adron-infrastructure/terraform-packer-install-scripts/install-terraform-packer-ubuntu.sh&quot;&gt;Linux&lt;/a&gt;. Oh wait, I might have lied, I only have install files for OS-X and Linux. If you’re running Windows just navigate out and follow these instructions for &lt;a href=&quot;https://www.terraform.io/intro/getting-started/install.html&quot;&gt;Terraform on Windows&lt;/a&gt; and &lt;a href=&quot;https://www.packer.io/intro/getting-started/setup.html&quot;&gt;Packer on Windows&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Alright, with Packer and Terraform installed, I’m ready to build some networking infrastructure and a base image. The first thing I do is run the Packer command, from the directory in which I created the three files related to my Nginx Server. The following is an animated .gif recording (made with &lt;a href=&quot;http://www.cockos.com/licecap/&quot;&gt;licecap&lt;/a&gt;) of running &lt;code&gt;packer build redirector.json&lt;/code&gt;. Note, I paused over some of the parts that take a few seconds, so just the actual changes are shown without the long delays over things like deleting instance or creating image steps. So don’t freak out when you run a packer build and some things take a few seconds or minutes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/packer-build.gif&quot; alt=&quot;packer build&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now that we have the packer built image in Google Cloud I can build the Nginx server using this image. Here’s what I put together for the Terraform file to create the Nginx server. Note, I’ve placed this file in the root of the project repository (where I’ve placed all of my Terraform files that I mentioned previously in this article).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;redirector.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this file I’ve declared a Terraform Compute Instance type, and named it redirector. For the disk, I’ve set it to the image name that Packer created for me, then the network_interface has an access_config that has the nat_ip set to the .address of the redirector static IP. Previously in the article I setup the DNS to point &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; to that IP address, so this is the final step here. The other information in the Terraform Template, suffice it to say, is a topic for another day. I will mention however, that the tags “http-server” and “https-server” are there to ensure that the Google Firewalls are appropriately opened up to these ports (80 and 443 respectively). Albeit I’m not using 443 at the moment, it’s open for subsequent material I may write on this topic.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    resource &amp;quot;google_compute_instance&amp;quot; &amp;quot;redirector&amp;quot; {
      name = &amp;quot;redirector&amp;quot;
      machine_type = &amp;quot;f1-micro&amp;quot;
      tags = [
        &amp;quot;http-server&amp;quot;,
        &amp;quot;https-server&amp;quot;]
      zone = &amp;quot;us-central1-b&amp;quot;

      disk {
        image = &amp;quot;redirector-1471307522&amp;quot;
      }

      network_interface {
        network = &amp;quot;default&amp;quot;
        access_config {
          nat_ip = &amp;quot;${google_compute_address.redirector.address}&amp;quot;
        }
      }

      service_account {
        scopes = [
          &amp;quot;userinfo-email&amp;quot;,
          &amp;quot;compute-ro&amp;quot;,
          &amp;quot;storage-ro&amp;quot;]
      }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, I can use the Terraform CLI and it’ll pull in the all the .tf files for processing and build out the static IP, DNS entry, and respective instance with the nginx.conf file already baked in. With a single command of &lt;code&gt;terraform apply&lt;/code&gt; and it will all be done!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/terraform-apply.gif&quot; alt=&quot;terraform apply&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now, of course the first time this is applied, be sure to give the DNS Servers some time to propagate. When done, the URL redirection will be in place.&lt;/p&gt;
&lt;p&gt;If you see any errors or confusing parts of this article or &lt;a href=&quot;http://blog.adron.me/articles/nginx-notes-from-the-url-redirect/&quot;&gt;part 1&lt;/a&gt; let me know. You can even take it a step further and &lt;a href=&quot;https://github.com/Adron/adron.github.io&quot;&gt;fork my repo&lt;/a&gt; and, make the changes to the &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/master/_working/contents/articles/nginx-notes-from-the-url-redirect-part-two/index.md&quot;&gt;markdown file here&lt;/a&gt; and submit a pull request. I’ll review and get a new static site built with the edits ASAP! Thanks.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Speaking Trips, Tech, and Treks</title>
      <link>http://adron.github.io/articles/speaking-trips-tech-and-treks/</link>
      <pubDate>Mon, 25 Jul 2016 19:35:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/speaking-trips-tech-and-treks/</guid>
      <author></author>
      <description>&lt;p&gt;I’ll be off on some coding adventures in the coming months. I also hope to catch up with a lot of people and their respective projects, learn a few things, and if it’s possible maybe teach a few people a thing or three about immutable infrastructure, lessons I’ve learned, and how to avoid infrastructure catastrophes while building the next bad ass awesome application. This blog entry is about the details of my logistics, and I’ll follow up with more details of the coding adventure along the way. For now: details, details, and details.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://conferences.oreilly.com/software-architecture&quot;&gt;&lt;img src=&quot;/articles/speaking-trips-tech-and-treks/oreillyarchitectureconf.png&quot; alt=&quot;O&amp;#39;Reilly Architecture Conference 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;takes place in &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu&quot;&gt;London&lt;/a&gt; October 19-21, 2016 and &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-ca&quot;&gt;San Francisco&lt;/a&gt; November 14-16, 2016&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;moving-enterprise-practices-and-development-to-open-source&quot;&gt;Moving Enterprise Practices and Development to Open Source&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;in London&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Official Talk URI: &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52257&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52257&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My Talk URI: &lt;a href=&quot;http://blog.adron.me/talks/Moving-Enterprise-Practices-and-Development-to-Open-Source/&quot;&gt;http://blog.adron.me/talks/Moving-Enterprise-Practices-and-Development-to-Open-Source/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this talk I’ll tell the story of our efforts at Home Depot, and provide bullet points and suggestions for helping you to acheive the move to open source practices in your enterprise. The benefits are huge, and overall it’s a lot more fun to boot!&lt;/p&gt;
&lt;p&gt;Key Points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Steps we took to get into the open.&lt;/li&gt;
&lt;li&gt;Practices to take up and start using.&lt;/li&gt;
&lt;li&gt;Things to avoid when moving to open source models.&lt;/li&gt;
&lt;li&gt;How to make the most of things for the community and the enterprise.&lt;/li&gt;
&lt;li&gt;Tooling, interoperability, services, and how to get it done.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;building-immutably-to-continuous-delivery-with-minimal-inputs&quot;&gt;Building Immutably to Continuous Delivery with Minimal Inputs&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;in London and in San Francisco&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Official Talk URI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;London &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52254&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52254&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;San Francisco &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-ca/public/schedule/detail/52258&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-ca/public/schedule/detail/52258&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My Talk URI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;London &lt;a href=&quot;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-London&quot;&gt;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-London&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;San Francisco &lt;a href=&quot;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-San-Francisco/&quot;&gt;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-San-Francisco/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prerequisite knowledge&lt;/p&gt;
&lt;p&gt;Basic understanding of web applications, architecture &amp;amp; design, and basic knowledge of windows &amp;amp; linux server systems.&lt;/p&gt;
&lt;p&gt;Materials or downloads needed in advance&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com&quot;&gt;Github Account&lt;/a&gt;, &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;AWS&lt;/a&gt; (or &lt;a href=&quot;https://cloud.google.com/&quot;&gt;GCE&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com&quot;&gt;Azure&lt;/a&gt;, etc) Account, and &lt;a href=&quot;https://codeship.com/&quot;&gt;CodeShip Account&lt;/a&gt;. Also a computer with OS-X, Windows, or Linux loaded with Node.js is also required.&lt;/p&gt;
&lt;p&gt;This workshop focuses on building a continuously delivered pipeline using Node.js (however easily transferable to Ruby/Rails/Java/Scala/.NET etc.). The workshop will trace the steps from inception to deployed application (with a domain pointed appropriately and all) that can then be developed against to continue whatever effort and intent of the developer(s)!&lt;/p&gt;
&lt;p&gt;Key Points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parts: Application, Domain Name, Infrastructure, Integration, &amp;amp; Delivery&lt;/li&gt;
&lt;li&gt;Build an Application: Steps for building &amp;amp; actually building a simple Node.js Application to deploy.&lt;/li&gt;
&lt;li&gt;Getting a domain name, determining name servers &amp;amp; DNS servers, setting it up and getting it pointed at our application.&lt;/li&gt;
&lt;li&gt;Setting up and determining the deployment scenario on AWS &amp;amp; discussion of other infrastructure choices.&lt;/li&gt;
&lt;li&gt;Deploying the application through the complete process of code, integrate, test, build, deploy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/articles/speaking-trips-tech-and-treks/hashiconf2016.png&quot; alt=&quot;Hashiconf 2016&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;organizing-infrastructure-config-workflow&quot;&gt;Organizing Infrastructure Config &amp;amp; Workflow&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;September 7-8, 2016 @ Napa Valley, California&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Official Talk URI: &lt;a href=&quot;https://www.hashiconf.com/talks/organizing-infrastructure-config-workflow.html&quot;&gt;https://www.hashiconf.com/talks/organizing-infrastructure-config-workflow.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My Talk URI: &lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m super stoked about this talk, as I’m getting to co-present with Evan Brown. Evan’s a friend of mine since I met him a whiel back while he worked at AWS, however he’s now a Senior Software Engineer at Google. We’re going to tag team style this talk to bring you as much information as we can about organzing your infrastructure configuration and workflow.&lt;/p&gt;
&lt;p&gt;My abstract for this talk goes something like this, “&lt;em&gt;When starting with the various products Terraform, Packer, Vagrant, and others, it isn’t always apparent where and in what way one should organize the actual project. In this talk I’d like to delve into what I’ve done to organize solutions for development, production, and related pipelines. I’ll talk from my point of view and what I’ve seen others do to keep their workloads organized and their infrastructure and application pipelines clean and well organized.&lt;/em&gt;“&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Portland Biketown Launches - Check out the API</title>
      <link>http://adron.github.io/articles/biketown-api/</link>
      <pubDate>Thu, 21 Jul 2016 08:13:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/biketown-api/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/logo.png&quot; alt=&quot;Biketown Logo&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Good morning Portland! After a few years of hiccups, the Portland Bike Share has finally gotten started! We can thank our corporate overlords over at Nike for kicking in that last chunk of millions to get a bike and station layout that is absolutely superb!&lt;/p&gt;
&lt;p&gt;For a little bit more about the opening day and metrics on uses check out &lt;a href=&quot;http://bikeportland.org/&quot;&gt;Bike Portland&lt;/a&gt; has posted &lt;a href=&quot;http://bikeportland.org/2016/07/20/over-2300-trips-taken-on-biketown-bike-share-in-first-24-hours-187922&quot;&gt;Over 2,300 trips taken on Biketown bike share in first 24 hours&lt;/a&gt;, &lt;a href=&quot;http://bikeportland.org/2016/07/19/bike-share-is-alive-photos-and-recap-from-the-launch-event-187867&quot;&gt;“This is awesome!” Photos and notes from the Biketown launch event&lt;/a&gt;, and others.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;biketown-pdx-&quot;&gt;Biketown PDX!&lt;/h2&gt;
&lt;p&gt;Alright, before diving into the API, let’s discuss the actual way the system works. There are several components to how things go, but it involves the &lt;strong&gt;&lt;em&gt;workflow&lt;/em&gt;&lt;/strong&gt; of &lt;strong&gt;&lt;em&gt;joining&lt;/em&gt;&lt;/strong&gt;, then &lt;strong&gt;&lt;em&gt;unlocking&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;riding&lt;/em&gt;&lt;/strong&gt;, and then &lt;strong&gt;&lt;em&gt;locking&lt;/em&gt;&lt;/strong&gt; it back up. At least, that’s the basic workflow, but there’s obviously a bit more understanding needed to know what to actually do with the bike share. In the next few sections, I’ll break this into &lt;strong&gt;&lt;em&gt;Workflow&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Systemic Geographic Mapping and Stuff&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&quot;workflow&quot;&gt;Workflow&lt;/h3&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com/pricing&quot;&gt;&lt;img src=&quot;/articles/biketown-api/join.png&quot; alt=&quot;Join&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;The first step of the workflow is joining. There’s three ways to do this: single ride, day pass, or annual membership. The single ride is $2.50 per trip. The day pass is $12 a day and the annual membership is $12 per month. Now each of these prices are pretty straight forward, but there are indeed a few little gotchas here and there. Nothing that would break the bank, but let’s talk more about this first step.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single Ride&lt;/em&gt; - The single ride is good if you’ve arrived somewhere but have a short distance to go. Like say you arrive at Pioneer Square on the MAX, and want to get over to the east side real quick around area Burnside. Obviously using transit to get back over the Burnside is an awkward mess, so jumping on a Biketown bike is a perfect solution. This is where the quick $2.50 ride comes into play. Now theoretically most human beings could clear Pioneer Square clear up to about 20th &amp;amp; Burnside in under 30 minutes. However, this is one of the gotchas - exceed 30 minutes and it is 10 cents a minute after that. Not a big deal, but if you didn’t read the fine print it’ll sneak up on ya. There’s one more note to this situation though, it isn’t all penalty fees. When you bring your bike back to the station you actually get a $1.00 account credit! So really, if you use the bike share even somewhat regularly, such as once or twice a month, your price really ends up being about a $1.50 per ride instead of $2.50.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Day Pass&lt;/em&gt; - This basically provides 180 minutes per day and an unlimited number of rides. Which this dual qualifier just doesn’t sound right. If I can have unlimited rides, but am limited to 180 minutes, it doesn’t sound like unlimited rides. Grumble grumble &lt;em&gt;nothing bugs me like poor logic applied in real world business&lt;/em&gt;. But anyway, that’s what is written. The other add, but benificial thing is that if you get a day pass, you can expand on that day pass to take out 4 additional bikes at a time, the first bike counts as the day pass purchaser’s bike, then the other 3 are only $6 per hour, nor do these bikes count toward the 180 minutes. Overall, sounds like a deal, but it’s also attached to that oddly worded logic of the day pass deal. I guess it works out. One the 180 minutes is exceed, it’s 10 cents a minute (so not unlimited rides, but just this…) and upon returning the bike to a rack station, a $1 is applied back to the account as credit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Annual Membership&lt;/em&gt; - This is the account I bought, partially to get into the founders 1000. Which I’m a proud member of. Basically I get extra benifits, but even purchasing one now, post the first founders round of purchasers gets you a good deal. The $12 a month cost gets you unlimited rides, with 90 minutes of ride time included per day. Over 90 minutes is 10 cents a minute. All the other specs are basically the same, but this is a great deal if you want to insure you have easy access at any time to the bike share.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Other Notes&lt;/em&gt; - It’s important to note also, that if you don’t park the bike back at a Biketown rack it’s $2.00 within the system area and $20 outside the system area. The later price can hit the piggy bank a bit. If you’re curious what the service area is, check out the &lt;em&gt;Systemic Geographic Mapping&lt;/em&gt; section below. If you somehow manage to &lt;strong&gt;&lt;em&gt;lose&lt;/em&gt;&lt;/strong&gt; a bike, heaven forbid, you’ll owe a  &lt;strong&gt;$1500.00&lt;/strong&gt; whopper, which they can and likely would nail your ass in small claims for that.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alright, so that is the levels of joining you can partake upon, but what about actually joining? One way is to sign up on the &lt;a href=&quot;https://www.biketownpdx.com/&quot;&gt;Biketown site itself&lt;/a&gt;. Signing up on the site is likely the easiest of all the methods. Then you’ll get an account number and your passcode, then you can just use that to rent a bike wherever and whenever. The next way is to sign up with the little computer attached to the bike. I’ve seen one person do this, and I’m to fidgety to even attempt this, I did my registration via the site. Then the other way is via the mobile app (&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.biketownpdx&quot;&gt;Android&lt;/a&gt; or &lt;a href=&quot;https://itunes.apple.com/us/app/biketownpdx/id1132076989&quot;&gt;iOS&lt;/a&gt;, which is also really easy. Ok, that’s basically it for signing up. Now you’ll be in the system and able to work with the various aspects of the system, such as obviously the bikes themselves.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/unlock.png&quot; alt=&quot;Unlock&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Now comes the part where you go get a bike and unlock it. There are three absurdly easy ways to find the bikes. One, is to simply see the unbelievably orange things sitting about the area locked to whatever. Two, you can go out to the website and check out the &lt;a href=&quot;https://www.biketownpdx.com/map&quot;&gt;map and go to one of those locations&lt;/a&gt;. Third, you can use the mobile application, which is likely the most useful since you’d often be on the go when you get a bike. At least, for me that’s the way I generally use the system.&lt;/p&gt;
&lt;p&gt;The overall map looks a bit like this…&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.biketownpdx.com/map&quot;&gt;&lt;img src=&quot;/articles/biketown-api/maps.jpg&quot; alt=&quot;The Bike Map&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The other way to find and get a bike at the same time is to actually reserve a bike. This puts a hold on a particular bike as you travel toward the bike to pick it up. To learn more about reserving a bike download the app and give it a try.&lt;/p&gt;
&lt;p&gt;If you just go to where a bike or bikes are then you’ll click a button, the screen will come alive, then enter your account number and your account code. Once you’ve done that you’ve checked out the bike and are ready to ride. Also, feel free to enjoy a video on the matter of unlocking and locking.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/mPWZhknfI48?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;So moving right along…&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/ride.png&quot; alt=&quot;ride&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Riding… ok, ummm, I think this is pretty self-explanatory. You ride the bicycle to where you intend to go. It’s really not complicated. But just in case here are a few tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ride at a steady speed in the bike lane, path, or if there isn’t a path or bike lane take the full lane as the law states in Oregon code.&lt;/li&gt;
&lt;li&gt;Don’t ride on the sidewalk unless you have to. It’s a pretty shitty thing to do in all seriousness, and also illegal in some circumstances.&lt;/li&gt;
&lt;li&gt;Enjoy the ride!&lt;/li&gt;
&lt;li&gt;Don’t ride into trees. They’re really hard.&lt;/li&gt;
&lt;li&gt;Enjoy the breeze flowing through your hair (or if you’re like me, flowing over your scalp!)&lt;/li&gt;
&lt;li&gt;Enjoy the fact you’re being super clean, responsible, you’re doing your body and everybody else some good by riding a bike, and getting things done at the same time!&lt;/li&gt;
&lt;li&gt;Just take your time and keep an eye out, you’ll get there just fine.&lt;/li&gt;
&lt;li&gt;You’re not reducing yourself to motor-vehicle usage, be proud of that.&lt;/li&gt;
&lt;li&gt;Also be glad you’re not some asshole in a car. Everybody, even me, when we drive we’re assholes. It’s just the law of physics and the rule of cages is all, don’t cry over it or anything.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ok, enough random rules, observations, and guidelines. You get the idea, ride the bike, have fun, get where you’re going. Smile, love one another. Koombayaaaa and stuff.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com/pricing&quot;&gt;&lt;img src=&quot;/articles/biketown-api/lock.png&quot; alt=&quot;lock&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Once you’re done with the bike lock it up to a bike kiosk. You can technically just lock it to a post or what not, it’s up to you, but note the costs above in the plans I described earlier. If out of zone it’s $20 bucks, if inside the zone and not in a kiosk it’ll cost you $2.00. So it’s usually best to just lock it to a standard bright orange rack kiosk.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Whew, done with the description. Let’s talk about the coding factor now…&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;systemic-geographic-mapping-api-stuff&quot;&gt;Systemic Geographic Mapping API Stuff&lt;/h3&gt;
&lt;p&gt;Ok, I don’t really know what “Systemic Geographic Mapping API Stuff” but it sounds like it encompasses the key aspects of what features the API has. So let’s talk data.&lt;/p&gt;
&lt;p&gt;The first bit of data that is useful is the GBFS. This is the General Bikeshare Feed Specification. This is available here: &lt;a href=&quot;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&quot;&gt;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That’s a &lt;em&gt;little&lt;/em&gt; data, an overview of the system one could say. The real meat however is in the authenticate API. It’s available at &lt;a href=&quot;https://app.socialbicycles.com/developer&quot;&gt;https://app.socialbicycles.com/developer&lt;/a&gt;. Give it a try with a curl.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://biketownpdx.socialbicycles.com/opendata/gbfs.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The response is as shown. A pretty straight forward JSON data blurb. Showing the pricing, alerts, regions, calendar, hours, free bike status (??), station status, station information, and system information url references.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469237395&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;en&quot;&lt;/span&gt;: {
      &lt;span class=&quot;string&quot;&gt;&quot;feeds&quot;&lt;/span&gt;: [
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;gbfs&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_information&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_information.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;station_information&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/station_information.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;station_status&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/station_status.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;free_bike_status&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/free_bike_status.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_hours&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_hours.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_calendar&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_calendar.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_regions&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_regions.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_pricing_plans&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_pricing_plans.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_alerts&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_alerts.json&quot;&lt;/span&gt;
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any of the references you can do a simple curl against and get a good chunk of data. For instance.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl http://biketownpdx.socialbicycles.com/opendata/system_information.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result returns as such.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469290649&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;system_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;biketownpdx&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;language&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;en&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;BIKETOWNpdx&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.com/&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;purchase_url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.com/&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;timezone&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;America/Los_Angeles&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;phone_number&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;(866) 512-2453&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;customerservice@biketownpdx.com&quot;&lt;/span&gt;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I first looked at this list I got keenly interested in the &lt;code&gt;free_bike_status&lt;/code&gt;. I’d always want to know where the free bikes are when I want to rent one. A simple curl request and I knew what I could accrue from this end point. The blurb is sizably bigger than the previous two, so I actually cut out the mid section so it didn’t take until tomorrow to scroll to the end.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469290813&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;bikes&quot;&lt;/span&gt;: [
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_6779&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0218 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.65348833333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.50477166666667&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_6265&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0188 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.70043833333334&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.535826666666665&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7160&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0131 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.674115&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.51180333333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      &lt;span class=&quot;string&quot;&gt;``&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…a whole bunch of entries cut out for brevity…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7308&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0984 AIR TRAINER&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.64039333333334&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.55905833333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7301&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0971 AIR TRAINER&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.644855&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.516286666666666&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far this is purely the public facing, non-authentication based API for Biketown. You can get a host of information and do all sorts of useful things with just this information. But, I will be following up in the coming days with a review of the actual authenticated API for Biketown. I’m looking forward to hacking together some cool apps and interfaces myself, but I’m also really interested to see what others put together!&lt;/p&gt;
&lt;p&gt;Last thing for this post, if you’re curious about the oddly colored bikes that are clearly not orange. You can rent those two, they have a particular theme as detailed here. Something to do with Nike branding and Nike shoes of some sort, I’m not entirely sure as I don’t really wear any Nike gear. Ironically, since I bike I need tougher stuff that’s oriented toward biking. Nike doesn’t really seem to have any market play in that realm.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qs6m9lQ9qRE?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Until that next API call, cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp; Packer - Part 1</title>
      <link>http://adron.github.io/articles/nginx-notes-from-the-url-redirect/</link>
      <pubDate>Thu, 14 Jul 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/nginx-notes-from-the-url-redirect/</guid>
      <author></author>
      <description>&lt;p&gt;I set out on a mission yesterday to put together a URL Redirect Server. Before I even get into the nitty gritty of how I got this to work via Nginx, I’ll add two caveats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I don’t really know much about Nginx at all. I’ve written up and configured one reverse proxy and handed that off to some ops team. Theoretically it worked (in their testing). But other than that, I’ve barely done anything myself with Nginx.&lt;/li&gt;
&lt;li&gt;I’ve no idea really if this is even a good practice. URL Redirects of this sort actually seem like a hack. They work, but it seems like there really ought to be a better less onion layer like way to do this type of redirection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With those two caveats I’ll add a few questions for you, dear reader.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If you have any suggestions for an easier way than spinning up a whole Nginx Server to do URL Redirects I’d love to hear them!&lt;/li&gt;
&lt;li&gt;Is this a best practice way to do subdomain to URL Redirects? If not, I’d probably like to be doing whatever is best practice.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, now that we’re past my caveats, questions, and requests for help, let’s roll on the how-to of all this.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This whole setup started when I realized while doing a migration from one DNS Provider to Google DNS. Google DNS doesn’t convolute their DNS Services with URL Redirect features or other non-DNS features. When I stumbled into the fact that there were some URL Redirects that had muddled themselves into Google DNS as actual CNAME DNS entries, I knew I’d need to get those migrated to something that could actually do URL redirects.&lt;/p&gt;
&lt;p&gt;The need was super simple in scope. Have a subdomain, like &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; redirect (302 and eventually 301, more on that in a minute) to something like &lt;a href=&quot;http://api.compositecode.com/dataservices/information.html&quot;&gt;http://api.compositecode.com/dataservices/information.html&lt;/a&gt;. I did some reading about &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations&quot;&gt;Apache vs. Nginx&lt;/a&gt;. I determined I’d go with Nginx as I knew it to be a solid server with minimal fuss.&lt;/p&gt;
&lt;h2 id=&quot;setting-up-nginx&quot;&gt;Setting up Nginx&lt;/h2&gt;
&lt;p&gt;Before getting into a smart way to setup Nginx, I just dove in to figure out how to setup a redirect.&lt;/p&gt;
&lt;p&gt;First I spun up an Ubuntu 16.04 Server on Google Cloud. Here’s the interface for creating a new instance on Google Compute Engine (GCE).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-01.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next setup the criteria for the instance. In my particular situation I’m assuming an almost non-existent need for resources so I’ve select the uber cheapo $4.49 instance. For that instance I named it url-redirector, stuck it in the us-central1-a zone, selected the micro (1 shared vCPU) with 0.6 GB Memory, using the Ubuntu 16.04 LTS image, gave it default access, selected HTTP traffic, and clicked create.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-02.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once created it displayed on the Compute Engine dashboard screen. There I have my IP and SSH options.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-03.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Clicking on the SSH vertical elipsis I then selected the &lt;code&gt;View gcloud command&lt;/code&gt; option. A dialog appears with the gcloud command to connect to this new instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-04.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;I copied the command to ssh into my Google Cloud server instance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud compute --project &amp;quot;that-big-universe&amp;quot; ssh --zone &amp;quot;us-central1-a&amp;quot; &amp;quot;url-redirector&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point I went ahead and logged into this new instance and installed Nginx.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install -y nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On Ubuntu 16.04 a new firewall technology is used called Uncomplicated Firewall (UFW). To setup that firewall, open up the HTTP and SSH ports. Some instructions point to an Nginx HTTP so I added that too. Then I enabled the firewall.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo ufw allow http  #adds port 80
sudo ufw allow ssh  #adds port 22
sudo ufw allow &amp;#39;Nginx HTTP&amp;#39;
sudo ufw enable
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I noticed this prompted for a “&lt;code&gt;y|n&lt;/code&gt;“ as I enabled the firewall. So I’ll have to figure that out later as I work through automating and building out this server for deployment and prep with Packer and Terraform later. At this point however I have the server running, with Nginx, and am ready to test out a redirect.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Configuration File Structure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A lot of the samples I find all over the web are in little snippets like the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    root /data/www;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    location / {
        root /data/www;
    }

    location /images/ {
        root /data;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
        fastcgi_pass  localhost:9000;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param QUERY_STRING    $query_string;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In these three examples I have location with a value for the root property in the top one, then in the next the server with two location sections and then finally a location. So many of these snippets are used and can be confusing without context for how and where things are structured within the configuration file itself.&lt;/p&gt;
&lt;p&gt;Let’s break this out real quick to the requisite parts of the file. Nginx has modules controlled by directives in the configuration file. A directive consistes of name and parameters separated by spaces and ending with a semicolon. A block directive or simple directive has the same overall structure. The difference being a block directive has a set of instructions surrounded by braces. A context is a block directive that has additional directives inside the braces. Directives placed in the configuration file outside of contexts is in the main context.&lt;/p&gt;
&lt;p&gt;Some of the key contexts to be familiar with in configuration of Nginx are the &lt;em&gt;events&lt;/em&gt;, &lt;em&gt;http&lt;/em&gt;, &lt;em&gt;main&lt;/em&gt;, &lt;em&gt;server&lt;/em&gt;, &lt;em&gt;http&lt;/em&gt;, and &lt;em&gt;location&lt;/em&gt; directives. Also, it’s good to know that the &lt;em&gt;events&lt;/em&gt; and &lt;em&gt;http&lt;/em&gt; directives reside int he &lt;em&gt;main&lt;/em&gt; context, &lt;em&gt;server&lt;/em&gt; in &lt;em&gt;http&lt;/em&gt;, and &lt;em&gt;location&lt;/em&gt; in &lt;em&gt;server&lt;/em&gt;. The most common one often edited, at least in my minor experience so far is the &lt;em&gt;server&lt;/em&gt; context. This &lt;em&gt;server&lt;/em&gt; context of course resides in the &lt;em&gt;http&lt;/em&gt; context which resides in the &lt;em&gt;main&lt;/em&gt; context. This looks something like what is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http {
    server {
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check out a &lt;a href=&quot;http://adron.github.io/docs/nginx-default-config-file&quot;&gt;sample nginx.conf files&lt;/a&gt; to get an idea of what the default config file looks like after installation. For more information also check out this other &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts&quot;&gt;Digital Ocean blog entry “Understanding the Nginx Configuration File Structure and Configuration Contexts”&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another important thing to know, besides how the nginx.conf file is structured and formatted, is where the thing is actually located. Here are some of the file locations for it and related important files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/var/www/html&lt;/code&gt; is where the actual content that Nginx serves is located.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx&lt;/code&gt; is where the configuration files are. Including the nginx.conf file I’ll need to edit for the redirect.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/sites-available&lt;/code&gt; is the directory where per-site “server blocks” are stored. Typically server block config is done here and then enabled by linking to the other directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/sites-enabled&lt;/code&gt; is the directory where enabled per-site “server blocks” are stored linked by config files in the sites-available directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/snippets&lt;/code&gt; is where config fragments are included that are used elsewhere in Nginx configuration.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/nginx/access.log&lt;/code&gt; is where the web server records log files unless configured to do so elsewhere.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/nginx/error.log&lt;/code&gt; is where Nginx errors are recorded.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What I needed to do at this point was edit the nginx.conf, or some file, and ensure that it had the appropriate redirection in the file. My first take at this looked like the following edit. I opened up the nginx.conf file and added this to the &lt;code&gt;http {}&lt;/code&gt; context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http {
    server {
        server_name data.adron.me;
        return 302 http://api.compositecode.com/dataservices/information.html;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this juncture however, with this hack of the config file I had a working URL Redirection. Upon further reading I realized that maybe this wasn’t the most ideal place to put the redirection.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;I’ve got a solid redirect in place for &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; that is sending traffic to &lt;a href=&quot;http://api.compositecode.com/dataservices/information.html&quot;&gt;http://api.compositecode.com/dataservices/information.html&lt;/a&gt;. However I’m not sure I’ve set this up using an ideal practice. So I went back to reading more of the documentation. RTFMing, it’s important.&lt;/p&gt;
&lt;p&gt;Part 2, coming up soon, with more docs read for better insight! &amp;lt;- this line will eventually link, like a linked list, to the next part of this series.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nginx.com/&quot;&gt;Nginx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/wiki/&quot;&gt;Nginx Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-14-04-lts&quot;&gt;Installing Nginx on Ubuntu Server 14.04 LTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-16-04&quot;&gt;Installing Nginx on Ubuntu Server 16.04&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations&quot;&gt;Aapche vs. Nginx: Practice Considerations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts&quot;&gt;Understanding the Nginx Configuration File Structure and Configuration Contexts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>.NET Fringe and Node PDX Conference Retrospective</title>
      <link>http://adron.github.io/articles/net-fringe-retrospective/</link>
      <pubDate>Tue, 12 Jul 2016 13:37:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/net-fringe-retrospective/</guid>
      <author></author>
      <description>&lt;p&gt;Well, that’s a wrap - tied with a bow - for .NET Fringe 2016 and Node PDX 2016. That’s two years in a row for .NET Fringe and the 3rd year for Node PDX (2012, 2013, and 2016). All of the conferences have been very stressful, intense, and rewarding. I’ve learned a lot in the process and had a chance to work together with a lot of great people including Troy Howard, Glenn Block, Scott Hanselman, Phil Haack, Itamar Syn-Hersko, Alena Hall, and many others.&lt;/p&gt;
&lt;p&gt;At this point I’ve deemed it time for a solid retrospective on organizing, community, and related topics. I’m breaking this article into the following segments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conference Organizing - Taking a Break&lt;/li&gt;
&lt;li&gt;Community Organizing vs. Value Added&lt;/li&gt;
&lt;li&gt;Workshops - What’s valuable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;conference-organizing&quot;&gt;Conference Organizing&lt;/h2&gt;
&lt;p&gt;Conferences themselves are great experiences for the vast majority of people that attend the conferences. It’s also a great way to build a community that knows each other beyond the virtual space. Having these connections is invaluable - from the connections that Steve Jobs &amp;amp; Wozniak made at conferences that led to Apples creation to Microsoft at the same, to today with open source conferences like OSCON, Strangeloop, and other great community led conferences. These are the places where conversations start that build this industry and take us into the future.&lt;/p&gt;
&lt;p&gt;In that sense, I hope Node PDX and .NET Fringe have helped to grow the community in Portland and beyond. I hope it has helped people to expand on ideas, projects, and overall grow as individuals and build more cohesive organizations. I too, have grown and been able to expand and build on ideas and various projects because of these efforts. In many ways these conferences have helped me to build my future.&lt;/p&gt;
&lt;p&gt;I myself am going to take a break this coming dozen or more months, ma ybe permanantly, from conference organizing. I have however already started plotting some of the next big projects that I will contribute or build. Namely, I intend to start speaking and providing workshops on several key spaces within the tech industry that I see a horrid gap that needs filled. More on that real soon.&lt;/p&gt;
&lt;h2 id=&quot;community-organizing-vs-value-added&quot;&gt;Community Organizing vs. Value Added&lt;/h2&gt;
&lt;p&gt;I’ve always enjoyed organizing events of various types. From meetups like the Elastic Meetup that I’m currently helping to organize or conferences like .NET Fringe or Node PDX. Each tech stack, event type, and related slices of categorization have different &lt;em&gt;communities&lt;/em&gt; built around it. Some have inspiration, others networking options, some are great for project building or team building. Whatever the case they each have their positives. In the same light, each type of event has it’s various negatives too.&lt;/p&gt;
&lt;p&gt;Conferences are almost all organized around speakers speaking at an audience. Sometimes there is time for questions, but there is strong argument that questions for a speaker doesn’t add a lot and often derails the momentum of talks for the overall audience. Some conferences have workshops before the actual presentation sessions. Other conferences work around an unconference or open spaces style event setup. Each style has benefits for people and negatives, as an example, I myself love to attend open spaces conferences and feel that I gain the most value from conferences like that. &lt;/p&gt;
&lt;p&gt;I’ve always aimed to mix the elements together to find the best combination of value for people, along with Troy, Glenn, and the teams we’ve put together to organize these conferences. It’s actually an extremely difficult mix to get right. I think we’ve done a good job of getting that mix right, but I’m sure there are a number of things we can improve on to get even more value out of conferences for people.&lt;/p&gt;
&lt;p&gt;In an attempt to get more value out of social gatherings like conferences, meetups, and the like I’m going to work dilligently in the coming weeks to get new ideas together to build even better events. Some of the requests and demands of various audiences range widely. Here’s a few questions I’ve noted as of late, with a tweet that kicked off several of the conversations.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I&amp;#39;m kind of over conferences. The whole, &amp;quot;Speaker gets up and talks&amp;quot; mode of transferring information is busted. I learn by doing.&lt;/p&gt;&amp;mdash; Scott Koon (@lazycoder) &lt;a href=&quot;https://twitter.com/lazycoder/status/752002282498068481&quot;&gt;July 10, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;gathering-questions-for-ideas&quot;&gt;Gathering Questions for Ideas&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What do people enjoy in gatherings that help us attain the maximum learning?&lt;/li&gt;
&lt;li&gt;What makes gatherings interesting enough to attend?&lt;/li&gt;
&lt;li&gt;What negatives can we remove?&lt;/li&gt;
&lt;li&gt;What makes the environment good for meeting, talking, and working together on ideas to learn more?&lt;/li&gt;
&lt;li&gt;What are an ideal set of goals, specific goals, to actually work toward?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then some of the other goals that I aim to figure out, largely by testing out or building tools to do this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improve ability to communicate with specific members of the attendee audience when needed, with appropriate mediums, and reasonable expectations of information disseminate.&lt;/li&gt;
&lt;li&gt;Find ways to ticket by group, event, time, and related criteria that will allow communication and group association to simplify both things (ticketing and grouping).&lt;/li&gt;
&lt;li&gt;Find better ways to delegate payments and billing that aren’t hard linked to individual people and singular accounts.&lt;/li&gt;
&lt;li&gt;Find better ways to allocate work to volunteers and those interested in helping that has more globally viewable content to help give everybody involve better visibility into what we’re trying to get done.&lt;/li&gt;
&lt;li&gt;Study up on and work on my communication skills. This is, of course, something that has been an ongoing learning experience which I suspect will continue being an ongoing learning experience.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;workshops&quot;&gt;Workshops&lt;/h2&gt;
&lt;p&gt;I’ve got a ton of material that I’d like to break out into groupings for screencasts/video how-to or training content, blog entries, and hands on workshop training. After discussing space opportunities 
Mark at NedSpace (thanks again for helping with .NET Fringe Mark!) and have worked with Code Fellows (Marty rocked 2 Node PDX Workshops) and working with Mathias Brandewinder, Evelina Gabasova, Aaron Stannard, Beau Palmquist, and Jared Schaab. After gaining that experience I’m seriously working on determining how to provide more workshops, but with a bit more of a twist. I want to add new elements to workshops that can extend the entertaining value of the workshops but also the learnings of the various workshops I’d like to provide.&lt;/p&gt;
&lt;p&gt;One of the ideas that keeps rolling around in my head, which really is rooted in this question, “How do I combine the elements that I love providing in meetups, conferences, and existing workshops into a medium and mode of delivery that people would find valuable?” In summary, how can I do and teach the things I really enjoy so that people determine it is enough value to pay for? As in any business, it’s an interesting challenge. So in the coming weeks I’ll have more conversations and more ramblings on the blog here about what I’m determined to acheive with the delivery of workshops and gatherings related to learning lots of awesome things.&lt;/p&gt;
&lt;p&gt;Until then, I hope you’ve had a spectacular time at .NET Fringe AND Node PDX. I send thanks to all of the attendees and all involved - thanks and CHEERS!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Day 2 Multi-thinking-threads Smeared Around the Brainstorming at .NET Fringe</title>
      <link>http://adron.github.io/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/</link>
      <pubDate>Tue, 12 Jul 2016 09:04:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/logo.png&quot; alt=&quot;.NET Fringe Logo&quot;&gt;&lt;/p&gt;
&lt;p&gt;Sitting at .NET Fringe, day 2. Just introduced James Newton-King. Got a million conversations running through my mind. A lot of these conversations are worth noting, so I’ll just give a quick break out right here.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;docker-containers-windows&quot;&gt;Docker, Containers, &amp;amp; Windows&lt;/h2&gt;
&lt;p&gt;Started a conversation with Solomon Hykes (&lt;a href=&quot;https://twitter.com/solomonstre&quot;&gt;@solomonstre&lt;/a&gt;) regarding Windows and Docker Container technology use. I also started a lot of conversations yesterday and intend to have a few regarding these tech elements today.&lt;/p&gt;
&lt;h2 id=&quot;workshops-in-portland&quot;&gt;Workshops in Portland&lt;/h2&gt;
&lt;p&gt;I’ve had a conversation about future workshops, space, and the requisite needs around that to ensure I can deliver some awesome pending workshops to the Portland audience. Also started a conversation for people that would like to come into town for workshops, and have the assumed awesome time in Portland. We do have amazing beer, coffee, wine, food, and more. Thus any workshop in Portland will have appropriate things for any attendees. This is almost locked in, if you’re curious about these workshops, which will be seriously epic, &lt;a href=&quot;http://blog.adron.me/thrashingcodenews.html&quot;&gt;subscribe here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;hack-kubernetes-olympia&quot;&gt;Hack Kubernetes Olympia&lt;/h2&gt;
&lt;p&gt;Talked shortly with &lt;a href=&quot;https://twitter.com/NotMyself&quot;&gt;@NotMyself&lt;/a&gt;, and am plotting to take an Amtrak Cascades trip up to Olympia for a 1-2 day workshop on Kubernetes and related technologies. I’m thinking Docker + Swarm + Kubernetes + DevOps + how to make one’s life dramatically easier while delivering 10x what one could deliver just 5 years ago. This, I assure you will be a blast too.&lt;/p&gt;
&lt;h2 id=&quot;windows-server-vs-the-coders-universe&quot;&gt;Windows Server vs…  the coders Universe&lt;/h2&gt;
&lt;p&gt;So it seems that my assumption is safe. A large number of people in the .NET space love C#, F#, (even VB.NET), and other elements of .NET. There seems to be a resounding frustration around Windows OS itself, namely server not Windows 10. As a development OS it’s fine, albeit there are probably as many or more OS-X as Windows machines running and, dare I say at least 2 Linux machines at .NET Fringe right now. (Right &lt;a href=&quot;https://twitter.com/adymitruk&quot;&gt;@adymitruk&lt;/a&gt;) I’m very cool with this, as the pressure will grow to make Windows Server more, how should I put it, “Devopsified” or something like that might work.&lt;/p&gt;
&lt;h2 id=&quot;memetic-independence&quot;&gt;Memetic Independence&lt;/h2&gt;
&lt;p&gt;Ok, I almost started writing something about that in this blog entry, but it’ll get it’s own in the near future. &lt;a href=&quot;https://twitter.com/dsyme&quot;&gt;@dsyme&lt;/a&gt; hit on a dramatically important topic for the longevity and life of any open source software stack, and very applicative to .NET.&lt;/p&gt;
&lt;h2 id=&quot;the-9am-summary&quot;&gt;The 9am Summary&lt;/h2&gt;
&lt;p&gt;So it’s only 9:00am right now. I think that’ll be good for now. Will add more thoughts, observations, and other news bits later today. If you’re wanting help kicking off a project, connected to someone I might know, or otherwise talk tech, coding, and some devops universe topic - I’ll be around, just let me know!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>.NET Fringe Bike Ride</title>
      <link>http://adron.github.io/articles/Bike-Rides/</link>
      <pubDate>Fri, 08 Jul 2016 07:29:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/Bike-Rides/</guid>
      <author></author>
      <description>&lt;p&gt;In my &lt;strong&gt;&lt;em&gt;not so humble opinion&lt;/em&gt;&lt;/strong&gt; every conference should have a bike ride. But I realize it isn’t always possible. This is one of the ways conferences that Troy &amp;amp; I put on here in Portland are very different. We have a love for Portland; &lt;em&gt;the energy, the chill, vibrant yet relaxed, laid back, bike like, walking friendly city that it is&lt;/em&gt;. It’s a beautiful city that really can only be seen or felt by active transportation. If you walk, run, bike, skate board, dog sled, sled, cross country ski, or otherwise travel around Portland you get to actually see, feel, and hear this city. No other mode really works. Transit is fun, driving is like a cage, and with both you miss the vast majority of the life and blood of what makes Portland a great city!&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/Bike-Rides/nodepdx-bike-ride.jpg&quot; alt=&quot;Node PDX Bike Ride&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;-net-fringe-bike-ride&quot;&gt;.NET Fringe Bike Ride&lt;/h2&gt;
&lt;p&gt;With all that said, obviously we’re having a bike ride at .NET Fringe! I’ll be the lead, and give everybody a solid tour around some key parts of the city. I’ll show you all some odd things, weird stuff, probably some strange people, architecture and other elements and features of this place called Portland! Here’s the details:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Anybody can join the ride, even people that aren’t attending .NET Fringe. If we have 3 people ride or 500, it doesn’t matter, we’ll have a good roll about town.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;BYOB - Bring Your Own Bike AKA Bring Your Own Beer. For us, it means both. This might sound complicated, but I promise it’s not. There are a zillion places to rent a bike in about 20 seconds. Links below where to pick up a ride of your choice for the ride about the city.&lt;/li&gt;
&lt;li&gt;Show up at the designated location (also listed below) at the designated time (also listed below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;That’s it!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ll summarize these simple steps to simply say “Just show up!” This isn’t a spandex crowd ride, this is a people chillin’ in Portland ride, so don’t worry nobody is getting left behind. We’ll enjoy some coffee, probably a beer, the city, and maybe a chat or three about the latest in tech, code patterns, and other miscellaneous hot topics like IoT not spamming your wifi and burning your muffins!&lt;/p&gt;
&lt;p&gt;Before renting a bike though, check out the options at the hotel you’re staying. Many if not most hotels in Portland have nice bikes that you can use for free. The Ace Hotel, Hotel Rose, and others all have a number that are freely available to guests of the hotel. &lt;/p&gt;
&lt;p&gt;So, in lieu of a bike access at hotel, home, friends, or otherwise, some great places to get bike rentals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.waterfrontbikes.com/&quot;&gt;Waterfront Bike&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Waterfront+Bicycle/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0xbed7f9780615f52d!8m2!3d45.5213399!4d-122.6709741&quot;&gt;10 SW Ash St #100, Portland, OR 97204&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.pedalbiketours.com/&quot;&gt;Pedal Bike Tours&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Pedal+Bike+Tours/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0x6c1861d1ea8716e0!8m2!3d45.5216706!4d-122.672739&quot;&gt;133 SW 2nd Ave, Portland, OR 97204&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://portlandbicycletours.com/&quot;&gt;Cycle Portland Bike Tours &amp;amp; Rentals&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Cycle+Portland+Bike+Tours+%26+Rentals/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0xed9ef696a5172958!8m2!3d45.5241437!4d-122.672562&quot;&gt;117 NW 2nd Ave, Portland, OR 97209&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We’ll meet at the waterfront here @ &lt;a href=&quot;https://www.google.com/maps/@45.5213697,-122.6699997,19.25z&quot;&gt;100 SW Naito Parkway&lt;/a&gt; and depart at &lt;strong&gt;[[UPDATED &lt;code&gt;5:15pm&lt;/code&gt;]] &lt;/strong&gt; on Sunday.&lt;/p&gt;
&lt;p&gt;The ride path is a secret (mostly because we’ll be JIT via dynamic path finding along the route). However, I can say it’ll be low car volume, easy paths, and minimal hills (Portland is mostly flat by Cascadian standards).&lt;/p&gt;
&lt;p&gt;See all of ya out there!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Node PDX 2016 Photos</title>
      <link>http://adron.github.io/articles/Node-PDX-2016-Photos/</link>
      <pubDate>Wed, 29 Jun 2016 11:25:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/Node-PDX-2016-Photos/</guid>
      <author></author>
      <description>&lt;p&gt;Here’s a selection of photos from Node PDX. To check out all of the photos I’ve uploaded them on &lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Videos are available at &lt;a href=&quot;https://www.youtube.com/playlist?list=PLILnvQDgzULPSdF9Eppfl5MqQe0M3hhtx&quot;&gt;https://www.youtube.com/playlist?list=PLILnvQDgzULPSdF9Eppfl5MqQe0M3hhtx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/codes.jpg&quot; alt=&quot;Codes&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/liz.jpg&quot; alt=&quot;Liz&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/liz2.jpg&quot; alt=&quot;Liz&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/a1.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/azat4.jpg&quot; alt=&quot;Azat&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/b.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/computers.jpg&quot; alt=&quot;Computers&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben.jpg&quot; alt=&quot;Ben Michel&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/azat.jpg&quot; alt=&quot;Azat&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/chillin.jpg&quot; alt=&quot;Chillin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/elastic.jpg&quot; alt=&quot;Elastic&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hacking.jpg&quot; alt=&quot;Hacking&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hardware-hacking.jpg&quot; alt=&quot;Hardware&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hardware-hacking2.jpg&quot; alt=&quot;Hardware&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/j3.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jacob.jpg&quot; alt=&quot;Jacob&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/james3.jpg&quot; alt=&quot;James&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jamesh2.jpg&quot; alt=&quot;Jacob&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben1.jpg&quot; alt=&quot;Ben Michel&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jon.jpg&quot; alt=&quot;Jon&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jon2.jpg&quot; alt=&quot;Jon&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben-music.jpg&quot; alt=&quot;Ben Michel &amp;amp; Band&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music2.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music3.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/matt.jpg&quot; alt=&quot;Matt&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/matt2.jpg&quot; alt=&quot;Matt&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/rethink.jpg&quot; alt=&quot;Rethink&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/reyes.jpg&quot; alt=&quot;Reyes&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/suchita.jpg&quot; alt=&quot;Suchita&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/suchita1.jpg&quot; alt=&quot;Suchita&quot;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Node PDX 2016 Bike Ride, Photos, and More</title>
      <link>http://adron.github.io/articles/node-pdx-2016-bike-ride/</link>
      <pubDate>Wed, 29 Jun 2016 10:25:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-bike-ride/</guid>
      <author></author>
      <description>&lt;p&gt;Node PDX, at least for me, kicked off Saturday morning before the conference. This involved the Geek Train, which as always was a great ride. After returning everyone went off for the evening and I prepared more for the conference.&lt;/p&gt;
&lt;p&gt;The following day involved Sunday conference setup, workshops, and the Node PDX bike ride. Here’s a few photos of the ride and our break at Cup &amp;amp; Bar. In the next blog entry I’ll have more pictures &amp;amp; videos of the talks coming up.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/nodepdx-bike-ride.jpg&quot; alt=&quot;Node PDX Bike Ride&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar.jpg&quot; alt=&quot;Cup and Bar&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-1.jpg&quot; alt=&quot;Cup and Bar One&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-bikes.jpg&quot; alt=&quot;Cup and Bar Bikes&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-chats.jpg&quot; alt=&quot;Cup and Bar Chats&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A Channel 9 Video on .NET Fringe 2016</title>
      <link>http://adron.github.io/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/</link>
      <pubDate>Wed, 15 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/chan9logo.png&quot; alt=&quot;Channel 9 Logo&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I was working on some code and related infrastructure configurations at &lt;a href=&quot;https://workfrom.co/albina-press&quot;&gt;Albina Press&lt;/a&gt; today. But took a short break to join &lt;a href=&quot;https://twitter.com/thoward37&quot;&gt;Troy Howard&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/&quot;&gt;Glenn Block&lt;/a&gt; to speak with &lt;a href=&quot;https://twitter.com/sethjuarez&quot;&gt;Seth Jaurez&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Golnaz89&quot;&gt;Golnaz Alibeigi (even though she was hiding, she was there!&lt;/a&gt; to talk about &lt;a href=&quot;http://dotnetfringe.org/&quot;&gt;.NET Fringe&lt;/a&gt;.&lt;/p&gt;
&lt;iframe src=&quot;https://channel9.msdn.com/Events/NET-Fringe/NET-Fringe-2016/NET-Fringe-2016/player&quot; width=&quot;560&quot; height=&quot;315&quot; allowFullScreen frameBorder=&quot;0&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;For more info:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#speakers&quot;&gt;Speakers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#map&quot;&gt;Venue &amp;amp; Lodging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#lightningtalks&quot;&gt;Lightning Talks (submit one, still open)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#geektrain&quot;&gt;Geek Train&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#tickets&quot;&gt;Tickets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Node.js Patterns - From Callbacks to Observer by Azat Mardan</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-azat-mardan/</link>
      <pubDate>Tue, 14 Jun 2016 19:35:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-azat-mardan/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-azat-mardan/azat.jpg&quot; alt=&quot;Azat Mardan&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Introducing Azat Mardan!&lt;/p&gt;
&lt;p&gt;Azat is author of many JavaScript and Node.js best sellers including &lt;em&gt;Practical Node.js&lt;/em&gt;, &lt;em&gt;Pro Express.js&lt;/em&gt; and &lt;em&gt;Rapid Prototyping with JS&lt;/em&gt;. He works as a Technology Fellow at Capital One Financial Corporation where he provides expertise in software engineering.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This presentation is for you, if you’re a JavaScript engineer who is interested in deepening your understanding of Node.js patterns so you can create and design Node.js applications intelligently. With the right pattern, applications will be more scalable and easier to maintain. If you aspire one day to become a Node.js architect (or maybe you’re already one and want to extend your knowledge), this presentation is for you.&lt;/p&gt;
&lt;p&gt;You will learn from this talk:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Starting with basic: what is event loop and callback: setTimeout(), setImmediate() and process.nextTick()&lt;/li&gt;
&lt;li&gt;The observer pattern with EventEmitter&lt;/li&gt;
&lt;li&gt;Middleware pattern&lt;/li&gt;
&lt;li&gt;Module patterns: module.exports et al&lt;/li&gt;
&lt;li&gt;Hacking object prototype and global refs&lt;/li&gt;
&lt;li&gt;Factory pattern and pseudo-classical inheritance&lt;/li&gt;
&lt;li&gt;Async patterns: Async, NeoAsync, async await, generators and Promises&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more work and links form Azat, check out these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://webapplog.com&quot;&gt;http://webapplog.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Company: &lt;a href=&quot;http://capitalone.io&quot;&gt;http://capitalone.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/azat-co&quot;&gt;http://github.com/azat-co&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Books: &lt;a href=&quot;http://webapplog.com/books&quot;&gt;http://webapplog.com/books&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Other links: &lt;a href=&quot;http://azat.co&quot;&gt;http://azat.co&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too)</title>
      <link>http://adron.github.io/articles/working-with-google-compute-engine/</link>
      <pubDate>Sun, 12 Jun 2016 15:54:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/working-with-google-compute-engine/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;strong&gt;Mission:&lt;/strong&gt; I wanted to setup an instance, that I could install various things on and prepare it to act as a Terraformer or central server within GCE to spawn instances, setup networks, and generally manage the network autonomously of any local scripts or junk I have on my local computer. To set this up, I would of course have to launch it from my local computer, so there’s a whole range of things I’d need to have execute. To accomplish this, here’s what I did.&lt;/p&gt;
&lt;h2 id=&quot;first-steps-google-compute-engine&quot;&gt;First Steps: Google Compute Engine&lt;/h2&gt;
&lt;p&gt;First I logged in and setup a GCE Account (&lt;a href=&quot;https://cloud.google.com/compute/docs/quickstart&quot;&gt;read specifically about creating and getting started with a GCE account&lt;/a&gt;) and got &lt;em&gt;gcloud&lt;/em&gt; configured. The &lt;em&gt;gcloud&lt;/em&gt; is a cli to manage GCE. It’s actually a super powerful tool that comes in handy for all sorts of things. Besides managing GCE, it has a thin wrapper around &lt;a href=&quot;https://en.wikipedia.org/wiki/Secure_Shell&quot;&gt;ssh&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Secure_copy&quot;&gt;scp&lt;/a&gt;, and working with servers with those respective tools. I’ll use it a bit later to actually run some scripts against the instance I’ll be creating.&lt;/p&gt;
&lt;p&gt;Once you’ve signed up for GCE there’s a few things worth noting. One is the idea of the &lt;em&gt;project&lt;/em&gt; that Google uses within GCE. This is something you’re create, or rename the default, or in some way bring into existence to use. A &lt;em&gt;project&lt;/em&gt; is something that a host of instances, instance groups, load balancers, networks, networking, and more can be allocated against. It’s also something that can be setup for or inside a specific billing group. It might also be helpful to really get an understanding of what a &lt;em&gt;project&lt;/em&gt; is by reading the &lt;a href=&quot;https://cloud.google.com/compute/docs/projects&quot;&gt;Google documentation on &lt;em&gt;projects&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Once the project is ready, we can move forward with installing &lt;em&gt;gcloud&lt;/em&gt;. The way this is done is by installing the Google Cloud SDK. The curl below pulls down and executes the installation. Then the following command restarts the shell. Finally the gcloud init command kicks off the initialization of the gcloud cli.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl https://sdk.cloud.google.com | bash
exec -l $SHELL
gcloud init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running gcloud init does several things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Authenticates the user (or allows re-use of saved credentials).&lt;/li&gt;
&lt;li&gt;Requests the user’s project &amp;amp; saves it in the gcloud configuration.&lt;/li&gt;
&lt;li&gt;Requests and sets a default zone based on the project in the gcloud configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point gcloud is setup for use, however upon connecting for the first time to an instance, gcloud will prompt to create a new ssh key set. This key set will be created and autonomous of the key set I have setup for git or other cli ssh tooling I’ll use. I’ll talk more about that later. NOTE: It is very important for subsequent steps to insure the gcloud ssh key is generated. I’ll get around to that in a moment under the “&lt;a href=&quot;#gcloudterraform&quot;&gt;&lt;em&gt;User gcloud w/ Terraform&lt;/em&gt;&lt;/a&gt;“ section.&lt;/p&gt;
&lt;p&gt;The specific instructions for setting up &lt;em&gt;gcloud&lt;/em&gt; are also available here in &lt;a href=&quot;https://cloud.google.com/sdk/&quot;&gt;getting started with the Google Cloud SDK&lt;/a&gt;. This includes a little more description of what is included and related information about the Google Cloud SDK.&lt;/p&gt;
&lt;h3 id=&quot;gcloudterraform&quot;&gt;Using gcloud w/ Terraform&lt;/h3&gt;

&lt;p&gt;When building Terraform configurations for Google Cloud there are a number of settings that &lt;em&gt;gcloud&lt;/em&gt; can pull up very easily. Here are some of the commands I’ve used most frequently when setting up google compute instances.&lt;/p&gt;
&lt;p&gt;List machine types in a project in table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List the URIs of all machine types in a project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list --uri
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all machine types in the us-central1-b and europe-west1-d zones.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list --zones us-central1-b europe-west1-d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all images in a project in table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all the URI images in a project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list --uri
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last thing is connecting to instances, with &lt;em&gt;gcloud&lt;/em&gt; looks like the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute --project &amp;quot;project-name&amp;quot; ssh --zone &amp;quot;us-central1-b&amp;quot; &amp;quot;instance-name&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s some super useful ways to execute commands with the &lt;em&gt;gcloud&lt;/em&gt; cli, which provides a great way for bash scripting against instances.&lt;/p&gt;
&lt;p&gt;These all provide quick ways to get the specific GCE specific settings for the Terraform file. Which brings up a perfect point to get into a basic Terraform instance creation.&lt;/p&gt;
&lt;h2 id=&quot;next-terraforming-with-terraform&quot;&gt;Next: Terraforming with Terraform&lt;/h2&gt;
&lt;p&gt;If you don’t have &lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt; installed, the following bash commands will get you all setup on your machine. With this script below I can wrap this up as an installation script for the instance further along in this how-to. We’ll just have to tweak it specifically for Linux, as this script is focused around downloading and installing the Darwin (OS-X) version.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;cd /home/adron

# Create a move into directory.
mkdir terraform_0_6_14
cd terraform_0_6_14

# Download.
curl -O https://releases.hashicorp.com/terraform/0.6.14/terraform_0.6.14_darwin_amd64.zip
# Unzip and install
unzip terraform_0.6.14_darwin_amd64.zip

export PATH=/home/terraform_0_6_14:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To confirm that Terraform is installed correctly, just type terraform. The following should be displayed, which will let you know that the path variable is set to the correct path.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ terraform
usage: terraform [--version] [--help] &amp;lt;command&amp;gt; [&amp;lt;args&amp;gt;]

Available commands are:
    apply       Builds or changes infrastructure
    destroy     Destroy Terraform-managed infrastructure
    get         Download and install modules for the configuration
    graph       Create a visual graph of Terraform resources
    init        Initializes Terraform configuration from a module
    output      Read an output from a state file
    plan        Generate and show an execution plan
    push        Upload this Terraform module to Atlas to run
    refresh     Update local state file against real resources
    remote      Configure remote state storage
    show        Inspect Terraform state or plan
    taint       Manually mark a resource for recreation
    untaint     Manually unmark a resource as tainted
    validate    Validates the Terraform files
    version     Prints the Terraform version
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may also want to add the PATH to the ~/.bash_profile on your own OS-X machine, like I did. Instead of that last bit of script that just exports the PATH variable, I swapped it out with the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;echo &amp;quot;
export PATH=/home/terraform_0_6_14:$PATH
&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, the odd spacing and new lines are important, because that will append the export to PATH in a way that provides space before and below the line. It just leaves the ~/.bash_profile file looking a little cleaner.&lt;/p&gt;
&lt;p&gt;Once you’ve added it to your ~/.bash_profile, remember to either restart the terminal or source the file to get the PATH variable updated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next thing we’ll need for Terraform use with GCE is the &lt;em&gt;account.json&lt;/em&gt; file. This is the file that a service account sets up to secure our connection between GCE and Terraform.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/user_accountjson_001.png&quot; alt=&quot;Account JSON Permissions&quot;&gt;&lt;/p&gt;
&lt;p&gt;Navigate to the Permissions section of the GCE interface and add a service account. When you click to create a service account you’ll be prompted with the following.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/user_accountjson_002.png&quot; alt=&quot;Furnish Account JSON&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here check the “Furnish a new private key” and click on the JSON for the key type. Then create create. This will create the service account and the key will download locally. The key is not named account.json, but the file downloaded is what to use as the account.json file, it just needs renamed.&lt;/p&gt;
&lt;p&gt;Now we’re ready to get into actually putting together an infrastructure project. Let’s start with a basic setup. First I need the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;account.json&lt;/li&gt;
&lt;li&gt;theterraformfile.tf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are needed files and will get a terraform workflow started, but I break them out a bit more. Terraform files after all are all collected and then processed, so the configuration doesn’t have to all be in a single file.&lt;/p&gt;
&lt;p&gt;What I have been doing lately, is take the terraform file and break it out accordingly. For the connection I create a connection.tf file, for configuration around instances I create an instances.tf file, for network addresses (static IPs) that goes in an addresses.tf file. If any of those files get to big within a project I break those out further like instance-instancename1.tf and instance-instancename2.tf.&lt;/p&gt;
&lt;p&gt;With that practice applied, I end up with a project with the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;account.json&lt;/li&gt;
&lt;li&gt;instances.tf&lt;/li&gt;
&lt;li&gt;addresses.tf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then run git init and add two more files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;.gitignore&lt;/li&gt;
&lt;li&gt;README.md&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These have no relevance to the actual Terraform files, but they’re standard practice and come in very helpful once the project starts to grow. You’ll want a README.md for notes and documentation and you’ll definitely want to keep trash out of the project with the .gitignore, so even though they’re not required right now, if you’re following along add the files.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;https://github.com/Adron/starting-with-gce/blob/master/README.md&quot;&gt;README.md&lt;/a&gt;, of course, we write our documentation! So anyway, it’ll be there in the &lt;a href=&quot;https://github.com/Adron/starting-with-gce&quot;&gt;repo&lt;/a&gt; I’ve created for this blog entry here.&lt;/p&gt;
&lt;p&gt;In the .gitignore file add the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;.DS_Store
account.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the connection.tf file I added the following connection information. The ${file(“../secrets/account.json”)} configuration interpolates the path of the file based on where the project is located and pulls in the appropriate values for GCE.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# Configure the Google Cloud provider
provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;account.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;that-big-universe&amp;quot;
  region      = &amp;quot;us-central1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that in place, I added this to the instances.tf file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# Create a new instance
resource &amp;quot;google_compute_instance&amp;quot; &amp;quot;flirpderp&amp;quot; {
    name = &amp;quot;flirpderp&amp;quot;
    machine_type = &amp;quot;f1-micro&amp;quot;

    zone = &amp;quot;us-central1-b&amp;quot;

    disk {
        image = &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
    }

    network_interface {
        network = &amp;quot;default&amp;quot;
        access_config {}
    }

    service_account {
        scopes = [&amp;quot;userinfo-email&amp;quot;, &amp;quot;compute-ro&amp;quot;, &amp;quot;storage-ro&amp;quot;]
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the machine_type and disk image above I just used the following gcloud commands.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this first build, I just wanted to get a basic template with a small (and by association super cheap) instance. For this I went with &lt;em&gt;f1-micro&lt;/em&gt;. For the disk, I used the base disk image load of the &lt;em&gt;ubuntu-1404-trusty-v20160406&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;All configuration set, I opened up a bash terminal and typed in the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform plan
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command then displayed the following result.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Refreshing Terraform state prior to plan...

The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Note: You didn&amp;#39;t specify an &amp;quot;-out&amp;quot; parameter to save this plan, so when
&amp;quot;apply&amp;quot; is called, Terraform can&amp;#39;t guarantee this is what will execute.

+ google_compute_instance.flirpderp
    can_ip_forward:                                      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;0&amp;quot;
    disk.#:                                              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    disk.0.auto_delete:                                  &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    disk.0.image:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
    machine_type:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;f1-micro&amp;quot;
    metadata_fingerprint:                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    name:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;flirpderp&amp;quot;
    network_interface.#:                                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    network_interface.0.access_config.#:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    network_interface.0.access_config.0.assigned_nat_ip: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.address:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.name:                            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.network:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;default&amp;quot;
    self_link:                                           &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    service_account.#:                                   &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    service_account.0.email:                             &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    service_account.0.scopes.#:                          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;3&amp;quot;
    service_account.0.scopes.1632638332:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;
    service_account.0.scopes.2428168921:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/userinfo.email&amp;quot;
    service_account.0.scopes.2862113455:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/compute.readonly&amp;quot;
    tags_fingerprint:                                    &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    zone:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;us-central1-b&amp;quot;

Plan: 1 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s walk through this result to get an idea of what just happened. Terraform has taken all of the Terraform files, which currently is only one file with actual configuration in it, and processed them to create a plan of changes. At the very bottom of the results the line “Plan: 1 to add, 0 to change, 0 to destroy.” simple shows what will occur if I were to apply these changes. Many of the values are also set as which simply means that when processed they’ll be calculated and set. Otherwise most of the other values are simply the settings I’ve put in via the actual Terraform configuration files.&lt;/p&gt;
&lt;p&gt;Now I applied the configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform apply
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of this command will display as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;google_compute_instance.flirpderp: Creating...
  can_ip_forward:                                      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;0&amp;quot;
  disk.#:                                              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  disk.0.auto_delete:                                  &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  disk.0.image:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
  machine_type:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;f1-micro&amp;quot;
  metadata_fingerprint:                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  name:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;flirpderp&amp;quot;
  network_interface.#:                                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  network_interface.0.access_config.#:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  network_interface.0.access_config.0.assigned_nat_ip: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.address:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.name:                            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.network:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;default&amp;quot;
  self_link:                                           &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  service_account.#:                                   &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  service_account.0.email:                             &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  service_account.0.scopes.#:                          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;3&amp;quot;
  service_account.0.scopes.1632638332:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;
  service_account.0.scopes.2428168921:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/userinfo.email&amp;quot;
  service_account.0.scopes.2862113455:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/compute.readonly&amp;quot;
  tags_fingerprint:                                    &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  zone:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;us-central1-b&amp;quot;
google_compute_instance.flirpderp: Creation complete

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I logged in at this point to verify the creation of the instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/flirpderp.png&quot; alt=&quot;Google Cloud Interface&quot;&gt;&lt;/p&gt;
&lt;p&gt;In the interface the instance (or instances if I have multiple) shows up in a list underneath the fancy CPU utilization chart.&lt;/p&gt;
&lt;h3 id=&quot;cleanup&quot;&gt;Cleanup&lt;/h3&gt;
&lt;p&gt;Since I don’t actually want this instance to stay live currently, to destroy the instance I can use the terraform destroy command. If there were other instances in this set of Terraform configuraiton files, it would also destroy those too. Destroy, suffice to say is something that is very destructive and should be used carefully. For this example I’m going to destroy this instance now, but since I have the configuration I’ll add a little bit more to it and recreate it shortly.&lt;/p&gt;
&lt;p&gt;I issue this command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform destroy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This displays…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Do you really want to destroy?
  Terraform will delete all your managed infrastructure.
  There is no undo. Only &amp;#39;yes&amp;#39; will be accepted to confirm.

  Enter a value: yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I confirm by typing ‘yes’ and then the following result of this acction is returned.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;google_compute_instance.flirpderp: Refreshing state... (ID: flirpderp)
google_compute_instance.flirpderp: Destroying...
google_compute_instance.flirpderp: Destruction complete

Apply complete! Resources: 0 added, 0 changed, 1 destroyed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, it’s pretty cool that I can build a single instance, but that’s of extremely limited use if I can’t get it deployed out into GCE in a usable state. The most common ways I’d want to wrap up configuration and installation of software on an instance is to issue some bash commands to the instance. Well, Terraform has ways that exactly that can be done. I’ll cover that in the follow up to this article.&lt;/p&gt;
&lt;h3 id=&quot;references-&quot;&gt;References:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/starting-with-gce/tree/blog-entry-01&quot;&gt;The Github Repository branch for this blog entry.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Startup Things - How Ya Linux Series - 0000</title>
      <link>http://adron.github.io/articles/how-ya-linux-0000-Startup-things/</link>
      <pubDate>Sat, 11 Jun 2016 15:35:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/how-ya-linux-0000-Startup-things/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/how-ya-linux-0000-Startup-things/penguinbash.jpg&quot; alt=&quot;Penguin Bash&quot;&gt;
&lt;/div&gt;

&lt;p&gt;When Linux starts up (or most Unix variants or OS-X for that matter, which is after all a kind of Unix variant) there are particular scrips that execute. The key two are ~/.bash_profile and ~./bashrc. When you log in the ~/.bash_profile executes and when you startup a shell then the ~/.bashrc executes.&lt;/p&gt;
&lt;p&gt;These two files are standard executable script files, so any bash will do. For instance, some of the bash script I end up in my ~/.bash_profile includes a git prompt, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if [ -f &amp;quot;$(brew --prefix)/opt/bash-git-prompt/share/gitprompt.sh&amp;quot; ]; then
    source &amp;quot;$(brew --prefix)/opt/bash-git-prompt/share/gitprompt.sh&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Another few lines of code actually load my nvm, which is my Node.js Version Manager.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export NVM_DIR=&amp;quot;/Users/axh6454/.nvm&amp;quot;
[ -s &amp;quot;$NVM_DIR/nvm.sh&amp;quot; ] &amp;amp;&amp;amp; . &amp;quot;$NVM_DIR/nvm.sh&amp;quot;  # This loads nvm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also have a few functions I’ve created, that load and are ready for my use at  any location I open the terminal at.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker() { if [ $1 ]; then
    docker-machine start $1
    docker-machine env $1
    eval $(docker-machine env $1)
    docker ps -a
fi };

cleandocker() {
    # Wipe out the images and containers.
    docker rm $(docker ps -a -q)
    docker rmi $(docker images -q)
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first function executes simply by entering &lt;code&gt;gimme docker nameOfDockerVirtualMachineImage&lt;/code&gt;. It then checks for the virtual machine image parameter (the $1) and then executes various docker-machine commands against that image. Then ends with the evaluation and execution of the docker machine terminal connection.&lt;/p&gt;
&lt;p&gt;The second function deletes my docker containers and then deletes my images. This way I can start fresh without deleting an entire docker virtual machine (sometimes the later may actually be easier). It’s a quick way to start fresh with docker images and containers when working through a lot of minor changes.&lt;/p&gt;
&lt;p&gt;The last thing I’ll cover real quick that is commonly located in these startup scripts are some environment variables being set. For instance, I use Terraform to build out infrastructure. For that, sometimes I setup some Terraform variables, that are built to work specifically when prefaced with TF&lt;em&gt;VAR&lt;/em&gt;. So my variables look something like this when set in script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export TF_VAR_username=&amp;quot;root&amp;quot;
export TF_VAR_password=&amp;quot;someSecretPassword&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So that’s some examples and the basic gist of things you might see, and what you might want to run with your ~/.bash_profile or ~/.bashrc files. Happy bash hacking!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Short Story of Node PDX, and Node PDX 2016</title>
      <link>http://adron.github.io/articles/node-pdx-2016/</link>
      <pubDate>Wed, 08 Jun 2016 14:30:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016/</guid>
      <author></author>
      <description>&lt;p&gt;Some of you may know the story, but I’ll tell it again for those that don’t. In 2012 Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37&quot;&gt;@thoward37&lt;/a&gt;) and I were sitting at the Side Door hacking on some project code. We started talking about where and what was up with the Node.js project, community, and asking ourselves what the future of that was. You see, we’d toyed about with the technology here and there but we hadn’t really done anything with it.&lt;/p&gt;
&lt;p&gt;We continued our coding, enjoying a tasty locally brewed beer, frothy and good. After a reasonable amount of said tasty beer, we started discussing a way to get up to speed faster on Node.js. In our infinitely wise and slightly intoxicated minds we both thought, “Hey, let’s throw a conference!”. We immediately started discussing this idea and a number of decisions were made…&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;inception-by-conversation&quot;&gt;Inception by Conversation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Oh man, we should do exactly that, let’s have a conference! It’ll be super easy to ramp up if we just get a bunch of smart Node.js people together.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yeah, and it’d be a total blast. There are a number of smart people working in this space.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Let’s!”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yes.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Cheers!”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Cheers!”&lt;/p&gt;
&lt;p&gt;Beer drinking. So there we sat, and we began, the dilligent decision making at what was obviously the perfect time to make decisions about a conference!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Have you ever organized anything like this before?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Naw. You?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Ummm, nope.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “What seems like a reasonable timespan to get this put together?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; … sip, sip, sip, big drink. “Hmmm, I don’t know, 4 or 5 weeks, maybe 4?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Meh, sounds good.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Cool, so we’ll have it in about 5 weeks.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yup.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “How many days, speakers and such?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Troy&lt;/strong&gt;&lt;/strong&gt; “Let’s go for two days and we’ll just do one track.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Done and done.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;(Ok, it might have been slightly different, but this is the gist of it.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In that moment of infinite wisdom we began the journey to create and organize our first conference. It thoroughly kicked our ass but was super fun.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/nodepdx-logo-2012.png&quot; alt=&quot;Node PDX 2012&quot;&gt;
&lt;/div&gt;

&lt;p&gt;We also learned some very key things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Organizing an inclusive conference is both easy and ridiculously stressful and difficult.&lt;/li&gt;
&lt;li&gt;Organizing a conference with 4-5 weeks before the date is batshit insane.&lt;/li&gt;
&lt;li&gt;Making decisions about organizing something one has never organized is probably not the best thing to do after coding for hours on end and maybe one to many beers.&lt;/li&gt;
&lt;li&gt;Community focused and grassroots organized conferences are really fun and arguably more educational than that corporate shit shill.&lt;/li&gt;
&lt;li&gt;Organizing volunteers and speakers is not actually easy at all.&lt;/li&gt;
&lt;li&gt;Non-profit incoroporation, actually any type of corporation is very poorly organized for this type of event. Either way, it adds a financial burden just for undertaking such an enterprise.&lt;/li&gt;
&lt;li&gt;One can actually learn a lot at a conference, but the people contacts are vastly more important.&lt;/li&gt;
&lt;li&gt;One can actually not learn a whole lot if actually organizing the conference, yet this first year we managed to do both learning and connecting with many of the great attendees of the conference.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/NodePDX-2012-site.png&quot; alt=&quot;Node PDX 2012 Site&quot;&gt;
&lt;/div&gt;

&lt;p&gt;So this basically summarizes year one of Node PDX. That was &lt;a href=&quot;http://2012.nodepdx.org/&quot;&gt;Node PDX 2012&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;node-pdx-2013&quot;&gt;Node PDX 2013&lt;/h2&gt;
&lt;p&gt;Node PDX 2013 started off a bit differently. We gave ourselves more runway to work with. I believe initially it was at least several months. We also gave ourselves plenty of resources to work with and incorporated anyway, which still is a complete discouragement from actually doing these things.&lt;/p&gt;
&lt;p&gt;Troy also did effectively all of the graphic design, which I might add, turned out pretty rad! Check it out for a trip down memory lane at the &lt;a href=&quot;http://2013.nodepdx.org/&quot;&gt;archive site&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/NodePDX-2013.png&quot; alt=&quot;Node PDX 2013&quot;&gt;
&lt;/div&gt;

&lt;p&gt;We got the ball rolling and Node PDX 2013 was a huge hit. We had involvement from all sorts of sponsors from great companies like &lt;a href=&quot;https://newrelic.com/&quot;&gt;New Relic&lt;/a&gt;, &lt;a href=&quot;https://www.urbanairship.com/&quot;&gt;Urban Airship&lt;/a&gt;, &lt;a href=&quot;https://liftsecurity.io/&quot;&gt;^lift&lt;/a&gt;, &lt;a href=&quot;https://www.mozilla.org/en-US/&quot;&gt;Mozilla&lt;/a&gt;, &lt;a href=&quot;https://www.jivesoftware.com/&quot;&gt;Jive&lt;/a&gt;, &lt;a href=&quot;http://www.janrain.com/&quot;&gt;Janrain&lt;/a&gt;, &lt;a href=&quot;http://www.walmartlabs.com/&quot;&gt;Walmart Labs&lt;/a&gt;, &lt;a href=&quot;http://www.piepdx.com/&quot;&gt;PIE PDX&lt;/a&gt;, &lt;a href=&quot;http://basho.com/&quot;&gt;Basho&lt;/a&gt;, &lt;a href=&quot;https://www.stickermule.com/&quot;&gt;Sticker Mule&lt;/a&gt;, &lt;a href=&quot;http://siliconflorist.com/&quot;&gt;Silicon Florist&lt;/a&gt;, and &lt;a href=&quot;http://devion.com/&quot;&gt;Devion&lt;/a&gt;. We also had a great speaker line up, had excellent local food, great freshly brewed &amp;amp; roasted coffee, and lots more. I even got hit in the head with a quad-copter! It was absolutely a superb time. &lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/burnout.jpg&quot; alt=&quot;Conference Burnout&quot;&gt;
&lt;/div&gt;

&lt;h2 id=&quot;conference-burnout&quot;&gt;Conference Burnout&lt;/h2&gt;
&lt;p&gt;After 2013 Troy and I had a case of the burnouts kick us. He went the route of just organizing more conferences, I however went the route of not organizing any conferences, or much of anything for a while.&lt;/p&gt;
&lt;p&gt;This however lasted over a year for me, I started working on some projects, co-founded a startup, worked to raise capital with the team, built a product, ran out of money, spent most of 2015 not working, produced some training material and a lot more. Basically I was working on anything that involved not working on conference (or meetup) organizing.&lt;/p&gt;
&lt;h2 id=&quot;2016-hits-and-energy-returns&quot;&gt;2016 Hits and Energy Returns&lt;/h2&gt;
&lt;p&gt;At this point I’d had a significant amount of time off. I’d also managed to spend time in Europe, recover from my doldrums, get married to a most amazing an awesome person, and felt maybe I’d dive into some conference organizing again. I’d missed Node PDX &amp;amp; the comraderie and learning it brought. With that deduction I struck up another conversation to see if Troy was interested in organizing another Node PDX. I think it went something like this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Hey Troy, wanna run another Node PDX?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Maybe.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Let’s grab some coffee and discuss.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Alright. Should we meet at…” at this point we spend 45 minutes discussing where we should meet for coffee.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We then departed our respective locations to meet at a coffee shop somewhere in Portland. We then met and started talking about, as we often do, everything except what we were going to talk about. Then, as if spuriously interupted,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Hey Troy, wanna run another Node PDX?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Ok.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So here we are now, with just 11 days to go before another Node PDX. We’re rounding up and finalizing the last steps of the effort right now. The speakers have been notified, we’ve gotten confirmations, and we’re getting the wheels on the bikes ready, the beer cooled off, the food prepared (ok, actually that’ll be prepared later), and psyched for the upcoming event. With that said, we’re definitely back in the groove and looking forward to this year’s event! We hope to see you there.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://nodepdx.org/#tickets&quot;&gt;Join us at Node PDX&lt;/a&gt;, enjoy a &lt;a href=&quot;http://nodepdx.org/lagniappe.html#bikes&quot;&gt;bike ride&lt;/a&gt; to see parts of Portland, and if you’re coming down from Seattle be sure to enjoy the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#geektrain&quot;&gt;$15 buck ride&lt;/a&gt; via the &lt;a href=&quot;http://www.amtrakcascades.com/&quot;&gt;Amtrak Cascades&lt;/a&gt; to Portland for the conference.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>How to Build a Bike Shed by David Manning &amp; Adam Ulvi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/</link>
      <pubDate>Tue, 07 Jun 2016 19:20:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/davidadam.jpg&quot; alt=&quot;David Manning &amp;amp; Team&quot;&gt;
&lt;/div&gt;

&lt;p&gt;This is a very Portland, very unique to Node PDX talk, by Adam and David who work at ZHealth Documentation and have opinions about things.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Nuff’ said eh!&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Despite having no formal construction experience, Adam and David have been tasked with designing a new bike shed outside of the Olympic Mills Commerce Center. They have spent long hours in extensive research, and are excited to share their results with the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Attendees will receive plans and a Starter Kit of building materials.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For more important information about what a bike is, what a shed is, and how these two things combined make bike sheds, check out this useful links.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bikes: &lt;a href=&quot;https://en.wikipedia.org/wiki/Bicycle&quot;&gt;https://en.wikipedia.org/wiki/Bicycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sheds: &lt;a href=&quot;https://en.wikipedia.org/wiki/Shed&quot;&gt;https://en.wikipedia.org/wiki/Shed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bike Sheds: &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_triviality&quot;&gt;https://en.wikipedia.org/wiki/Shed#Specific-use_sheds&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Get JavaScript Running on a $2 WiFi-Enabled Device by Andrew Chalkley</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-andrew-chalkley/</link>
      <pubDate>Tue, 07 Jun 2016 11:20:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-andrew-chalkley/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-andrew-chalkley/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-andrew-chalkley/andrew.jpg&quot; alt=&quot;Andrew Chalkley&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Andrew Chalkley is a full-time teacher at online education provider Treehouse. He’s a polyglot programmer with a passion for hardware. Andrew’s posts on the hardware platform Arduino have been featured in Hacker Monthly and used in higher educational institutions around the world. He’s also lectured at University on JavaScript and the Internet of Things.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ESP8266 is a very popular Internet of Things device, because of it’s price and availability. You can program it with Arduino, Python and even JavaScript. Using JavaScript on a small device doesn’t have to be difficult. Andrew will show you the easiest way to install JavaScript on am Internet of Things device and how to run your JavaScript applications on it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://forefront.io&quot;&gt;http://forefront.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Company: &lt;a href=&quot;http://teamtreehouse.com&quot;&gt;http://teamtreehouse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/chalkers&quot;&gt;http://github.com/chalkers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Flasher.js: &lt;a href=&quot;http://github.com/thingssdk/flasher.js&quot;&gt;http://github.com/thingssdk/flasher.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Demystifying TypeScript Decorators by James Churchill</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-james-churchill/</link>
      <pubDate>Sun, 05 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-james-churchill/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-james-churchill/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-james-churchill/james-churchill-nyc.jpg&quot; alt=&quot;James Churchill&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Portlander James has worked extensively with a variety of technologies, including ASP.NET MVC, SQL Server, JavaScript, TypeScript, Knockout.js, and AngularJS. James, a self-confessed geek, enjoys talking about programming and learning new technologies. He recently joined the Treehouse team as a teacher and is excited to have the opportunity to help beginners become developers.&lt;/p&gt;
&lt;p&gt;James also enjoys participating in the greater Cascadian Developer Community, presenting talks in Portland, Seattle, Salt Lake City, Boise, Eugene, Salem, and Hood River. Last April, James started and co-organized the Portland TypeScript Meetup (&lt;a href=&quot;http://typescriptpdx.com/&quot;&gt;http://typescriptpdx.com/&lt;/a&gt; which is an awesome meetup, come check it out sometime!).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When he is not working, he can be found skiing with his wife and kids, remodeling the house, playing music with his band, or hanging out in the yard with his chickens.&lt;/p&gt;
&lt;p&gt;In “Demystifying TypeScript Decorators” will show us TypeScript decorators, based on the ES2016 decorator proposal and introduced as part of TypeScript 1.5, provide developers with a way to modify a JavaScript class, property, method, or method parameter using a convenient declarative syntax. We’ll start this session by creating our own decorator, to see firsthand how they work. Then, we’ll take a look at how decorators can be used in a variety of settings.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://smashdev.com&quot;&gt;http://smashdev.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/smashdevcode&quot;&gt;http://github.com/smashdevcode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;http://twitter.com/SmashDev&quot;&gt;http://twitter.com/SmashDev&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>How to Electron by Blaine Schmeisser</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-blaine-schmeisser/</link>
      <pubDate>Sun, 05 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-blaine-schmeisser/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-blaine-schmeisser/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-blaine-schmeisser/blainesch.jpg&quot; alt=&quot;Blaine Schmeisser&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I’m happy to introduce Blaine Schmeisser. He’s a recent Portland transplant currently working as a Senior Software Engineer at New Relic. He has a passion for building and shipping software and an advocate for pair programming. Outside of tech, Blaine spends his free time with his dog and maintains a simplistic, eco-friendly lifestyle.&lt;/p&gt;
&lt;p&gt;Blaine’s “How to Electron” answers questions you have about building user interface applications with JavaScript. Have you ever wanted to build desktop apps with web technology you already know? If you’ve never heard of Electron or just want to learn more about it, this talk will cover what Electron is and how to utilize it to create powerful tools like Atom and Slack. You will learn the history of Electron, how to get started, the trade-offs of picking various boiler plates, and the unique Electron specific APIs that are vital to being a Electron developer.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;https://github.com/blainesch&quot;&gt;https://github.com/blainesch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;https://twitter.com/blainesch&quot;&gt;https://twitter.com/blainesch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://blainesch.com&quot;&gt;http://blainesch.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>The SAM Pattern - a distributed system view of Front-End architectures by Jean-Jacques Dubray</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jean-jacques-dubray/</link>
      <pubDate>Sat, 04 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jean-jacques-dubray/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jean-jacques-dubray/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jean-jacques-dubray/jj-sized.png&quot; alt=&quot;Jean-Jacques Dubray&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jean-Jacques Dubray is the founder of &lt;a href=&quot;http://xgen.io&quot;&gt;xgen.io&lt;/a&gt; and &lt;a href=&quot;http://www.gliiph.com&quot;&gt;gliiph&lt;/a&gt;. He has been building Service Oriented Architectures,
and API platforms for the last 15 years. He is a former member of the research staff at HRL and earned his Ph.D. from
the University of Provence (Luminy campus), home of the Prolog language. He is the inventor of the &lt;a href=&quot;http://www.xgenio.com/bolt-introduction.pdf&quot;&gt;BOLT methodology&lt;/a&gt; and the SAM pattern.&lt;/p&gt;
&lt;p&gt;In his talk Jean-Jacques Dubray presents that Web Applications are rapidly becoming sophisticated distributed systems. When you look at a Facebook page or a Netflix catalog,
the number of components interacting with each other requires complex synchronization and state management capabilities, reaching
the limits of the MVC pattern.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the last couple of years, several reactive architectures have started to get some interest (React, Cycle.js, ELM) without
generating significant traction (compared to established frameworks like Angular), while struggling to position effects in their
programming model. A new reactive, functional pattern, the State-Action-Model pattern (SAM) was introduced in early 2016 on the
foundation of TLA+ semantics.&lt;/p&gt;
&lt;p&gt;The pattern, which is unapologetically driven by simplicity, promotes a clear delineation between the business logic and the view
and challenges the complexity of frameworks like Google’s Angular or Facebook’s React/Redux.&lt;/p&gt;
&lt;p&gt;SAM’s unidirectional flow is also challenging interactive patterns like BFF (Back-End for Front-End) or the Vertical Slice Pattern
which suggest creating view-specific APIs, per platform, app, versions of an app…&lt;/p&gt;
&lt;p&gt;We’ll start by reviewing some of the key challenges of modern UX and Front-End Architectures. We will then present the
key concepts of SAM and walk the audience through some node.js code samples (including server-side TimeTravel).&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Modern Javascript Frameworks - Introduction to Ember.JS and Ember-CLI by Suchita Doshi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-suchita-doshi/</link>
      <pubDate>Sat, 04 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-suchita-doshi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-suchita-doshi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-suchita-doshi/suchita-doshi.jpg&quot; alt=&quot;Suchita Doshi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Suchita is UI Lead for the analytics module of Yahoo Admanager Plus team and Core member of Emberjs group @Yahoo, Speaker at Women Who code organization (Introduction To Emberjs/Ember CLI), Conducted Webinar for the TenXList members on EmberJS. She’s passionate about improving developers ergonomics and a hardcore “cricket” fan.&lt;/p&gt;
&lt;p&gt;In other Suchita news, she’s opening bats-woman for the Bay Area Cricket Association team! 😀&lt;/p&gt;
&lt;p&gt;Suchita describes her talk as “There will never be a “one size fits all” approach to web development. If you want your application to be minimally interactive, then server side rendered HTML would be the way to go, else, if it were a more interactive application, then client side framework would benefit you.
Why not use just JQuery instead of adopting these Modern Javascript Frameworks? Think about it! If your application has interactivity on the lighter side, then JQuery would work well, but as soon as you introduce more states in your application, it would then become messier and heavier on the DOM. You would need to use the ‘data-‘ attributes to store the data in your DOM and also remember how to map them with the triggered events.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here is where client side frameworks come to the rescue. I have worked on several client side frameworks like Backbone.js, Ember.js. Few of the many features I love about Ember.js are the two-way data binding, Computed Properties, the run loop, convention over configuration nature, ease of handling routing and many more.
In this talk I would be covering the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to Emberjs and why Ember&lt;/li&gt;
&lt;li&gt;How Ember js makes a difference&lt;/li&gt;
&lt;li&gt;Ember convention over configuration nature&lt;/li&gt;
&lt;li&gt;Introduction to Ember routes, components and templates&lt;/li&gt;
&lt;li&gt;Introduction to Ember CLI&lt;/li&gt;
&lt;li&gt;Computed Properties&lt;/li&gt;
&lt;li&gt;Live Demo on how it’s really intuitive in a couple of non-trivial scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So basically my goal is to attract more developers to adapt modern javascript frameworks and make a difference in the way complex apps are built.”&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WebSockets Bring Light at the End of the Tunnel by Joel Lord</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-joel-lord/</link>
      <pubDate>Fri, 03 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-joel-lord/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-joel-lord/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-joel-lord/joel-lord.jpg&quot; alt=&quot;Joel Lord&quot;&gt;
&lt;/div&gt;

&lt;p&gt;As a Development Manager, Joel’s motivation and proven technical prowess makes him a key member of Spiria’s software development team. With a degree in computational astrophysics, his interests eventually made their way to software and Web design. Today, his knowledge of JavaScript lets him to support a variety of projects on both the front end and back end. As we move into the age of the Internet of Things, Joel is ready with his passion for programming node bots and experimenting with gadgets.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Joel is going to speak on Web Sockets and tunnels of light… or to describe it more specifically more and more, people seem to be obsessed with real-time data.  But what does real-time mean in the world of REST servers and one-way communication?  Most modern web applications are now either displaying a snapshot of data at a given time or use a polling mechanism to update series of data at a given interval.
In this talk, you will learn about the power of WebSockets and how they can (and should!) be used in your modern web applications. In these 30 minutes, I will go through the process of building a Node server that can push data to multiple clients in real-time.  You will see how this can be easy using the socket.io library.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>MMOWAM - Build Server-less Games with a DSN by Josh Marinacci</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-josh-marinacci/</link>
      <pubDate>Fri, 03 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-josh-marinacci/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-josh-marinacci/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-josh-marinacci/josh-marinacci.jpg&quot; alt=&quot;Josh Marinacci&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Josh is an O’Reilly author, developer advocate, and recovering engineer. He is
currently head of the developer evangelism team at PubNub. Previously he worked
as a UI researcher at Nokia, and a developer advocate at Palm and Sun. He is
passionate about user interfaces and education. Josh lives in sunny Eugene,
Oregon.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Josh will be talking about building a multiplayer casual game for fun. Well, it’s fun until you have to write a server
component to run it. Now you have to implement game matching, keeping clients in
sync, in game chat, score tracking and more. In this Josh will show you how to
use a Data Stream Network (DSN) write a game without any server at all. The
network itself can connect users, load clients, and keep everything in sync
without having to learn distributed computing programming. Josh will build and
play a MMOWAM (Massively Multiplayer Online Whack-A-Mole) game to show how easy
it can be.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;game MMOWAM (whack-a-mole)&lt;/li&gt;
&lt;li&gt;show mini version of each player on dashboard&lt;/li&gt;
&lt;li&gt;show current score / level&lt;/li&gt;
&lt;li&gt;show how much is left&lt;/li&gt;
&lt;li&gt;random number syncing to ensure everyone has the same board&lt;/li&gt;
&lt;li&gt;use a random channel w/ tiny UID to let anyone join&lt;/li&gt;
&lt;li&gt;show number of players&lt;/li&gt;
&lt;li&gt;start when 4 players in? one player hit’s start? let all player see total count as well and status of the other players&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>The Web Platform is the Universal Instrument by Ben Michel</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-ben-michel/</link>
      <pubDate>Thu, 02 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-ben-michel/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-ben-michel/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-ben-michel/benmichel.jpg&quot; alt=&quot;Ben Michel&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Ben Michel has a pretty epic talk scheduled for Node PDX… if you don’t know Ben he’s a Musician–Developer. He composes &amp;amp; performs live soundtracks and cares a lot about community music.&lt;/p&gt;
&lt;p&gt;The talk he has planned for you all is described as, “Music as an idea, expression, commercial endeavor, and communal art is in its most volatile state since the European Renaissance. We’ve moved from the public adoption of recording technology, through the massive rise and fall of the recording industry, to a new age that was first seeded at Bell Labs during the Computer Science era.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Max Mathews encouraged a generation of computer musicians by declaring the Nyquist-Shannon “sampling theorem shows that there are really no limits to the sounds you can make…the computer is a universal musical instrument.”&lt;/p&gt;
&lt;p&gt;Now with a fuller understanding of what Mathews was implying, we can take it a step further and say that the Browser is the universal musical instrument. It’s the most accessible, cross-compatible runtime yet–and with the growth of Web Audio and Web MIDI standardization, we’re on the verge of a new renaissance in musical collaboration and interaction.&lt;/p&gt;
&lt;p&gt;Unfortunately, the promotion of individualism in our popular culture, and the divide between developers and working artists has kept us from realizing the potential of building useful tools for distributed music collaboration, even in the web platform.&lt;/p&gt;
&lt;p&gt;Still, I can see a world coming where community music and recorded works are not identified by regional boundaries, but distributed data regions and organic peer to peer networks. If the development of Web Audio and it’s supporting standards stabilize, music collaboration and exposition could be made available to everyone with no hinderances from age, class, or personal ability.&lt;/p&gt;
&lt;p&gt;The WebSound project is my iterative solution to this problem through long-term community engagement, and Audio/MIDI tool versioning.&lt;/p&gt;
&lt;p&gt;Our first endeavor is to build a few useful live performance tools enabling remote collaboration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Real-time Web MIDI performances streamed to a live-event, enabling the performer to lead songs or compositions remotely. Achieved through an optimized VPN and P2P WebRTC DataChannels.&lt;/li&gt;
&lt;li&gt;Communally performed live music making with MIDI controlled WebAudio and WebSocket broadcasting.&lt;/li&gt;
&lt;li&gt;Audience interaction with the exposed parameters of a live band’s instrumentation–via broadcast methods and microcontroller installations.”&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>I Play the JavaScript by Matt McKegg</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-matt-mckegg/</link>
      <pubDate>Thu, 02 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-matt-mckegg/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-matt-mckegg/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-matt-mckegg/mattmckegg.jpg&quot; alt=&quot;Matt McKegg&quot;&gt;
&lt;/div&gt;

&lt;p&gt;A JavaScript hacker and backyard musician and from Wellington, New Zealand. Lover of all things open and modular. I spend most of my time pressing buttons of various shapes, sizes and colours. Sometimes these buttons make sounds.&lt;/p&gt;
&lt;p&gt;Matt has been making music with computers for about 10 years, but once he tried to move from bedroom composing to live performance, he got incredibly frustrated at how hard it was to play computer music live. He decided to start working on his own live electronic performance software written in JavaScript that would let me play the way he wanted to play. 3 years later, it’s finally starting to become a reality.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here is one of the Matt’s recent performances, for your viewing pleasure. &lt;/p&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/L2BVDJWHdy0?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>The House Is Not On Fire - Building a home automation robot with Arduino, Raspberry Pi and Node.js by Artur Paikin</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-artur-paikin/</link>
      <pubDate>Wed, 01 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-artur-paikin/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-artur-paikin/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-artur-paikin/art-stida.jpg&quot; alt=&quot;Artur Paikin&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Artur describes himself as, “I’m a web developer and traveler. I write stories about my adventures in Russian and English on my site: &lt;a href=&quot;http://arturpaikin.com&quot;&gt;http://arturpaikin.com&lt;/a&gt; and run a small technology cooperative called &lt;a href=&quot;http://unebaguette.com&quot;&gt;Baguette&lt;/a&gt;, where I work on cool projects, currently building an ambitious next generation file uploader with &lt;a href=&quot;https://transloadit.com/&quot;&gt;Transloadit&lt;/a&gt;. I ride a &lt;a href=&quot;https://www.instagram.com/p/xC0qC2SSYb&quot;&gt;foldable bicycle&lt;/a&gt;, &lt;a href=&quot;http://unebaguette.com/web-course/&quot;&gt;teach&lt;/a&gt; web development and sometimes &lt;a href=&quot;https://www.instagram.com/p/4_6LO8ySVL/&quot;&gt;garden&lt;/a&gt; on the balcony.”&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Artur has built an open source home automation system called &lt;a href=&quot;https://github.com/arturi/kotihome&quot;&gt;Koti Home&lt;/a&gt; (Koti means home in Finnish language). It’s powered by an Arduino connected to Raspberry Pi, MQTT protocol for messaging, Node.js on the client and server, web sockets. You can interact with Koti robot via a React (like the cool kids do) control panel, Telegram Chat Bot and even your own voice.&lt;/p&gt;
&lt;p&gt;Arthur will talk about how he’s turned this project into reality — the tech he used and the challenges he faced. From a blinking LED to a voice controlled home automation robot.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Code First Docs How we Threw Out The Book &amp; Put Code First With Twilio Documentation by Jarod Reyes</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jarod-reyes/</link>
      <pubDate>Wed, 01 Jun 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jarod-reyes/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jarod-reyes/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jarod-reyes/jarodreyes.jpg&quot; alt=&quot;Jarod Reyes&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jarod is alarmingly disinterested in “how things are done”. He spent much of his grade school years disrupting class, running social experiments and singing love ballads to his teachers. Nowadays he can be found working with an exceptional team of developers at Twilio who are laser-focused on improving the landscape of developer documentation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Jarod describes Code First Docs as&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“My job at Twilio is straightforward, write documentation that doesn’t suck. This may seem fairly straightforward, but it turns out to be harder than an &lt;a href=&quot;https://c1.staticflickr.com/5/4048/4353601145_5c12467871_b.jpg&quot;&gt;Atari 2600 cartridge&lt;/a&gt;. For the last 30 years we have asked developers to do their jobs by equipping them with essentially giant books that we have adapted to the internet age by simply putting them on the web. At Twilio we weren’t satisfied with this traditional approach so we threw out the book and challenged some basic assumptions about creating documentation for developers.&lt;/p&gt;
&lt;p&gt;What is the journey of the modern developer? How does documentation fit into their flow? Are there ways to create documentation that enables developers to work smarter, as opposed to interrupting their day? We’ll discuss these questions and more as I share how we got to the realization that we needed a documentation revolution; this is the story of how we raised up code to be the supreme leader of documentation.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;https://twitter.com/jreyesdev&quot;&gt;@jreyesdev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;https://github.com/jarodreyes&quot;&gt;github.com/jarodreyes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Ops for Devs by Adam Ulvi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-adam-ulvi/</link>
      <pubDate>Tue, 31 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-adam-ulvi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-adam-ulvi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Node applications exist at the end of a long, somewhat magical series of tubes. What spells are being cast to make this all work? Let’s find out!&lt;/p&gt;
&lt;p&gt;In this talk Adam will explore the steps required to host a Node application on a small, affordable linux virtual private server (like a DigitalOcean droplet). This is not a tutorial, but rather, a walk-through of the configuration steps, background information the role each step plays, and the “why” behind the choices we are making.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-adam-ulvi/adamulvi.jpg&quot; alt=&quot;Adam Ulvi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;The reference implementation is taken from the current production gruntjs.com server.&lt;/p&gt;
&lt;p&gt;By following the request lifecyle, we will touch on basic tcp/ip networking, DNS configuration and history, node application development, nginx proxy configuration, and basic linux system configuration.&lt;/p&gt;
&lt;p&gt;At the end of the presentation developers should have a better understanding of the simple application’s infrastructure requirements, external dependencies, and targets of opportunity for future improvement.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/aulvi&quot;&gt;github.com/aulvi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IRC: s5fs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m looking forward to Adam’s talk, since I’ve been doing a lot of ops along with my dev work lately. Come check out Adam’s talk at &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;Node PDX&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Speakers and More For Node PDX 2016</title>
      <link>http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/</link>
      <pubDate>Tue, 24 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/</guid>
      <author></author>
      <description>&lt;p&gt;Spock and I are excited to announce our first set of speakers for &lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX 2016&lt;/a&gt;, which you’ve seen slowly coming out each day! I hope you’re ready and have your &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;tickets&lt;/a&gt; bought already. So far I’ve introduced &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-tomomi-imura/&quot;&gt;Tomomi&lt;/a&gt;, &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-jonny-oropeza/&quot;&gt;Jon&lt;/a&gt;, and &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-liz-abinante/&quot;&gt;Liz&lt;/a&gt;. Today I’ll introduce Adam Ulvi a bit later.&lt;/p&gt;
&lt;p&gt;We’ve also announced the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#geektrain&quot; target=&quot;_blank&quot;&gt;Geek Train for Node PDX&lt;/a&gt; and the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#bikes&quot; target=&quot;_blank&quot;&gt;Node PDX Bike Ride&lt;/a&gt;. A little &lt;a href=&quot;http://www.merriam-webster.com/dictionary/lagniappe&quot; target=&quot;_blank&quot;&gt;lagniappe&lt;/a&gt; if you will.  ;)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-tomomi-imura/&quot;&gt;Tomomi&lt;/a&gt;, &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-jonny-oropeza/&quot;&gt;Jon&lt;/a&gt;, and &lt;a href=&quot;http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/&quot;&gt;Liz&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/speakers-and-more-for-node-pdx-2016/spock-horns.jpg&quot; alt=&quot;Spock&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX 2016&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Geek Train&lt;/strong&gt; provides super cheap $15 train fare from anywhere north of Portland along the Amtrak Cascades route. I’ll actually meet the train in Seattle and ride from Seattle back to Portland for the conference. How that works is if you’re in Bellingham, Everett, Seattle, Tacoma, or wherever along the northern stretch can &lt;a href=&quot;https://ti.to/nodepdx/nodepdx-2016/with/gl6purbdlmo&quot; target=&quot;_blank&quot;&gt;purchase a ticket from us here&lt;/a&gt;. Once you purchase a ticket we’ll all have tickets for a specific train and will board along the line and join up in a specific car on the train (which we’ll have assigned day of the trip).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;bike ride&lt;/strong&gt; will make a loop through west and east of the Willamette River with a chance to check out all sorts of parts of the city. We’ll stop and try some of the wicked tasty locally roasted coffee and roll into one of the local taprooms that has dozens of local brews on tap. Between those tasty beverages I’ll point out some of the most excellent architecture, bridge design (ya like bridges eh?), neighborhoods, and other things that are characteristic of Portland. This will be a slow ride, so no need to have alley cat like reflexes and riding skills, just come and enjoy a chill, casual, and fun slow ride through Portland.&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;http://dotnetfringe.org/&quot; target=&quot;_blank&quot;&gt;.NET Fringe 2016&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;For .NET Fringe we’ll have the announcements for speakers coming very soon. We’ve taken a slightly different approach with a voting mechanism among organizers which we’ll be wrapping up and then will hurry up with the announcement, I know everybody needs to know ASAP!&lt;/p&gt;
&lt;p&gt;We’ll also be setting up a Geek Train &amp;amp; .NET Fringe bike ride too, we’ve just got to get everything posted. So keep an eye on the .NET Fringe site or &lt;a href=&quot;http://dotnetfringe.org/#signup&quot; target=&quot;_blank&quot;&gt;subscribe to updates&lt;/a&gt; and it’ll have updates popping up real soon.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A Foolish Quest Creating Knitting Patterns Using JavaScript by Liz Abinante</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-liz-abinante/</link>
      <pubDate>Mon, 23 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-liz-abinante/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-liz-abinante/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-liz-abinante/knitting.png&quot; class=&quot;image float-left&quot; /&gt;Liz Abinante lives in Portland, Oregon and works as a Senior Software Engineer at &lt;a href=&quot;https://newrelic.com/&quot;&gt;New Relic&lt;/a&gt;. She is infectiously enthusiastic about web development, teaching, learning, and feminism. She used to write JavaScript, then walked up to the wrong desk one day and now she writes some Java too. She enjoys speaking at conferences, knitting, sewing, and a hacking away on interesting problems. She swears she’s a lot more interesting than this bio makes her sound. She’s often been compared to cartoon characters due to her enormous personality and penchant for singing and/or dancing her way through life.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;liz.jpg&quot; class=&quot;image float-right&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Liz’s presentation is &lt;strong&gt;&lt;em&gt;A Foolish Quest: Creating Knitting Patterns Using JavaScript&lt;/em&gt;&lt;/strong&gt;. The talk will show taking something real-world and math-based, like knitting, and turning into a program is actually super easy (no one is surprised here). But! What happens when you combine that with best practices and expected conventions, along with industry-wide standards for design and presentation? Things get a lot more complicated than just crunching numbers, especially when your output will result in lots of manual hours for people creating a real object. This is the story of how Liz built a customizable knitting pattern generator in JavaScript (after she’d built it in Ruby first, of course), and the lessons learned when you try and do math for more than just math’s sake.&lt;/p&gt;
&lt;p&gt;Join the Node PDX Conference by &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;buying a ticket&lt;/a&gt; and come check out Liz’s presentation!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Isomorphic Business Logic (Or How to convince even the most die-hard C#/Java/Rails-on-the-Backend boss that you need to run a node server) Jonny Oropeza</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jonny-oropeza/</link>
      <pubDate>Wed, 18 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jonny-oropeza/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jonny-oropeza/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jonny-oropeza/jon.jpg&quot; alt=&quot;Jon Oropeza&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jon Oropeza is a full-stack engineer at HD Quote Center, a post-aquisition startup solving tricky ecommerce problems for their parent company, The Home Depot. Prior to that, he designed and developed software for the insurance industry with his partners at LifePro Financial Services, and also co-founded a deep learning / computer vision oriented startup called Tilt Video.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Jon will be presenting “&lt;strong&gt;Isomorphic Business Logic (Or How to convince even the most die-hard C#/Java/Rails-on-the-Backend boss that you need to run a node server)&lt;/strong&gt;“ which might just be the talk with the longest title of the conference!&lt;/p&gt;
&lt;p&gt;Business logic is all the tricky calculations, rules and transformations that never seem to be in the hot new framework’s example ToDo app. Lately I’ve been finding it’s also the key to convincing clients and bosses that they NEED to run a node layer, no matter what other backend techs they happen to be rocking. In this talk I’ll dive into why and how, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An intro to isomorphic javascript&lt;/li&gt;
&lt;li&gt;Challenges that arise from wanting a performant client and server-side verification&lt;/li&gt;
&lt;li&gt;How this gets exacerbated if you happen to be using a microservices-based backend&lt;/li&gt;
&lt;li&gt;Business logic - that pesky stuff that isn’t in the ToDo App&lt;/li&gt;
&lt;li&gt;Story time: A real world example of an app trying to apply the same logic in 2 different languages&lt;/li&gt;
&lt;li&gt;Isomorphic business logic to the rescue!&lt;/li&gt;
&lt;li&gt;The close… How all of this translates to ‘you need to run a node server’ :)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Come check out Jon’s talk at &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;Node PDX&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>From Software to Hardware How Do I Track My Cat with JavaScript Tomomi Imura</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-tomomi-imura/</link>
      <pubDate>Tue, 17 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-tomomi-imura/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-tomomi-imura/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I’m stoked to introduce Tomomi (&lt;a href=&quot;http://twitter.com/girlie_mac&quot;&gt;@girlie_mac&lt;/a&gt;). Tomomi is an avid open web &amp;amp; open technology advocate and creative technologist, who had been active in the mobile space for past 8+ years. Now she is working at PubNub in San Francisco. When she is not at work, she still geeks around and hacks some stuff like Amazon Dash to Rickroll people.&lt;/p&gt;
&lt;p&gt;Tomomi will be presenting “&lt;strong&gt;From Software to Hardware: How Do I Track My Cat with JavaScript&lt;/strong&gt;“.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;jamie-detected.png&quot; class=&quot;image float-right&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In the era of Internet of Things, connecting things to the mobile devices and web is becoming ubiquitous. You can control room light using your mobile phone. You can monitor your heart rate and weight on browser. JavaScript engineers like you already have skills to prototype ideas to build software, so why not hardware too?&lt;/p&gt;
&lt;p&gt;Tomomi, a front-end engineer with no background in electrical engineering, tells how she got started with hardware hacking with JavaScript, also talks about her recent fun project, &lt;a href=&quot;https://github.com/girliemac/RPi-KittyCam&quot;&gt;KittyCam&lt;/a&gt;, a Raspberry Pi camera with cat facial detection to see when her cat Jamie is eating while being away from home.&lt;/p&gt;
&lt;p&gt;If you’re interested in seeing Tomomi speak, get registered for &lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX before the tickets are gone&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Dropping the Ball, GSD, and Staying Productive</title>
      <link>http://adron.github.io/articles/dropping-the-ball-gsd-and-staying-productive/</link>
      <pubDate>Thu, 12 May 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/dropping-the-ball-gsd-and-staying-productive/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;em&gt;[&lt;strong&gt;NOTE:&lt;/strong&gt; This was actually written Thursday the 5th, things make more sense with that in mind.]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I sat here today, and several normal things happened that made me think of some seriously important things. The thoughts are presented very well by Scott Hanselman in a talk on &lt;em&gt;scaling oneself&lt;/em&gt;. He’s got a lot of gems in this presentation (links and video below), which he’s given a few times. In those presentations he makes a few very quotable statements that I had pop into my mind.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“It’s not what you read, it’s what you ignore.” - Scott Hanselman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The other really great gem is,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Sometimes &lt;em&gt;&lt;strong&gt;dropping the ball&lt;/strong&gt;&lt;/em&gt; is the right thing to do.”  - Scott Hanselman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Both of these are so true. It’s an important balancing act that one must perform to maintain a high level of productivity, especially in any complex work. Seriously, even digging a ditch can be complex, just look at Boston. They spent the years 1982 through 2002 to work on this project. They failed a dozen times on a dozen aspects of the project. It barely finished even a percentage of what was intended all for an initial estimate that was $2.8 Billion that ended up being $14.8 billion (only $8.08 Billion in 1982 dollars though :o ). In this situation, just to finish, the city had to actually drop the ball on a number of aspects of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Big_Dig&quot; target=&quot;_blank&quot;&gt;Big Dig&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But I digress, my problems I’m working on solutions for aren’t anywhere near the dilemma of the Big Dig. I do however find myself needing to chose between becoming swamped and living life, or dropping the ball. If I chose carefully I can still succeed even while dropping the ball on some things. Because sometimes it is indeed, the right thing to do.&lt;/p&gt;
&lt;p&gt;An alternative,&lt;strong&gt; delegate &lt;/strong&gt;and get help.&lt;/p&gt;
&lt;p&gt;Another solution to dropping the ball or not dropping the ball, is to simply delegate and pass the ball to others who can help out. Both &lt;em&gt;dropping the ball&lt;/em&gt; and &lt;em&gt;delegating&lt;/em&gt; are honestly great leadership skills that can be harnessed to effectively multiply your productivity levels. Both of them can seem almost like the same thing to those that have expectations upon your work, and both can be force multipliers for you, but their results can obviously be very different initially. In the end, both end up requiring someone to pick up the work or write off the work. I’ll leave you to guess which one results in which result. ;)&lt;/p&gt;
&lt;p&gt;As these things popped into my head I looked at my immediate to-do list of things. I knew I was rather bombarded with things I needed to do, so it was time to figure out what could be delegated and what could be dropped. This list, of course is only &lt;em&gt;tech related&lt;/em&gt; and &lt;em&gt;work&lt;/em&gt; related. It is also a list that has to be done before the end of the week, which is Sunday @ 6pm in time for Game of Thrones for this particular instance.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Infrastructure: DNS migration completion from provider X to Google Cloud DNS via Terraform &amp;amp; Atlas.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Resolve a firewall change.&lt;/li&gt;
&lt;li&gt;Determine Zookeeper working situation with Kubernetes &amp;amp; container tech vs. installed on VM. Prepare a seamless immutable infra deployment of said Zookeeper cluster.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Setup voting for proposals and get team to vote.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get bike ride event posted for day before conference.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get schedule put together for workshops.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Finalize curriculum, course topics, abstracts, and titles for workshops.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get Geek Train setup, scheduled, call Amtrak to confirm date and get a ticket block.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get marketing done around Geek Train, Bike Ride, Workshops, etc.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Update website w/ progress.&lt;/li&gt;
&lt;li&gt;Node PDX - Get bike ride event posted for day before conference.&lt;/li&gt;
&lt;li&gt;Node PDX - Get schedule put together for workshops.&lt;/li&gt;
&lt;li&gt;Node PDX - Meet with Code Fellows about partnership and workshop resources (space etc)&lt;/li&gt;
&lt;li&gt;Node PDX - Get proposals sorted and prepared for selection and make selection w/ team.&lt;/li&gt;
&lt;li&gt;Node PDX - Get Geek Train setup, scheduled, call Amtrak to confirm date and get a ticket block.&lt;/li&gt;
&lt;li&gt;PDX Node - (Not PDX Node and not Node PDX!) meetup tonight (Thursday) at Urban Airship to plan the future of the meetup and coordinate with organizers!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ok, that’s enough. You get the idea. I’m a bit underwater on things. But this is how it works. There are weeks where there isn’t a high priority on a single thing, and then BOOM, the deluge has come upon me and I have no hope of finishing things in a timely manner. Privatization, delegation, and dropping the ball are the options available during this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question Things, Question Yourself, Always Ask Questions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I always ask several questions about things I need to get done during this time. For instance, how could I get help or even get someone to organize a bike ride or do the work of setting up logistics around the geek train? How could I make the amount of work I need to do to setup the DNS migration and complete it the absolute minimum while ensuring it’ll get done right, on time, and seamlessly without interruption? Could I just drop the Zookeeper and Kubernetes work for now? There is always a balance to be reached among things that provides the maximum return.&lt;/p&gt;
&lt;p&gt;Among all the questions there are two other things that are super important. Again, I’m going to pull a Hanselman quote.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Effectiveness is doing the right thing.
Efficiency is doing things right.  - &lt;em&gt;Scott Hanselman&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These two things are huge. If either falters, even in a small way, I’ve found it’s better to call a full stop and reflect on what I’m doing. I’ve also found, that when others start to give in and their efficiency and effectiveness drops, it’s time to call a full stop. This is something that’s hugely helpful when providing leadership for people too, help them help you help everybody move forward and don’t let them fall prey to be overworked and overwhelmed!&lt;/p&gt;
&lt;p&gt;These are a few things, largely focused around Scott’s blog entries and presentations. Absolutely great, well researched, and he practices what he preaches. Scott is a seriously kick ass, highly reliable, consistent guy.&lt;/p&gt;
&lt;p&gt;On to some other things that Scott might have said, but these are things I’ve come up with just from life. The following might actually seem counter-intuitive, but I promise you when these practices are mastered you will stand out strong while others falter around you. However they’re tricky, because if you have a “warm body in seat” type of boss, don’t have work flexibility around hours, schedule, remote or onsite all of these become extremely difficult. In spite of this they’re all wroth investing in to get them to work for you. I’ve easily quadrupled what I can do by doing the following.&lt;/p&gt;
&lt;p&gt;&lt;h1&gt;My Productivity List&lt;/h1&gt;
Remember one thing. Work is not your core focus and reason to exist in life. &lt;strong&gt;&lt;em&gt;You, your family, your love is why you work in order to live and to create and build&lt;/em&gt;&lt;/strong&gt;. Don’t get these things mixed up ever. If work takes to much toll, figure something out to reduce it’s damage to your life.&lt;/p&gt;
&lt;h2 id=&quot;coffee-without-work&quot;&gt;Coffee Without Work&lt;/h2&gt;
&lt;p&gt;Have your &lt;em&gt;&lt;strong&gt;coffee without work in the morning&lt;/strong&gt;&lt;/em&gt;. I can’t rave enough about getting one’s head in the game before actually starting on work tasks. Whatever your morning tradition is, mine being that wicked awesome coffee that Portland is famous for, this needs to be done without having work interfere. If someone is emailing you or calling you don’t let it interrupt. If you feel you need to be interrupted in the morning then you really need to find different work where this time will be respected.&lt;/p&gt;
&lt;p&gt;You might have another coffee with coffee folk at work, but whatever the case, have your first coffee in your own head space without interruptions. Better yet, have it with your wife, children, or loved ones so you remember why you are who you are and do what you do.&lt;/p&gt;
&lt;h2 id=&quot;cut-the-to-do-list-in-half&quot;&gt;Cut The To-do List in Half&lt;/h2&gt;
&lt;p&gt;Ever noticed the lies of to-do lists? It takes practice to create to-do lists that are actually able to be completed on a schedule. Don’t even lie about it, that’s what all of our first to-do lists do, is lie to us. There are tons of rules and thoughts around to-do lists. Keep em’ to three isn’t a bad one, but as you’ve seen I have a catastrophe in the making listed above. So I need to split that to-do list into manageable segments.&lt;/p&gt;
&lt;p&gt;The times to-do lists turn into a multidimensional array of to-do lists are to frequent to count. So cut them in half, stay focused on one list. ONE LIST, not anymore. If you have more delete them. They’re waste, total waste. I keep a single list and &lt;em&gt;notes&lt;/em&gt;. The notes are merely random thoughts and things that might one day end up one day on a list. That leads me to the next thing…&lt;/p&gt;
&lt;h2 id=&quot;write-note-and-think&quot;&gt;Write, Note, and Think&lt;/h2&gt;
&lt;p&gt;Write down things, not particularly lists, but just things that you think or ponder frequently. This helps one formalize what their thoughts are. Write these notes and think, think, and think some more. For me, this helps me refocus and insure I’m always working (or actively procrastinating at least) effectively and efficiently on things instead of getting hit with analysis paralysis or other such anti-pattern problems.&lt;/p&gt;
&lt;h2 id=&quot;take-a-break&quot;&gt;Take a Break&lt;/h2&gt;
&lt;p&gt;Take a break frequently. Taking a break frequently and move around. Walk around a space, the block, or whatever you can find. Walk for at least 15 minutes every 2-4 hours. I’m sure doctors say this too, but I’ve got this on my list of productivity helpers because it legitimately helps people keep that brain clear and helps in numerous other ways. This activity will also help knock out thinking road blocks, resolve errors that crop up, and generally keep you quick thinking. Otherwise we humans tend to fade at a dramatically faster rate during the day without a break, in spite of what we sometimes think we need to do. So take a break, walk around.&lt;/p&gt;
&lt;h2 id=&quot;be-active-stay-healthy-blagh-blagh-blagh-&quot;&gt;Be Active, Stay Healthy… Blagh Blagh Blagh…&lt;/h2&gt;
&lt;p&gt;I’m touchy about this one and I know a bunch of people are. But this is seriously pivotal to staying productive! There are more studies than I can count and might hit on the topic in a subsequent blog entry. For now, it’s safe to say I stay active and it is massive part of how I stay productive.&lt;/p&gt;
&lt;h2 id=&quot;don-t-work-hard-work-smart&quot;&gt;Don’t Work Hard, Work Smart&lt;/h2&gt;
&lt;p&gt;This is said by half the planet, but seriously take it to heart. If you’re working hard, then you’re likely getting behind. If you find yourself repeatedly doing some copy and pasting, or just cranking through typing line after line of some nonsense, or you’ve been delved into a problem for many hours, step back. Are you just working hard at the problem or actually trying to work smartly to resolve the problem? Far to often we work at the problem instead of trying to actually think our way through the problem or even around the problem!&lt;/p&gt;
&lt;p&gt;Another article I saw popup recently, which translates to the idea behind don’t work hard, work smart is &lt;a href=&quot;http://www.inc.com/will-yakowicz/stop-being-busy-and-start-being-productive.html&quot; target=&quot;_blank&quot;&gt;stop being busy, start being productive&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;don-t-meeting-&quot;&gt;Don’t &lt;em&gt;Meeting&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Does this need repeated? There’s a reason there are other options on meeting invites besides the &lt;em&gt;accept&lt;/em&gt; option. Use them readily, frequently, and with intent. Remove yourself from, and don’t let yourself fall into the trap of creating meetings that are unnecessary. &lt;a href=&quot;https://gettingreal.37signals.com/ch07_Meetings_Are_Toxic.php&quot; target=&quot;_blank&quot;&gt;Meetings are toxic&lt;/a&gt;, and seriously one of the biggest problems of going to &lt;em&gt;work&lt;/em&gt; is that far to often work doesn’t happen at work. Largely because of, as Jason Fried states, “&lt;em&gt;M &amp;amp; M&lt;/em&gt;“.&lt;/p&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/5XD2kNopsUs?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;For the last few, these are just a few things to NOT do. If you find yourself stuck in these anti-patterns of productivity start looking for a way out. These anti-patterns are basically indicators of a death march. You aren’t going to fix it, let it die.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;em&gt;&lt;strong&gt;requested&lt;/strong&gt;&lt;/em&gt; overtime happens more than once a month. I’d even say, if overtime requests happens more than once a year, get out. This is a sure indicator of being underfunded, understaffed, poorly managed, and a lack of project leadership that understand how to achieve the best results  for a project, product, service, or otherwise. The only time overtime is acceptable is if &lt;em&gt;&lt;strong&gt;YOU&lt;/strong&gt;&lt;/em&gt; choose for &lt;em&gt;&lt;strong&gt;YOU&lt;/strong&gt;&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;YOUR COMPANY&lt;/strong&gt;&lt;/em&gt; to work overtime. In the same turn, don’t request of others this nonsensical thing, it’s a sure sign you’ve lost control of dictating your company’s future effectively.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Do not lose sleep&lt;/strong&gt;&lt;/em&gt;. Unless it’s because you’re super excited, that happens sometimes. But if you do lose sleep, make absolutely sure that you regain it somehow. If you lose sleep to often you will absolutely, 100% land in a seriously flawed and troublesome failing state. This is not a good situation to be in.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;This next one might sound odd, but I do nto jest even lightly about this one. &lt;em&gt;&lt;strong&gt;Drink more water&lt;/strong&gt;&lt;/em&gt; than you do now. Statistically Americans are somewhere around 96-97% chronically dehydrated. That means we’re almost always operating under less than ideal personal physical condition. This is very bad… if you don’t buy this one, go read up on how dehydration works. Then think about it, I promise it’s far more important than you might thing and it’s ridiculously easy to actually fix. This isn’t the 10th century anymore, nobody is really walking down to the river for water, just grab a bottle and carry it on your person.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;A few more related references:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;First and foremost, check out Scott’s &lt;a href=&quot;http://www.hanselman.com/blog/ScottHanselmansCompleteListOfProductivityTips.aspx&quot; target=&quot;_blank&quot;&gt;list of tips&lt;/a&gt;.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;Here’s one Scaling Yourself from 2012 @ Dev Day&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/IWPgUn8tL8s?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;Also Scaling Yourself at goto; conf.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/FS1mnISoG7U?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    <item>
      <title>Immutable Infrastructure - Some Reads and Clarification of What It Is</title>
      <link>http://adron.github.io/articles/immutable-infrastructure-some-reads-clarification-what-it-is/</link>
      <pubDate>Tue, 12 Apr 2016 13:39:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/immutable-infrastructure-some-reads-clarification-what-it-is/</guid>
      <author></author>
      <description>&lt;p&gt;First let’s get these terms a little more defined with the help of some well written articles on the matter.&lt;/p&gt;
&lt;h2 id=&quot;an-introduction-to-immutable-infrastructure&quot;&gt;An Introduction to Immutable Infrastructure&lt;/h2&gt;
&lt;p&gt;A well written piece by &lt;a href=&quot;https://twitter.com/joshstella&quot; target=&quot;_blank&quot;&gt;@joshstella&lt;/a&gt; on O’Reilly Radar titled “&lt;a href=&quot;http://radar.oreilly.com/2015/06/an-introduction-to-immutable-infrastructure.html&quot; target=&quot;_blank&quot;&gt;An Introduction to Immutable Infrastructure&lt;/a&gt;“. Here are some key elements in Josh’s description of immutable infrastructure.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Immutable infrastructure (II) provides stability, efficiency, and fidelity to your applications through automation and the use of successful patterns from programming.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This provides a basic description, at a very high level, of what immutable infrastructure is. The keys to note are the idea of programming the infrastructure instead of tediously setting it up manually as has traditionally been done.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Immutable infrastructure requires full automation of your runtime environment. This is only possible in compute environments that have an API over all aspects of configuration and monitoring. Therefore, II can be fully realized only in true cloud environments. It is possible to realize some benefits of II with partial implementations, but the true benefits of efficiency and resiliency are realized with thorough implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this part another key point, from a functional perspective of what immutable infrastructure is, is brought up. The availability of APIs to control all aspects of the infrastructure and beyond are needed to truly implement this pattern of infrastructure use. Without APIs to programmatically enable this there is no way to truly create immutable infrastructure.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Historically, we’ve thought of machine uptime and maintenance as desirable because we associate the health of the overall service or application with them. In the data center, hardware is expensive and we need to carefully craft and maintain each individual server to preserve our investments over time. In the cloud, this is an anachronistic perspective and one we should give up on in order to create more resilient, simpler, and ultimately more secure services and applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Paraphrased - kill your tediously and manually managed servers! &lt;em&gt;Woohoo!&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;why-you-should-build-an-immutable-infrastructure&quot;&gt;Why You Should Build an Immutable Infrastructure&lt;/h2&gt;
&lt;p&gt;“&lt;a href=&quot;https://blog.codeship.com/immutable-infrastructure/&quot; target=&quot;_blank&quot;&gt;Why You Should Build an Immutable Infrastructure&lt;/a&gt;“ by &lt;a href=&quot;http://Even though the  https://twitter.com/flomotlik&quot; target=&quot;_blank&quot;&gt;@flomotlik&lt;/a&gt; is an excellent write up with a bit more detail about how, where, and why to build out immutable infrastructure. The blog &lt;a href=&quot;https://twitter.com/codeship&quot; target=&quot;_blank&quot;&gt;@Codeship&lt;/a&gt; overall is an excellent place to find more implementation details about designing, uses, and ways to put together your own immutable infrastructure. In the article I’ve linked Florian draws some solid points about their experience with immutable infrastructure. Some of the key features Florian details include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State Isolation&lt;/li&gt;
&lt;li&gt;Atomic Deployments and Validation&lt;/li&gt;
&lt;li&gt;Fast Recovery by Preserving History&lt;/li&gt;
&lt;li&gt;Simple Experimentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of these are valid reasons to go with an immutable infrastructure design practice. Florian also puts together some great links &amp;amp; reference material at the end of the article too.&lt;/p&gt;
&lt;h2 id=&quot;summary-&quot;&gt;Summary…&lt;/h2&gt;
&lt;p&gt;So these are reasonable good reads on immutable infrastructure, something, that if you’re in charge of any type of application deployment will benefit from in some significant ways. So learn up, and feel free to ping me for further discussion on twitter &lt;a href=&quot;https://twitter.com/adron&quot; target=&quot;_blank&quot;&gt;@Adron&lt;/a&gt;. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Difficult Open Source Path</title>
      <link>http://adron.github.io/articles/the-difficult-open-source-path/</link>
      <pubDate>Thu, 24 Mar 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/the-difficult-open-source-path/</guid>
      <author></author>
      <description>&lt;p&gt;Bringing a closed source, or just simply an internally managed code base, into the wild of open source software can be an arduous and surreal process. In this article I’m going to ramble on about exactly that, with a few learned lessons and key successes I’ve had.&lt;/p&gt;
&lt;p&gt;I’m currently helping the Home Depot Quote Center determine what is useful software to open source, and then helping them move toward open sourcing that software. In the past I’ve managed the open source development of .NET Extensions of Cloud Foundry, called Iron Foundry, which provided .NET support to the Cloud Foundry Platform. I’ve also helped organize and run open source efforts for plugins at New Relic, Basho, and a host of other smaller companies. Sometimes I’ve been a code contributor, sometimes I’m just interacting with contributors and managing pull requests. Either way it has been a lot of fun and every time it has been a seriously intense learning opportunity.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;lesson-1-open-source-amp-individual-freedom&quot;&gt;Lesson 1: Open Source &amp;amp; Individual Freedom&lt;/h2&gt;
&lt;p&gt;One thing to keep in mind, which I realize, but find myself being reminded of, is that people are truly free to either contribute, use, or completely disregard or ignore your open source project. The analogy of herding cats is often used to describe software development, and open source software development is like herding cats hopped up on a bunch of catnip that whimsically decide to do whatever they want.&lt;/p&gt;
&lt;p&gt;Of course, an open source project might have paid contributors. If a project has paid contributors we at least get back to a contained room of cat herding. But either way, never forget that someone may or may not build that feature, or close the issue, or submit a pull request the way you’ve set out to have the project run. Which brings me to the next lesson.&lt;/p&gt;
&lt;h2 id=&quot;lesson-2-write-up-roles-rules-process-guidelines&quot;&gt;Lesson 2: Write Up Roles, Rules, Process, &amp;amp; Guidelines&lt;/h2&gt;
&lt;p&gt;As soon as the team goes from one person to two, effort should immediately be put into creating roles, rules, and process for how contributions will be accepted, pull requests will be committed, how to submit or work on issues, and the whole host of work flow associated with getting things done for the project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Roles&lt;/strong&gt;, in this particular instance, can be broken down in different ways. Sometimes a project might have somebody managing the pull requests coming in, someone else or even several people are managing the product development issues for new features, another person might be handing bug issues that come up, and the possibilities continue. Some simple examples often look like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Project Leader - (Manager, Boss, Head Honcho, or whatever the title) would be in charge of and might even be the person who started the project.&lt;/li&gt;
&lt;li&gt;Contributor - Individual submitting features via pull request to the project.&lt;/li&gt;
&lt;li&gt;Feature Creator - Individual submitting feature requests and ideas via issues listings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Slightly more complex examples might be something like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Project Creator - Again, the person who created, started, and owns the project.&lt;/li&gt;
&lt;li&gt;Feature Architect - Some who specifically designs features from a technical stand point.&lt;/li&gt;
&lt;li&gt;Feature User Experience - Someone who works with users of the OSS project to determine how and in which ways the community is using the project and determine ways to make the experience better.&lt;/li&gt;
&lt;li&gt;Feature Contributor - Someone who contributes code for features, implementing based on contributor specs, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Beyond that, one just merely needs to detail the roles as much as necessary to help people determine what and how they’ll be contributing to the project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules&lt;/strong&gt; for a project can cover a wide range of things. One increasingly popular and sometimes useful thing to add, especially with a diverse group of people working on a project, is a basic code of conduct. This helps outline what is or is not appropriate behavior on the issue threads and general public conversation within the group. We have to remember that open source often has people involved that aren’t exactly employees or directly related to the person that started a project. Because of this individuals often come to a project without any particular guidelines about what is or isn’t appropriate behavior.&lt;/p&gt;
&lt;p&gt;Other rules that are dramatically simpler and easier to deal with, are breaking down and defining what is considered an acceptable pull request, how things should be documented, code standards, and other related technical rules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt; for a project is often key to keeping people involved over time. Without a good process in which contributors really feel like they’re part of the team and getting their pull requests accepted, things can fall apart pretty quickly. Nothing like a bored programmer to go find something else to do that has nothing to do with your open source project!&lt;/p&gt;
&lt;p&gt;A good process helps to define the steps that a contributor would need to go through to contribute a piece of code to a feature, who they would need to communicate with, how to submit a pull request, and finally how to wrap up getting the pull request pulled from the latest code. This is as important to people and it is to defining the technical steps for the system itself to be sustaining from an ongoing continuous integration and deployment point of view.&lt;/p&gt;
&lt;p&gt;Once these core things are formalized it dramatically decreases tedious communication about working through the most basic of tasks while working on a project.&lt;/p&gt;
&lt;h2 id=&quot;lesson-3-branding-amp-marketing&quot;&gt;Lesson 3: Branding &amp;amp; Marketing&lt;/h2&gt;
&lt;p&gt;“Oh my god what are you talking about Adron, what’s that crap got to do with an open source project?” I can hear the naysayers immediately on this topic. But rest assured, branding and marketing will either make or break a project. If you’re repo is kind of clunky and cluttered it sends a bad message that you aren’t really paying attention to your project. If someone comes to your repo and immediately sees a reasonable logo, or some type of consistent README.md with useful information and messaging (that’s marketing by the way) about what, where, how, and why this project exists, you’re exponentially more likely to get people involved in contributing and even more dramatically more likely to get people using the project.&lt;/p&gt;
&lt;p&gt;In the OSS Manifesto a baseline of files are suggested for an OSS project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have a readme file&lt;/li&gt;
&lt;li&gt;Have a contributing file&lt;/li&gt;
&lt;li&gt;List all core team members in the readme file&lt;/li&gt;
&lt;li&gt;Have a license file&lt;/li&gt;
&lt;li&gt;Have a changelog&lt;/li&gt;
&lt;li&gt;Follow semantic versioning&lt;/li&gt;
&lt;li&gt;Tag all major releases&lt;/li&gt;
&lt;li&gt;Provide documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll add to this, throw in an &lt;em&gt;.svg or reasonably usable &lt;/em&gt;.png of a logo or some easily identifiable symbol for the project. Every major project has some sort of logo, it really doesn’t even matter if its a pretty lousy looking logo, it just needs to be there to make the project easily identifiable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/the-difficult-open-source-path/open-source-logos.png&quot; alt=&quot;Open Source logos&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;lesson-4-the-software-needs-to-work&quot;&gt;Lesson 4: The Software Needs to Work&lt;/h2&gt;
&lt;p&gt;Having the respective readme, contributing file, general doc, listing of all core members; these things I’ve listed so far are all nice but there’s one more thing I’ve not mentioned yet. That is having a working publicly accessible &lt;strong&gt;&lt;em&gt;continuous integration&lt;/em&gt;&lt;/strong&gt; build that is working. Any and every open source project should have a repository setup with a running build. Any new pull requests gets accepted or even the smallest commit should get a build started.&lt;/p&gt;
&lt;p&gt;There are many ways, more so for open source projects than probably any other kind, to get a continuous integration build going. Check out products and services like &lt;a href=&quot;https://codeship.com/&quot; target=&quot;_blank&quot;&gt;Codeship&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/teamcity/&quot; target=&quot;_blank&quot;&gt;TeamCity&lt;/a&gt;, &lt;a href=&quot;https://www.appveyor.com/&quot; target=&quot;_blank&quot;&gt;Appveyor&lt;/a&gt;, or &lt;a href=&quot;https://travis-ci.org/&quot; target=&quot;_blank&quot;&gt;Travis CI&lt;/a&gt;. These are just a few of the many options to get a continuous integration setup running for your open source project.&lt;/p&gt;
&lt;h2 id=&quot;lesson-5-there-will-be-other-lessons-to-learn&quot;&gt;Lesson 5: There will be other lessons to learn&lt;/h2&gt;
&lt;p&gt;An open source project is a pretty wild ride of code chops, organizational skills, and keep systemic development sustainable for a project. It can be tough, but a lot of fun, and very rewarding.&lt;/p&gt;
&lt;p&gt;With that, happy hacking and stay tuned, there’s more to come!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Quick Append to Text File with BASH</title>
      <link>http://adron.github.io/articles/quote-append-to-text-file-with-bash/</link>
      <pubDate>Sun, 13 Mar 2016 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/quote-append-to-text-file-with-bash/</guid>
      <author></author>
      <description>&lt;p&gt;I commonly have the scenario where I want a bash script to throw in something at the tail end of the ~/.bash_profile or ~/.profile script or just append some results like a log file to some existing text file. Well here are two super easy ways to add text to a text file.&lt;/p&gt;
&lt;p&gt;Method one, using echo to append the text with the I/O redirection to the text file like this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo &amp;quot;line 1&amp;quot; &amp;gt;&amp;gt; greetings.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or even like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo &amp;quot;line 1
line 2
line 3&amp;quot; &amp;gt;&amp;gt; greetings.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Method two, using cat to read until EOT and redirect it to append to text file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOT &amp;gt;&amp;gt; greetings.txt
line 1
line 2
line 3
EOT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That’s it, easy peasy. Enjoy your shell hacking!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Today I'm Using a Mac</title>
      <link>http://adron.github.io/articles/today-using-a-mac/</link>
      <pubDate>Fri, 11 Mar 2016 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/today-using-a-mac/</guid>
      <author></author>
      <description>&lt;p&gt;Today I’m using a Mac (since 2011, but inspired to write this today in 2016) not because I have some profound love for Apple (I don’t really) or miss Steve Jobs (he was a dick, but I bet I’d have gotten along with him) only because I don’t want to spend excess time messing with Windows headaches and the games I generally play over the last 7-8 years have been things like SimCity, Civ 5, and Cities: Skylines. All run perfectly fine on Mac w/ Steam. If I played 1st Person shooters I’d probably still have a Windows machine stashed in the corner for that…&lt;/p&gt;
&lt;p&gt;…and…&lt;/p&gt;
&lt;p&gt;…as for Macs, I converted solely because of what I saw a few key coders acheive in seconds over a Windows machine. I’ve not seen a single person come close to what these people could accomplish on a *nix based platform vs Windows. I switched, my headaches went away blagh blagh blagh (you know the ads, I sound like that) and then between OS-X &amp;amp; VMware Fusion I found I had a machine I could do everything from a coding perspective on (I initially bought an MBA). Then when I got the Retina Pro 15” I realized not only did I have every programming platform in existence available to me (even .NET!) I also realized it was the only machine of it’s size, weight, and horsepower that would let me edit in screen full frame 1080p or even 4k video without choking on itself. Windows didn’t even have a viable option on the market at the time (and really, it still doesn’t).&lt;/p&gt;
&lt;p&gt;At this point I’ve given up trying to even use Windows to do work, primarily cuz it’s bad at video, bad at building code (most comparable machines just don’t build 1 to 1 code bases as fast), has weak POSIX compliance, Powershell is just a pain in the ass, it has poor SSH support (load 3rd party software? does it even internet) and security in general is completely bonkers, and Windows can never seem to find or maintain security integrity around any non-WINS/AD identified network (ok, in Windows defense, this is a Windows Server concern not Windows Desktop).&lt;/p&gt;
&lt;p&gt;Beyond that even the OS-X UI is preferable to the sluggish, strange multi-tasking awkwardness of Windows 2010 (and it’s dramatically improved over 8/8.1, 7, Vista, XP, &amp;amp; 2000). The fact I can launch a program and it doesn’t kill process &amp;amp; memory resources while I’m doing something has always fascinated me vs. Windows, which seems to hand over every available resource to whatever is attempting to launch. What is that nonsense even? Let it launch on a lower priority thread or something. I could go on…&lt;/p&gt;
&lt;p&gt;I’ve got plenty of complaints about OS-X, but it stays out of the way when I need to build code, automate infrastructure, sling dynamic code (re: Ruby, JavaScript, etc) and generally tears through Core CLR code &amp;amp; .NET Mono code dramatically better than suggish old VS on a box with more resources then this MBP. Honestly, it’s kind of sad how it seems to magically do better then Windows hardware. There aren’t a whole lot of specific reasons except that Macs are usually just integrated (motherboard/RAM/Proc/Video) better than most of the other junk that gets released to market. Of course if someone wants pure horsepower, yeah, got buy a desktop and get 4x-20x what comes in the best Mac, then run Linux. You’ll get stupid amounts of performance to build and process stuff with that. But in the consumer based world, if you want the maximum options with the minimal amount of bullshit in your life, you go and buy a MBP and get on with life. I could go on…&lt;/p&gt;
&lt;p&gt;I’m sure there’s a million other things where X device for Y niche is more perfect or perfectly acceptable, and I doubt I’d disagree, so go on, get yourself one of those. But again, for “the maximum options with the minimal amount of bullshit in your life, you go and buy a MBP and get on with life”. On that note, I’m off to sling some Core CLR code against a prospective Scala solution and test a micro-services idea of mine - using Docker and jazz on my OS-X box. I’ll be done in 20 minutes and will move on to probably a relaxing round of Cities: Skyline. ;)&lt;/p&gt;
&lt;p&gt;Thanks for reading my partial rant /&lt;em&gt;slash&lt;/em&gt;/ exploration of why I’ve ended up on Apple Hardware.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Docker Tips n' Tricks - Bash Things With Docker</title>
      <link>http://adron.github.io/articles/docker-tips-n-tricks-bash-things-with-docker/</link>
      <pubDate>Wed, 09 Mar 2016 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/docker-tips-n-tricks-bash-things-with-docker/</guid>
      <author></author>
      <description>&lt;p&gt;If you use Docker frequently, you’ve likely memorized a few repetitive commands…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine start XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then you run…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine env XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;…and then you type…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval $(docker-machine env XyZvirtualMachine)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One does this about a zillion times if there are multiple virtual machines or for other various reasons. I wanted to simplify this repetitive task so I wrote a bash function, thanks to a &lt;a href=&quot;http://stackoverflow.com/questions/35761480/scripting-docker-not-connected-after-running-script&quot; target=&quot;_blank&quot;&gt;fumble I posted on Stackoverflow&lt;/a&gt; and then an assist by my good friend Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37&quot; target=&quot;_blank&quot;&gt;@thoward37&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This quick hack consisted of this &lt;a href=&quot;https://gist.github.com/Adron/8dc06eb398f403225daa&quot; target=&quot;_blank&quot;&gt;Github gist&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker() { if [ $1 ]; then
    docker-machine start $1
    docker-machine env $1
    eval $(docker-machine env $1)
    docker ps -a
fi }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stick that in your ~/.bash_profile (or ~/.bashrc if you’re on *nix) and you’re good to go. Then at the bash prompt just type in this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BOOM! Less typing for the win!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Researching &amp; Learning About Zookeeper - A Guide</title>
      <link>http://adron.github.io/articles/research-learning-about-zookeeper/</link>
      <pubDate>Mon, 01 Feb 2016 16:30:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/research-learning-about-zookeeper/</guid>
      <author></author>
      <description>&lt;p&gt;I’ve started working with Zookeeper. Since I’ve started doing that I’ve put together this blog post. It’s aim is to provide a structured approach to learning Zookeeper and researching the elements that make its features tick. Along the way I have a few call outs to people that have also provided excellent talks, material, or contributions to learning about Zookeeper along the way. With that, let’s get started.&lt;/p&gt;
&lt;p&gt;Zookeeper is a consensus system written based on ideas presented via consensus algorithms. The idea is key value stores that keep all of their data in memory for read heavy workloads. The qualities in this context present a system that is highly consistent, with intent for access from distributed systems to data that won’t be lost.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;start-learning&quot;&gt;Start Learning&lt;/h3&gt;
&lt;p&gt;The starting point should be a complete read of the &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Apache Zookeeper Project Home Page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At this point I took an administrators’ angle on determining what I needed to know and do next. I knew that my situation would meet the basic assumptions of reliability around Zookeeper; First is that only a minority of servers in a deployment would fail at a particular time or become inaccessible from a crash, partition, or related issue, and second is that deployed machines would have correctly operating clocks, storage, and network components that perform consistently.&lt;/p&gt;
&lt;p&gt;I had also made an assumption that I would need &lt;em&gt;&lt;strong&gt;2 x F + 1&lt;/strong&gt; &lt;/em&gt;machines in order to maintain data consistency. The F here is the number of failed or inaccessible machines. This meant that if I wanted to have 2 failures, I’d need at least 5 machines. For a failure of up to 3 machines, that would be 7 machines. Pretty easy, just a little simple math.&lt;/p&gt;
&lt;p&gt;The other thing I was curious about, especially on a single machine, would be Zookeeper’s overall overhead. Would it come into contention with the services that are already running? Would it be ok to put Zookeeper on the machines that run the micro-services that Zookeeper is providing information to? Well, Zookeeper does indeed content with other application for CPU, network, memory, and storage. For this reason I have to balance the deployment of Zookeeper in relation to the other applications, as my server loads may not be super high, and thus I’d be able to have Zookeeper on some of the servers that have actual other services deployed. But YMMV depending on your services you’ve got deployed.&lt;/p&gt;
&lt;p&gt;While I was thinking through how I’d build out the architecture for my implementation of Zookeeper I came upon a very important note in the documentation,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“ZooKeeper’s transaction log must be on a dedicated device. (A dedicated partition is not enough.) ZooKeeper writes the log sequentially, without seeking Sharing your log device with other processes can cause seeks and contention, which in turn can cause multi-second delays.&lt;/p&gt;
&lt;p&gt;Do not put ZooKeeper in a situation that can cause a swap. In order for ZooKeeper to function with any sort of timeliness, it simply cannot be allowed to swap. Therefore, make certain that the maximum heap size given to ZooKeeper is not bigger than the amount of real memory available to ZooKeeper. For more on this, see Things to Avoid below.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After reading up on the following documentation it seemed like a good time to do a test deployment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html&quot; target=&quot;_blank&quot;&gt;Zookeeper Admin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_minimumConfiguration&quot; target=&quot;_blank&quot;&gt;Zookeeper Minimum Configuration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;BEGIN BUG DESCRIPTION - 1ST DOCKER ATTEMPT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NOTE: If you just want to get to the Zookeeper installation &amp;amp; setup and skip this issue, GOTO &lt;a href=&quot;#awsInstallation&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My first go was to pull up a clean Ubuntu docker image and prep it as a container. Then start installing the necessary parts of Zookeeper. These steps consisted of the following. I made a video for it (see toward the bottom of this entry), so you can actually see the flow and I also wrote the commands I’m tying in bash below. Then you can pick your preferred use.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine start fusion-fire
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Docker machine starts my virtual machine on OS-X that runs the Docker daemon, which I’ve named fusion-fire, thus the command above. Then after that I pulled down an Ubuntu image, started a container from the image, connecting to the container and all set for installation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker pull ubuntu
docker run -it ubuntu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To install the Zookeeper server and begin execution I then issued the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get -Y install default-jdk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While this was executing I also ran into a situation where the Java Development Kit was hanging on getting the certificates put into place.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;The last dozen or so &lt;a href=&quot;https://twitter.com/hashtag/Ubuntu?src=hash&quot;&gt;#Ubuntu&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/docker?src=hash&quot;&gt;#docker&lt;/a&gt; images I&amp;#39;ve tried to run &amp;quot;sudo apt-get install default-jre&amp;quot; on have all ended up spiking the CPU.&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/693219719441096704&quot;&gt;January 29, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;I began looking into this problem, and found currently on Ubuntu 14.04, running sudo-apt-get update and then running the install will trigger the bug. Two other points of reference are &lt;a href=&quot;https://github.com/docker/docker/issues/18180&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://bugs.launchpad.net/ubuntu/+source/ca-certificates-java/+bug/1396760&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, and there are other postings and issues related to the issue, just google. So what I did at that point to fix this issue was the following.&lt;/p&gt;
&lt;p&gt;First I forcefully killed the docker container by just restarting the whole docker VM.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine stop fusion-fire
docker-machine start fusion-fire
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once that stopped I then started the virtual machine again.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get -y install default-jre
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When it started I ran sudo apt-get install again. At that point apt-get attempted to recover but the install kept getting stuck on registering the certificates. So I gave up on this avenue for now. Hopefully a future Docker &amp;amp; Linux Kernal fixes the problem. So instead I went out and just spooled up some AWS instances for now, I’ll update this blog entry with a “Part II: Docker is Zookeeper Fixed” when the Java + Linux Kernal + Docker issue is remedied, until then, here’s the installation process on the AWS instances.&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;awsInstallation&quot;&gt;&lt;/a&gt;
&lt;strong&gt;END BUG DESCRIPTION - AWS Instance Zookeeper Installation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once this was setup I started 5 nano instances for Zookeeper (nano, since it’s just a test example for learning) and then logged in using broadcast with iTerm 2. From there each instance had the following commands executed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install -y default-jdk
cd /opt/
sudo mkdir zookeeper
cd zookeeper/
sudo wget http://mirror.tcpdiag.net/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
sudo tar -zxvf zookeeper-3.4.6.tar.gz
cd conf/
sudo nano zoo.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;NOTE: Nano is the text editor I used above for “sudo nano zoo.cfg”. If you don’t have it available just install it with “sudo apt-get install nano”.&lt;/p&gt;
&lt;p&gt;In that zoo.cfg I entered the following. For the IPs I actually used the AWS private IPs for the config file example below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;tickTime=2000
dataDir=/var/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
server.1=172.31.19.66:2888:3888
server.2=172.31.19.67:2888:3888
server.3=172.31.19.68:2888:3888
server.4=172.31.19.69:2888:3888
server.5=172.31.19.70:2888:3888&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now I started the service using the zkServer.sh script file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo /opt/zookeeper/zookeeper-3.4.6/bin/zkServer.sh start-foreground
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When I booted up I ran into an error about the myid file, so I added the file with a sequential number for the byid in the /var/zookeeper directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo nano /var/zookeeper/myid
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In each of the files I added a number, respectively 1 through 5 for the id of each and saved those files. Upon attempting to start the zookeeper service with the following command I finally got to see the various nodes in the ensemble gain access to each other and start working. Which, I gotta admit, was a pretty damn cool feeling.&lt;/p&gt;
&lt;p&gt;After all that fussing it seemed good to note, especially since they’re hard to find in the documentation (which is kind of a bit hard to use), here are some of the switches for zkServer.sh.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;start
start-foreground (super useful for debugging)
stop
restart
status
upgrade
print-cmd&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once this is done, restart the service but this time instead of using the start-foreground command, just use the start command and that will start the service and return the bash back to you to issues commands or whatnot. An easy way to test out Zookeeper now that it is running is to use the Zookeeper CLI. This is the zkCli.sh shell script (or zkcli.bat file if you’re running it on windows - which I’d strongly suggest NOT to do).&lt;/p&gt;
&lt;p&gt;Ok, that’s it for this entry. More to come in the near future. Cheers!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Excellent Additional References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a title=&quot;raft&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/raft.pdf&quot;&gt;In Search of an Understandable Consensus Algorithm (Extended Version)&lt;/a&gt; - Diego Ongaro &amp;amp; John Ousterhout @ Stanford University&lt;/li&gt;
&lt;li&gt;&lt;a title=&quot;paxos-simple&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/paxos-simple.pdf&quot;&gt;Paxos Made Simple&lt;/a&gt; by Leslie Lamport&lt;/li&gt;
&lt;li&gt;Camille Fournier (&lt;a href=&quot;https://twitter.com/skamille&quot; target=&quot;_blank&quot;&gt;@skamille&lt;/a&gt;) provided an excellent talk about &lt;a href=&quot;http://www.infoq.com/interviews/fournier-consensus&quot; target=&quot;_blank&quot;&gt;Zookeeper (Consensus Systems) on InfoQ&lt;/a&gt;. In this talk Camille also mentions the &lt;a title=&quot;chubby-osdi06&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/chubby-osdi06.pdf&quot;&gt;The Chubby Lock Service for Loosely Coupled Distributed Systems&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://youtu.be/j4uwKP7WJFk&quot; target=&quot;_blank&quot;&gt;Zookeeper for the Skeptical Architect by Camille Fournier&lt;/a&gt; - RICON East 2013
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/j4uwKP7WJFk?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
Talks about why Riak, Cassandra, and even the company Camille works at (Rent the Runway) doesn’t use Zookeeper. An interesting talk from the regard of why not to use it in some cases.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>All That Tech SitRep - Elastic Meetup and Quote Center Updates</title>
      <link>http://adron.github.io/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/</link>
      <pubDate>Mon, 25 Jan 2016 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/qc_377x285.png&quot; alt=&quot;Quote Center&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I started working with the Quote Center (QC) back in November, and wrote about it in “&lt;a href=&quot;http://compositecode.com/2015/10/31/after-816-days/&quot;&gt;After 816 Days I’m Taking a Job!&lt;/a&gt;“ Now that I’m a few months into the effort, it’s &lt;strong&gt;&lt;em&gt;sitrep&lt;/em&gt;&lt;/strong&gt; time. Sitrep, btw is military speak for&lt;/p&gt;
&lt;p&gt;&lt;em&gt;S&lt;/em&gt; ituational &lt;em&gt;R&lt;/em&gt; eport.&lt;/p&gt;
&lt;p&gt;The three core priorities I have at Quote Center in my role are: Community Contributions, Site Reliability, and Talent Recon.&lt;/p&gt;
&lt;h2 id=&quot;community-contributions-and-organizing-&quot;&gt;Community Contributions (and Organizing)&lt;/h2&gt;
&lt;p&gt;Some of the progress I’ve made, is direct and immediate involvement with some really interesting groups here in Portland. The first seemed a prime option, and that’s the &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Elastic User Group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Myself and some of the QC Team traveled late last year to check out the &lt;a href=&quot;http://compositecode.com/2015/12/03/elasticon-tour-2015-in-seattle/&quot;&gt;Elasticon Tour stop in Seattle&lt;/a&gt;. It was an educational experience where I got some of my first introductions to &lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; and also a new product &lt;a href=&quot;https://www.elastic.co/&quot;&gt;Elastic&lt;/a&gt; had just released recently called &lt;a href=&quot;https://www.elastic.co/products/beats&quot;&gt;Beats&lt;/a&gt;. I was fairly impressed by what I saw and several other things aligned perfectly for follow up community involvement after that.&lt;/p&gt;
&lt;p&gt;I’ve since kept in touch with the Elastic Team and started coordinating the &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Elastic User Group in Portland&lt;/a&gt; (Join the group on &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Meetup&lt;/a&gt; for future meetings &amp;amp; content). In March the group will be hosting a great meetup from Ward &amp;amp; Jason…&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot;&gt;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So be sure to &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot; target=&quot;_blank&quot;&gt;RSVP&lt;/a&gt; for that &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot; target=&quot;_blank&quot;&gt;meetup&lt;/a&gt; as it’s looking to be a really interesting presentation.&lt;/p&gt;
&lt;p&gt;The second group I’ve stepped up to help out with is the &lt;a href=&quot;http://www.meetup.com/Docker-Portland-OR/&quot; target=&quot;_blank&quot;&gt;Docker Meetup&lt;/a&gt; here in Portland. The first meetup we have planned at this time is from Casey West.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.meetup.com/Docker-Portland-OR/events/228249211/&quot;&gt;http://www.meetup.com/Docker-Portland-OR/events/228249211/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;site-reliability&quot;&gt;Site Reliability&lt;/h2&gt;
&lt;p&gt;One of the other priorities I’ve been focusing on is standard site reliability. Everything from automation to continuous integration and deployment. I’ve been making progress, albeit at this stage going from zero to something, in the space of a site reliability practice takes time. I’ve achieved a few good milestones however, which will help build upon the next steps of the progress.&lt;/p&gt;
&lt;p&gt;We’ve started to slowly streamline and change our practice around Rackspace and AWS Usage. This is a very good thing as we move toward a faster paced continuous integration process around our various projects. At this time it’s a wide mixture of .NET Solutions that we’re moving toward .NET Core. At the same time there are some Node.js and other project stacks that we’re adding to our build server process.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Team City&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Our build server at this time is shaping up to be Team City. We have some build processes that are running in Jenkins, but those are being moved off and onto a TeamCity Server for a number of reasons. I’m going to outline these reasons and I’m happy to hear any reasons there may be other better options. So feel free to throw a tweet at me or leave a comment or three.&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Jetbrains has a pretty solid and reliable product in Team City. It tends to be cohesive in building the core types of applications that we would prospectively have: Java, .NET, Node.js, C/C++ and a few others. That makes it easy to get all projects onto one build server type.&lt;/li&gt;
    &lt;li&gt;TeamCity has intelligence about what is and isn’t available for Java &amp;amp; .NET, enabling various package management and other capabilities without extensive scripting or extra coding needed. There are numerous plugins to help with these capabilities also.&lt;/li&gt;
    &lt;li&gt;TeamCity has fairly solid, quick, and informative support.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Those are my top reasons at this point. Another reason, which isn’t really something I felt should be enumerated, because it’s a feeling versus something I’ve confirmed. That is, the Jenkins Community honestly feels a bit haphazard and disconnected. Maybe I’m just not asking or haven’t seen the right forums to read or something, but I’ve found it a frustrating experience to deal with the Jenkins Server and find information and help regarding getting a disparate and wide ranging set of tech stacks building on it. TeamCity has always just been easy, and getting some continuous integration going the easiest way possible is very appealing.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Monitoring&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We use a number of resources for monitoring of our systems. New Relic is one of them, and they’re great, however it’s a bit tough when things are locked down inside of a closed (physically closed) network. How does one monitor those systems and the respective network? Well, you get &lt;a href=&quot;http://compositecode.com/2015/11/25/nagios-and-ubuntu-64-bit-14-04-lts-setup-configuration/&quot;&gt;Nagios or something of the sort installed and running&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I installed it, but Nagios left me with another one of those dirty feelings like I just spilled a bunch of sour milk everywhere. I went about cleaning up the Nagios mess I’d made and, upon attending the aforementioned Elasticon Tour Stop in Seattle, decided to give Beats a try. After a solid couple weeks of testing and confirming the various things work well and would work well for our specific needs, I went about deploying Beats among our systems.&lt;/p&gt;
&lt;p&gt;So far, albeit only being a few weeks into using Beats (and still learning how to actually make reports in Kibana) Beats appears to have been a good decision. Dramatically more cohesive and not spastically splintered all over the place like Nagios. I’m already looking into adding additional Beats beyond the known three; Topbeats, Packetbeats, and Filebeats. There are a number of other beats that we could add specific to our needs, that would be good open source projects. Stay tuned for those, I’ll talk about them in this space and get a release out to all as soon as we lay a single line of code for those.&lt;/p&gt;
&lt;h2 id=&quot;talent-recon&quot;&gt;Talent Recon&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Currently, nothing to report, but more to come in the space of talent recon.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Docker Tips n' Tricks - Using Vmware Fusion</title>
      <link>http://adron.github.io/articles/docker-tips-n-tricks-vmware-fusion/</link>
      <pubDate>Sat, 02 Jan 2016 00:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/docker-tips-n-tricks-vmware-fusion/</guid>
      <author></author>
      <description>&lt;p&gt;In this article I’m going to cover a few steps in getting started with VMware and Docker instead of the default VirtualBox and Docker. The basic prerequisites for this are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;VMware Fusion &amp;gt;= v8.x &lt;img src=&quot;/articles/docker-tips-n-tricks-vmware-fusion/vmware-fusion.png&quot; alt=&quot;VMware Fusion 8.1.0&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker Toolbox w/ Docker&lt;code&gt;shell-script$ docker --version
Docker version 1.9.0, build 76d6bc9&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To start with, one of the things I didn’t find super intuitive was finding out where boot2docker’s URL is. I then attempted to create the virtual machine several times with what I thought it would be and then realized, to my dismay, that it defaulted to what it generally would need to be. A serious case of &lt;a href=&quot;https://en.wikipedia.org/wiki/RTFM&quot; target=&quot;_blank&quot;&gt;RTFM&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once the prereqs are met, just run the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;docker-machine create nameOfTheVirtualMachine --driver vmwarefusion
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll see the creation results display to the terminal then. They should look something like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Running pre-create checks...
Creating machine...
(fusion-fire) Creating SSH key...
(fusion-fire) Creating VM...
(fusion-fire) Starting fusion-fire...
(fusion-fire) Waiting for VM to come online...
Waiting for machine to be running, this may take a few minutes...
Machine is running, waiting for SSH to be available...
Detecting operating system of created instance...
Detecting the provisioner...
Provisioning with boot2docker...
Copying certs to the local machine directory...
Copying certs to the remote machine...
Setting Docker configuration on the remote daemon...
Checking connection to Docker...
Docker is up and running!
To see how to connect Docker to this machine, run: docker-machine env fusion-fire
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After that, just run that last command from the creation results.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;docker-machine env fusion-fire
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then again you’ll get another results as shown below with another command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.244.159:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/adron/.docker/machine/machines/fusion-fire&amp;quot;
export DOCKER_MACHINE_NAME=&amp;quot;fusion-fire&amp;quot;
# Run this command to configure your shell:
# eval &amp;quot;$(docker-machine env fusion-fire)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Execute the command.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;shell-scripteval &amp;quot;$(docker-machine env fusion-fire)&amp;quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you take a look at the Virtual Machine Library on VMware now you should see your machine, and pop the actual VM open and you should see that standard boot2docker screen with wide open root access to that virtual machine.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/docker-tips-n-tricks-vmware-fusion/vmware-fusion2.png&quot; alt=&quot;VMware boot2docker&quot;&gt;&lt;/p&gt;
&lt;p&gt;At this point I wanted to take the virtual machine for a little spin. I issued the following commands to pull an elasticsearch container, run it, and then get the bash prompt of that running container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;docker pull elasticsearch
docker run -it elasticsearch
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point I saw the log displaying so I killed the run with Ctrl+C, got a list of the just exited container so I could get the Container ID to restart it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;docker ps -a
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then with everything in place I started it and logged into the container instance.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;docker exec -it 257e98847bbb bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which then shows…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;root@257e98847bbb:/#
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’m in. At this point I could work with the container however I’d need to.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Elasticsearch, Beats, and Learning in Portland</title>
      <link>http://adron.github.io/articles/elasticsearch-beats-learning-in-portland/</link>
      <pubDate>Thu, 17 Dec 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/elasticsearch-beats-learning-in-portland/</guid>
      <author></author>
      <description>&lt;p&gt;Recently I attended the &lt;a href=&quot;http://compositecode.com/2015/12/03/elasticon-tour-2015-in-seattle/&quot; target=&quot;_blank&quot;&gt;Elasticon Tour Stop in Seattle&lt;/a&gt; with &lt;a href=&quot;https://twitter.com/thebigscaryguy&quot; target=&quot;_blank&quot;&gt;@thebigscaryguy&lt;/a&gt; &amp;amp; the Elastic Team we have at the Home Depot Quote Center. I have always dug &lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot; target=&quot;_blank&quot;&gt;Elastic Search&lt;/a&gt; a bit and after the tour stop &amp;amp; some research I was very interested in &lt;a href=&quot;https://www.elastic.co/products/beats&quot; target=&quot;_blank&quot;&gt;Beats&lt;/a&gt; too. After that we decided we’d help to kick start the &lt;a href=&quot;http://www.meetup.com/The-Portlandia-ElasticSearch-Meetup-Group/&quot; target=&quot;_blank&quot;&gt;Portland Elastic Meetup&lt;/a&gt; again. So I reached out, as usual, via twitter first for a pulse on interest.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Hey Portlanders! Who uses or is interested in Elastic Search, Beats, Kibana or other Elastic related tech?&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/674358248611307520&quot;&gt;December 8, 2015&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;I got some immediate interest in a few tweets from &lt;a href=&quot;https://twitter.com/WardCunningham&quot; target=&quot;_blank&quot;&gt;@WardCunningham&lt;/a&gt; &lt;a href=&quot;https://twitter.com/tweetcaco&quot; target=&quot;_blank&quot;&gt;@tweetcaco&lt;/a&gt; and others that made me think, “&lt;em&gt;yup, definitely something worth pursuing!&lt;/em&gt;“&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Next Steps…&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Next I’m aiming to get a few speakers lined up. This is where I’d love your help. What would you like to hear about? What would you like to learn? Want to learn more about &lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot; target=&quot;_blank&quot;&gt;Elastic&lt;/a&gt;, &lt;a href=&quot;https://www.elastic.co/products/beats&quot; target=&quot;_blank&quot;&gt;Beats&lt;/a&gt;, or some other &lt;a href=&quot;https://lucene.apache.org/core/&quot; target=&quot;_blank&quot;&gt;Lucene&lt;/a&gt; related, distributed style system, or something inside or even outside of Elastic’s product offerings? Let me know about what you’d like to hear about and the team will make it happen one way or another!&lt;/p&gt;
&lt;p&gt;[googleapps domain=”docs” dir=”forms/d/14cEu_UE61lzXdaqrPtP2w618SjmP7Is3f88CPuHuzI8/viewform” query=”embedded=true” width=”900” height=”1600” /]&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Not Totally Done with 2015, But...</title>
      <link>http://adron.github.io/articles/not-totally-done-with-2015/</link>
      <pubDate>Tue, 15 Dec 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/not-totally-done-with-2015/</guid>
      <author></author>
      <description>&lt;p&gt;I was sitting hacking away on my ride into work (I ride the bus/train so I can get a solid hour of work in before I ever get to the office). I was dorking around with a bash script I’d recently written that was taking the place of a file watcher.&lt;/p&gt;
&lt;p&gt;At the same time I was toying around with keywords and such on a watcher that watches twitter, and stumbled onto @poornima’s tweet.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;What Happens When You Don’t Acknowledge Your Accomplishments: By Poornima Vijayashanker Earlier this week I me… &lt;a href=&quot;https://t.co/OG1wdcPAZi&quot;&gt;https://t.co/OG1wdcPAZi&lt;/a&gt;&lt;/p&gt;&amp;mdash; poornima (@poornima) &lt;a href=&quot;https://twitter.com/poornima/status/677146823883022336&quot;&gt;December 16, 2015&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;At first I just read &lt;a href=&quot;http://femgineer.com/2015/12/what-happens-when-you-dont-acknowledge-your-accomplishments/&quot; target=&quot;_blank&quot;&gt;the article&lt;/a&gt;, but then I thought it would be a good idea to actually write up what I’d accomplished for this year too. Especially being that 2015 has been an exceptional and very different year for me.&lt;/p&gt;
&lt;p&gt;First however, a little context of why 2015 was an exceptional year. 2013 ended in a ridiculous way. I’d just finished 2+ years working as a tech evangelist and product manager &amp;amp; coder for AppFog, Tier 3, and then Basho while writing with the Orchestrate.io Team. I’d however gotten ridiculously burned out by the end of 2013, so I literally took time to sit on my porch, have a beer, and watch the trees blow in the breeze.&lt;/p&gt;
&lt;p&gt;To recover from my burn out I kicked off 2014 by co-founding a start with a friend, Aaron. We proved out a lot of things, for one that 40 hour work weeks are utter bullshit. The whole startup work yourself to the bone is also bullshit. We accomplished a ton of things and built a system with barely any capital whatsoever. I was impressed, and when I showed others they were impressed.&lt;/p&gt;
&lt;p&gt;Then at the end of that, I realized I hadn’t resolved my burn out, it had just abated while I lived the startup life. So I started 2015 off by not doing anything. That’s right, I didn’t do a damn thing. However many in the industry thought I was still working, I still dropped into a meetup here or there, but otherwise I was pretty sick of the whole tech industry. At least, I felt I was sick of it.&lt;/p&gt;
&lt;p&gt;By February I had landed a gig helping out &lt;a href=&quot;https://strongloop.com/&quot; target=&quot;_blank&quot;&gt;Strongloop&lt;/a&gt; put together its curriculum and training material. I even went and delivered some of the training. It was good, but that wasn’t really the exact thing I wanted to do either (it didn’t help that it was all in the suburbs, and that’s another whole point of burn out I have - I’m done with suburbia).&lt;/p&gt;
&lt;p&gt;But as I wrapped that up I put together some more training material and worked on a few side jobs. I realized something at this time, I’d removed so many of my expenses that I was doing fine even without working much at all. I learned that I didn’t need to have the “&lt;em&gt;American Life&lt;/em&gt;“ with a noose around my neck of debt and other nonsense. I was, in essence, debt free, mortgage free, loan free, and I didn’t owe anybody a thing.&lt;/p&gt;
&lt;p&gt;So April rolled around and .NET Fringe happened. That was interesting because I started getting interested in technology again in a huge way. Oddly, not particularly .NET, but just in languages and systems in general. I started digging in again to things that made me curious that I wanted to implement.&lt;/p&gt;
&lt;p&gt;Again, not working but just learning. Then I started working on a contract at CDK Global, helped some interns put together a hackathon team, and generally just enjoyed being in the field and getting things done. Without any tie downs or nooses anywhere to be seen.&lt;/p&gt;
&lt;p&gt;Then I realized, “Holy shit Adron, you’d gotten burned out because of things - often just daily nonsense - that was tying you down and when you’re free and don’t have to live at the whim of managers, loans, money and others you’re happy…”&lt;/p&gt;
&lt;p&gt;At that moment I realized the real accomplishment in 2015. I learned what I need to stay happy in the industry. That’s what I’m doing today, at a strategic level, is staying happy with my work. On a tactical level I’ve been slowly working toward that and the fruits of that work will be self-evident in 2016.&lt;/p&gt;
&lt;p&gt;I hope 2015 kick ass for you, enjoy Star Wars, and see you all in 2016!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Elasticon Tour 2015 in Seattle</title>
      <link>http://adron.github.io/articles/elasticon-tour-2015-in-seattle/</link>
      <pubDate>Wed, 02 Dec 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/elasticon-tour-2015-in-seattle/</guid>
      <author></author>
      <description>&lt;p&gt;Today is the tour stop of the &lt;a href=&quot;https://www.elastic.co/elasticon/tour/2015&quot; target=&quot;_blank&quot;&gt;Elasticon Tour&lt;/a&gt; that swung into Seattle. Myself and some of the &lt;a href=&quot;http://hdquotecenter.com/&quot; target=&quot;_blank&quot;&gt;Home Depot Quote Center&lt;/a&gt; team headed up via the &lt;a href=&quot;http://www.amtrakcascades.com/&quot; target=&quot;_blank&quot;&gt;Geek Train&lt;/a&gt; for the event. We arrived the night before so we could get up and actually be awake and ready for the event.&lt;/p&gt;
&lt;p&gt;Just to note, a good clean place to stay, that isn’t overpriced like most of Seattle is the &lt;a href=&quot;https://www.google.com/search?q=Pioneer+Square+Hotel&amp;amp;oq=Pioneer+Square+Hotel&amp;amp;aqs=chrome..69i57j69i60l3.216j0j7&amp;amp;sourceid=chrome&amp;amp;es_sm=91&amp;amp;ie=UTF-8#safe=off&amp;amp;q=Pioneer+Square+Hotel&amp;amp;rflfq=1&amp;amp;tbm=lcl&amp;amp;rlfi=hd:;si:10477062606859836019&quot; target=&quot;_blank&quot;&gt;Pioneer Square Hotel&lt;/a&gt; - usually about $110-120 bucks. If you’re in town for a conference, sometimes it’s even worth skipping the “preferred hotels” and staying here. But I digress…&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When the team and I walked in we waited a little bit for registration to get started. We stood around and chatted with some of our other cohort. Once the registration did open, we strolled into the main public space and started checking out some demos.&lt;/p&gt;
&lt;h2 id=&quot;streamsets&quot;&gt;StreamSets&lt;/h2&gt;
&lt;p&gt;The first thing I noticed of the demos is something that’s catching a lot of attention. It’s a partner of &lt;a href=&quot;https://www.elastic.co/&quot; target=&quot;_blank&quot;&gt;Elastic’s&lt;/a&gt; called &lt;a href=&quot;http://streamsets.com/&quot; target=&quot;_blank&quot;&gt;StreamSets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset1.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset2.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset3.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;From what I could figure out from just watching the demo is that StreamSets is a ingest engine. That’s simple enough to determine just taking a look at their site. But being able to watch the demo also enlightened me to the way the interface IDE (the thing in the dark pictures above) worked.&lt;/p&gt;
&lt;p&gt;The IDE provided ways to connect to ingestion data with minimal schema and actually start to flow the ingestion of this data through the engine. One of the key things that caught my attention at this point was the tie in with &lt;a href=&quot;http://kafka.apache.org/&quot; target=&quot;_blank&quot;&gt;Kafka&lt;/a&gt; and &lt;a href=&quot;https://hadoop.apache.org/&quot; target=&quot;_blank&quot;&gt;Hadoop&lt;/a&gt; with the respective ingest and egress of data to sources ranging from AWS S3 to things like Elastic’s engine or other various sources that I’ll be working with in the coming months.&lt;/p&gt;
&lt;p&gt;For more information about StreamSets here are a few other solid articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/blog/elasticsearch-plus-streamsets-for-reliable-data-ingestion/&quot; target=&quot;_blank&quot;&gt;Elastic Search Plus StreamSets for Reliable Data Ingestion&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/blog/introducing-the-streamsets-data-collector/&quot; target=&quot;_blank&quot;&gt;Introducing the Streamsets Data Collector&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and connect to keep up with what StreamSets is doing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://twitter.com/streamsets&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and install instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/resources/installing-streamsets/&quot; target=&quot;_blank&quot;&gt;All The Installations&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/resources/installing-streamsets/#install-docker&quot; target=&quot;_blank&quot;&gt;Run via Docker&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and most importantly, the code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/streamsets&quot; target=&quot;_blank&quot;&gt;Github StreamSets&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;beats-not-http-lifehacker-com-are-beats-by-dre-headphones-any-good-1509805994-the-http-lmkprod-com-9-reasons-to-not-buy-beats-by-dre-headphones-lousy-http-forums-macrumors-com-threads-why-not-to-buy-the-beats-by-dre-1376663-target-_blank-dumb-a-a-href-http-www-viewpoints-com-expert-reviews-2013-11-08-why-i-will-never-buy-beats-by-dre-headphones-https-youtu-be-xkvzwj4pz7a-&quot;&gt;Beats (&lt;a href=&quot;http://lifehacker.com/are-beats-by-dre-headphones-any-good-1509805994&quot;&gt;Not&lt;/a&gt; &lt;a href=&quot;http://lmkprod.com/9-reasons-to-not-buy-beats-by-dre-headphones/&quot;&gt;the&lt;/a&gt; &lt;a href=&quot;http://forums.macrumors.com/threads/why-not-to-buy-the-beats-by-dre.1376663/&amp;quot; target=&amp;quot;_blank&amp;quot;&amp;gt;Dumb&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;quot;http://www.viewpoints.com/expert-reviews/2013/11/08/why-i-will-never-buy-beats-by-dre/&quot;&gt;Lousy&lt;/a&gt; &lt;a href=&quot;https://youtu.be/XkVZwj4pZ7A&quot;&gt;Headphones&lt;/a&gt;)&lt;/h2&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;./packetbeat-fish-and-cluster.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Recently I &lt;a href=&quot;http://compositecode.com/2015/11/25/nagios-and-ubuntu-64-bit-14-04-lts-setup-configuration/&quot;&gt;installed Nagios&lt;/a&gt; as I will be doing a lot of systems monitoring, management, and general devops style work in the coming weeks to build out solid site reliability. Nagios will theoretically do a lot of the things I need it to do, but then I stumbled into the recently released &lt;a href=&quot;https://www.elastic.co/products/beats&quot; target=&quot;_blank&quot;&gt;Beats&lt;/a&gt; by &lt;a href=&quot;https://www.elastic.co/&quot; target=&quot;_blank&quot;&gt;Elastic Search&lt;/a&gt; (not by Dre, see above links in the title).&lt;/p&gt;
&lt;p&gt;I won’t even try to explain Beats, because it is super straight forward. I do suggest checking out the site if you’re even slightly interested, but if you just want the quick lowdown, here’s a quote that basically summarizes the tool.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Beats is the platform for building lightweight, open source data shippers for many types of operational data you want to enrich with Logstash, search and analyze in Elasticsearch, and visualize in Kibana. Whether you’re interested in log files, infrastructure metrics, network packets, or any other type of data, Beats serves as the foundation for keeping a beat on your data.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So there ya go, something that collects a ton - if not almost all of - the data that I need to manage and monitor the infrastructure, platforms, network, and more that I’m responsible for. I’m currently diving in, but here’s a few key good bits about Beats that I’m excited to check out.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;./packetbeat-fish-nodes-bkgd.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;1-packetbeat&quot;&gt;1 - PacketBeat&lt;/h3&gt;
&lt;p&gt;This is the real-time network packet analyzer that integrates with Elasticsearch and provides the respective analytics you’d expect. It gives a level of visibility with Beats between all the network servers and such that will prospectively give me insight to were our &lt;em&gt;&lt;a href=&quot;https://youtu.be/f99PcP0aFNE&quot; target=&quot;_blank&quot;&gt;series of tubes&lt;/a&gt; or getting clogged up&lt;/em&gt;. I’m looking forward to seeing our requests mapped up with our responses!  ;)&lt;/p&gt;
&lt;h3 id=&quot;2-filebeat&quot;&gt;2 - FileBeat&lt;/h3&gt;
&lt;p&gt;This is a log data shipper based on the Logstash-Forwarder. At least it was at one point, it appears to look like it is less and less based on it. This beat monitors log directories for log files, tails the fails, and forwards them to Logstash. This completes another important part of what I need to systemically monitor within our systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random fascinating observations:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Did I mention Beats is written in Go? Furtherering Derek’s tweet from 2012!  ;)&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Prediction: Go will become the dominant language for systems work in IaaS, Orchestration, and PaaS in 24 months. &lt;a href=&quot;https://twitter.com/hashtag/golang?src=hash&quot;&gt;#golang&lt;/a&gt;&lt;/p&gt;&amp;mdash; Derek Collison (@derekcollison) &lt;a href=&quot;https://twitter.com/derekcollison/status/245522124666716160&quot;&gt;September 11, 2012&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;Beats has a cool logo, and the design of the tooling is actually solid, as if someone cared about how one would interact with the tools. I’ll see how this holds up as I implement a sample implementation of things with Beats &amp;amp; the various data collectors.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More References &amp;amp; Reading Material for Beats:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.elastic.co/blog/beats-1-0-0&quot; target=&quot;_blank&quot;&gt;Beats 1.0.0 Release&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/elastic/beats&quot; target=&quot;_blank&quot;&gt;Beats on Github&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s it for the highlights so far. If anything else catches my eye this evening at the Elasticon Tour, I’ll get started rambling about it too!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Nagios on Ubuntu 14.04 LTS Setup and Configuration</title>
      <link>http://adron.github.io/articles/nagios-ubuntu-setup-configuration/</link>
      <pubDate>Tue, 24 Nov 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/nagios-ubuntu-setup-configuration/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;h2&gt;1st - The Virtual Machine&lt;/h2&gt;
First I created a virtual machine for use with VMware Fusion on OS-X. Once I got a nice clean Ubuntu 14.04 image setup I installed SSH on it so I could manage it as if it were a headless (i.e. no monitor attached) machine (&lt;a href=&quot;http://compositecode.com/setting-up-ubuntu-with-ssh-wmware-tools-on-vmware-fusion/&quot;&gt;instructions&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In addition to installing openssh, these steps also include build-essential, make, and gcc along with instructions for, but don’t worry about installing VMware Tools. The instructions are cumbersome and in parts just wrong, so skip that. The virtual machine is up and running with ssh and a good C compiler at this point, so we’re all set.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;2nd - The LAMP Stack&lt;/h2&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo apt-get install apache2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once installed the default page will be available on the server, so navigate over to 192.168.x.x and view the page to insure it is up and running.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nagios-ubuntu-setup-configuration/lampsetup.png&quot; alt=&quot;LAMP Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next install mysql and php5 mysql.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo apt-get install mysql-server php5-mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;During this installation you will be prompted for the mysql root account password. It is advisable to set one.&lt;/p&gt;
&lt;p&gt;Then you will be asked to enter the password (the one you just set about 2 seconds ago) for the MySQL root account. Next, it will ask you if you want to change that password. Select ‘n’ so as not to create another password for the root acount since you’ve already created the password just a few seconds before.&lt;/p&gt;
&lt;p&gt;For the rest of the questions, you should simply hit the enter key for each prompt. This will accept the default values. This will remove some sample users and databases, disable remote root logins, and load these new rules so that MySQL immediately respects the changes we have made.&lt;/p&gt;
&lt;p&gt;Next up is to install PHP. No grumbling, just install PHP.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo apt-get install php5 libapache2-mod-php5 php5-mcrypt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next let’s open up dir.conf and change a small section to change what files apache will provide upon request. Here’s what the edit should look like.&lt;/p&gt;
&lt;p&gt;Open up the file to edit. (in vi, to insert or edit, hit the ‘i’ button. To save hit escape and ‘:w’ and to exit vi after saving it escape and then ‘:q’. To force exit without saving hit escape and ‘:q!’)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo vi /etc/apache2/mods-enabled/dir.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is what the file will likely look like once opened.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;&amp;lt;IfModule mod_dir.c&amp;gt;
DirectoryIndex index.html index.cgi index.pl index.php index.xhtml index.htm
&amp;lt;/IfModule&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Move the index.php file to the beginning of the DirectoryIndex list.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;&amp;lt;IfModule mod_dir.c&amp;gt;
DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm
&amp;lt;/IfModule&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now restart apache so the changes will take effect.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo service apache2 restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next let’s setup some public key for authentication. On your local box complete the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;ssh-keygen
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don’t enter a passphrase, you will be able to use the private key for auth without entering a passphrase. If you’ve entered one, you’ll need it and the private key to log in. Securing your keys with passphrases is more secure, but either way the system is more secure this way then with basic password authentication. For this particular situation, I’m skipping the passphrase.&lt;/p&gt;
&lt;p&gt;What is generated is id_rsa, the private key and the id_rsa.pub the public key. They’re put in a directory called .ssh of the local user.&lt;/p&gt;
&lt;p&gt;At this point copy the public key to the remote server. On OS-X grab the easy to use ssh-copy-id script with this command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;brew install ssh-copy-id
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl -L https://raw.githubusercontent.com/beautifulcode/ssh-copy-id-for-OSX/master/install.sh | sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then use the script to copy the ssh key to the server.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;ssh-copy-id adron@192.168.x.x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next let’s setup some public key for authentication. On your local box complete the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;ssh-keygen
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That should give you the ability to log into the machine without a password everytime. Give it a try.&lt;/p&gt;
&lt;p&gt;Ok, so now on to the meat of this entry, Nagios itself.&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;Nagios Installation&lt;/h2&gt;
Create a user and group that will be used to run the Nagios process.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo useradd nagios
sudo groupadd nagcmd
sudo usermod -a -G nagcmd nagios
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install these other essentials.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo apt-get install libgd2-xpm-dev openssl libssl-dev xinetd apache2-utils unzip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Download the source and extract it, then change into the directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl -L -O https://assets.nagios.com/downloads/nagioscore/releases/nagios-4.1.1.tar.gz
tar xvf nagios-*.tar.gz
cd nagios-*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next run the command to configure Nagios with the appropriate user and group.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;./configure --with-nagios-group=nagios --with-command-group=nagcmd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When the configuration is done you’ll see a display like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Creating sample config files in sample-config/ ...

*** Configuration summary for nagios 4.1.1 08-19-2015 ***:

General Options:
-------------------------
Nagios executable: nagios
Nagios user/group: nagios,nagios
Command user/group: nagios,nagcmd
Event Broker: yes
Install ${prefix}: /usr/local/nagios
Install ${includedir}: /usr/local/nagios/include/nagios
Lock file: ${prefix}/var/nagios.lock
Check result directory: ${prefix}/var/spool/checkresults
Init directory: /etc/init.d
Apache conf.d directory: /etc/httpd/conf.d
Mail program: /bin/mail
Host OS: linux-gnu
IOBroker Method: epoll

Web Interface Options:
------------------------
HTML URL: http://localhost/nagios/
CGI URL: http://localhost/nagios/cgi-bin/
Traceroute (used by WAP):

Review the options above for accuracy. If they look okay,
type &amp;#39;make all&amp;#39; to compile the main program and CGIs.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now run the following make commands. First run make all as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;make all
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that runs the following will be displayed upon success. I’ve included it here as there are a few useful commands in it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;*** Compile finished ***

If the main program and CGIs compiled without any errors, you
can continue with installing Nagios as follows (type &amp;#39;make&amp;#39;
without any arguments for a list of all possible options):

make install
- This installs the main program, CGIs, and HTML files

make install-init
- This installs the init script in /etc/init.d

make install-commandmode
- This installs and configures permissions on the
directory for holding the external command file

make install-config
- This installs *SAMPLE* config files in /usr/local/nagios/etc
You&amp;#39;ll have to modify these sample files before you can
use Nagios. Read the HTML documentation for more info
on doing this. Pay particular attention to the docs on
object configuration files, as they determine what/how
things get monitored!

make install-webconf
- This installs the Apache config file for the Nagios
web interface

make install-exfoliation
- This installs the Exfoliation theme for the Nagios
web interface

make install-classicui
- This installs the classic theme for the Nagios
web interface

*** Support Notes *******************************************

If you have questions about configuring or running Nagios,
please make sure that you:

- Look at the sample config files
- Read the documentation on the Nagios Library at:
https://library.nagios.com

before you post a question to one of the mailing lists.
Also make sure to include pertinent information that could
help others help you. This might include:

- What version of Nagios you are using
- What version of the plugins you are using
- Relevant snippets from your config files
- Relevant error messages from the Nagios log file

For more information on obtaining support for Nagios, visit:

https://support.nagios.com

*************************************************************

Enjoy.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After that successfully finishes, then execute the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo make install
sudo make install-commandmode
sudo make install-init
sudo make install-config
sudo /usr/bin/install -c -m 644 sample-config/httpd.conf /etc/apache2/sites-available/nagios.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now some tinkering to setup the web server user in www-data and nagcmd group.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo usermod -G nagcmd www-data
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now some Nagios plugins. You can find the plugins listed for download here: &lt;a href=&quot;http://nagios-plugins.org/download/&quot;&gt;http://nagios-plugins.org/download/&lt;/a&gt; The following are based on the 2.1.1 release of plugins.&lt;/p&gt;
&lt;p&gt;Change back out to the user directory on the server and download, tar, and change into the newly unzipped files.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;cd ~
curl -L -O http://nagios-plugins.org/download/nagios-plugins-2.1.1.tar.gz
tar xvf nagios-plugins-*.tar.gz
cd nagios-plugins-*
./configure --with-nagios-user=nagios --with-nagios-group=nagios --with-openssl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now for some ole compilation magic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;make
sudo make install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now pretty much the same things for NRPE. Look &lt;a href=&quot;http://sourceforge.net/projects/nagios/files/nrpe-2.x/&quot;&gt;here&lt;/a&gt; to insure that 2.15 is the latest version.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;cd ~
curl -L -O http://downloads.sourceforge.net/project/nagios/nrpe-2.x/nrpe-2.15/nrpe-2.15.tar.gz
tar xvf nrpe-*.tar.gz
cd nrpe-*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then configure the NRPE bits.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;./configure --enable-command-args --with-nagios-user=nagios --with-nagios-group=nagios --with-ssl=/usr/bin/openssl --with-ssl-lib=/usr/lib/x86_64-linux-gnu
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then get to making it all.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;make all
sudo make install
sudo make install-xinetd
sudo make install-daemon-config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then a little file editing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo vi /etc/xinetd.d/nrpe
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the file for the line only_from to include the following where 192.x.x.x is the IP of the Nagios Server.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;only_from = 127.0.0.1 192.x.x.x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save the file, and restart the Nagios server service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo service xinetd restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now begins the Nagios Server configuration. Edit the Nagios configuration file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo vi /usr/local/nagios/etc/nagios.cfg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find this line and uncomment the line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;#cfg_dir=/usr/local/nagios/etc/servers
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save it and exit.&lt;/p&gt;
&lt;p&gt;Next creat the configuration file for the servers to monitor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo mkdir /usr/local/nagios/etc/servers
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next configure the contacts config file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo vi /usr/local/nagios/etc/objects/contacts.cfg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fine this line and set the email address to one you’ll be using.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;email adronsemail@compositecode.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now add a Nagios service definition for the check_nrpe command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo vi /usr/local/nagios/etc/objects/commands.cfg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add this to the end of the file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;define command{
command_name check_nrpe
command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Save and exit the file.&lt;/p&gt;
&lt;p&gt;Now a few last touches for configuration in Apache. We’ll want the Apache rewrite and cgi modules enabled.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo a2enmod rewrite
sudo a2enmod cgi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now create an admin user, we’ll call them ‘nagiosadmin’.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a symbolic link of nagios.conf to the sites-enabled directory and then start the Nagios server and restart apache2.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo ln -s /etc/apache2/sites-available/nagios.conf /etc/apache2/sites-enabled/
sudo service nagios start
sudo service apache2 restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Enable Nagios to start on server boot (because, ya know, that’s what this server is going to be used for).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo ln -s /etc/init.d/nagios /etc/rcS.d/S99nagios
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now navigate to the server and you’ll be prompted to login to the web user interface.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nagios-ubuntu-setup-configuration/nagioslogin.png&quot; alt=&quot;Nagios Login&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now begins the process of setting up servers you want to monitor… stay tuned, more to come.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Using the File System fs.* with Node.js</title>
      <link>http://adron.github.io/articles/using-the-file-system-fs-w-nodejs/</link>
      <pubDate>Sun, 22 Nov 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/using-the-file-system-fs-w-nodejs/</guid>
      <author></author>
      <description>&lt;p&gt;I have a few basic tasks that I need to perform on the file system with Node.js. I’m going to clone a repository into a directory, but before that, if the directory that the clone action will put the repository in exists, I’d like to do something with that directory first. To check for the existence of the directory I quickly found two functions that work well for this purpose.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;First there is the asynchronously executing “exists” function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; fs = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'fs'&lt;/span&gt;);

fs.exists(&lt;span class=&quot;string&quot;&gt;'/etc/passwd'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;exists&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(exists ? &lt;span class=&quot;string&quot;&gt;&quot;it's there&quot;&lt;/span&gt; : &lt;span class=&quot;string&quot;&gt;'no passwd!'&lt;/span&gt;);
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function takes the path, passed in, then has a callback that can then react to the result which is true or false. A similar function for a synchronous call is available too, called “existsSync”.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; fs = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'fs'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; result = fs.existsSync(path)

&lt;span class=&quot;comment&quot;&gt;// result will be true or false.&lt;/span&gt;
&lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(result);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now there is one major problem with these two functions. Currently, they’re marked as “deprecated” with a stability expectation of 0. This means simply, that they’re likely to go away in the near future. Now, I hate the idea of using these functions with the idea that I upgrade to a new version one day and my application is nuked. That just isn’t really acceptable.&lt;/p&gt;
&lt;p&gt;So I go digging around at the other functions that the documentation states to use instead. For the asynchronous fs.exists(path, callback) function it states to use “fs.stat” or “fs.access” instead. Let’s take a look at these two first.&lt;/p&gt;
&lt;p&gt;The “fs.stat” function is very similar to “fs.exists” in calling signature, it takes a path and a callback to execute. I created the short snippet below to show what this function looks like.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; fs = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'fs'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; path2 = &lt;span class=&quot;string&quot;&gt;'thisShouldntExist'&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; path1 = &lt;span class=&quot;string&quot;&gt;'newdirectory'&lt;/span&gt;;

&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;myDirectoryExistsCheck&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;path&lt;/span&gt;) &lt;/span&gt;{
  fs.stat(path2, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, stat&lt;/span&gt;) &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err.code === &lt;span class=&quot;string&quot;&gt;'ENOENT'&lt;/span&gt;) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'No file asynchronously found.'&lt;/span&gt;)
    } &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err)
    } &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'File found asynchronously - Mode: '&lt;/span&gt; + stat.mode + &lt;span class=&quot;string&quot;&gt;' Size: '&lt;/span&gt; + stat.size);
    }
  });
}

myDirectoryExistsCheck(path1);
myDirectoryExistsCheck(path2);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the first call finding a directory and the second call not finding a directory, here’s the results I got from this code snippet.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;File found asynchronously - Mode: 16877 Size: 102
No file asynchronously found.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the first functions, which are now deprecated, the amount of code has ballooned up pretty dramatically over making a standard function call with a true or false result, to something where I have to confirm based off of the data returned in a fs.stats object. I wrote a little console.log code just to show what this object looks like when it is printed out. This…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;fs.stat(path1, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, stat&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(stat);
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…prints out this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;{ dev: 16777220,
  mode: 16877,
  nlink: 3,
  uid: 501,
  gid: 20,
  rdev: 0,
  blksize: 4096,
  ino: 10692619,
  size: 102,
  blocks: 0,
  atime: Mon Nov 23 2015 11:23:55 GMT-0800 (PST),
  mtime: Mon Nov 23 2015 11:20:14 GMT-0800 (PST),
  ctime: Mon Nov 23 2015 11:20:14 GMT-0800 (PST),
  birthtime: Mon Nov 23 2015 11:19:40 GMT-0800 (PST) }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s kind of nice to have an object come back with data that one can use to derive a result from, but it’s kind of a bummer when all I want to do is write code that checks for existence and returns true or false. Now, in either case, if an error occurs, such as what happens when a file or directory is not found with the “fs.stat” function, the result looks like this.  This…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;fs.stat(path2, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, stat&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err);
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…prints out this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;{ [Error: ENOENT: no such file or directory, stat &amp;#39;thisShouldntExist&amp;#39;]
  errno: -2,
  code: &amp;#39;ENOENT&amp;#39;,
  syscall: &amp;#39;stat&amp;#39;,
  path: &amp;#39;thisShouldntExist&amp;#39; }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another thing I added, to show two useful functions when there is a file or directory present is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;fs.stat(path, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, stat&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err.code === &lt;span class=&quot;string&quot;&gt;'ENOENT'&lt;/span&gt;) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'No file asynchronously found.'&lt;/span&gt;);
    } &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Some other error occurred.'&lt;/span&gt;);
    }
  } &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'File found asynchronously - Mode: '&lt;/span&gt; + stat.mode + &lt;span class=&quot;string&quot;&gt;' Size: '&lt;/span&gt; + stat.size);
    &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Other things to checks:'&lt;/span&gt;);
    &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'  - '&lt;/span&gt; + stat.isFile());
    &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'  - '&lt;/span&gt; + stat.isDirectory());
  }
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This of course checks for errors, which will be thrown if there is not a file or directory to find. But if there is, the stat object that is returned asynchronously via the callback has several functions attached, the two that are immediately useful for me are the “isFile()” and “isDirectory()” functions. They’re pretty self explanatory.&lt;/p&gt;
&lt;p&gt;Now, of course this still means you’re writing code to deal with errors instead of what the “fs.exists” functions would do. So really, what needs to be done is a wrapper needs to be written to handle the somewhat basic and crude handling of the file system. But since this is such a common need for many applications, I thought, “hey, time to check and see if there’s some npm library bagic that’s available!” …and oddly enough I wasn’t impressed by anything I could dig up. Maybe search-fu wasn’t so hot. But it looks like I’ll be building up this stuff from scratch. With that, happy hacking and I’ll be back later with more…&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Docker Tips n' Tricks - Delete All The Images &amp; Containers</title>
      <link>http://adron.github.io/articles/docker-tips-n-tricks-delete-all-the-images-containers/</link>
      <pubDate>Sun, 01 Nov 2015 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/docker-tips-n-tricks-delete-all-the-images-containers/</guid>
      <author></author>
      <description>&lt;p&gt;Two simple commands that’ll wipe your installation clean of images and containers.&lt;/p&gt;
&lt;p&gt;Deletes all containers&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker rm $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Deletes all images&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>After 816 Days I'm Taking a Job!</title>
      <link>http://adron.github.io/articles/after-816-days-taking-a-job/</link>
      <pubDate>Fri, 30 Oct 2015 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/after-816-days-taking-a-job/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/after-816-days-taking-a-job/header.jpg&quot; alt=&quot;MAX Train&quot;&gt;&lt;/p&gt;
&lt;p&gt;The new mission, or as some may call it, a job! The context for those that might not be familiar with my adventures is that I’ve been working independently as a consultant, contractor, community builder, beer drinker, hacker, teacher, trainer, mentor, curriculum builder, and training content creator. The last time I held something that resembled a job was 560 business days ago, or more specifically 816 days ago. Honestly, I’m not even sure that &lt;a href=&quot;http://compositecode.wordpress.com/2012/11/21/sitrep-thor-iron-foundry-basho/&quot; target=&quot;_blank&quot;&gt;it could be considered a job, it was a strange gig to say the least&lt;/a&gt;. Recently after this long break I’m taking up a new job position with some interesting objectives and priorities.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s some of what I wrote to outline the specific objectives and priorities for the new team I’m joining and to insure I had clear priorities for myself. I do, after all, prize clear objectives very high on the “&lt;em&gt;things that are useful &amp;amp; cool&lt;/em&gt;“ list.&lt;/p&gt;
&lt;h2 id=&quot;objectives&quot;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Community Contributions&lt;/strong&gt; - Help launch and build the community around the release of a yet to be announced open source micro-services framework (we’re currently calling it the &lt;em&gt;Forge Framework&lt;/em&gt;) following an open source software model. I’ll also be telling you about all the work that has gone into this framework so far form Jesse, Beau, and the team. This will cover their various battles, from discussions to decisions, all leading up to the release of the framework. At this point, our time frame to release this is somewhere around the Feburary time frame. Currently it is in production, but we will need to make sure we have a reason repository of code we can release. We’re aiming for it to be in good shape for everybody to use when it’s released. &lt;em&gt;(I’ll be managing the overall effort, so ping me if you’re interested in jumping into the project)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site Reliability&lt;/strong&gt; - Help build infrastructure for site reliability, deployment, etc (immutable, container based, etc) to deliver the company’s key products, APIs, micro-services, and improve the back-end deployment and delivery options and capabilities. This is going to include a lot of cool technology including things like Docker, kafka, CoreCLR, and a host of other things that I’ll be blogging about on a regular basis. Along with this infrastructure and site reliability I’ll help set guidelines, approaches, and future objectives for delivery and deployment of software. When I implement things, I’ll aim to blog it, when I learn new tips and tricks, I’ll aim to blog it, and whenever I break a build, I’ll blog that too. Whatever it is, I’m aiming to increase my frequency a great deal in the coming days, weeks, and months.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Talent Recon&lt;/strong&gt; - I’m looking for, scouting around like force recon, and connecting talent to future work we will be having come open in early 2016. (Again, this is where I get to come and hack with you, help build awesome open source software, and let you my fellow coding cohort know about the company’s existing and upcoming awesome work we’ll be hiring for! For those that know me, you know I’m serious about making sure I line up the right people with the right types of gigs, I’m no recruiter, I’m a coder, so I fight against wildly innappropriate misalignment and related silliness!)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are my top priorities as I step into this role with the &lt;a href=&quot;http://hdquotecenter.com/&quot; target=&quot;_blank&quot;&gt;Quote Center&lt;/a&gt;, a kind of &lt;strong&gt;&lt;em&gt;laboratory of inventive ideas&lt;/em&gt;&lt;/strong&gt; for &lt;a href=&quot;http://www.homedepot.com/&quot; target=&quot;_blank&quot;&gt;Home Depot&lt;/a&gt;. You’ll be hearing a lot more about this in the coming days, and if you’re interested in working with me and an awesome group of people - reach out and let me know &lt;a href=&quot;https://twitter.com/adron&quot; target=&quot;_blank&quot;&gt;@Adron&lt;/a&gt; on Twitter or just email me. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Latest 5th Generation Dell XPS 13 Developer Edition</title>
      <link>http://adron.github.io/articles/latest-fifth-gen-dell-xps-13-developer-edition/</link>
      <pubDate>Wed, 22 Jul 2015 14:54:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/latest-fifth-gen-dell-xps-13-developer-edition/</guid>
      <author></author>
      <description>&lt;p&gt;Just about 4 weeks ago now I purchased a Dell XPS 13 Developer Edition directly from Dell. The reason I purchased this laptop is because of two needs I have while traveling and writing code.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I wanted something &lt;em&gt;small&lt;/em&gt;, &lt;em&gt;compact&lt;/em&gt;, that had &lt;em&gt;reasonable power&lt;/em&gt;, and…&lt;/li&gt;
&lt;li&gt;It needed to run &lt;em&gt;Linux&lt;/em&gt; (likely &lt;em&gt;Ubuntu&lt;/em&gt;, but I’d have taken whatever) from the factory and have active support.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s my experience with this machine so far. There are lots of good things, and some really lousy things about this laptop. This is the lowdown on all the plusses and minuses. But before I dive into the plusses and minuses, it is important to understand more of the context in which I’m doing this review.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dell didn’t send me a free laptop. I paid $1869 for the laptop. Nobody has paid me to review this laptop. I purchased it and am reviewing it purely out of my own interest.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;&lt;a href=&quot;http://www.dell.com/us/business/p/xps-13-linux/pd&quot; target=&quot;_blank&quot;&gt;XPS 13 Developer Edition&lt;/a&gt;&lt;/strong&gt; that I have has &lt;em&gt;8GB RAM&lt;/em&gt;, &lt;em&gt;512 GB SSD&lt;/em&gt;, and the stunningly beautiful 13.3-inch &lt;em&gt;UltraSharp™ QHD+ (3200 x 1800) InfinityEdge Touch Display&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exterior Chassis Materials&lt;/strong&gt; -&amp;gt; CNC machined aluminum w/ Edge-to-edge Corning® Gorilla® Glass NBT™ on QHD+ w/ Carbon fiber composite palm rest with soft touch paint.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Keyboard&lt;/strong&gt; -&amp;gt; Full size, backlit chiclet keyboard; 1.3mm travel&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Touchpad&lt;/strong&gt; -&amp;gt; Precision touchpad, seamless glass integrated button&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;negatives&quot;&gt;Negatives&lt;/h2&gt;
&lt;h3 id=&quot;the-freakin-keyboard-and-trackpad&quot;&gt;The Freakin’ Keyboard and Trackpad&lt;/h3&gt;
&lt;p&gt;Let’s talk about the negatives first. This way, if you’re looking into purchasing, this will be a faster way to go through the decision tree. The first and the LARGEST negative is the keyboard. Let’s just talk about the keyboard for a moment. When I first tweeted about this laptop, one of the first responses I got in relation to this machine was a complaint - and a legitimate one at that - is the blasted keyboard.&lt;/p&gt;
&lt;p&gt;There are plenty of complaints and issues listed &lt;a href=&quot;http://www.dell.com/support/article/us/en/19/SLN297563/EN&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;http://en.community.dell.com/techcenter/os-applications/f/4613/t/19470368&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;http://en.community.dell.com/techcenter/os-applications/f/4613/t/19627933&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; via the Dell Support site. Twitter is flowing with such too about the keyboard. To summarise, the keyboard sticks. The trackpad, by association, also has some sticky behavior.&lt;/p&gt;
&lt;p&gt;Now I’m going to say something that I’m sure some might fuss and hem and haw about. I don’t find the keyboard all that bad, considering it’s not an Apple chiclet keyboard and Apple trackpad, which basically make everything else on the market seem unresponsive and unable to deal with tactile response in a precise way. In that sense, the Dell keyboard is fine. I just have to be precise and understand how it behaves. So far, that seems to resolve the issue for me, same for the trackpad related issues. But if you’re someone who doesn’t type with distinct precision - just forget this laptop right now. It’s not even worth the effort. However, if you are precise, read on.&lt;/p&gt;
&lt;h3 id=&quot;the-sleeping-issue&quot;&gt;The Sleeping Issue&lt;/h3&gt;
&lt;p&gt;When I first received the laptop several weeks ago it had a sleeping issue. Approximately 1 out of every 3-5 times I’d put the computer to sleep it wouldn’t resume from sleep appropriately. It would either hang or not resume. This problem however, has a pretty clean fix available &lt;a href=&quot;http://www.dell.com/support/article/uk/en/ukdhs1/SLN297551/en&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;…issue with your XPS 13 (9343) system failing to  resume from suspend while running Ubuntu 14.04? See here: &lt;a href=&quot;http://t.co/EZDxp5wTct&quot;&gt;http://t.co/EZDxp5wTct&lt;/a&gt; &amp;lt;- THAT&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/621744827617669120&quot;&gt;July 16, 2015&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;not-performant&quot;&gt;Not Performant&lt;/h3&gt;
&lt;p&gt;Ok, so it has 8GB RAM, and SSD, and an i7 Proc. However it does not perform better than my 2 year old Mac Book Air (&lt;em&gt;i7, 8 GB RAM, 256 GB SSD&lt;/em&gt;). It’s horribly slow compared to my 15” Retina w/ 16GB RAM and i7 Proc. Matter of fact, it doesn’t measure up well against any of these Apple machines. Linux however has a dramatically smaller footprint and generally performs a lot of tasks as well or better than OS-X.&lt;/p&gt;
&lt;p&gt;When I loaded Steam and tried a few games out, the machine wasn’t even as performant as my Dell 17” from 2006. That’s right, I didn’t mistype that, my Dell from 2006. So WTF you might ask - I can only guess that it’s the embedded video card and shared video card memory or something. I’m still trying to figure out what the deal is with some of these performance issues.&lt;/p&gt;
&lt;p&gt;However…   on to the positives. Because there is also positives about the performance it does have.&lt;/p&gt;
&lt;h2 id=&quot;positives&quot;&gt;Positives&lt;/h2&gt;
&lt;h3 id=&quot;the-packaging&quot;&gt;The Packaging&lt;/h3&gt;
&lt;p&gt;Well the first thing you’ll notice, that I found to be a positive, albeit an insignificant one but it did make for a nice first experience is the packaging. Dell has really upped their game in this regard, instead of being the low-end game, Dell seems to have gotten some style and design put together for the packaging.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/01.jpg&quot; alt=&quot;Dell XPS 13 Developer Edition Box&quot;&gt;&lt;/p&gt;
&lt;p&gt;The box was smooth, and seamless in most ways. Giving a very elegant feel. When I opened up the box the entire laptop was in the cut plastic wrap to protect all the surfaces.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/02.jpg&quot; alt=&quot;Plastic Glimmer from protective plastics&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/03.jpg&quot; alt=&quot;Umm, what is this paper booklet stuff. :-/&quot;&gt;&lt;/p&gt;
&lt;p&gt;Removing the cut plastic is easy enough. It is held together with just some simple stickiness (some type of clean glue).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/04.jpg&quot; alt=&quot;Removing the Plastic&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once off the glimmer of the machine starts to really show. The aluminum surface material is really really nice.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/05.jpg&quot; alt=&quot;A Side View of the XPS 13&quot;&gt;&lt;/p&gt;
&lt;p&gt;The beauty of an untainted machine running Ubuntu Linux. Check out that slick carbon fiber mesh too.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/06.jpg&quot; alt=&quot;Carbon Fiber Mesh&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here it is opened and unwrapped, not turned on yet and the glimmer of that glossy screen can be seen already.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/07.jpg&quot; alt=&quot;A Glimmer of the Screen&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here’s a side by side comparison of the screens for the glossy hi res screen against the flat standard res screen. Both are absolutely gorgeous screens, regardless of which you get.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/08.jpg&quot; alt=&quot;XPS 13 Twins&quot;&gt;&lt;/p&gt;
&lt;p&gt;Booting up you can see the glimmer on my XPS 13.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/09.jpg&quot; alt=&quot;Glimmer on the Bootup&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;the-screen&quot;&gt;The Screen&lt;/h3&gt;
&lt;p&gt;The screen, even during simple bootup and first configuration of Ubuntu like this it is evident that the screen is stunning. The retina quality screen on such a small form factor is worth the laptop alone. The working resolution is 1920x1080, but of course the real resolution is 3200x1800. Now, if you want, you could run things at this resolution at your own risk to blindness and eye strain, but it is possible.&lt;/p&gt;
&lt;p&gt;The crispness of this screen is easily one of the best on the market today and rivals that of the retina screens on any of the 13” or 15” Apple machines. The other aspect of the screen, which isn’t super relevant when suing Ubuntu is that it is touch enabled. So you can poke things and certain things will happen, albeit Ubuntu isn’t exactly configured for touch display. In the end, it’s basically irrelevant that it is a touch screen too, except in the impressive idea that they got a touch screen of this depth on such a small machine!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/10.jpg&quot; alt=&quot;Booted Up&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here’s a little more of the glimmer, as I download the necessary things to do some F# builds.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/11.jpg&quot; alt=&quot;Setting up F#&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;performance-and-boot-time&quot;&gt;Performance and Boot Time&lt;/h3&gt;
&lt;p&gt;Boot time is decent. I’m not going to go into the seconds it takes but it’s quick. Also when you get the update for sleep, that’s really quick too. So no issue there at all.&lt;/p&gt;
&lt;p&gt;On the performance front, as I mentioned in the negatives there are some issues with performance. However, for many - if not most - everyday developer tasks like building C#, F#, C++, C, Java, and a host of other languages the machine is actually fairly performant.&lt;/p&gt;
&lt;p&gt;In doing other tasks around Ruby, PHP (yes, I wrote a little bit of PHP just to check it out, but I did it safely and deleted it afterwards), JavaScript, Node.js, and related web tasks were also very smooth, quick, and performant. I installed Atom, Sublime 3, WebStorm, and Visual Studio Code and tried these out for most of the above web development. Everything loads really fast on the machine and after a few loads they even get more responsive, especially WebStorm since it seems to load Java plus the universe.&lt;/p&gt;
&lt;p&gt;Overall, if you do web development or some pretty standard compilable code work then you’ll be all set with this machine. I’ve been very happy with it’s performance in these areas, just don’t expect to play any cool games with the machine.&lt;/p&gt;
&lt;h3 id=&quot;weight-and-size&quot;&gt;Weight and Size&lt;/h3&gt;
&lt;p&gt;I’ll kick this positive feature off with some addition photos of the laptop compared to a Mac Book Pro 15” Retina and a Apple Air 13”.&lt;/p&gt;
&lt;p&gt;First the 13” Air.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/12.jpg&quot; alt=&quot;Stacked from the side.&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/13.jpg&quot; alt=&quot;USB, Power, Headphones and Related Ports up close.&quot;&gt;&lt;/p&gt;
&lt;p&gt;No the Mac Book Pro 15” Retina&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/14.jpg&quot; alt=&quot;MBP 15&amp;quot;. The XSP 13 is considerably smaller - as it obviously would be.&quot;&gt;&lt;/p&gt;
&lt;p&gt;…and then on top of the Mac Air 13”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/15.jpg&quot; alt=&quot;On top of the MBA 13&amp;quot;&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/16.jpg&quot; alt=&quot;The 13&amp;quot; sitting on top of the 15&amp;quot; Retina&quot;&gt;&lt;/p&gt;
&lt;p&gt;Of course there are smaller Mac Book Pros and Mac Book Air Laptops, but these are the two I had on hand (and still use regularly) to do a quick comparison with. The 13” Dell is considerably smaller in overall footprint and is as light or lighter than both of these laptops. The XPS makes for a great laptop for carrying around all the time, and really not even noticing its presence.&lt;/p&gt;
&lt;h3 id=&quot;battery-life&quot;&gt;Battery Life&lt;/h3&gt;
&lt;p&gt;The new XPS 13 battery life, with Ubuntu, is a solid 6-12 hours depending on activity. I mention Ubuntu, because as anybody knows the Linux options on conserving battery life are a bit awkward. Namely, they don’t always do so well. But with managing the screen lighting, back light, and resource intensive applications it would be possible to even exceed the 12 hour lifespan of the batter with Ubuntu. I expect with Windows the lifespan is probably 10-15% better than under Ubuntu. That is, without any tweaks or manual management of Ubuntu.&lt;/p&gt;
&lt;p&gt;So if you’re looking for a long batter life, and Apple options aren’t on the table, this is definitely a great option for working long hours without needing to be plugged in.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/beer.png&quot; alt=&quot;Cheers!&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Overall, a spectacular laptop in MOST ways. However that keyboard is a serious problem for most people. I can imagine most people will NOT want to deal with the keyboard. I’m ok with it, but I don’t mind typing with hands up and off the resting points on the laptop. If Dell can fix this I’d give it a 100% buy suggestion, but with the keyboard as buggy and flaky as it is, I give the laptop at 60% buy suggestion. If you’re looking for a machine with Ubuntu out of the box, I’d probably aim for a Lenovo until Dell fixes the keyboard situation. Then I’d even suggest this machine over the Lenovo options.&lt;/p&gt;
&lt;p&gt;…and among all things, I’d still suggest running Linux on a MBA or MBP over any of these - the machines are just more solid in manufacturing quality, durability, and the tech (i.e. battery, screen, etc) are still tops in many ways. But if you don’t want to feed the Apple Nation’s Piggy Bank, dump them and go with this Dell or maybe a Lenovo option.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Happy hacking and cheers!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>AWS Beanstalk Worker with Node.js and SQS</title>
      <link>http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/</link>
      <pubDate>Tue, 18 Nov 2014 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/amazon-sqs_200x200.png&quot; alt=&quot;Amazon SQS&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First I created a project for the node.js worker. The first steps for this are identical to that of creating the Hapi.js site that publishes messages to the queue. Go through these three steps for the worker and then I’ll continue from there.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish#webapplication&quot;&gt;create the web application&lt;/a&gt; which will act as our worker service. I gave mine the name of &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;testing-aws-sqs-worker&lt;/a&gt;, the site publishing to the queue I called &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;testing-aws-sqs-site&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Next &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/#mocha&quot;&gt;add dependencies needed&lt;/a&gt;, like mocha.&lt;/li&gt;
&lt;li&gt;Finally make sure the &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/#aws&quot;&gt;AWS environment variables&lt;/a&gt; are set appropriately.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;…and now on to the security, configuration and worker specific parts of this series…&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security Needs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before getting the actual worker setup I need to have a role setup in IAM (&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once here click on the Roles section of IAM. Then click on Create New Role.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next set the role name.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now select Amazon EC2 here. I noted this wasn’t immediately intuitive. But once I realized that the security item I’m looking for is a sub-item under Amazon EC2 things made more sense.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next next odd thing that occurred in this web wizard was that the number 3 step is skipped. Again, that took me a second to realize maybe that’s an optional step. Whatever the case, it shouldn’t be displayed unless it’s a step that might actually occur in all paths, otherwise just make it disappear. Anyway, step 4 is where the next step awaits.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next step I’ll add the JSON that defines this role. It looks like this in the wizard (and I’ve included the actual JSON just below the image of the wizard). NOTE: In this screen shot I’ve named the role one thing, but when I select it below I’ve actually renamed it to “serverComms”. These two are indeed the same role, I just didn’t want to go back and redo all the screenshots around a minor rename. :)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-07.png&quot; alt=&quot;Screen 7&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;Version&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;2012-10-17&quot;&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;Statement&quot;&lt;/span&gt;: [
    {
      &lt;span class=&quot;string&quot;&gt;&quot;Sid&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;QueueAccess&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Action&quot;&lt;/span&gt;: [
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:ChangeMessageVisibility&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:DeleteMessage&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:ReceiveMessage&quot;&lt;/span&gt;
      ],
      &lt;span class=&quot;string&quot;&gt;&quot;Effect&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Allow&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Resource&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;*&quot;&lt;/span&gt;
    },
    {
      &lt;span class=&quot;string&quot;&gt;&quot;Sid&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;MetricsAccess&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Action&quot;&lt;/span&gt;: [
        &lt;span class=&quot;string&quot;&gt;&quot;cloudwatch:PutMetricData&quot;&lt;/span&gt;
      ],
      &lt;span class=&quot;string&quot;&gt;&quot;Effect&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Allow&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Resource&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;*&quot;&lt;/span&gt;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Click next and the summary is provided before final creation of the role.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-08.png&quot; alt=&quot;Screen 8&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Web Worker Application&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first thing I need is to go ahead and get the worker setup in the AWS Management Console. I create a new environment by clicking on Launch New Environment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-09.png&quot; alt=&quot;Screen 9&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next up is setting the environment tier and type and the configuration. I set these to Worker, Node.js, and Load Balanced.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-10.png&quot; alt=&quot;Screen 10&quot;&gt;&lt;/p&gt;
&lt;p&gt;Then upload the project zip file. I zipped and uploaded this file &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/#upload&quot;&gt;similarly to the way I did the site for submitting messages to the queue&lt;/a&gt;. To see what code I’m uploading - the blog entry is kind of circular - so I added the code part toward the bottom of this entry. For the exact code, check out the later part of the entry and the finished code here in the &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-11.png&quot; alt=&quot;Screen 11&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now click next through environment info and additional resources. In configuration details the main thing I need is to select the IAM security role for the instance being created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-12.png&quot; alt=&quot;Screen 12&quot;&gt;&lt;/p&gt;
&lt;p&gt;Click through the environment variables and on to Worker Details. Here I select the queue that I created in &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/&quot;&gt;part 1 of this series&lt;/a&gt;. Just below that enter the URI end point that the worker will provide the queue to send messages via POST. I’ll get to the code later in this article. But for now, I just selected /hi as the end point.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-13.png&quot; alt=&quot;Screen 13&quot;&gt;&lt;/p&gt;
&lt;p&gt;Finally, the last step is to review and Launch the worker instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-14.png&quot; alt=&quot;Screen 14&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Codes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At this point I’ll still be using hapi.js and good.js, so I follow the installation of these libraries similar to the ones I used for the site app in &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/&quot;&gt;part 2 of this series&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install hapi --save
npm install good --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I’ve setup a &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker/blob/master/server.js&quot;&gt;server.js&lt;/a&gt; as shown below. This API end point provides an action, in this case a write to the log, and then just finishes. This will prove out a complete movement of message from publisher site to queue to answering worker service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt;
  AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;),
  awsRegion = &lt;span class=&quot;string&quot;&gt;'us-west-2'&lt;/span&gt;,
  sqs = {},
  Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;),
  Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;),
  queueUri = &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/621392439615/sample'&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  &lt;span class=&quot;attr&quot;&gt;method&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'POST'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;path&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'/hi'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    AWS.config.update({
      &lt;span class=&quot;attr&quot;&gt;accessKeyId&lt;/span&gt;: process.env.AWS_ACCESS_KEY_ID,
      &lt;span class=&quot;attr&quot;&gt;secretAccessKey&lt;/span&gt;: process.env.AWS_SECRET_KEY,
      &lt;span class=&quot;attr&quot;&gt;region&lt;/span&gt;: awsRegion
    });
    sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

    server.log(&lt;span class=&quot;string&quot;&gt;'response: '&lt;/span&gt;, request.payload.name);
    server.log(&lt;span class=&quot;string&quot;&gt;'Starting receive message.'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'...a 200 response should be received.'&lt;/span&gt;);

    reply();
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, note that Hapi.js takes the request (read more on &lt;a href=&quot;http://hapijs.com/&quot;&gt;Hapi.js here&lt;/a&gt;) and sticks the body of the request in the property payload. Since AWS SQS sends across JSON in the way I’ve set it up (see &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/&quot;&gt;part 1&lt;/a&gt; and &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/&quot;&gt;part 2&lt;/a&gt;) the received message coming in looks like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;April&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code, the request.payload.name code gives us the name April. Run this and when the SQS receives input to process it will immediately send the message to the worker which will then process the code. When the worker returns a 200, the message is marked complete and removed from the queue. When I navigate to the nodejs.log in the AWS Beanstalk logs section of the environment, I get the last few items that I submitted to the queue for processing. The code above responds as shown below in the log.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;-------------------------------------
/var/log/nodejs/nodejs.log
-------------------------------------
141119/011034.709, response: , Susan
141119/011034.709, Starting receive message., ...a 200 response should be received.
141119/011034.688, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (26ms)
141119/011039.927, response: , April
141119/011039.928, Starting receive message., ...a 200 response should be received.
141119/011039.925, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (6ms)
141119/011045.232, response: , Jessica
141119/011045.232, Starting receive message., ...a 200 response should be received.
141119/011045.229, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (7ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;BOOM! All done. A few notes before I end this entry though. Note that with the worker feature being used for Beanstalk and SQS there really isn’t much code that is needed on the receipt end of the worker. I merely needed to respond 200, to complete the request from the point of view of the SQS worker service. Then whatever code I have that I want to act on the process with can work on the data received in the body from the queue. More than a few examples out there don’t really show this, but instead show the manual way of writing code that will poll and act upon the messages in the queue. The Beanstalk worker configuration is dramatically simpler in comparison to this practice. If you do want to read more about manually polling and acting on the data check out “&lt;a href=&quot;https://milesplit.wordpress.com/2013/11/07/using-sqs-with-node/&quot;&gt;Using SQS With Node&lt;/a&gt;“, it’s the only end-to-end example I’ve seen with Node.js being used. There is also of course the documentation, but it doesn’t provide clear cut examples of what exactly a good practice around working with the queue and requires a lot of RTFMing which quit frankly is a TLDR; scenario for doing something like this.&lt;/p&gt;
&lt;p&gt;Hope this blog post is helpful in getting Node.js working with the worker role. If you have any questions, comments or it appears I’ve missed a step, let me know and I’ll edit this and the related posts to make sure they’re as accurate and as simple to follow as I can get them.&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS</title>
      <link>http://adron.github.io/articles/hapijs-aws-worker-publish/</link>
      <pubDate>Thu, 06 Nov 2014 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hapijs-aws-worker-publish/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
  &lt;img src=&quot;/articles/hapijs-aws-worker-publish/SDKs-copy_nodeJS-200x2100.png&quot; alt=&quot;Node.js SDK&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name=&quot;webapplication&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First I created a project for the node.js web application. This just used the simple &lt;code&gt;npm init&lt;/code&gt; command and I stepped through the prompts for name, version, description, entry point, and so on.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sane defaults.

See `npm help json` for definitive documentation on these fields
and exactly what they do.

Use `npm install &amp;amp;pkg&amp;amp; --save` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
name: (testing-aws-sqs-site)
version: (0.0.0) 0.0.1
description: This project that will feed data to the queue for the AWS SQS sample.
entry point: (index.js) server.js
test command: mocha
git repository: (https://github.com/Adron/testing-aws-sqs-site.git)
keywords: aws, sqs, elastic, elastic beanstalk, queue, worker
author: Adron Hall
license: (ISC) Apache 2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;mocha&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Dependencies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Next I installed some dependencies like mocha and whatever else I’d need down the line and the next major dependency, the AWS SDK. To see a complete list of the dependencies just check out the &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site/blob/master/package.json&quot;&gt;package.json&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install aws-sdk --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next step is to create a test directory which I’ll use to test out some of the services as I move forward. Some of these tests will not fit into the BDD, TDD, or any other style of tests, as I will write them in a way that they’ll test the SDK, system and related elements for future use in continuous delivery. So just follow me here and don’t freak out, they’re not as frivolous as they seem at first.&lt;/p&gt;
&lt;p&gt;I added mocha as my test framework, and since it uses a folder called test as the default to execute tests, I added a folder and placed a file in that folder called aws_sdk.js. I then added the following test just to have an example test to work from.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; should = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;'should'&lt;/span&gt;);

describe ( &lt;span class=&quot;string&quot;&gt;'When trying out this sample application in AWS you'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{

  it ( &lt;span class=&quot;string&quot;&gt;'should have an environment variable set for AWS_ACCESS_KEY_ID'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    process.env.AWS_ACCESS_KEY_ID.should.exist;
  });

  it ( &lt;span class=&quot;string&quot;&gt;'should have an environment variables set for AWS_SECRET_KEY'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    process.env.AWS_SECRET_KEY.should.exist;
  })

});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then execute that with a call to mocha, and the two tests will fail.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ mocha

  When trying out this sample application in AWS you
    1) should have an environment variable set for AWS_ACCESS_KEY_ID
    2) should have an environment variables set for AWS_SECRET_KEY

  0 passing (4ms)
  2 failing

  1) When trying out this sample application in AWS you should have an environment variable set for AWS_ACCESS_KEY_ID:
     TypeError: Cannot read property &amp;#39;should&amp;#39; of undefined
      at Context.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;anonymous&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp; (/Users/adron/Codez/testing-aws-sqs-site/test/aws_sdk.js:12:34)
      at callFn (/usr/local/lib/node_modules/mocha/lib/runnable.js:249:21)
      at Test.Runnable.run (/usr/local/lib/node_modules/mocha/lib/runnable.js:242:7)
      at Runner.runTest (/usr/local/lib/node_modules/mocha/lib/runner.js:373:10)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:451:12
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:298:14)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:308:7
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:246:23)
      at Object._onImmediate (/usr/local/lib/node_modules/mocha/lib/runner.js:275:5)
      at processImmediate [as _immediateCallback] (timers.js:336:15)

  2) When trying out this sample application in AWS you should have an environment variables set for AWS_SECRET_KEY:
     TypeError: Cannot read property &amp;#39;should&amp;#39; of undefined
      at Context.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;anonymous&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp; (/Users/adron/Codez/testing-aws-sqs-site/test/aws_sdk.js:16:30)
      at callFn (/usr/local/lib/node_modules/mocha/lib/runnable.js:249:21)
      at Test.Runnable.run (/usr/local/lib/node_modules/mocha/lib/runnable.js:242:7)
      at Runner.runTest (/usr/local/lib/node_modules/mocha/lib/runner.js:373:10)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:451:12
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:298:14)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:308:7
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:246:23)
      at Object._onImmediate (/usr/local/lib/node_modules/mocha/lib/runner.js:275:5)
      at processImmediate [as _immediateCallback] (timers.js:336:15)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a name=&quot;aws&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At this point I’ll go ahead and set these environment variables in my ~/.bash_profile file. On other machines this may just be a .bashrc file or something else you’ve configured for your bash. Add the environment variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# AWS Credentials
export AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY
export AWS_SECRET_KEY=YOUR_SUPER_SECRET_AWS_KEY
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you’ve added these to your bash, source the file to activate and set these new environment variables. My command is to source my local .bash_profile file, but you’d need to source whichever file you’ve set the variables in that starts up with your bash.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now executing the mocha tests I get a beautiful confirmation that I do have the environment variables in place and set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ mocha

  When trying out this sample application in AWS you
    ✓ should have an environment variable set for AWS_ACCESS_KEY_ID
    ✓ should have an environment variables set for AWS_SECRET_KEY

  2 passing (4ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have these two passing I’ve added another that shows the SDK to have the settings have actually been set. The main reason here is also to just discover how it is set and where those values are stored on the AWS object. I discovered that to set the config, just issue a call to update({}) and pass in the respective configuration as name value pairs using JSON.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;before(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  AWS.config.update({
    &lt;span class=&quot;attr&quot;&gt;accessKeyId&lt;/span&gt;: process.env.AWS_ACCESS_KEY_ID,
    &lt;span class=&quot;attr&quot;&gt;secretAccessKey&lt;/span&gt;: process.env.AWS_SECRET_KEY,
    &lt;span class=&quot;attr&quot;&gt;region&lt;/span&gt;: awsRegion});
})

it(&lt;span class=&quot;string&quot;&gt;'should have the AWS Access Key set in the AWS config'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; config = AWS.config;
  config.credentials.accessKeyId.should.equal(process.env.AWS_ACCESS_KEY_ID);
  config.credentials.secretAccessKey.should.equal(process.env.AWS_SECRET_KEY);
})

it(&lt;span class=&quot;string&quot;&gt;'should have the AWS region set to us west 2'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  AWS.config.region.should.equal(awsRegion);
})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The configuration data is then stored in the config credentials for the access key and secret access key. The region is stored as a value on the config object. Those should pass and then let’s move straight on to setting up a basic site that can send the queue some data.&lt;/p&gt;
&lt;p&gt;For more information about the configuration and setup of the AWS SDK check out the &lt;a href=&quot;http://docs.aws.amazon.com/AWSJavaScriptSDK/guide/node-configuring.html&quot;&gt;SDK Documentation on the topic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Web Site Application&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To create this web site application I’m going to use hapi.js. You can of course use anything you want to for this part of the example such as express, geddy or whichever. The general premise of what I’m going to put together for the front end of this whole application is going to be extremely simple. By proxy it will then be easily applied to any of the other framework options.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install hapi --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that was done I installed the good library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install good --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First part of the site I spooled up was to create a server.js file in the root of the project and add the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;)

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(&lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  &lt;span class=&quot;attr&quot;&gt;method&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;path&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'/'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, world!'&lt;/span&gt;);
  }
});

server.route({
  &lt;span class=&quot;attr&quot;&gt;method&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;path&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'/{name}'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err; &lt;span class=&quot;comment&quot;&gt;// something bad happened loading the plugin&lt;/span&gt;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dependency I added, good, brings some logging features to the project now. So with this, when executing the server file to get the server running, I get the following response on the command line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ node server.js
141020/004110.009, info, Server running at: http://adrons-mbp:3000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I issued some curl commands against the end points.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;17:42 $ curl localhost:3000
Hello, world!~
17:42 $ curl localhost:3000/Frank
Hello, Frank!~
17:42 $ curl localhost:3000/Sally
Hello, Sally!~
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the logging on, the following results proved out that everything was running ok.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ node server.js
141020/004219.213, info, Server running at: http://adrons-mbp:3000
141020/004230.236, request, http://adrons-mbp:3000: get / {} 200 (10ms)
141020/004236.850, request, http://adrons-mbp:3000: get /Frank {} 200 (2ms)
141020/004240.514, request, http://adrons-mbp:3000: get /Sally {} 200 (1ms)
141020/004254.937, request, http://adrons-mbp:3000: get /Cat {} 200 (0ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next thing I need to actually do is send a message to the queue to be processed. In the server.js file I added the following code, with the entire server.js file shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; should = AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;),
  awsRegion = &lt;span class=&quot;string&quot;&gt;'us-west-2'&lt;/span&gt;,
  sqs = {},
  Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;),
  Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  &lt;span class=&quot;attr&quot;&gt;method&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;path&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'/'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, world!'&lt;/span&gt;);
  }
});

&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sendSqsMessage&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
&lt;span class=&quot;meta&quot;&gt;  'use strict'&lt;/span&gt;;

  AWS.config.update({
    &lt;span class=&quot;attr&quot;&gt;accessKeyId&lt;/span&gt;: process.env.AWS_ACCESS_KEY_ID,
    &lt;span class=&quot;attr&quot;&gt;secretAccessKey&lt;/span&gt;: process.env.AWS_SECRET_KEY,
    &lt;span class=&quot;attr&quot;&gt;region&lt;/span&gt;: awsRegion
  });
  sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; params = {
    &lt;span class=&quot;attr&quot;&gt;MessageBody&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'The Message Body Goes Here'&lt;/span&gt;,
    &lt;span class=&quot;attr&quot;&gt;QueueUrl&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/588271471917/a_sample'&lt;/span&gt;,
    &lt;span class=&quot;attr&quot;&gt;DelaySeconds&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
  };

  sqs.sendMessage(params, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, data&lt;/span&gt;) &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err, err.stack);
    } &lt;span class=&quot;comment&quot;&gt;// an error occurred&lt;/span&gt;
    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Victory, message sent for '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
    }
    ;
  });
}

server.route({
  &lt;span class=&quot;attr&quot;&gt;method&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;path&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'/{name}'&lt;/span&gt;,
  &lt;span class=&quot;attr&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    sendSqsMessage(&lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name));
    reply(&lt;span class=&quot;string&quot;&gt;'Your message '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;' has been sent to queue!'&lt;/span&gt;);
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err; &lt;span class=&quot;comment&quot;&gt;// something bad happened loading the plugin&lt;/span&gt;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll step through the key lines above to detail where and what the functionality is.&lt;/p&gt;
&lt;p&gt;The line below is important, as AWS Beanstalk assumes the PORT environment variable will be set and used.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I added the sendMessage function. In this function I update the configuration, which is required to get the appropriate variables set. On the AWS instance itself, which I’ll cover shortly, these are where the environment variables will be picked up to instantiate the AWS configuration for the SQS object.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sendSqsMessage&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
&lt;span class=&quot;meta&quot;&gt;  'use strict'&lt;/span&gt;;

  AWS.config.update({
    &lt;span class=&quot;attr&quot;&gt;accessKeyId&lt;/span&gt;: process.env.AWS_ACCESS_KEY_ID,
    &lt;span class=&quot;attr&quot;&gt;secretAccessKey&lt;/span&gt;: process.env.AWS_SECRET_KEY,
    &lt;span class=&quot;attr&quot;&gt;region&lt;/span&gt;: awsRegion
  });
  sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; params = {
    &lt;span class=&quot;attr&quot;&gt;MessageBody&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'The Message Body Goes Here'&lt;/span&gt;,
    &lt;span class=&quot;attr&quot;&gt;QueueUrl&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/588266671666/the_path_to_the_queue'&lt;/span&gt;,
    &lt;span class=&quot;attr&quot;&gt;DelaySeconds&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
  };

  sqs.sendMessage(params, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, data&lt;/span&gt;) &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err, err.stack);
    } &lt;span class=&quot;comment&quot;&gt;// an error occurred&lt;/span&gt;
    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Victory, message sent for '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
    };
  });
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So all in all, the code is kind of dirty, but it gets the point across. Whenever I send an HTTP GET request against domain/name a post to the queue with the /name part of the URI will be sent. Now it’s time to get the actual instance deployed in AWS and test this.&lt;/p&gt;
&lt;p&gt;In the example above, as a reminder where the URL for the queue is located, navigate to the SQS part of the AWS console and click on the actual queue itself. In the information section of the queue you’ll see the URL listed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;For more information on the queue and how to set it up check out the preview article here.&lt;/p&gt;
&lt;h2 id=&quot;setting-up-an-aws-beanstalk-instance&quot;&gt;Setting up an AWS Beanstalk Instance&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;If you’ve not used AWS Beanstalk the console interface will automatically show a display screen that only has options to create an application. If there are already applications running the Beanstalk Environment the create application button will be toward the top right of the console.&lt;/p&gt;
&lt;p&gt;It’s important to note I’ll be creating two environments within a single application within the Beanstalk environment. Both of them will be their own load balanced, environments acting just as if they were located in different geographical regions in AWS.&lt;/p&gt;
&lt;p&gt;The first step once I’ve clicked the create application button is to set the application name and description. The name, is required, the description is not.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Clicking on next then puts me on the environment creation screen. I’ve set the environment tier to web server, the predefined configuration is using Node.js, and the environment type is a load balanced with autoscaling environment. With these set, click next.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;upload&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the next step I’ll need to upload the application. I’ve got the cloned application repo navigated to in bash, execute ‘&lt;em&gt;open .&lt;/em&gt;‘ [1] against it to open the finder [2] to that location, right click and compress [3] the folder and all of the contents. I now have a ready to upload and deploy file package.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now select the file, make sure the radio button is selected also, as selecting a file doesn’t automatically select the radio button. Then click on next. The application deployment file will then upload.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_07.png&quot; alt=&quot;Screen 7&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next dialog will provide a form to set the environment name, URL, and description. Click on the &lt;em&gt;Check availability&lt;/em&gt; button to determine if the URL is available that is chosen.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_08.png&quot; alt=&quot;Screen 8&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next I click through the additional resources, configuration details and environment tags leaving the default settings. The on the final review information screen I’ll click the launch button and the status of deployment will show.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_09.png&quot; alt=&quot;Screen 9&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once that spools up, click on the URL to navigate the browser to the URL that the site is now available publicly at and add a name to the URL. Here’s the default &lt;em&gt;Hello World!&lt;/em&gt; display.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_10.png&quot; alt=&quot;Screen 10&quot;&gt;&lt;/p&gt;
&lt;p&gt;The display when adding a name (or any set of strings) to the URL, in this particular case to this URL here &lt;em&gt;&lt;a href=&quot;http://awsqueuesampleapp-env.elasticbeanstalk.com/&quot;&gt;http://awsqueuesampleapp-env.elasticbeanstalk.com/&lt;/a&gt;&lt;/em&gt; with a name attached like this &lt;em&gt;&lt;a href=&quot;http://awsqueuesampleapp-env.elasticbeanstalk.com/April&quot;&gt;http://awsqueuesampleapp-env.elasticbeanstalk.com/April&lt;/a&gt;&lt;/em&gt; the following displays and sends the name to the AWS SQS Queue we have setup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_11.png&quot; alt=&quot;Screen 11&quot;&gt;&lt;/p&gt;
&lt;p&gt;To determine if everything I’ve done has worked ok, I navigate back to the AWS console and then into the SQS section. On the queue list I pick the queue that is being used and there sits the queue items I’ve added by hitting the URL shown above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_12.png&quot; alt=&quot;Screen 12&quot;&gt;&lt;/p&gt;
&lt;p&gt;Check under the Messages Available, which I’ve submitted 15 messages and they sit there in the queue, waiting for the next stage of this series - building the worker node. Keep reading, that’s up next. Cheers!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances</title>
      <link>http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/</link>
      <pubDate>Wed, 05 Nov 2014 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Amazon-SQS_200x200.png&quot; alt=&quot;Amazon SQS&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before diving straight in, I’m going to outline the specific goals and what I am using to accomplish these goals. The goal is to have a simple web application, that will get some element of data posted to a queue. The queue will then have data that a worker service needs to then process. As I step through each of these requirements I’ll determine the actual push and pull mechanisms that will get the job done.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_Elastic-Beanstalk_200x200.png&quot; alt=&quot;Deployment &amp;amp; Management - Elastic Beanstalk&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/elasticbeanstalk/&quot;&gt;AWS Elastic Beanstalk Worker&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/elasticbeanstalk/&quot;&gt;AWS Elastic Beanstalk&lt;/a&gt; is a service used to deploy and scale web application and services. In this particular example I’ll be using Node.js for all the work, but other options are available such as Java, .NET, PHP, Python, Ruby and even anything you can stick in a Docker Container. Simply put, you can run whatever you need in Beanstalk and gain all the advantages of the virtualized services and scaling of the toolset.&lt;/p&gt;
&lt;p&gt;The worker feature that I’ll be using in this how-to, referred to by AWS as Worker Tiers, is setup to handle background tasks at scale. Think of things like doing database cleanup, setting action flags, events, firing triggers or simply sending an email notification. The worker tier that I’ll be using, again with Node.js, will simple be there to process messages that I’ll put into the queue.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Amazon-SQS_200x200.png&quot; alt=&quot;SQS&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;AWS Simple Queue Service (SQS)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;AWS Simple Queue Service&lt;/a&gt;, or &lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;SQS&lt;/a&gt; for short, is a distributed and scalable hosted queue service for storing messages that need to be reliably available between systems. By using SQS I can then create decoupled components of an application that are autonomous of each other in execution. This provides more options around scaling up or scaling down particular workloads, apps and services throughout the application ecosystem that I’ve built.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/cloudwatch/&quot;&gt;CloudWatch&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_CloudWatch-200x200.png&quot; alt=&quot;Cloudwatch&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Even though the use of &lt;a href=&quot;http://aws.amazon.com/cloudwatch/&quot;&gt;CloudWatch&lt;/a&gt; is actually transparent to this project, I needed to bring it up, because without things being setup appropriately CloudWatch will definitely let you know that it is involved in this architecture.&lt;/p&gt;
&lt;p&gt;CloudWatch is a monitoring service for cloud resources. In this particular scenario that I’m detailing here it is setup automatically by Elastic Beanstalk to monitor and autoscale instances as demand dictates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/iam/&quot;&gt;Identity and Access Management (IAM)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_IAM-200x200.png&quot; alt=&quot;IAM&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/iam/&quot;&gt;AWS IAM&lt;/a&gt; provides security for individual AWS resources and also a way to manage users and administrators of those resources. In this particular scenario I won’t cover the default user that I have setup, but assume that I’m using a user with permissions to all resources. I will be adding some roles to enable CloudWatch and Elastic Beanstalk to interoperate appropriately with the SQS under the premise of an Elastic Beanstalk Worker environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/sdk-for-node-js/&quot;&gt;AWS Node.js SDK&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;http://aws.amazon.com/sdk-for-node-js/&quot;&gt;Nodejs SDK&lt;/a&gt; that Amazon provides for the AWS Web Services is pretty extensive. I have noticed it suffers a little from the “&lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/God_object&quot;&gt;God Object&lt;/a&gt;&lt;/em&gt;“ type of context where it does everything in one giant library, &lt;em&gt;however&lt;/em&gt;, it really kind of makes sense for something like AWS’s Services.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/SDKs-copy_nodeJS-200x2100.png&quot; alt=&quot;Node.js SDK&quot;&gt;
&lt;/div&gt;

&lt;p&gt;The SDK provides JavaScript objects for AWS services including S3, EC2, and almost every other practical service they have. The package is available for download the standard npm way.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  npm install aws-sdk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the getting started section of the AWS documentation, the samples are generally given using a loadable json file with the secret key information for connecting to your AWS resources. In this scenario I’ll actually use a different way to setup that configuration, which I’ll elaborate on further into this series.&lt;/p&gt;
&lt;h2 id=&quot;back-to-business&quot;&gt;Back to Business&lt;/h2&gt;
&lt;p&gt;The first order of business is to get a queue created. Since everything I’m going to put together in this sample is primarily focused around processing a queue, it seems like the perfect place to start. First open up the AWS Console and navigate to the SQS admin page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next click on the Create New Queue button to launch the create queue dialog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;On the dialog enter the queue name and change any of the queue settings that you need to. In this particular situation I didn’t change any and just went with the defaults.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now the queue is created. However I can’t really do anything with it at this point. I need to open up permissions to whatever I want to have access it. Clicking on the just created queue and then selecting the Permissions tab just below that will bring up the tab dialog that provides options for adding various permission levels for access.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Adding permissions…&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;Add a Permission to sample&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;The queue is now all setup. In the next entry I’ll setup a web application project that will send data to the queue. I’ll also update this article with the links to the subsequent articles at the very top - and the bottom of the article here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Bashit... Just a Custom Bash Prompt Setup for Git</title>
      <link>http://adron.github.io/articles/bashit/</link>
      <pubDate>Thu, 09 Oct 2014 00:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/bashit/</guid>
      <author></author>
      <description>&lt;p&gt;I use git. I’m honestly shocked when someone doesn’t use git (&lt;em&gt;or at least some DVCS&lt;/em&gt;) these days. It just seems somewhat draconian to use any of the legacy source control systems (&lt;em&gt;albeit there are some rare exceptions, like game development graphics collateral&lt;/em&gt;). I was reminded of something by the great hands on session that Pamela Ocampo &lt;a href=&quot;https://twitter.com/pmocampo&quot;&gt;@pmocampo&lt;/a&gt; and Rachel &lt;a href=&quot;https://twitter.com/raychatter&quot; target=&quot;_blank&quot;&gt;@raychatter&lt;/a&gt; gave at &lt;a href=&quot;http://opensourcebridge.org/&quot; target=&quot;_blank&quot;&gt;OS Bridge&lt;/a&gt; titled “&lt;a href=&quot;http://opensourcebridge.org/sessions/1378&quot; target=&quot;_blank&quot;&gt;NerdCred++; How to Customize your Bash Prompt&lt;/a&gt;“.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;After the session I dug into customizing my bash prompt. After doing a lot of manual editing I ended up just forking and implementing Michael Gonderman’s (&lt;a href=&quot;https://twitter.com/magicmonty&quot; target=&quot;_blank&quot;&gt;@magicmonty&lt;/a&gt;) &lt;a href=&quot;https://github.com/Adron/bash-git-prompt&quot; target=&quot;_blank&quot;&gt;bash-git-prompt&lt;/a&gt;. The way to get this installed is pretty simple, albeit it does include a few steps (&lt;em&gt;and yes, the &lt;a href=&quot;https://github.com/Adron/bash-git-prompt/blob/master/README.md&quot; target=&quot;_blank&quot;&gt;README.md&lt;/a&gt; basically has the instructions, but I’ve copied them here just to discuss and for ease of readability). &lt;/em&gt;Another key points of reference include Sebastian Celis’s (&lt;a href=&quot;https://twitter.com/scelis&quot; target=&quot;_blank&quot;&gt;@scelis&lt;/a&gt;) “&lt;a href=&quot;http://sebastiancelis.com/2009/11/16/zsh-prompt-git-users/&quot; target=&quot;_blank&quot;&gt;A zsh prompt for git users&lt;/a&gt;“ on his &lt;a href=&quot;http://sebastiancelis.com/&quot; target=&quot;_blank&quot;&gt;blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;!--more--&gt;First clone the repo (even though I’ve forked it I still pulled directly from&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ cd ~
$ git clone https://github.com/magicmonty/bash-git-prompt.git .bash-git-prompt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To verify that it is cloned ok, source the gitprompt.sh file from bash. It should immediately dive into a new prompt with a check mark and current directory, with the time immediately under that. Sweet, that worked!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ source ~/.bash-git-prompt/gitprompt.sh
✔ ~
10:48 $
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where the check mark is where git changes will display when navigating into a directory path that is a git repository and making changes. The format will look something like (&lt;branch&gt; &lt;branch tracking&gt;|&lt;local status&gt;). The symbols on the prompt, when working with git are as follows:&lt;/p&gt;
&lt;p&gt;✔: repository clean
●n: there are n staged files
✖n: there are n unmerged files
✚n: there are n changed but unstaged files
…n: there are n untracked files
⚑n: there are n stash entries
↑n: ahead of remote by n commits
↓n: behind remote by n commits
↓m↑n: branches diverged, other by m commits, yours by n commits&lt;/p&gt;
&lt;p&gt;The next step is to make this permanent. Open up your ~/.bashrc file (or whichever you use, in my case I’m using ~./bash_profile, so be sure to figure out which one your system is using to actually load your bash). In the bash file add a single line to source the gitprompt.sh file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# a bunch of other stuff in the file, whatever it might be... etc., etc.

source ~/.bash-git-prompt/gitprompt.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve added some links below that add additional options to customize your bash prompt (thank Pamela &amp;amp; Rachel). Even though all of this might seem like such a small little thing, having that extra information readily displayed on the prompt can be a huge time saver. Especially if you’re regularly in the code, committing from TDD or BDD practices or even just paired with somebody going through doing a refactor. It can be HUGE time saver, it definitely has for me.&lt;/p&gt;
&lt;p&gt;…and thanks to ALL that gave me the motivation &amp;amp; for putting together the presentation and code for the prompt. Props to &lt;a href=&quot;https://twitter.com/scelis&quot; target=&quot;_blank&quot;&gt;@scelis&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/pmocampo&quot; target=&quot;_blank&quot;&gt;@pmocampo&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/raychatter&quot; target=&quot;_blank&quot;&gt;@raychatter&lt;/a&gt; &amp;amp; the others that have contributed to making bad ass bash prompts!&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;h2 id=&quot;resources-&quot;&gt;Resources:&lt;/h2&gt;
&lt;p&gt;Pamela &amp;amp; Rachel’s Slide Deck &amp;amp; Additional Information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://pamo.github.io/nerdcred/slides/#/&quot; target=&quot;_blank&quot;&gt;Slide Deck&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://pamo.github.io/nerdcred/&quot; target=&quot;_blank&quot;&gt;Additional Info from Pamela &amp;amp; Rachel&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.kirsle.net/wizards/ps1.html&quot; target=&quot;_blank&quot;&gt;Bash $PS1 Generator 2.0&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://andrewray.me/bash-prompt-builder/&quot; target=&quot;_blank&quot;&gt;Bash Prompt Builder&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ezprompt.net/&quot; target=&quot;_blank&quot;&gt;Ez Prompt&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Working in -34c Wintersmith Customization and Github Hosting</title>
      <link>http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting/</link>
      <pubDate>Tue, 18 Feb 2014 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting/</guid>
      <author></author>
      <description>&lt;p&gt;Getting Wintersmith customized, building and deployed to Github and a domain name pointed takes a few extra steps. So let’s roll…&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-01.png&quot; alt=&quot;Wintersmith Icon 1&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step #1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Setup &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt;. See my previous blog entry “&lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt;“ for this information.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-02.png&quot; alt=&quot;Wintersmith Icon 2&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step #2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now it’s time to get things deployed to Github. This takes a few interesting, non-intuitive steps, but once done things work extremely well. To get the appropriate git branch setup I worked with an existing git repo. This repo is the same repo that I’ve used for the public facing &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Deconstructed Site&lt;/a&gt;. The code repo is located @ &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Deconstructed Github Repo&lt;/a&gt;. I added a &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;github pages branch&lt;/a&gt; to this repository, for more information on how to do this check out my Jekyll how-to “&lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Bringing to Life an Open Source Project via Github &amp;amp; Jekyll - Part 1&lt;/a&gt;” which I detail at the beginning how to get a Github Pages site running.&lt;/p&gt;
&lt;p&gt;Once the site is up and running I switched over to it and cleared out that path. I kept a few things I’d need like the .gitignore, README.md and a few other files. I then put the repo directory that I detailed in “&lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt;” right here in the gh-pages branch. With that in place I then just committed and pushed this code to the gh-pages repository. That gave me the initial baseline for the site.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-03.png&quot; alt=&quot;Wintersmith Icon 3&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step #3&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Get the customizations done and site domain/subdomain redirected. The steps to get the domain setup to have a custom domain pointed at your gh-pages github site is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a file named CNAME in the root of your gh-pages branch and in that CNAME file add one line with the domain that is being directed to this gh-pages site. My &lt;a href=&quot;https://github.com/Adron/deconstructed/blob/gh-pages/CNAME&quot; target=&quot;_blank&quot;&gt;CNAME file&lt;/a&gt; looks simply like this: &lt;code&gt;docs.deconstructed.io&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next setup either an DNS A record or cname record. The cname will give you the advantage of having Github manage which IPs are in use in their system, so if there is any failover, DDOS or IP changes then you’re protected from that. To setup an A record add the A record to point to 204.232.175.78 or setup a cname to point to your github .io account, which in my case is &lt;a href=&quot;http://adron.github.io/&quot;&gt;http://adron.github.io/&lt;/a&gt;. The following is what the record looked like in my Route 53 settings.&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/dns-deconstructed.png&quot; alt=&quot;DNS Setting&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Last but not least the configuration settings that need to be made in Wintersmith.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First set the locals url setting to the appropriate domain or subdomain. In my case that meant changing the value from &lt;em&gt;&lt;a href=&quot;http://localhost:8080/&quot;&gt;http://localhost:8080/&lt;/a&gt;&lt;/em&gt; to &lt;em&gt;&lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;http://docs.deconstructed.io/&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;  “locals”: {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  &amp;quot;url&amp;quot;: &amp;quot;http://docs.deconstructed.io&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;Deconstructed Docs&amp;quot;,
  &amp;quot;owner&amp;quot;: &amp;quot;Adron Hall&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;This site provides the documentation around the Deconstructed API Services.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  }&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the root of the project (where the Wintersmith build ends up) add a .nojekyll file so that Jekyll won’t be used unnecessarily to try and build the Wintersmith project.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;…and with that, I’ve covered the bases for getting a Wintersmith site (blog or whatever you’re like to use it for) up and running. Feel free to ask any questions in the comments and I’ll help work through any issues you’ve encountered. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Wintersmith Creating Documentation</title>
      <link>http://adron.github.io/articles/wintersmith-creating-documentation/</link>
      <pubDate>Sun, 16 Feb 2014 18:00:00 -0600</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/wintersmith-creating-documentation/</guid>
      <author></author>
      <description>&lt;p&gt;I set out a few days ago to put together a documentation site. I had a few criteria for this site:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;A static site that I could push to Github to use with their github pages feature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The static site is generated from markdown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It just works. It’s easy to get it into a workflow without breaking the tool or breaking a solid workflow.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That was it, what I’d consider some pretty straight forward criteria. However it wasn’t that easy, until it was. Here’s a few of the issues I ran through on the way to getting a solid tool with a solid workflow working together. Beware however if you have fickle reading eyes, the following is a rant about what does and does not work.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;[rant on]&lt;/h2&gt;
&lt;strong&gt;Middleman Broken Ruby and Broken Gems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I have a Mac Book Pro Retina 15”. The machine runs OS-X Mavericks. I’ve had zero issue with this OS. It comes with Ruby 2 and some version of gems. My first attempt was to take a stab with &lt;a href=&quot;http://middlemanapp.com/&quot; target=&quot;_blank&quot;&gt;middleman&lt;/a&gt;, the same static site builder used by many companies including Basho. Even though I ran into problems which I detailed in “&lt;a href=&quot;http://compositecode.com/2012/12/09/basho-first-week-coding-research-adventures/&quot; target=&quot;_blank&quot;&gt;Basho – First Week Coding &amp;amp; Research Adventures…&lt;/a&gt;“ and “&lt;a href=&quot;http://compositecode.com/2012/12/14/un-breaking-mountain-lion-os-x/&quot; target=&quot;_blank&quot;&gt;Un-breaking OS-X Mountain Lion&lt;/a&gt;“ eventually middleman &lt;em&gt;mostly&lt;/em&gt; worked.&lt;/p&gt;
&lt;p&gt;Well, I didn’t get to a working app very fast. Immediately Ruby 2 had issues and gemsets puked middleman everywhere. I then ran into some confusing permissions errors. About 15 minutes into this process of troubleshooting middleman I had flashbacks of the first few days at Basho and thought, “&lt;em&gt;this is bullshit, something has to work better than this catastrofuck of software version conflicts&lt;/em&gt;“. So I dropped middleman dead.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assemble, Assemble, Assemble…    ??!?#@$%! WTF!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I attempted &lt;a href=&quot;http://assemble.io/&quot; target=&quot;_blank&quot;&gt;assemble&lt;/a&gt; next for the node.js stack. It &lt;em&gt;looked&lt;/em&gt; to have a lot of promise. It uses grunt.js and a bunch of other tools to manage a static site generating, bootstrap using stack. The more I looked at it however it seemed busy. Busy as in “&lt;em&gt;I’m going to do more than three things so I’ll maybe do none of them right&lt;/em&gt;“.&lt;/p&gt;
&lt;p&gt;Reading about assemble I turned to another hacker slinging some code at the bar I sat at. She looked at the project and asked, “&lt;em&gt;what’s it supposed to do exactly? I get that it’s a framework of tools but it doesn’t’ exactly lay out what it is supposed to be doing besides arbitrarily managing some parts of the stack.&lt;/em&gt;“ That seemed reasonable to me.&lt;/p&gt;
&lt;p&gt;Before I just tossed assemble.io to the trash heap of options I wanted to ask at least one more person. So the next day I asked my good friend and super genius Troy Howard. It was a short verdict, “drop that shit”.&lt;/p&gt;
&lt;p&gt;That was enough for me, assemble was officially dead for this project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slate, This Seems Slick But…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I then took a stab at &lt;a href=&quot;http://tripit.github.io/slate/&quot; target=&quot;_blank&quot;&gt;Slate&lt;/a&gt;. &lt;a href=&quot;http://tripit.github.io/slate/&quot; target=&quot;_blank&quot;&gt;Orchestrate.io just created some excellent documentation&lt;/a&gt; using the Slate solution. So I dove into this, getting a test site up and running rapidly. It seemed like a mostly viable solution until I started running into issues with how and where I wanted things displayed for the code samples and other material. It appeared, if I were going to use Slate, I’d be using it almost exactly as is. I might borrow pieces of it in the future, even the layout to some degree, but for now I wanted something else that I could incorporate my themes as needed. Alas, I was super happy with Slate, it just wasn’t a great fit for now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where The Hell Are My Options, Jekyll?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At this point I was getting a little frustrated. I then went to a tried and true solution in &lt;a href=&quot;http://jekyllrb.com/&quot; target=&quot;_blank&quot;&gt;jekyll&lt;/a&gt;. Jekyll is a pretty solid solution, with some bugs and oddball issues but nothing major. I started working with it and even transitioning a jekyll project into my theme. Hacking a jekyll blog into a reasonable documentation solution this seemed like the way to go.&lt;/p&gt;
&lt;p&gt;But then I got a wild urge to see if there was anything else in Node.js land that I was missing. I really didn’t want to sling a Ruby project if I didn’t have to. I’d rather keep all the stacks around JavaScript for this particular set of projects. No reason to diverge when I’m just dealing with such simple straight forward web projects. I’ll diverge when something truly validate diverging, like doing some real math with a real functional language or something. Trading Node.js for one single project to go with a pseudo Ruby project for static site generation just didn’t seem appealing. So I started looking around one more time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Made in -34°C&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/wintersmith-creating-documentation/temp.png&quot; alt=&quot;-34° Celsius&quot;&gt;
    Yup, -34 Celsius. That’s about as cold as it gets. Click for the full size chart!
&lt;/div&gt;

&lt;p&gt;The next solution I tried was &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt;. This solution appeared to have everything that I’d been looking for feature wise. It was a node.js project, it generated static content, could generate blogs but other things too, was simple, had plugins, was straight forward and more. I was a little paranoid after the solutions I’d fought my way through earlier so I went to the only place that would insure that I’d have a solution I could be confident in. I went straight to the &lt;a href=&quot;https://github.com/jnordberg/wintersmith&quot; target=&quot;_blank&quot;&gt;source&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;I’ll admit I took a peak at the package.json file before going head long into the source. A quick perusal of the dependencies list looked ok.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  dependencies: {
    marked: ~0.3.0,
    coffee-script: ~1.6.3,
    async: ~0.2.9,
    highlight.js: ~8.0.0,
    jade: ~1.1.5,
    ncp: ~0.5.0,
    rimraf: ~2.2.6,
    winston: ~0.7.2,
    colors: ~0.6.2,
    optimist: ~0.6.0,
    minimatch: ~0.2.14,
    mime: ~1.2.11,
    js-yaml: ~3.0.1,
    mkdirp: ~0.3.5,
    chokidar: ~0.8.1,
    server-destroy: ~1.0.0,
    npm: ~1.3.24,
    slugg: ~0.1.2
  },
  devDependencies: {
    shelljs: 0.1.x
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I immediately took note of a few things. The first was that there was actually a breakout of dev dependencies versus actual project dependencies. That’s a good first sign. The second thing I just went through the list and checked the various library dependencies, there were a few that I’ve played around with before that I trusted; highlight.js, coffee-script, async, js-yaml and npm were all cool by me. It didn’t seem to crazy out of whack. With that I went forth into the code with zero expectations…&lt;/p&gt;
&lt;p&gt;The first files I dug into were the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/config.coffee&quot; target=&quot;_blank&quot;&gt;config.coffee file&lt;/a&gt;, which pointed out a few things I’d want to possibly tweak a little later such as the port number and other things the wintersmith server would use when running the preview server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Config
  ### The configuration object ###

  @defaults =
    # path to the directory containing content&amp;#39;s to be scanned
    contents: &amp;#39;./contents&amp;#39;
    # list of glob patterns to ignore
    ignore: []
    # context variables, passed to views/templates
    locals: {}
    # list of modules/files to load as plugins
    plugins: []
    # modules/files loaded and added to locals, name: module
    require: {}
    # path to the directory containing the templates
    templates: &amp;#39;./templates&amp;#39;
    # directory to load custom views from
    views: null
    # built product goes here
    output: &amp;#39;./build&amp;#39;
    # base url that site lives on, e.g. &amp;#39;/blog/&amp;#39;
    baseUrl: &amp;#39;/&amp;#39;
    # preview server settings
    hostname: null # INADDR_ANY
    port: 8080
    # options prefixed with _ are undocumented and should generally not be modified
    _fileLimit: 40 # max files to keep open at once
    _restartOnConfChange: true # restart preview server on config change
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Second code file that looked interesting, the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/renderer.coffee&quot; target=&quot;_blank&quot;&gt;renderer.coffee&lt;/a&gt; code file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fs = require &amp;#39;fs&amp;#39;
util = require &amp;#39;util&amp;#39;
async = require &amp;#39;async&amp;#39;
path = require &amp;#39;path&amp;#39;
mkdirp = require &amp;#39;mkdirp&amp;#39;
{Stream} = require &amp;#39;stream&amp;#39;

{ContentTree} = require &amp;#39;./content&amp;#39;
{pump, extend} = require &amp;#39;./utils&amp;#39;

if not setImmediate?
  setImmediate = process.nextTick

renderView = (env, content, locals, contents, templates, callback) -&amp;amp;gt;
  setImmediate -&amp;amp;gt;
    # add env and contents to view locals
    _locals = {env, contents}
    extend _locals, locals

    # lookup view function if needed
    view = content.view
    if typeof view is &amp;#39;string&amp;#39;
      name = view
      view = env.views[view]
      if not view?
        callback new Error &amp;amp;quot;content &amp;#39;#{ content.filename }&amp;#39; specifies unknown view &amp;#39;#{ name }&amp;#39;&amp;amp;quot;
        return

    # run view
    view.call content, env, _locals, contents, templates, (error, result) -&amp;amp;gt;
      error.message = &amp;amp;quot;#{ content.filename }: #{ error.message }&amp;amp;quot; if error?
      callback error, result

render = (env, outputDir, contents, templates, locals, callback) -&amp;amp;gt;
  ### Render *contents* and *templates* using environment *env* to *outputDir*.
      The output directory will be created if it does not exist. ###

  env.logger.info &amp;amp;quot;rendering tree:\n#{ ContentTree.inspect(contents, 1) }\n&amp;amp;quot;
  env.logger.verbose &amp;amp;quot;render output directory: #{ outputDir }&amp;amp;quot;

  renderPlugin = (content, callback) -&amp;amp;gt;
    ### render *content* plugin, calls *callback* with true if a file is written; otherwise false. ###
    renderView env, content, locals, contents, templates, (error, result) -&amp;amp;gt;
      if error
        callback error
      else if result instanceof Stream or result instanceof Buffer
        destination = path.join outputDir, content.filename
        env.logger.verbose &amp;amp;quot;writing content #{ content.url } to #{ destination }&amp;amp;quot;
        mkdirp.sync path.dirname destination
        writeStream = fs.createWriteStream destination
        if result instanceof Stream
          pump result, writeStream, callback
        else
          writeStream.end result, callback
      else
        env.logger.verbose &amp;amp;quot;skipping #{ content.url }&amp;amp;quot;
        callback()

  items = ContentTree.flatten contents
  async.forEachLimit items, env.config._fileLimit, renderPlugin, callback

module.exports = {render, renderView}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Fairly straight forward code. Puts together the rendered content and I noted a few key things. There was a solid process order that was repeated; env, content, locals, contents, templates, callback. Because of this it looked like local variables were set to statically set certain things based on configuration instead of dynamic location. This could bite me, but with this quick glance, at least I knew where and what was happening with the order of generation.&lt;/p&gt;
&lt;p&gt;I then did a scan of the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/templates.coffee&quot; target=&quot;_blank&quot;&gt;templates.coffee&lt;/a&gt; and a few other code files. Having gotten a fair idea of where and what was being done, I went looking for a quick start. Things looked pretty good, so I crossed my fingers and my rant ends here…&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;[/rant off]&lt;/h2&gt;
So now that the rant mode was over, here’s what I did to make wintersmith my documentation solution. Most of this is in a state of flux as I automate and put more into the project to simplify the workflow.&lt;/p&gt;
&lt;p&gt;Here’s how I got started super fast.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/wintersmith-creating-documentation/wintersmith-04.png&quot; alt=&quot;Wintersmith Icon 4&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;First step is get &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt; running.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;npm install wintersmith -g
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that you’ll need to install it globally (thus the -g) and may need to install Wintersmith with sudo prepended to that command.&lt;/p&gt;
&lt;p&gt;The next thing that I did was create a directory that I’d use to build the static generated contents. This material I’d put into a git repository on github (namely the &lt;a href=&quot;https://github.com/Deconstructed/deconstructed/tree/gh-pages&quot; target=&quot;_blank&quot;&gt;deconstructed gh-pages repo&lt;/a&gt;). I’ll call this generically the root directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir rootDirectory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that I navigated into the rootDirectory and created a new Wintersmith Application.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wintersmith new myAppName
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That now gives me a directory structure like this&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rootDirectory&lt;/li&gt;
&lt;li&gt;myAppName&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that I have this, the app content, markdown, views and related templates are in myAppName. To view the app, I changed directories into myAppName and ran wintersmith preview like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wintersmith preview
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Opening up a browser I can navigate to &lt;a href=&quot;http://localhost:8080&quot; target=&quot;_blank&quot;&gt;http://localhost:8080&lt;/a&gt; and see the fully rendered site. To publish the site however one needs to run wintersmith build, however there’s one problem. I want the site to publish to the rootDirectory where the application content currently sites. To do this I have to edit the &lt;em&gt;config.json&lt;/em&gt; file. Just above the locals code settings shown below…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  locals: {
    url: http://localhost:8080,
    name: The Wintersmith&amp;#39;s blog,
    owner: Someone,
    description: Ramblings of an immor(t)al demigod
}
[/sourcecode]

I added an output key value property to the file as shown. It merely takes the results and shifts them back a directory so they end up in the rootDirectory.

[sourcecode language=&amp;quot;javascript&amp;quot;]
{
  output:../,
  locals: {
    url: http://docs.deconstructed.io,
    name: Deconstructed Docs,
    owner: Adron Hall,
    description: This site provides the documentation around the Deconstructed API Services.
  },
  plugins: [
    ./plugins/paginator.coffee
  ],
  require: {
    moment: moment,
    _: underscore,
    typogr: typogr
  },
  jade: {
    pretty: true
  },
  markdown: {
    smartLists: true,
    smartypants: true
  },
  paginator: {
    perPage: 6
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also changed the perPage setting to 6, just so I could get a little more content on the main page eventually. There is also the change for the domain name and a few other parameters that I’ll catch up on with the next blog entry.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In my next blog entry I’ll cover a quick how-to on how to setup the CNAME in github pages to get the static wintersmith site up at a subdomain/domain name. I’ll also dive into setup with AWS Route 53, which generically applies to setting a gh-pages site up with any DNS provider. So subscribe and I’ll have that post in the next 1-2 days.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>My Top 4 Ideal Dev Shop Product Characteristics and Yours?</title>
      <link>http://adron.github.io/articles/my-top-4-ideal-dev-shop-product-characteristics-yours/</link>
      <pubDate>Fri, 21 Oct 2011 19:00:00 -0500</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/my-top-4-ideal-dev-shop-product-characteristics-yours/</guid>
      <author></author>
      <description>&lt;p&gt;What is an ideal software project? What is an ideal delivery cycle? What is an ideal culture? From a client’s perspective do they see the team as a sluggish liability or is the development team proactive and looking for the next strategic or tactical step to take?&lt;/p&gt;
&lt;p&gt;Ideally, I see the development team as a group that should be leading a company with technology. If a team isn’t doing that, they’re likely to be running the risk of appearing as a liability and risk. Often these are the types of teams that are often outsourced or off-shored because it seems easier to the clients or management.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I don’t like the idea of getting stuck in a team like that. However, I’d do everything in my power to change that situation. In the past I’ve done just that. It is hard, but it is worth it. It boils down, unfortunately, to a perception and practice problem most of the time. A little like herding cats. Once you get them all together… well, you can read the picture. ;)&lt;/p&gt;
&lt;p&gt;[caption id=”” align=”alignright” width=”225” caption=”Herding Cats, ain&amp;#039;t a feeling like it in the world!”]&lt;img class=&quot; &quot; title=&quot;Herding Cats, Oh yeah!&quot; src=&quot;http://adronhall.smugmug.com/Software/Misc-Images/Bad-Resume/i-xPhHdVB/0/S/cat-herding-S.png&quot; alt=&quot;Herding Cats, Oh yeah!&quot; width=&quot;225&quot; height=&quot;180&quot; /&gt;[/caption]&lt;/p&gt;
&lt;p&gt;So what is my ideal team, product, and environment look like? That’s simple to answer.&lt;/p&gt;
&lt;p&gt;&lt;ol&gt;
    &lt;li&gt;Team cohesion through pairing, eating lunch together, having a beer once in a while, easy conversations, hallway troubleshooting, and other social interactions. These interactions should be easy, comfortable, almost as if everybody were friends. Better yet, the ideal situation is simply that people working on a project actually be friends. No reason, in and ideal situation, for everyone not to be.&lt;/li&gt;
    &lt;li&gt;Frequent delivery of product. Weekly, maybe every two weeks, but not much longer than that. The customer or client needs to be kept informed. If it is difficult to deliver something every week or two, that should be the top fix it item on the list of things to do. In this ideal environment of mine, I’d like to keep conversation and delivery on a weekly basis. Two weeks, often is a long time between delivery points.&lt;/li&gt;
    &lt;li&gt;Communication among all lines of the company. There should be zero resistance to talking to any part of the company, developer directly to whoever is involved in the product. If there is a user, the developers should have access to them.&lt;/li&gt;
    &lt;li&gt;Casual work environments are important. Generation Y especially, but X and others also don’t particularly like an environment to be socially stuffy because of forced attire. Dress comfortably, yet respectfully.&lt;/li&gt;
&lt;/ol&gt;
Usually with three out of four of these I’m a happy developer. If I get lucky enough to actually find 4 of 4, I’m happier than a kid in a toy store!&lt;/p&gt;
&lt;p&gt;What other characteristics draw you into a team or a product to work on? What gets you excited about the software you’re going to build or the team you’re going to work with?&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;
    &lt;li&gt;&lt;em&gt;&lt;strong&gt;Bobby&lt;/strong&gt;&lt;/em&gt; (&lt;a href=&quot;https://twitter.com/#!/NotMyself&quot; target=&quot;_blank&quot;&gt;@NotMyself&lt;/a&gt;) followed up on &lt;a href=&quot;http://iamnotmyself.com/2011/10/25/my-ideal-development-shop/&quot; target=&quot;_blank&quot;&gt;his blog here&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;Even though she didn’t write it in response to my blog entry, &lt;a href=&quot;http://katemats.com/&quot; target=&quot;_blank&quot;&gt;Kate’s blog entries&lt;/a&gt; on how to be awesome, reflects a lot of a great team member. &lt;a href=&quot;http://katemats.com/2011/10/09/manage-your-career-being-awesome-part-1/&quot; target=&quot;_blank&quot;&gt;Part 1&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/16/being-a-great-teammate-being-awesome-part-2/&quot; target=&quot;_blank&quot;&gt;part 2&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/21/improve-your-communication-skills-listening-being-awesome-part-3a/&quot; target=&quot;_blank&quot;&gt;Part 3a&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/22/improve-your-communication-skills-being-awesome-part-3b/&quot; target=&quot;_blank&quot;&gt;Part 3b&lt;/a&gt;, and &lt;a href=&quot;http://katemats.com/2011/10/23/keep-improving-being-awesome-part-4/&quot; target=&quot;_blank&quot;&gt;Part 4&lt;/a&gt;. All good reads.&lt;/li&gt;
&lt;/ul&gt;
If you write up your thoughts or ideas on an ideal dev shop or ideal product, let me know and I’ll provide a link to your blog as well!  :)&lt;/p&gt;
</description>
    </item>
  </channel>
</rss>