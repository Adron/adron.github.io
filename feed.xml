<?xml version="1.0" encoding="utf-8" ?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adron's Composite Code</title>
    <atom:link href="http://adron.github.io/feed.xml" rel="self" type="application/rss+xml"></atom:link>
    <link>http://adron.github.io</link>
    <description>Coder, Messenger, Recon, Infrastructure, Ops</description>
    <pubDate>Mon, 24 Oct 2016 01:00:00 +0100</pubDate>
    <generator>Wintersmith - https://github.com/jnordberg/wintersmith</generator>
    <language>en</language>
    <item>
      <title>Marketing Obliviousness of DevOps, WTF is Site Reliability</title>
      <link>http://adron.github.io/articles/devops-ignorance-site-reliability-wtf/</link>
      <pubDate>Mon, 24 Oct 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/devops-ignorance-site-reliability-wtf/</guid>
      <author></author>
      <description>&lt;p&gt;Recently I started researching what people think DevOps means. What it was originally intended to mean and how ridiculous it is to actually see it in a job title. On the flip of that, since one of my titles was actually “Site Reliability Engineer” I started looking into what is perceived to be the roles of that job. This article is my findings, in full unconstrained wording, about the absurdity of one as a title and the specifics of the other.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://adron.github.io/articles/devops-ignorance-site-reliability-wtf/syntax%20error.gif&quot; alt=&quot;Syntax Error Explosion&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;part-i-devops-is-nope&quot;&gt;Part I - DevOps is… Nope&lt;/h2&gt;
&lt;p&gt;In linguistics the word DevOps is generally considered a &lt;em&gt;blend word&lt;/em&gt; or a &lt;em&gt;portmanteau&lt;/em&gt;. It’s the combination of developer or development and operations. Meanwhile, Google actually understands what it is. But hey, we know Google is basically a smarter than humanity AI at this point right? Well, ok, maybe Google’s definition of DevOps isn’t 100% spot on, but it’s fairly close to its perceived meaning.&lt;/p&gt;
&lt;p&gt;Google’s definition reads, “DevOps (a clipped compound of development and operations) is a culture, movement or practice that emphasizes the collaboration and communication of both software developers and other information-technology (IT) professionals while automating the process of software delivery and infrastructure changes.”&lt;/p&gt;
&lt;p&gt;Part of that definition also takes it into account that some companies have no clue what they’re doing. Hiring a “DevOps Engineer” and then they end up throwing that person into the fire of systems administration menial servitude or the absurdity of &lt;em&gt;cluster fucked crossed wires&lt;/em&gt; network administration. So often a DevOps Engineer is hired without a company, human resources department, or management having any idea that DevOps was and is mostly focused around an idea more than any practice or notion. Sure, some of the practices we undertake are specific, but the idea is more important. It’s the combination of development and operations into a focused effort instead of being two battling organizations.&lt;/p&gt;
&lt;p&gt;But has that even really happened? In most offices DevOps has grown into another segmented, broken, and often dysfunctional group autonomous of both operations and development. Where the DevOps engineers may be creating automation or who knows, maybe just off drinking in the corner, ops doesn’t know because they’re fighting fires and development doesn’t have any idea because they’re building flame throwers to put the fires out (ya know, fighting fire with fire and all).&lt;/p&gt;
&lt;p&gt;If you want to get super pedantic about DevOps and what it might mean, check out the Wikipedia or go get your google-fu karate ninja chops going and make up your own definition from the various sources. I’m sure it would be super entertaining! …or not?&lt;/p&gt;
&lt;p&gt;Suffice to say, DevOps hit full buzzword bingo status a few years ago now. Now it exists in that strange limbo of &lt;em&gt;worthless buzzword&lt;/em&gt; and &lt;em&gt;relatively useful in a relative way&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&quot;devops-damage-an-aside&quot;&gt;DevOps Damage - An Aside&lt;/h3&gt;
&lt;p&gt;During one of my efforts researching DevOps I stumbled into Pete Cheslock’s blog post, “&lt;a href=&quot;https://pete.wtf/2013/05/03/devops-in-your-job-title-is-doing-you-harm/&quot;&gt;DevOps in Your job Title is Doing You Harm&lt;/a&gt;“. He points out it is better to title yourself something like&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Site Reliability Engineer&lt;/li&gt;
&lt;li&gt;Automation Engineer&lt;/li&gt;
&lt;li&gt;Release Engineer&lt;/li&gt;
&lt;li&gt;DevTools Engineer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll add, if you see titles like…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DevOps Hadoop Cloud Engineer&lt;/li&gt;
&lt;li&gt;DevOps Ninja&lt;/li&gt;
&lt;li&gt;DevOps Programmer&lt;/li&gt;
&lt;li&gt;Operations DevOps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…it’s ok to respond with a &lt;em&gt;“WTF did I just read?”&lt;/em&gt; and then just go ahead and fire that company. The company obviously hasn’t invested even the 10-30 minutes into figuring out what they’re trying to do. The risk is huge, everything is just gonna be a giant tire fire, &lt;em&gt;leave before you even apply to a job with a title like one of these.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Pete actually goes on to mention,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don’t know why recently there is a need to move away from the same job titles we’ve used in the past, as if there is some negative connotation towards them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To which my research into what exactly a Site Reliability Engineer differs versus titles like&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;System Administrator&lt;/li&gt;
&lt;li&gt;Operations Engineer&lt;/li&gt;
&lt;li&gt;Network Engineer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These notes aren’t the only gem of smarts in this post of Pete’s. Go read the blog entry, it’s &lt;a href=&quot;https://pete.wtf/2013/05/03/devops-in-your-job-title-is-doing-you-harm/&quot;&gt;here&lt;/a&gt;, I’ll wait as you should have the context. One more solid blog entry, check out Jez Humble’s “&lt;a href=&quot;https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/&quot;&gt;There’s No Such Thing as a DevOps Team&lt;/a&gt;“. Again, I’ll wait so go ahead and read it.&lt;/p&gt;
&lt;p&gt;Well, it’s time I dove into role of Site Reliability Engineer.&lt;/p&gt;
&lt;h2 id=&quot;site-reliability-engineer&quot;&gt;Site Reliability Engineer&lt;/h2&gt;
&lt;p&gt;I’ve gotten a few mixed results around what people think this role and title encompasses, but unlike DevOps which has unfortunately become a buzzword with oodles of overloaded context and meaning. What is generally sought out in the role of a site reliability engineer can be described best by what Ben Traynor stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Fundamentally, it’s what happens when you ask a software engineer to design an operations function.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I see SRE individuals and teams as the people who are actually moving us past the dark past inferred with the mystic past associated with the strange black magic mysticism of systems administration, operations, and network engineering of the past. It’s setting the practices involved in running those systems into a known manner of operation, that is repeatable, and in many ways more importantly able to be automated.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Enterprise Open Source Anti-patterns</title>
      <link>http://adron.github.io/articles/enterprise-open-source-anti-patterns/</link>
      <pubDate>Thu, 20 Oct 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-open-source-anti-patterns/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV (That’s this article)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;first part&lt;/a&gt; of this series I kicked off writing about how we created a manifesto at &lt;a href=&quot;http://www.homedepot.com&quot;&gt;Home Depot&lt;/a&gt;. This is something I’d strongly urge anybody that is helping to lead an enterprise toward open source efforts. The &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;second part&lt;/a&gt; focused on tactical tools used with open source software development. I’ll be adding more to the tools conversation a bit later in this series. Then in &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;part three&lt;/a&gt; I delved into some of the positive cultural characteristics of a team working on open source projects.&lt;/p&gt;
&lt;p&gt;In this part of the series I want to share a few thoughts on some of the anti-patterns that came up in the process. These are specific hurdles that continue to afflict the efforts, and range from a general disturbance or an outright conflict with efforts.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As I was creating these, I did a quick search to see what prospective open source anti-patterns existing with or without the context of enterprise open source. Not surprisingly there were a few, and the few that I found via the search I’ve attributed to who I found had written about them just under each description.&lt;/p&gt;
&lt;h2 id=&quot;1-insular-anti-pattern&quot;&gt;1. Insular Anti-Pattern&lt;/h2&gt;
&lt;p&gt;This is the idea that a group is so used to interacting behind closed doors, only among each other, that they fail to message, market, or even discuss the actual open source project with prospective contributors or others that are interested in public. This makes for code repositories that are starkly devoid of any conversation or information about what is being developed or why. It’s also a pretty sure fire way of killing your project, or insuring that the only group that uses it and develops the code for the project are those that started it.&lt;/p&gt;
&lt;h2 id=&quot;2-no-source-anti-pattern&quot;&gt;2. No Source Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is when a project is announced, usually by upper management that has somehow failed to determine where, who, or who they’re going to create or get the source code written. Companies that do this look embarrassingly absurd and out of touch with their actual employees that do the actual work at the company. Do NOT be this company.&lt;/p&gt;
&lt;h2 id=&quot;3-wishful-thinking-anti-pattern&quot;&gt;3. Wishful Thinking Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is the broken idea that because a project is brought into the open (new or existing) someone else will join in and do the work. If you’re not ready to do the work yourself, then don’t expect others to want to jump in and help you.&lt;/p&gt;
&lt;h2 id=&quot;4-extroverted-anti-pattern&quot;&gt;4. Extroverted Anti-pattern&lt;/h2&gt;
&lt;p&gt;This is similar to the No Source Anti-pattern. The pattern here is that a group - not particularly management - has gotten so excited preaching the idea of the project even when the project may or may not be moving forward. They see talk of the project as the means to an end even more than the actual code and project itself. This is most identifiable when a marketing or recruitment team sees the project as a means to market or recruit people but don’t have any vested interest in the actual code or project itself.&lt;/p&gt;
&lt;h2 id=&quot;5-forkaphobia-anti-pattern&quot;&gt;5. Forkaphobia Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is one of the craziest anti-patterns. The juxtoposition of this anti-pattern is the &lt;em&gt;forking paradox&lt;/em&gt;. The forking paradox is stated as &lt;em&gt;the easier it is to fork the software, the more difficult it is to the fork the community. If forking is easy, experimentation with ideas is persued while still remaining safely downstream. If forking is difficult, experimenters are reduced to dissenters - resulting in endless arguments (best case) or divorce (worst case).&lt;/em&gt; Bryan summarizes this one well with “Corporate Entities must therefore encourage forking - open source that cannot be forked has no vitality”.&lt;/p&gt;
&lt;h2 id=&quot;6-governance-anti-pattern&quot;&gt;6. Governance Anti-pattern&lt;/h2&gt;
&lt;p&gt;This is best seen in governance of real things, like people. The massive and complex ordeal of maintaining governance around a software project can become so large and unwieldy to to enforce an order and dictate on the future progress of the project. Necessitating a governance body or board is often a sign the project has become unwieldy with to many influencers who can’t agree on the direction. At this point, to maintain health and vitality it’s often best to fork the solution to break the stranglehold of the Governance Anti-pattern.&lt;/p&gt;
&lt;h2 id=&quot;7-eschewing-leadership-anti-pattern&quot;&gt;7. Eschewing Leadership Anti-pattern&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;via &lt;a href=&quot;https://twitter.com/bcantrill&quot;&gt;Bryan Cantrill @bcantrill&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Good open source have good leadership. When consensus isn’t available, good leadership turns that into positive direction and inspires people to move forward regardless. Projects that are started but nobody wants to take a leading role, even among people who generally decide on the direction, leads to a project that quickly spirals out of control into branches and forks and gets lost.&lt;/p&gt;
&lt;h2 id=&quot;8-demanding-assignment-anti-pattern&quot;&gt;8. Demanding Assignment Anti-pattern&lt;/h2&gt;
&lt;p&gt;Demanding assignment relies on a community trusting a commercial entity. Bad actors in open source (a notorious example is Oracle) however have destroyed that trust. To prevent this anti-pattern a contributor agreement to protect the source base from 3rd party claims of copyright and patent infringement. Copyright assignment still may make sense, but should be used only as a social contract.&lt;/p&gt;
&lt;h2 id=&quot;9-apathy-anti-pattern&quot;&gt;9. Apathy Anti-pattern&lt;/h2&gt;
&lt;p&gt;This anti-pattern is a combination of things like the Extroverted, Wishful Thinking, or No Source Anti-patterns. When this occurs a group simply throws their source code into a public repository but then does nothing else with it in the public repository. If active development isn’t done in the public repository, or a very effective story and information is provided as to why it’s a read-only kind of copy, there is an immediate threat that the project won’t just have apathetic developers that created it but worse, an apathetic audience who simply just won’t use it.&lt;/p&gt;
&lt;h2 id=&quot;10-opaque-anti-pattern&quot;&gt;10. Opaque Anti-pattern&lt;/h2&gt;
&lt;p&gt;In this anti-pattern a tool, set of tools, or other medium in which communication about the project is done almost entirely in a closed and invisible way. There are Github repositories for instance that the issues and wiki are turned off, and nobody communicates around the repository itself. Sometimes the communiation occurs in a closed email thread or other medium, like a closed Slack channel that is invite only. This isn’t to say that some communication could and should be kept in private, because there is some that should, but the bulk of the community’s communication should be available via public means. This is needed for others to use, understand, and work with the project. Otherwise the trust to make the project effective and move forward is simply not there. Don’t make your open source project efforts opaque!&lt;/p&gt;
&lt;p&gt;That’s my list of anti-patterns to watch out for when starting or moving an enterprise project into an open source model. There are probably more, and as usual, it’s an open invite to add more. Just let me know via twitter &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; and I’ll get them added right away.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;For more on Bryan’s talk on the anti-patterns he discusses, here is a video of the talk: &lt;iframe width=&quot;960&quot; height=&quot;540&quot; src=&quot;https://www.youtube.com/embed/NhgXQFk9noI?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;Here’s what I believe is the &lt;a href=&quot;http://www.slideshare.net/bcantrill/corporate-open-source-antipatterns&quot;&gt;slide deck&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV (That’s this article)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Enterprise Open Source Cultural Characteristics</title>
      <link>http://adron.github.io/articles/enterprise-cultural-characteristics/</link>
      <pubDate>Mon, 17 Oct 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-cultural-characteristics/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III (That’s this article)&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My friend Glenn Block &lt;a href=&quot;https://twitter.com/gblock&quot;&gt;@gblock&lt;/a&gt; contacted me via Twitter and we discussed some of what I had discussed in the previous post. He brought up some good points and I realized there were a few points I ought to bring up regarding what I’d previously written about.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;atlassian-tools-good-stuff&quot;&gt;Atlassian Tools, Good Stuff&lt;/h3&gt;
&lt;p&gt;Most of the fight I’ve had undertake has been what appears to be against the aforementioned Atlassian Tools: JIRA, Confluence, and Stash. I think it is important to clarify my position however, the tools are perfectly capable of and well suited for any closed source internal development, and even being used for open source if they’re paired with the appropriate practices and usage patterns. If they’re not, their use can amplify the difficulty in creating open source solutions - but that amplification is merely the amplification of those cultural practices that make it difficult to change to a process that helps build useful and effective open source projects.&lt;/p&gt;
&lt;p&gt;The other thing I mentioned, was the price tag of the Atlassian tools. I failed to mention that for open source, Github pricing for Enterprise efforts just like anybody else’s is free. I believe that’s the same for Bitbucket, so the comparison was rather disingenous on my behalf. The comparison and migration path before me, to get solutions into the open, was the free utilization of Github. JIRA, Confluence, and Stash on the other hand required practices that were costly and time consuming on our behalf. Such things as maintaining the servers running the software, management of security needs (SSL/TLS/HTTPS, etc), and the whole host of managing the entirety of these servers when all we really needed for open source work was repo + wiki + issues.&lt;/p&gt;
&lt;p&gt;But I do digress, I’m ready to move from tools to practices and how those have to change. Moving from internal software development that is hidden from prying eyes to open source development, beyond tools or manifestos, has it’s largest barriers simply in cultural change that is necessary.&lt;/p&gt;
&lt;h3 id=&quot;enterprise-open-source-cultural-characteristics&quot;&gt;Enterprise Open Source Cultural Characteristics&lt;/h3&gt;
&lt;p&gt;The section of this part of the series could have been named “The Hard Part”. Cultural change is something that moves at a glacial pace in an enterprise and must be a top down and bottom up effort. If it isn’t supported by management, it’ll likely fail, and if it isn’t supported by the contributors themselves, it will surely fail.&lt;/p&gt;
&lt;p&gt;First, here are some of the positive characteristics that always help. Whether it is a brand new greenfield project or an existing project that will be started or moved to be developed in the open, these are the characteristics that are invaluable.&lt;/p&gt;
&lt;h3 id=&quot;my-current-top-5&quot;&gt;My Current Top 5&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;…key culteral characteristics for enterprise open source development.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Self-Organizing - Leaders that lead and followers that follow. Don’t be the person that won’t get out of the way. Open source projects need followers that want to dive in, prospectively lead on parts, cut out corners to build, and projects need leaders to insure that the project stays true to its intent.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Decisive - We’re talking about the internet, the wild wide open internet, being decisive in an intelligent way is vital to help an open source project grow into what it is deemed to be.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Aware - It’s important when working on company projects in the open, as mention in the entry where I layed out the &lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Home Depot Manifesto&lt;/a&gt; which includes important awareness around trade secrets.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inclusive - The project needs to be aware of it’s particular cultural characteristics, but it’s also important to pick up new traits and characteristics to improve development practices over time. Encourage others to join the project and actually provide some type of outreach and support for anybody that wants to help out with the project. This alone I have found is one of the most difficult features that Enterprise Open Source projects need to build and encourage. Usually enterprise projects are simply insular because of their internal facing needs. Often they don’t even realize when they could have things easier or expanded to help all involved - until it happens.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Learning - The members of the project team on an Enterprise Open Source Project need to encourage learning new ways, practices, tools, and capabilities for the project. Encouraging some to always learn puts a project on a trajectory with continued innovation, improved practices, and perpetuating a healthy balance of progress into the future. Getting a project stuck on X set of tools and such doesn’t help anyone in the long run, just take a look at the past of so many infrastructure open source projects like Cloud Foundry, HashiCorp tools, etc that were once Ruby but have migrated almost entirely to Go. In this particularly situation, learning and keeping up on the new technology has helped those platforms move forward.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are more, but these are the top 5 at the moment. If you think I’ve missed any really important trait that should be mentioned, tweet at me &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; and it’s possible we could get the top 6.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III (That’s this article)&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Let's Talk Tactical Tools for Enterprise Open Source</title>
      <link>http://adron.github.io/articles/enterprise-open-source-tactical/</link>
      <pubDate>Sun, 16 Oct 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/enterprise-open-source-tactical/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In the first part I wrote about the Enterprise Open Source Manifesto that was written up for Home Depot’s open source efforts. In this part I’m going to tactical some of tooling &amp;amp; cultural characteristics that came into play.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;enterprise-open-source-tooling&quot;&gt;Enterprise Open Source Tooling&lt;/h3&gt;
&lt;p&gt;Every team had a number of tools in use upon the beginning of these efforts. I’m going to dive into a few of the tools we used and how those helped and hurt us all at the same time. After that Iv’e got a discussion on future tool choices, current tool migrations, and goals.&lt;/p&gt;
&lt;h3 id=&quot;existing-pre-oss-efforts&quot;&gt;Existing Pre-OSS Efforts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;JIRA&lt;/li&gt;
&lt;li&gt;Confluence&lt;/li&gt;
&lt;li&gt;Stash&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;jira-stash-and-confluence&quot;&gt;JIRA, Stash, and Confluence&lt;/h4&gt;
&lt;p&gt;JIRA has a lot of pluses and negatives, and I do mean a lot! I’m going to start with the pain points and then move onto the positives.&lt;/p&gt;
&lt;p&gt;Access - One of the major pain points was that JIRA had harbored a completely closed communication practice. What I mean by this was that all communications, as one would assume, were being done in a very insular way. Since the tool had traditionally been used only for closed source development, it was by it’s very nature configured to be exclusionary to any and all possible open source efforts.&lt;/p&gt;
&lt;p&gt;User Limits - The way JIRA is configured, one doesn’t merely get added or become a contributor in any general sense. One needs to fall under a particular user paradigm like Active Directory, controlled auth SSO style accounts, or something of that sort. This leaves JIRA very limited for public access and contributions from an organizational perspective.&lt;/p&gt;
&lt;p&gt;JIRA is extremely heavy and many open source efforts are super lean. I realize for a project with a lot of pull requests and interactions there needs some way to oganize all the interactions, but for small projects or even reasonably sized projects JIRA is overkill.&lt;/p&gt;
&lt;p&gt;Another issue is that JIRA becomes a practice that dictates effort versus effort and results that dictate practice. This in turn makes it even more difficult to break certain practices and dogma to move toward lighter weight practices. More seamless open source projects and the practices that would and can move an open source project forward are disregarded because X, Y, and Z activities must be performed because of the “JIRA”.&lt;/p&gt;
&lt;p&gt;Confluence is actually a great wiki tool. Albeit again, it’s a matter of overkill. Often the wiki that is needed is just a simple tool that can provide absolutely minimalistic wiki features. Maybe markdown is the standard mechanism to markup wiki pages with even. Whatever the case it needs to be simple.&lt;/p&gt;
&lt;p&gt;However, again just like with JIRA, these tools work great for dramatically larger and more complex projects. They can and do provide a great ability to cohesively bring together larger teams of people to work together in a more effective manner.&lt;/p&gt;
&lt;p&gt;Stash is useful in some ways, but again just like with JIRA, Confluence and related tooling it tends to be used to provide a way to hide away the source code internally. This in turn, just as with JIRA and Confluence work toward hiding software and not toward bringing it forward in an open and transparent way for others to work with.&lt;/p&gt;
&lt;h3 id=&quot;new-tools-for-enterprise-oss-efforts&quot;&gt;New Tools for Enterprise OSS Efforts&lt;/h3&gt;
&lt;h4 id=&quot;github&quot;&gt;Github&lt;/h4&gt;
&lt;p&gt;So Github comes to the rescue. For the most part there is a simple reason that it is the defacto go-to place for open source. It’s in the open, millions already use it, their git intergration is good, they have pretty straight forward minimalist focused interfaces and features, and it gets the job done.&lt;/p&gt;
&lt;p&gt;Does Github miss key features for some? Absolutely. Do issues get cumbersome and out of control after moderate conversation. Of course they do, especially with their single depth style of forum comments. Even with whatever disadvantages it has, Github was the go-to for us when we wanted to open source software too. It provided many of the key features we need; wiki, issues, and simple ways to track for simple projects.&lt;/p&gt;
&lt;p&gt;Now, with all the negatives pointed out, one could actually use JIRA, Stash, and Confluence for open source work. You just need to open up all of the software to the public. They’ve be perfectly capable from a technical point of view to accomplish the mission, albeit it’d probably cost a ton of cash.&lt;/p&gt;
&lt;h4 id=&quot;jell&quot;&gt;Jell&lt;/h4&gt;
&lt;p&gt;Need a quick tool for managing the daily punch list, or more simply, what I generally call the &lt;em&gt;My GSD for Today&lt;/em&gt; items? Jell is a great tool for this. Others that come to mind are Trello or even just plain old Google Docs (I guess that’s G-suite now). Whatever the case, it helps members to have a punch list if it’s a day-to-day, regularly worked on project. This helps with that communication across any contributors, even if contributors are all in a single office.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That’s it for part II. More to come for this series real soon, and I’ll update the post with a link right here to Part III as soon as it’s published.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Holy Shit Watch Out for That Enterprise Open Source!</title>
      <link>http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/</link>
      <pubDate>Wed, 12 Oct 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This blog entry is going to be the conjoined events of open source work at Home Depot, enterprise open source in general, and the ideas and punch lists for a talk I have coming up in London on open source enterprise practices. So this will be a hard drifting whirlwind, buckle up!&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the last year there’s been several specific projects I’ve led and consulted on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My work at Home Depot included efforts to bring various closed sourced solutions into the open, some which have been and others that have not been - but may be on their way! Read to the end to see how you might be able to help with this.&lt;/li&gt;
&lt;li&gt;I’ve provided consulting to several enterprise efforts over the last year as they’ve looked toward bolstering their experience and effort providing a coordinated participation within the open source community.&lt;/li&gt;
&lt;li&gt;Putting together a talk related specifically to helping enterprises bridge the gap between insular, closed source, limiting internal development to a inclusive, open source, community oriented contributor and user of software solutions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;enterprise-software&quot;&gt;Enterprise software&lt;/h2&gt;
&lt;p&gt;First let’s talk a little bit about enterprise software in general. There is an extremely wide range of disparity in Enterprise software. Some software turns out pretty good, others are complete catastrophes to the point the projects are cancelled and the software is deleted without remorse.&lt;/p&gt;
&lt;p&gt;Just recently this disparity in quality was brought up on via some tweets.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I don&amp;#39;t understand how huge companies with major $$$ can release software that&amp;#39;s such a shit-show - don&amp;#39;t they test it, dogfood, etc.?&lt;/p&gt;&amp;mdash; Dave Glick (@daveaglick) &lt;a href=&quot;https://twitter.com/daveaglick/status/786247215660621824&quot;&gt;October 12, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Dave Glick stated this and it spiraled into a conversation about how big companies, with seemingly endless budgets still produce such horrible applications sometimes. It reminds me of this article I read on the Pivatol Blog by Stacey Schneider (&lt;a href=&quot;https://twitter.com/sparkystacey&quot;&gt;@sparkystacey&lt;/a&gt; ), “Quiz Your Company: How Well Are You Setup to Develop Great Software?”&lt;/p&gt;
&lt;p&gt;Over time this horrible disparity can be narrowed, and the band of good to bad can move toward the “good software” end of the spectrum for enterprises. One of the key steps that helps to produce a better culture around good software for enterprises is moving the effort toward a more open practice with transparent communications, public involvement, and of course actual open source code and licensing.&lt;/p&gt;
&lt;h2 id=&quot;enterprise-open-source&quot;&gt;Enterprise Open Source&lt;/h2&gt;
&lt;p&gt;Let’s take a look at one of the best examples of an open source enterprise. Let’s talk about &lt;a href=&quot;https://www.netflix.com&quot;&gt;Netflix&lt;/a&gt;. Ok, you may be screaming in your head that Netflix doesn’t count, but at 19 years old (August 29th, of 1997 it was founded), $6.78 billion in 2015 revenue, $10.2 billion in assets, 83 million worldwide users, and 3,500 employees Netflix absolutely counts as a large enterprise.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://netflix.github.io/&quot;&gt;&lt;img src=&quot;/articles/holy-shit-watch-out-for-that-enterprise-open-source/netflix-oss-logo.png&quot; alt=&quot;Netflix OSS&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Netflix has gone hard core into the OSS realm. They’ve &lt;a href=&quot;http://techblog.netflix.com/2015/10/evolution-of-open-source-at-netflix.html&quot;&gt;written about it&lt;/a&gt; on their &lt;a href=&quot;http://techblog.netflix.com/&quot;&gt;Netflix Tech Blog&lt;/a&gt;. They’ve even gone so far as to create a &lt;a href=&quot;https://netflix.github.io/&quot;&gt;Netflix Open Source Software Center&lt;/a&gt; too. Of course all of this is is rolled together in the repositories on Github under the &lt;a href=&quot;https://github.com/Netflix&quot;&gt;Netflix Organization&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This has given Netflix massive credibility within the world of developers, providing a true resource and partner to the developer community. But what does that give Netflix from a more tactical point of view? I’ll list a few things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;More eyes on their code that they use to run production. Which translates into more ideas on improvements, catching issues faster, bug fixes inside and outside of the company, and more from this angle.&lt;/li&gt;
&lt;li&gt;Credibility in the industry translates to gaining the eye of the top tier people that Netflix wants and needs for their organization.&lt;/li&gt;
&lt;li&gt;Massive clout as a leader in innovation and technological change, which provides even more of both 1 and 2.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;home-depot-open-source-enterprise&quot;&gt;Home Depot, Open Source Enterprise&lt;/h1&gt;
&lt;p&gt;Ok, so Netflix is a big enterprise that has done it right. They’ve also been reaping the rewards in a huge way, and they’ve set a kind of guidance to others trying to tread that path. At Home Depot it’s been a bit work, but the effort has started with some tangible progress. Since software development and computer tech things is not the focus point at Home Depot, it is a logical path for the company to shift with it’s IT and related resources. As you probably know very well dear reader, Home Depot is a large brick and mortar storefront operation, and it’s best for Home Depot to focus on this, where their customers are!&lt;/p&gt;
&lt;p&gt;With that in mind, the idea for Home Depot to begin using more open source was super easy. But to start providing open source of their own and to get involved has been a dramatically larger challenge. The leadership has a very smart view of the matter, they want to be part of the community and provide and gain the advantages of going open source. Just like Netflix, there’s a lot to be gained.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/holy-shit-watch-out-for-that-enterprise-open-source/homedepot-contributors.png&quot; alt=&quot;Home Depot Contributors&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;getting-things-started&quot;&gt;Getting Things Started&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://allspark-thd.github.io/manifesto/&quot;&gt;Home Depot’s OSS Manifesto&lt;/a&gt; reads with the intent of the efforts and a break out of six specific tenets:&lt;/p&gt;
&lt;h3 id=&quot;we-value&quot;&gt;We Value&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Giving Back&lt;ul&gt;
&lt;li&gt;As developers we use tools provided by the wider community – it’s our responsibility to pay it forward&lt;/li&gt;
&lt;li&gt;Beyond the ethics, as we contribute, so will others – which improves the software we use&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Excellent Customer Server&lt;ul&gt;
&lt;li&gt;By using and improving open source, the software we provide to our associates and customers is of higher quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Creating shareholder value&lt;ul&gt;
&lt;li&gt;Making use of open source makes us more productive and efficient&lt;/li&gt;
&lt;li&gt;As we contribute software, we get the benefit of improvements from the entire community&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Entrepreneurial Spirit&lt;ul&gt;
&lt;li&gt;Encouraging associates to develop the software that interests them provides a creative outlet&lt;/li&gt;
&lt;li&gt;Many key software components we rely on were created as side projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Taking care of our people&lt;ul&gt;
&lt;li&gt;Allows associates to contribute, gives them a public showcase for their talents&lt;/li&gt;
&lt;li&gt;Participating in open source is a fantastic forum for learning from industry experts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Respect for all people&lt;ul&gt;
&lt;li&gt;Open source is one of the most diverse communities available&lt;/li&gt;
&lt;li&gt;Great feedback and communication skills can be developed working on large open source efforts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Doing the right thing&lt;ul&gt;
&lt;li&gt;Making code public is the best way to ensure that you take pride in your work&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Building strong relationships&lt;ul&gt;
&lt;li&gt;Open source allows developers to build relationships beyond their team&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;we-believe&quot;&gt;We Believe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Have a readme file&lt;/li&gt;
&lt;li&gt;Have a contributing file&lt;/li&gt;
&lt;li&gt;Have a license file&lt;/li&gt;
&lt;li&gt;Follow semantic versioning&lt;/li&gt;
&lt;li&gt;Have easily visible CI&lt;/li&gt;
&lt;li&gt;Tag all releases&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;have-an-idea-&quot;&gt;Have an Idea?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Could my code be helpful for other devs, and is it something that doesn’t already exist?&lt;/li&gt;
&lt;li&gt;Do I feel comfortable that work I’m doing does not include trade secrets?&lt;/li&gt;
&lt;li&gt;Do I have CI setup, and is it publically visible?&lt;/li&gt;
&lt;li&gt;Why are you still asking questions, push some code!&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;readme-file&quot;&gt;Readme file&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The readme is the first thing will people will see about your project. This should provide an explanation for why it exists, and why anyone would care about it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;What are my rights?
You also should include license information, so they understand how to use it. Our default license is Apache 2
How can I help?
If you’re open sourcing something, you are hopefully open to outside contributions. Make sure your expectations and process are clearly laid out for people who want to help. You should tell them how to make the thing run and how to test it – in simple, easy to follow steps.&lt;/li&gt;
&lt;li&gt;Does this thing even work?
A sign of a high quality project is well written tests, that are continuously run. By having CI setup and publicly shown, visitors to your repo can have confidence in the code. This could include badges or a link to an example of the live application&lt;/li&gt;
&lt;li&gt;Is anyone maintaining this and/or what just changed?
As you update the project, you should provide semantic versioning to allow consumers to understand the types of changes made, and allow them to use the project with security. You should include release notes that detail any important features or bug fixes, and specifics on any breaking changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;trade-secrets-what-shouldn-t-be-open-sourced-&quot;&gt;Trade Secrets - What shouldn’t be open sourced?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Code that includes work that is licensed by someone else&lt;/li&gt;
&lt;li&gt;Work that provides a significant competetive advantage over other retailers&lt;/li&gt;
&lt;li&gt;Projects that are dependent on THD specific environment&lt;ul&gt;
&lt;li&gt;This should be only true in rare cases&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code that does not have CI or automated unit tests&lt;ul&gt;
&lt;li&gt;Please don’t do this, even if you aren’t open sourcing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Code that is essentially the same as other open source projects&lt;ul&gt;
&lt;li&gt;Could you contribute to those projects instead?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;tactical-process&quot;&gt;Tactical Process&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ensure your manage/team lead approves the effort&lt;/li&gt;
&lt;li&gt;Request open source submission approval&lt;/li&gt;
&lt;li&gt;Push the code&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is of course our version of the OSS Manifesto as detailed at &lt;a href=&quot;http://ossmanifesto.org/&quot;&gt;http://ossmanifesto.org/&lt;/a&gt; (after I posted, realized this site is dead!  :( But here’s the &lt;a href=&quot;https://github.com/allspark-thd/manifesto&quot;&gt;repo of the HD Manifesto&lt;/a&gt;). This is one piece I highly suggest any group of individuals at an enterprise to give a read to, and create their own manifesto per their enterprise they work for. It’s good for many reasons to write this out and provide it.&lt;/p&gt;
&lt;p&gt;The main two reasons I really like the OSS Manifesto include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The transparency it provides to users of the project(s) of a particular enterprise.&lt;/li&gt;
&lt;li&gt;The other thing is that it provides a much needed brain storming session to identify and define the groups intent and efforts on a more metaphsycial level, which is hugely needed to understand how a team working on a project and it’s prospective contributors would interact with each other. Defining these core tenants is fundamental to a smooth workflow between contributors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/articles/holy-shit-watch-out-for-that-enterprise-open-source/&quot;&gt;Part I (That’s this article)&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-tactical/&quot;&gt;Part II&lt;/a&gt;, &lt;a href=&quot;http://adron.github.io/articles/enterprise-cultural-characteristics/&quot;&gt;Part III&lt;/a&gt;,
&lt;a href=&quot;http://adron.github.io/articles/enterprise-open-source-anti-patterns&quot;&gt;Part IV&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.netflix.com&quot;&gt;Netflix&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Netflix&quot;&gt;Netflix Wikipedia&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.homedepot.com&quot;&gt;Home Depot&lt;/a&gt; and &lt;a href=&quot;https://github.com/homedepot&quot;&gt;Home Depot Github Org&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>The Curse of Windows Server &amp; Windows Server 2016 Salvation</title>
      <link>http://adron.github.io/articles/the-curse-of-windows-server-windows-server-2016-salvation/</link>
      <pubDate>Fri, 07 Oct 2016 14:38:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/the-curse-of-windows-server-windows-server-2016-salvation/</guid>
      <author></author>
      <description>&lt;p&gt;Over the last year I’ve worked with &lt;a href=&quot;https://homedepot.com&quot;&gt;Home Depot&lt;/a&gt;, specifically the &lt;a href=&quot;http://www.quotecenter.com/&quot;&gt;Quote Center&lt;/a&gt; Group, strive forward toward a better future. Yeah, that sounds a bit campy, but seriously. I started with &lt;a href=&quot;http://blog.adron.me/articles/after-816-days-taking-a-job/&quot;&gt;three core objectives, which I wrote about previously&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Community Contributions&lt;/li&gt;
&lt;li&gt;Site Reliability&lt;/li&gt;
&lt;li&gt;Talent Recon&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve been able to help with each of those things over the last year, with more progress being made on some than others. Right now, I want to delve a bit into the adventure of &lt;a href=&quot;https://landing.google.com/sre/interview/ben-treynor.html&quot;&gt;site reliability&lt;/a&gt; at Quote Center. First off, I had the honor of being first guard for Quote Center in the realm of site reliability. I had a lot to do just to set some groundwork on what that position really meant. In addition to the other two &lt;em&gt;roles&lt;/em&gt;, err, &lt;em&gt;priorities&lt;/em&gt;, it was like taking a job that would have three roles rolled into one. For this article though, I’m going to write about specifically the site reliability and what I did to get some practice and culture around the notion of site reliability at Quote Center.&lt;/p&gt;
&lt;p&gt;The first thing, was simply to write out some ideas about what this would involve. Here are a few of my original questions that I scribbled on the matter.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Servers/Instances - Need to figure out where and what servers are magical black magic servers versus fully automated instances? Where be the goodies?&lt;/li&gt;
&lt;li&gt;Networking - What’s where and who’s doing this?&lt;/li&gt;
&lt;li&gt;Monitoring - What do we know exists, where, and how are we alerted when something goes down? How many things are there? How many could go down?&lt;/li&gt;
&lt;li&gt;How does site reliability measure up versus systems admin, network opes, or what not? Who says what?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was working entirely from a blank slate, it appeared the first step would be to get a better definition of what exactly this should cover. One thing I did do was read up on what the notion of Site Reliability Engineer was. I wanted to have a good industry definition of the role. That led to a quick set of resources via Google. Google seems to be the creator of said position, whether they are or not doesn’t matter, because the material they have on the role is excellent. To paraphrase a summary, what an SRE is.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An SRE is basically a software engineer that is responsible for designing operations functions. This includes interacting with production environments, automation, high availability improvements, monitoring, and more. All approached from a programmatic perspective versus the more traditional notion of hands on systems administration or network administration. Other terms most commonly associated with and responsibilities of SREs include; availability, latency, performance, efficiency, change management, monitoring, emergency response, and capacity planning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As I dove into this work, amid all the other priorities, I was spending about ~15-20 hours a week on the efforts under this priority (or role). This was ok to get things off the ground. Here are a few other key things I put together within the first 6 months.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We needed action ASAP to modernize and build on modern cloud infrastructure. I went through working with various partners in the organization to insure that our decisions would work with, or align with, or utilize software, services, and solutions that would jive with corporate. Even though I’d started down the route with Amazon Web Services (AWS), Home Depot made a &lt;a href=&quot;http://www.reuters.com/article/us-google-home-depot-cloud-idUSKCN0WO380&quot;&gt;higher level decision to move forward with Google Cloud Platform&lt;/a&gt;. This was an easy switch to make, because I’d also started a trial with various &lt;a href=&quot;https://www.hashicorp.com/&quot;&gt;HashiCorp&lt;/a&gt; tools (Atlas, Terraform, and Packer specifically) that made it a breeze to swap out anything already done.&lt;/li&gt;
&lt;li&gt;The next thing was to get some practices put into place to handle change management of infrastructure. I started working on this in the subsequent 3 months but made very little movement forward. This was because my other priorities took precedence during this time - the Talent Recon &amp;amp; Community Contributions priorities. During this time I worked with Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37/&quot;&gt;@thoward37&lt;/a&gt;) to put on two conferences we’d co-founded: &lt;a href=&quot;http://dotnetfringe.org/&quot;&gt;.NET Fringe 2016&lt;/a&gt; and &lt;a href=&quot;http://nodepdx.org/&quot;&gt;Node PDX 2016&lt;/a&gt;. However, even in spite of all those work, I was able to implement another major HashiCorp Server with Atlas. This helped to start shaping our workflow in a tremendous way.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This was great, and in that first 6 months I was able to get a lot of traction on those efforts. Then the Windows Server battle started…&lt;/p&gt;
&lt;h2 id=&quot;the-windows-server-nightmares&quot;&gt;The Windows Server Nightmares&lt;/h2&gt;
&lt;p&gt;More than a few things we wanted to get deployed using container technology. But because of the limitations of Windows Server around its complete lack of container capabilities and the limited support of drivers within .NET, our container hopes were dashed for the time being. Even with this in our way of moving forward with containers, we knew it would eventually be the future. So what did we do in the meantime to move forward and build out our microservices now?&lt;/p&gt;
&lt;p&gt;The team delved into deployment per Windows Server using a Windows Services Service based approach. In other words, the services you see when you pull up the MMC on Windows Server? Yeah, that’s what we used in the meantime to deal wtih the lack of container support. This gave our microservices the ability to get deployed with many of the feature notions we wanted and will eventually use with container tech. This however didn’t bode well for immutable deployments or clean continuous integraiton and deployment to Windows Server, and we continued to look forward to a container option in the near future with excitement.&lt;/p&gt;
&lt;h2 id=&quot;yay-windows-server-2016-to-the-rescue-&quot;&gt;Yay Windows Server 2016 to the Rescue!&lt;/h2&gt;
&lt;p&gt;Then, enter Windows Server 2016. The news that Windows Server 2016 would have container support was huge. We would absolutely move onto that to gain the advantage of containers if, and only if .NET Core didn’t gain enough driver and related capabilities that we didn’t get to move to Linux first. You see, if we had our druthers, we’d just move to Linux and forgo Windows Server altogether. But Windows Server 2016 at least provided us a path forward if .NET Core drivers and such weren’t ported before it’s release.&lt;/p&gt;
&lt;p&gt;On the flip of all this, you might ask, “&lt;em&gt;why would you deploy .NET stuff to&lt;/em&gt; Linux &lt;em&gt;instead of&lt;/em&gt; Windows Server?” There are a host of reasons, and the first that always pops into my mind wasn’t one of our actual concerns, but it is routinely for others. That would be pricing. Holy bajeezuz the licensing costs adds a lot to running Windows Server instances. It makes many multi-VM solutions cost prohibitive for many solutions, and hopefully containers may change this paradigm more effectively.&lt;/p&gt;
&lt;p&gt;If you are in the search for server tech for microservice hosting, suffice it to say, Windows Server is &lt;strong&gt;&lt;em&gt;NOT&lt;/em&gt;&lt;/strong&gt; particularly the way to move forward unless you have tons of Windows proprietary code base or IIS demands of some other proprietary demand for Windows Server. There is an extreme minimum of reasons to use Windows Server if you’re trying to deploy and efficiently manage microservices and the related infrastructure, practices, and advantages. The ecosystem, market, and industry as a whole has generally moved onto or has just been using &lt;em&gt;JVM + Cloud Provider + Automation Toolchain&lt;/em&gt;. This usually equates to &lt;em&gt;JVM + AWS + HashiCorp Tools&lt;/em&gt; or &lt;em&gt;JVM + GCP + Chef&lt;/em&gt; or &lt;em&gt;JVM + Azure + Puppet&lt;/em&gt;. Most of the future looks something like that. These tools are all dramatically better places to start than using a Windows OS based environment. But alas, back to the pending salvation of Windows Server 2016.&lt;/p&gt;
&lt;h2 id=&quot;the-other-fix-x-plat-net-core&quot;&gt;The Other Fix, X-Plat .NET Core&lt;/h2&gt;
&lt;p&gt;The other solution, post Windows Server 2016, which I look forward to with even more excitement is the ability to run .NET Core Apps on Linux. The reason, is that the operational characteristics for Linux, especially in a high availability, highly scalable, cloud environment (etc., etc., etc.) are years ahead of the Windows Server solutions at this time. On a cost per server and cost per unit of compute, Linux is easily the winner - and of course that is if you are even dealing with an OS yourself - if you’re in the vmless or serverless game then prices get even cheaper prospectively. However, as is obvious, Windows Server isn’t even in that game, it’s a purely cloud play really.&lt;/p&gt;
&lt;p&gt;If you are a Windows Server advocate and you do have legitimate needs to use Windows Server, but still want all the good bits that come along with container technology, Windows Server 2016 is going to be your salvation! Maybe. Soon it’ll even be available in Google Cloud (I hope REAL soon) and I can spool up a few examples of said OS with said .NET Core bits and then migrate said .NET Core bits directly to Linux! At least, I’m looking forward to doing just that.&lt;/p&gt;
&lt;h2 id=&quot;summary-how-you-could-help&quot;&gt;Summary &amp;amp; How You Could Help&lt;/h2&gt;
&lt;p&gt;As you know, from my article “&lt;a href=&quot;http://blog.adron.me/articles/sitrep-home-depot-wrap-up-next-talks-next-job/&quot;&gt;Home Depot Wrap Up and Job Talk&lt;/a&gt;“, I’ve moved to Seattle and am working on a transition. Quote Center is looking for people who would love to dive into the world of site reliability, working with not just Windows but also Linux, Node.js, and a host of other systems. If you’re keen on joining the team, feel free to &lt;a href=&quot;http://blog.adron.me/docs/contact/&quot;&gt;reach out to me&lt;/a&gt; and I can put you in touch with the right people to get the conversation rolling. Otherwise you can also just check out the &lt;a href=&quot;http://quotecenter.com/#openpositions&quot;&gt;job descriptions here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Home Depot Wrap Up and Job Talk</title>
      <link>http://adron.github.io/articles/sitrep-home-depot-wrap-up-next-talks-next-job/</link>
      <pubDate>Fri, 30 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/sitrep-home-depot-wrap-up-next-talks-next-job/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/home-depot.png&quot; alt=&quot;Home Depot&quot;&gt;
&lt;/div&gt;

&lt;p&gt;First, I will be available with a possible start date of November the 28th. I’m currently wrapping up some big projects and completing training for the Home Depot Team and the great progress we’ve made over the last year. If your company is looking for someone with my mixed array of technical skills and soft skills, you can &lt;a href=&quot;http://adron.github.io/docs/about&quot;&gt;check out my resume &amp;amp; details&lt;/a&gt; and initiate &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;job talk with me here&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;On to the rest of the news. If you’ve seen me speak lately I’ve mentioned the open source efforts we’ve had going on at &lt;a href=&quot;http://www.homedepot.com/&quot;&gt;Home Depot&lt;/a&gt; and related efforts I was working on. Some I’m working dilligently to release via the &lt;a href=&quot;https://github.com/homedepot/&quot;&gt;Home Depot OSS Organization on Github&lt;/a&gt; and I’ll still be releasing others soon via my Github account (&lt;a href=&quot;https://github.com/Adron&quot;&gt;@Adron&lt;/a&gt;) and blogging about it here on &lt;a href=&quot;http://blog.adron.me&quot;&gt;Composite Code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Since this is one of those rare times in my career where I’m not 100% sold on what I’ll do next, I’m open to fielding prospects and seeing what is out there. This is a different approach for me, as I usually determine a company, particular work that needs done and go after that gap. But I’d like to get a feel for what companies feel they need at this particular time. Since I have a wide range of skills, I can step into a number of positions and immediately start to contribute to projects within a company.&lt;/p&gt;
&lt;p&gt;Here are some positions I’d find attractive and could provide value for (or build) a team immediately!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Building or Expanding a Team&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Need someone to hire, build, and create a cohesive, diverse, and powerful culture of core contributors (developers, designers, advocates, evangelists, or similar). I can knock this one out of the park for the right company. Yes, I’m a bit particular, but I’m not just going to whimsically work for any company (the best people won’t work for just any old company anyway). If you are looking to put a team together and want somebody that can do that for you, I’d like to sit down to a conversation soon. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Coding Architect&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Have some architecture problems, that seem a bit unique or problematic? If you need someone to come in and push forward on design, patterns, practices, and actual implementation then this would also be a conversation I’d be interested in having. I’d be happy to dive into whatever the stack might be (or help decide on the stack): Java (Scala/Kotlin), Golang, Node.js or even .NET (C#/F#) for the right company. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Development &amp;amp; Operations Architect&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Have some architecture that needs to go along with an application and want to build or insure a solid continuous integration and delivery pipeline (or messaging based queue for delivery to production)? This is another possibility I’d be happy to talk about. I really love working with systems to build out reliable immutable infrastructure, data storage mechanisms (distributed, RDBMS, whatever the need calls for) and insure development can continue forward with extremely high confidence levels. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Developer Advocate/OSS Project Lead&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you have an open source project I’d love to take lead on it and also provide advocacy for that project. This role is not to be confused with evangelist, as that’s a fine role for other people, but I want to be in the code and advocating from a position with the team. I’ve done this before with projects like the Iron Foundry for Cloud Foundry and others, and loved it. &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;Let’s talk jobs&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Mergers &amp;amp; Acquisition Technical Evaluations&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is not something one sees everyday, but I’ve worked in a consulting role and have assisted others with this work before. I find it really interesting looking at prospective ROI, current run rates, but also at the specific details of whehter a product or service can even be incorporated and integrated into the acquiring company. In the case of merging, this differs from acquisition in that both entities and both companies’ products and services will both need to polymorph into a new whole. If you’re company is looking to get into some M &amp;amp; A’s, &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;let’s talk about how I can help&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If any of these sound like a need you have, please &lt;a href=&quot;http://adron.github.io/docs/job-talk/&quot;&gt;reach out with additional information&lt;/a&gt; and I will be in contact ASAP.&lt;/p&gt;
&lt;p&gt;Besides the above theoretical jobs above, here are a few other things that I would like in a job. Things that just make it all worthwhile, here’s a list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Work Environ / Soft Skills / Culture&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Flexible hours remote or remote (out of office). Whatever the case, I’d like to work with a company that has the ability and acumen to manage the workflow and efforts among team members remotely. If you’re a company that wants to upgrade the development and operational characteristics of the culture, I can also help your company incorporate highly effective remote capabilities.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/cascadia-bioregion.png&quot; alt=&quot;Cascadia&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;If there is travel, I prefer to keep it to a productively effective 10-15% of the time. Traveling dramatically decreases overall ability to contribute to actual work in an effective way. I do love to travel, speak, and get involved with the worldwide community but I always like to make sure that this involvement doesn’t stymie me from contributing to actual coding, design, and related efforts.  NOTE: If travel is within the Cascadian Bioregion (see image: includes YVR, PDX, SEA, etc) it’s easy to increase my travel to 15-25% of the time as travel within the region is so easy. I probably should include SFO too, it’s super easy to get there and doesn’t cause disruption to daily workflow. (i.e. &amp;lt; 2 hr trip)&lt;/li&gt;
&lt;li&gt;Design, build, and communicate. These are the things I like to do. I like to create what will work for high volume or high speed systems, then build prototypes and communicate how these work. Maybe I would be the one deploying to production, maybe the system is production that I’m deploying, but whatever the case is I’m happy to lead efforts on architecture and work with teams to build that architecture.&lt;/li&gt;
&lt;li&gt;I love to provide leadership for teams, I love to build teams, and I like working with teams. Albeit I’m particular about team diversity and culture, I can bring my own skills and the ability to bring people together on a team and expand teams. If the culture is off kilter, I can help with that. If the culture is spot on, I can work effectively with that. Whatever the case, I’m a high communication, GSD type of guy provided the right environment and reigns removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/gcp.png&quot; alt=&quot;Google Cloud Platform&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Technical Skills&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I’ve found Google Cloud Platform (GCP) a pleasure to work with lately. That combined with Terraform, Packer, and related HashiCorp tooling has been a lot of fun and provided an extremely high value for us at Home Depot.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/sitrep-home-depot-wrap-up-next-talks-next-job/hashicorp.png&quot; alt=&quot;HashiCorp&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;AWS has been another I’ve worked with that has been of stellar value, not particularly at Home Depot but at multitudes of startups and during consulting. AWS is still for many things my go to cloud provider option.&lt;/li&gt;
&lt;li&gt;Azure is another I’ve used that would be an interesting service to use again. It’s been well over 2 years since I worked with or provided Azure support or consulting. I’ve got a soft spot in my heart for this cloud provider since I led teams back in 2010 writing some of the first &lt;em&gt;white papers&lt;/em&gt; for the service!&lt;/li&gt;
&lt;li&gt;I’m comfortable with C#, JavaScript, Java (mostly), and am looking forward to writing more Golang and happily will dive into Scala, Erlang, F#, and a whole host of other languages.&lt;/li&gt;
&lt;li&gt;I’m happy to work with container tech (Rocket/CoreOS) or Docker and I’ll also help keep your company grounded that it might not be the panacea you’re looking for. But they definitely have lots of awesome uses!&lt;/li&gt;
&lt;li&gt;I’d prefer a Unix/Linux environment to work in, but I’ll happily help remove Windows Servers from deployment requirements!  ;-)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;http://adron.github.io/docs/&quot;&gt;Contact me&lt;/a&gt; or let’s &lt;a href=&quot;http://adron.github.io/docs/&quot;&gt;talk jobs&lt;/a&gt;, cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 4 - Conference Day 2 - A Short Summary</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-4/</link>
      <pubDate>Mon, 12 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-4/</guid>
      <author></author>
      <description>&lt;p&gt;I’m working on getting back in the saddle after a great week at HashiConf and a weekend away at Seaside on the Oregon Coast. With that, I haven’t had a lot of time to write up day 4, which involved a lot of great talks and conversations. Those topics will come up in some subsequent articles, in the meantime please enjoy these videos I made of my HashiConf Adventures.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/182234514?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234580?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234602?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe src=&quot;https://player.vimeo.com/video/182234619?byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Autopilot Pattern Application Organization</title>
      <link>http://adron.github.io/articles/autopilot-pattern-application-organization/</link>
      <pubDate>Fri, 09 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/autopilot-pattern-application-organization/</guid>
      <author></author>
      <description>&lt;p&gt;Context: What is the &lt;a href=&quot;http://autopilotpattern.io/#how-do-we-do-it&quot;&gt;Autopilot Pattern&lt;/a&gt;?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The autopilot pattern automates the lifecycle of each component of the application. Whether we architect our application as a single container, in tiers, or as microservices, each container that makes up the application has its own lifecycle, and its own set of actions that are necessary during that lifecycle. Each of these application components are often applications in themselves, like a database server, in-memory cache, or the reverse proxy that fronts our application, in addition to the Node.js, Python, Ruby, or other code that makes the set of components a complete application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The only caveat I would add here is that &lt;em&gt;containers&lt;/em&gt; are largely irrelevant as long as your infrastructure virtualization is programmatic controlled. Of course, hyper-visor based virtualization can be more troublesome or simplify things when building out infrastructure programmatically or from a configuration based perspective. Whatever the case, use what works for your situation. The larger point of all this is to automate things for consistency, reliability, and repeatability.&lt;/p&gt;
&lt;p&gt;The way I have started to break out applications into the autopilot pattern is based on what I’ve dubbed three eras:&lt;/p&gt;
&lt;h2 id=&quot;iron-throne-era&quot;&gt;Iron Throne Era&lt;/h2&gt;
&lt;p&gt;In this era has a deluge of nightmarish problems. You might as well as just give up the quest for the throne during this era. Hardware that isn’t programmatic plagues this era. Networking that needs manually configured or applications that don’t even understand basic TCP/IP Networking or related communications throw a massive barrier into full automation in this era.&lt;/p&gt;
&lt;h2 id=&quot;renaissance-era&quot;&gt;Renaissance Era&lt;/h2&gt;
&lt;p&gt;This era is when things started getting good. I like to think of this era as starting right around 2007, when automation started to take a much bigger step forward with all sorts of things we could actually automate. AWS launched in 07’ and from there, more networking automation, tooling, and application tooling exploded with the first semblances of real PaaS coming to fruition.&lt;/p&gt;
&lt;h2 id=&quot;iron-man-era&quot;&gt;Iron Man Era&lt;/h2&gt;
&lt;p&gt;This era is where we are now. With a plethora of methods to automate networks, applications, deployments, integration, and whatever else that comes up. We’ve gotten to a stage where having viable technology options aren’t the problem anymore. Our question now just lie around how and in which way do we organize, use, and get sorted our various fully automated application deployments.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s take a look at the applications from each of the eras.&lt;/p&gt;
&lt;h1 id=&quot;iron-throne-era-application&quot;&gt;Iron Throne Era Application&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/iron-throne-era.gif&quot; alt=&quot;Iron Throne Era Application&quot;&gt;&lt;/p&gt;
&lt;p&gt;Yup, so done with that era’s app. It’s best left in the past.&lt;/p&gt;
&lt;h1 id=&quot;renaissance-era&quot;&gt;Renaissance Era&lt;/h1&gt;
&lt;p&gt;So let’s talk about this era in respect to the autopilot pattern. There’s still likely to be one or two little pieces here or there that &lt;em&gt;might&lt;/em&gt; not be automated, but it should be an extreme rarity in this era.&lt;/p&gt;
&lt;p&gt;In this era we might have an ASP.NET MVC Application with a front end using Node.js to build the UI components for deployment. To specifically distinct build operations need to occur. Often this part of the over solution would at least be in one project repository or working directory. Often, and this is where we run into one of the most common plights of today’s devops or developer team. The application is in one directory but the server instances are deployed either manually or in a way that requires regular interaction and manipulation.&lt;/p&gt;
&lt;p&gt;Working through this application working toward deployment often looks like this for this application.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Application Build Starts&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;-&amp;gt; Continuous Integration (passes)&lt;/p&gt;
&lt;p&gt;-&amp;gt; Pipeline Checks Pass&lt;/p&gt;
&lt;p&gt;-&amp;gt; Existing Infrastructure Receives Executing Code&lt;/p&gt;
&lt;p&gt;In this era, the infrastructure is autonomous - almost entirely - of the application that actually runs on the infrastructure. The process for deployment of the infrastructure generally follows an approach like this.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;OS Installed or Image Created/Started&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;-&amp;gt; Server installed (Apache, Nginx, IIS, Etc)&lt;/p&gt;
&lt;p&gt;-&amp;gt; Networking setup appropriately for DNS/Routing/Etc.&lt;/p&gt;
&lt;p&gt;-&amp;gt; Structure setup and built/deployment code is placed on server&lt;/p&gt;
&lt;p&gt;Of course each of these flows are simplified. What I’m drawing an emphasis to is that they’re autonomous but must work in conjunction form the perspective of either repositories (folders or wherever they’re stored). Another thing to think about, is that the application cant’ actually deploy itself, nor can the infrastructure do anything without the application. This is obvious, but if you think about it for a moment, this is actually how we commonly store and organize our applications today. The code is in one repository and the infrastructure bits are shoved off in some other folder or repository somewhere else. This type of organization defines the very essence of the disconnected nature of this era’s efforts to automate application deployment and infrastructure.&lt;/p&gt;
&lt;h1 id=&quot;iron-man-era&quot;&gt;Iron Man Era&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;and onward to the Jarvis Era&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alright, this is the era we’re at now. This is the era I’m really looking forward to speaking with people about and coming up with today and tomorrow’s solutions!&lt;/p&gt;
&lt;p&gt;Forget the disparate nature of the renaissance era. Think of the core principles behind the &lt;a href=&quot;http://autopilotpattern.io/&quot;&gt;Autopilot Pattern&lt;/a&gt;. This is the era where things start to come together. Things are still somewhat in distinct repositories but sometimes might not be (more on that later). But things in this era are brought together via a systemic delivery mechanism, commonly referred to as continuous delivery. The organization of these applications, infrastructure, and related projects are more unclear then some of the limited, vertically developed applications of the renaissance era apps. Why not add the infrastructure markup, code, networking, or other related elements to the code repository? Isn’t that the idea behind devops originally anyway? Whatever the intent, here’s my proposals for this below, using a Node.js Application.&lt;/p&gt;
&lt;h1 id=&quot;iron-man-era-autopilot-pattern-application-structural-organization&quot;&gt;Iron Man Era Autopilot Pattern Application Structural Organization&lt;/h1&gt;
&lt;p&gt;Wow, that was a heckuva section title eh!&lt;/p&gt;
&lt;p&gt;First thing I always do is create a directory, change into that directory and run git init and create an ignore file. I generally go ahead and throw in the most important file of all to ignore at this point, the nefarious .DS_Store file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;mkdir whatever-the-app-is
git init
touch .gitignore
nano .gitignore
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;…add stuff and save it…&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;git add -A
git commit -m &amp;#39;First commit!&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/first-steps.gif&quot; alt=&quot;First Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;After that, I create three directories: terraform, packer, and nodejs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/second-steps.gif&quot; alt=&quot;Second Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;From here I create the application project that I’ll develop from.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/third-steps.gif&quot; alt=&quot;Third Steps&quot;&gt;&lt;/p&gt;
&lt;p&gt;Then the final step is to setup the infrastructure parts of the application.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/autopilot-pattern-application-organization/fourth-steps.gif&quot; alt=&quot;Fourth Steps&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;a-few-of-the-key-advantages&quot;&gt;A Few of the Key Advantages&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;With all of the core elements of the application combined; infrastructure, application code, configuration, and others combined there isn’t the confusion about where X or Y repo is located in relation to the overal project. Everything that is needed for the application, for it’s deployment, for it’s development, and for the future of the application is included in the repository.&lt;/li&gt;
&lt;li&gt;When working on this code repository, it is in essence practicing what is preached with regard to the ideals of &lt;em&gt;DevOps&lt;/em&gt;. Having the infrastructure and application code together truly does bring together development and operations.&lt;/li&gt;
&lt;li&gt;Communication, pending of course source control practices and workflow are followed, is drawn together even more among the individuals who would be working on the code for the application or infrastructure or whatever element of the solution.&lt;/li&gt;
&lt;li&gt;The continuous integration (CI) and delivery (CD) services now don’t need multiple authentication credentials or keys to go out and pull together the code, infrastructure, and related elements. Instead we’re down to one repository that then can be deployed via CD to whatever would host the infrastructure.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;the-conversation&quot;&gt;The Conversation&lt;/h2&gt;
&lt;p&gt;So is setting up directories and tossing the respective elements into the project the best way to do this? It may be, it may not be, but it’s one possible solution. The idea however to bring these things together in a way where they seamlessly work together demands some type of way to connect the architectural elements. Putting them in one repository is one distinctive solution. Another possible solution might be to have a parent repository that collects other repositories together that would have the respective infrastructure, application, and related glue code.&lt;/p&gt;
&lt;p&gt;Recently with the talk “&lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;Organizing Infrastructure Configuration and Workflow&lt;/a&gt;“ at HashiConf, Evan, myself and many others have started to discuss additional ways to put together the meat and potato basics of these applications. I believe I might even have to dub it something new, as it appears the collection of these things could bring together a truly better way to build and deploy applications consistently, reliably, with higher levels of quality.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 3 - Conference Day 1 - Presentation Time</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-3/</link>
      <pubDate>Thu, 08 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-3/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-3/01-hallway-hacking.jpg&quot; alt=&quot;Hallway Hacking&quot;&gt;&lt;/p&gt;
&lt;p&gt;Day 3 of my trip, and day 1 of the conference kicked off calmly. I made a cup of coffee with my &lt;a href=&quot;http://www.aerobie.com/product/aeropress/&quot;&gt;Aeropress&lt;/a&gt; &amp;amp; props to &lt;a href=&quot;https://twitter.com/aneel&quot;&gt;Aneel&lt;/a&gt; for planting the idea a bunch of months ago by showing me how he uses it.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Good morning &lt;a href=&quot;https://twitter.com/hashtag/HashiConf?src=hash&quot;&gt;#HashiConf&lt;/a&gt;. Cheers! &lt;a href=&quot;https://t.co/TxfqtBVmCS&quot;&gt;pic.twitter.com/TxfqtBVmCS&lt;/a&gt;&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/773545481704124417&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-3/02-repping-devopsday-pdx.jpg&quot; alt=&quot;Representing for Devops Day PDX&quot;&gt;
&lt;/div&gt;

&lt;p&gt;While picking up some breakfast, I realized, how one could create a conference of just hallway activity. I always find myself hacking in a hallway at every conference I’ve ever been to.&lt;/p&gt;
&lt;p&gt;For my respective tshirt of the day, I had to give some love and rep for Devops Day PDX. It was also an excellent conference that a number of organizers did a great job with.&lt;/p&gt;
&lt;p&gt;After breakfast all of the speakers, attendees, and everybody went into the main room for the keynote. We gathered, two big screens displayed beside the podium. Once everyone got seated &lt;a href=&quot;https://twitter.com/sethvargo&quot;&gt;Seth Vargo&lt;/a&gt; came out to kick off they keynote and introduce the speakers.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
&lt;img src=&quot;/articles/hashiconf-trip-day-3/03-ready-for-the-keynote.jpg&quot; alt=&quot;Ready for the Keynote&quot;&gt;
&lt;/div&gt;

&lt;p&gt;After the keynote I chatted about some thoughts on Vault and related security technology.&lt;/p&gt;
&lt;p&gt;I started to walk onward toward the speakers room again but ran into Bryan Cantrill (CTO @ Joyent, lover of Oracle) and James Nugent. They discussed a number of things, one being certain failings of Go. This was interesting to me as I’m just starting to hack around with the language and now have a list of things I will ensure I look into within the toolchain itself. I also wish I could have recorded this conversation for you dear reader, because let me tell ya, Bryan has more overheards (you know, OH on twitter) that need to be published on Twitter than I could even hope to record. We’re talking about 10-20 notable overheard quotes per second, he’s boss on phrasing.&lt;/p&gt;
&lt;p&gt;I’ll have more on Vault, some of the topics that came up in conversation, and more in subsequent blog entries. But for now I was happy with the simple things in life, like tweeting via paper. :-o  #shocks #muchsmartass&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Paper &lt;a href=&quot;https://t.co/vFBkijD8Io&quot;&gt;pic.twitter.com/vFBkijD8Io&lt;/a&gt;&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/773594438195027968&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;As scheduled (thanks for wrangling us speakers Kristen, you did an excellent job!) Evan and I were setup and ready precisely on time. We kicked off our presentation at exactly 3:35pm. More details (slide deck, code, links, etc) on the talk can be found on the page I’ve created for the talk &lt;a href=&quot;http://adron.github.io/articles/hashiconf-trip-day-3/&quot;&gt;here&lt;/a&gt; and whenever the video of the talk is available I’ll post a link there and update with a link here.&lt;/p&gt;
&lt;p&gt;The talk went exceptionally. Both Evan and I were happy with how things turned out. Namely, here are a few high points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code was committed live on Github for features related to create GCP Projects with Terraform. The respective resources will be available soon as they’re ready for a subsequent build.&lt;/li&gt;
&lt;li&gt;Evan did not suffer any consequences from the heat of standing behind the curtain, as wizards sometimes do.&lt;/li&gt;
&lt;li&gt;Our key points of conversation topics came across well, funny parts delivered with laughs, but more importantly there were more than a few people after the talk that also wanted to contribute and discuss further these ideas. The notion of bridging together one’s autopilot pattern based, 12-factor app style, intelligently monitored systems style architectures into application projects was something that is on more than a few people’s minds. I’ll have more on this as conversations continue, and hope you dear reader may want to jump into that conversation too.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Literally hiding behind the curtains at &lt;a href=&quot;https://twitter.com/hashtag/hashiconf?src=hash&quot;&gt;#hashiconf&lt;/a&gt; as &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@adron&lt;/a&gt; does his part of the talk. &lt;a href=&quot;https://twitter.com/hashtag/spooky?src=hash&quot;&gt;#spooky&lt;/a&gt; &lt;a href=&quot;https://t.co/9w65aQ916T&quot;&gt;pic.twitter.com/9w65aQ916T&lt;/a&gt;&lt;/p&gt;&amp;mdash; Evan Brown (@evandbrown) &lt;a href=&quot;https://twitter.com/evandbrown/status/773664064333492224&quot;&gt;September 7, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;After the presentation conversations went on for another 2 hours or so. But after that a number of Googlers and myself headed off for Oxford Market, Pliny the Elder, and adventure in Napa.&lt;/p&gt;
&lt;p&gt;If you’d like to dive into the conversations around application organization, configuration, maintenance, and management of said projects, do sign up to &lt;a href=&quot;http://blog.adron.me/thrashingcodenews.html&quot;&gt;Thrashing Code&lt;/a&gt; and I’ll be pushing forward that conversation and herding all of us cats into a medium in which we can discuss these things further.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 2 - Part II - Reception and Speakers Dinner</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-2-part-II/</link>
      <pubDate>Wed, 07 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-2-part-II/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/03-up-the-hill.jpg&quot; alt=&quot;Up the Hill&quot;&gt;&lt;/p&gt;
&lt;p&gt;Before diving in to day 3 of my trip, I need to do justice to the awesome reception, speakers dinner, and conversations of the night before.&lt;/p&gt;
&lt;p&gt;After arriving and synching up with Evan on our presentation, I wandered around the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt; for a little while and just explored what was around. The resort had several bars, a bowling alley, coffee shop, and a host of other amenities along with their endless supply of wine. The views around the vineyard, up on the view point atop the hill next to the resort was very nice.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/04-looking-back.jpg&quot; alt=&quot;Looking Back&quot;&gt;&lt;/p&gt;
&lt;p&gt;I walked up toward where the reception would be to take the picture above. About two thirds of the way to the top I turned around and took this panoramic shot. Then I walked back down to the mid-point and got this panoramic shot of the Meritage itself.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/04-the-wide-angle-meritage.jpg&quot; alt=&quot;The Wide Angle Meritage&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/02-mary.jpg&quot; alt=&quot;Mary&quot;&gt;
&lt;/div&gt;

&lt;p&gt;While standing there taking the panoramic I turned around and saw a statue of Mary covered in rosaries. I guess that’s a thing, one I’ve never really understood not being Catholic and all. But I digress, I continued onward.&lt;/p&gt;
&lt;p&gt;Eventually I returned to my room, finished up a few tweaks to my latest Terraform Project and then headed back out for the reception. I walked back up the hill and strolled into the reception area. There were about 100+ people there already hangout out, enjoying a glass or three of vino, and musicians were playing on the raised section of the patio area.&lt;/p&gt;
&lt;p&gt;I didn’t really chat to much with anybody at first as I really needed to wind down after the trip. So for the first 20 minutes of the reception I just kind of zoned out. Taking a few pictures and listening to the music was perfect for this. Eventually I walked around a bit and end up chatting with a number of people.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/05-the-reception.jpg&quot; alt=&quot;The Reception&quot;&gt;&lt;/p&gt;
&lt;p&gt;Evan was out, and we found some of his fellow Googlers &lt;a href=&quot;https://twitter.com/kelseyhightower/&quot;&gt;Kelsey Hightower&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/erjohnso/&quot;&gt;Eric Johnson&lt;/a&gt;, and eventually were joined by a number of others. We all talked shop, containers, some wine, the view, and all sundry of topics.&lt;/p&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/182030548?title=0&amp;byline=0&amp;portrait=0&quot; width=&quot;850&quot; height=&quot;478&quot; frameborder=&quot;0&quot; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;I stopped and took a short video of them playing and the overall view. It was super chill, easy to talk, and a nice breeze was blowing over the hill. A perfect match to the warm day.&lt;/p&gt;
&lt;p&gt;After the reception the speakers dinner kicked off inside the very hill we had just been atop. Entering the cave, as it was logically called, we were greeted by an epic HashiCorp Logo as we speakers walked in.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/06-entering-the-cave-hashicorp.jpg&quot; alt=&quot;HashiCorp&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/07-the-cave.jpg&quot; alt=&quot;The Cave&quot;&gt;
&lt;/div&gt;

&lt;p&gt;There we entered a grand room with a number of tables. Enjoyed a round or two of wine, then all took seats at round tables. Conversations were excellent, and we all continued enjoying the evening with a richly and perfectly prepared filet mignon and lobster, surf and turf indeed.&lt;/p&gt;
&lt;p&gt;After the dinner I walked out the entrance and conversation continued among &lt;a href=&quot;https://twitter.com/joshkodroff&quot;&gt;Josh Kodroff&lt;/a&gt;, several other people, and myself. After a while I bid all goodnight and headed off to get some sleep before conference day one!&lt;/p&gt;
&lt;p&gt;A most excellent day, and here the conference hasn’t even started yet. I’ve got to say, this is definitely the way to get ready for any conference though! Good food, good drinks, good conversation, among an excellent atmosphere.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2-part-II/08-the-cave-wide-pano.jpg&quot; alt=&quot;The Cave&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 2 - A Bus Ride, Napa Valley City Center, Italian, Coffee, and Terraform Notes</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-2/</link>
      <pubDate>Tue, 06 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-2/</guid>
      <author></author>
      <description>&lt;p&gt;Almost to Napa, but not yet. The train pulled in and I detrained. I will admit, I know of nothing about Martinez, California except for two things: It’s a stop on the way to Jack London Square (AKA Oakland) and thus San Francisco and it’s got a lot of knarly looking industrial plants spewing stuff into the air. Poisonous, I’ve no idea, but I know the one’s just west of the city (or town?) are. I enjoyed the ghost fleet at mooring, the sun rising from the east, and the smooth roll of the train. Now I was standing here ready to be on my way to Napa.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/napa-valley.jpg&quot; alt=&quot;Napa Valley&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However I have a 2 hour layover (is it a layover, transfer, or something else in train-speak-ese?). So I decided I was going to learn a thing or three about Martinez, California. I walked a few blocks into town and found a Starbucks. I felt like such a filthy tourist walking into a Starbucks in Martinez, hoping they’ve got the local joint somewhere nearby, I gave in and enjoyed the Seattle sugar drink anyway.&lt;/p&gt;
&lt;p&gt;There I noticed three police officers, somewhat jubilant about whatever day they were going to have. I chatted with them a bit and it seemed there was some easy work they’d be doing at a fair or festival type event. Another few people sat down and enjoyed the fact I’d brought my standard 3 prong adapter along for the ride. Ya see, shockingly, there wasn’t enough outlets for the phones, laptops, and other devices everybody wanted plugged in. So the strip was a welcome addition.&lt;/p&gt;
&lt;p&gt;I sat down and dorked out on some Terraform templates and started reading up on some blog entries about Terraform Modules. I was pleasantly surprised to find solid material on page 2 of the google results (where I look every other year or so). I found blog entries by &lt;a href=&quot;https://twitter.com/serialseb&quot;&gt;@serialseb&lt;/a&gt;, &lt;a href=&quot;https://github.com/bobtfish&quot;&gt;Tom&lt;/a&gt;, and &lt;a href=&quot;https://opencredo.com/author/bart/&quot;&gt;Bart Spaans&lt;/a&gt; (&lt;em&gt;links below in references&lt;/em&gt;). Those along with a host of other materials I started to get more of a picture around how, what, where, when, and why Terraform Modules. Stay tuned in a subsequent blog entry I’ll have thoughts, hacks, and other collections of things on what I learned and hacked together.&lt;/p&gt;
&lt;h3 id=&quot;word-absurdities-over-triple-grande-caramel-macchiatos&quot;&gt;Word Absurdities Over Triple Grande Caramel Macchiatos&lt;/h3&gt;
&lt;p&gt;I penned this blog entry while sipping at my &lt;em&gt;triple grande caramel macchiato&lt;/em&gt;. All the while pondering the absurdity of how English is constructed to identify such a thing as triple grande caramel macchiato and for the millionth time thought about the desecration in re-defining the word macchiato that Starbucks committed. A macchiato is not this strange sugared perverse creation that they serve, but whatever, it tastes good. It’s just a disingenuous and deceitful disrespect, combined with adding confusion to the naive, to taint a word that has existed for over a century which means something entirely different.&lt;/p&gt;
&lt;p&gt;But whatever, it’s almost time for the final 45 minute ride to Napa.&lt;/p&gt;
&lt;p&gt;I boarded the bus. The driver greeted me, scanned my ticket, and we discussed shortly the logistics of getting to Napa from Martinez. A timely departure and barely any traffic had me arriving on time.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/soscol-transit-center.jpg&quot; alt=&quot;Soscol Transit Center&quot;&gt;&lt;/p&gt;
&lt;p&gt;Since the Soscol Transit Center was located just a few blocks from downtown Napa Valley I decided to spend lunch there and take a walk around.&lt;/p&gt;
&lt;h3 id=&quot;oh-lunch-&quot;&gt;Oh Lunch!&lt;/h3&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2/caprese.jpg&quot; alt=&quot;Caprese&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-2/gnocchi.jpg&quot; alt=&quot;Gnocchi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Lunch was awesome. Caprese with heirloom tomatoes, actual fresh mozzarella and a thick, sweet, and rich balsamic reduction. Simply, caprese done right! I followed that with some gnocchi and a glass of white wine. It was time after all, being in Napa Valley, that I had some wine.&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;a href=&quot;http://www.ridethevine.com/vine&quot;&gt;&lt;img src=&quot;/articles/hashiconf-trip-day-2/vine-logo.png&quot; alt=&quot;Vine Transit&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;I hung out downtown for a short time after lunch and then boarded the &lt;a href=&quot;http://www.ridethevine.com/vine&quot;&gt;Vine&lt;/a&gt; Route 11 Bus from downtown Napa out to the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt;. I arrived and walked up to the front desk and checked in. Lo and behold there stood &lt;a href=&quot;https://twitter.com/evandbrown/&quot;&gt;Evan&lt;/a&gt;, a most fortuitous timing indeed.&lt;/p&gt;
&lt;h3 id=&quot;synching-up&quot;&gt;Synching Up&lt;/h3&gt;
&lt;p&gt;We immediately introduced ourselves to some of the great staff handling HashiConf and plotted to meet and synch up our talk. The deck of course being basically done (and available &lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;here&lt;/a&gt;) but we needed to insure some of the surprises that we have are ready. Yes, that’s right, there are surprises we’ll have at the talk itself. So it’s worth tuning in if you’re working with HashiCorp’s Terraform and Google Cloud Platform.&lt;/p&gt;
&lt;p&gt;For now, I bid adieu, I have conference activities to participate in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Those I referred above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://serialseb.com/blog/2016/05/11/terraform-working-around-no-count-on-module/&quot;&gt;Working Around the Lack of Count in Terraform Modules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://bobtfish.github.io/blog/2015/03/29/terraform-from-the-ground-up/&quot;&gt;Terraform from the Ground Up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://opencredo.com/terraform-infrastructure-design-patterns/&quot;&gt;Terraform Infrastructure Design Patterns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other Good Entries on Terraform Modules &amp;amp; Related Material:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.davekonopka.com/2016/terraform-conditionals.html&quot;&gt;Terraform Conditionals, Sort of&lt;/a&gt; by &lt;a href=&quot;https://twitter.com/davekonopka&quot;&gt;Dave Konopka&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/blogs/apn/terraform-beyond-the-basics-with-aws/&quot;&gt;Terraform: Beyond the Basics with AWS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>HashiConf Trip Day 1 - Coast Starlight and Terraform</title>
      <link>http://adron.github.io/articles/hashiconf-trip-day-1/</link>
      <pubDate>Mon, 05 Sep 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hashiconf-trip-day-1/</guid>
      <author></author>
      <description>&lt;p&gt;This week, my trip to &lt;a href=&quot;https://hashiconf.com&quot;&gt;HashiConf&lt;/a&gt; kicked off officially at 2:25pm, when the Amtrak Coast Starlight departed Portland.&lt;/p&gt;
&lt;p&gt;I had more than a few goals for the trip down to Napa Valley for HashiConf. By priority, the top 5 goals:&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/gate-5.jpg&quot; alt=&quot;Gate 5&quot;&gt;
&lt;/div&gt;

&lt;ol&gt;
&lt;li&gt;Give a talk with Evan and respectively get a conversation started around organizing immutable infrastructure projects along the lines of 12-factor apps and the autopilot pattern.&lt;/li&gt;
&lt;li&gt;Meet as many of the HashiConf Team as I can.&lt;/li&gt;
&lt;li&gt;Make something like a documentary video short of the trip, the conference, and whatever else might be pertinent. It’s an experiment, it’ll work or it won’t.&lt;/li&gt;
&lt;li&gt;Blog the event. Maybe just a couple entries, or three, or more.&lt;/li&gt;
&lt;li&gt;Have a relaxing, chill, introspective, educational, and laid back trip while enjoying some wine at the &lt;a href=&quot;http://meritagecollection.com/meritageresort/&quot;&gt;Meritage&lt;/a&gt; (this is where the conference is being held).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;-organizing-infrastructure-config-and-workflow-http-blog-adron-me-talks-organizing-infrastructure-config-and-workflow-&quot;&gt;&lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;Organizing Infrastructure Config and Workflow&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I wrapped up a few more things for the talk, which are now 98% done. I just have a 1% review with my co-presenter &lt;a href=&quot;https://twitter.com/evandbrown/&quot;&gt;Evan&lt;/a&gt;, and then the other 1% a few tweaks to the repositories I’ll be showing and speaking from. You can already find the slide deck and material for the talk &lt;a href=&quot;http://adron.github.io/articles/hashiconf-trip-day-1/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;here&lt;/a&gt;. There will however be more information and details once the talk is over.&lt;/p&gt;
&lt;p&gt;After that I headed down with &lt;a href=&quot;https://twitter.com/lenadroid&quot;&gt;Lena&lt;/a&gt; and discussed a few things, including giving her the first rough presentation via iPad with the v1 of the Retina Display. This reminded, hot damn that version of the iPad is ridiculously heavy, don’t give presentations with it. Afterwards she gave me a critique of things I ought not to forget. With that done, I finished packing up, and we both headed toward the train station.&lt;/p&gt;
&lt;p&gt;I detrained at Union Station and went in to wait for my train. At this point I have a little aside for this blog entry. It’s just a philosophy I have about things which makes the way I approach life very different than the way much of humanity seems to approach life.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/metropolitan-lounge.jpg&quot; alt=&quot;Metropolitan Lounge&quot;&gt;
&lt;/div&gt;

&lt;h2 id=&quot;approaching-life-on-my-terms&quot;&gt;Approaching Life on My Terms&lt;/h2&gt;
&lt;p&gt;One of the things I’m very particular about is how, when, where, and in which way I travel to places. I do everything I can to follow a few principle ideals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Don’t hurry. Otherwise I miss the important moments.&lt;/li&gt;
&lt;li&gt;Enjoy those moments. They only happen once.&lt;/li&gt;
&lt;li&gt;Live my life, there’s only this one I have.&lt;/li&gt;
&lt;li&gt;Demand respect for my time, if others don’t, fire them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sometimes I get stuck in the rat race of airports, but I try to travel by train whenever possible. The experiences I’ve had are too amazing to outline here, but suffice it to say, train travel has been very rewarding for me and a dramatically more human experience than the meat-tubes of the modern airliner.&lt;/p&gt;
&lt;h2 id=&quot;onto-the-flanged-wheel&quot;&gt;Onto The Flanged Wheel&lt;/h2&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/train-one-way.jpg&quot; alt=&quot;Train One Way&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/train-another-way.jpg&quot; alt=&quot;Train Another Way&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Flanged wheels are what train use btw, it’s that lip on the wheel keeps them on the tracks. At 2:25 pm the south bound Amtrak Coast Starlight pulled out of Portland’s Union Station on time. Something this train does about 94% of the time these days. A marked improvement over the abysmal 40% on-time arrival and 6% non-arrivals that were happening back in 2010 and before. Union Pacific straightened it’s grumpy-ass out and started running the trains better, but I digress.&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/sleeping-car-only.jpg&quot; alt=&quot;Roomette&quot;&gt;
&lt;/div&gt;

&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/hashiconf-trip-day-1/roomette.jpg&quot; alt=&quot;Roomette&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I got comfortable and settled into an evening of blog writing, reading further on Go, enjoy the views, and review the talk. Dinner was served at a punctual 6:00pm reservation I’d attained, and by then I’d accomplished almost every one of these things. In addition to these a &lt;em&gt;fire&lt;/em&gt; occurred at work where our Stash Git Server went to shit on us. It’s a bit difficult to manage a &lt;em&gt;fire&lt;/em&gt; when one is between Klamath Eugene, Oregon and Mount Shasta, where the mountain isn’t really kind to one’s internet connectivity. But I did what I could and recovered from some server images. With that up and running I settled in for the night by re-watching Captain America Civil War, ya know, primarily for the hilarious comments Peter Parker makes. Until tomorrow… adieu.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Generate or Regenerate gcloud ssh Keys - How Ya Linux Series - 0001</title>
      <link>http://adron.github.io/articles/how-ya-linux-0001-generate-regenerate-ssh-key/</link>
      <pubDate>Fri, 26  Aug 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/how-ya-linux-0001-generate-regenerate-ssh-key/</guid>
      <author></author>
      <description>&lt;p&gt;Sometimes while working with the various ssh keys you have you might need to regenerate them. Specifically I ran into this need while working with some Google Cloud Platform (GCP) instances with Terraform and GCP’s &lt;em&gt;gcloud&lt;/em&gt; CLI tool. Generally, when you start working with the &lt;em&gt;gcloud&lt;/em&gt; CLI it will, upon need if it doesn’t exist, create a key for you. When it does so it sticks the key it generates in the &lt;code&gt;~/.ssh/&lt;/code&gt; directory and names the key &lt;code&gt;google_compute_engine&lt;/code&gt;. To create a new ssh key pair here, navigate to the &lt;code&gt;~/.ssh/&lt;/code&gt; directory and issue the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;sudo ssh-keygen -t rsa -f ~/.ssh/google_compute_engine -C you_fancy_username@whatever.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that is command is executed, a few moments later and a few prompts later you’ll have a new key.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;13:16 $ sudo ssh-keygen -t rsa -f ~/.ssh/google_compute_engine -C adron_hall@homedepot.comPassword:
Generating public/private rsa key pair.
/Users/axh6454/.ssh/google_compute_engine already exists.
Overwrite (y/n)? y
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /Users/axh6454/.ssh/google_compute_engine.
Your public key has been saved in /Users/axh6454/.ssh/google_compute_engine.pub.
The key fingerprint is:
SHA256:8xHVr19EdgPxLr2nWAkuZa8exMdEqbHNzoBxlHhFkZM adron_hall@ataplace.com
The key&amp;#39;s randomart image is:
+---[RSA 2048]----+
|           ooBB= |
|          o.=.E.+|
|          .= *.*o|
|          .o+o= o|
|        S . *=o= |
|         o * +=.o|
|          o o +oo|
|           . = .o|
|           .+ .  |
+----[SHA256]-----+
✔ ~/.ssh
13:16 $
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it. Sort of. For GCP be sure to check out the docs on managing ssh keys. There are docs on &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh&quot;&gt;&lt;code&gt;gcloud compute config-ssh&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys&quot;&gt;Adding and Removing SSH keys&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Visual Studio Code (an intro with snark!) and Hashicorp Configuration Language</title>
      <link>http://adron.github.io/articles/visual-studio-code-and-hcl/</link>
      <pubDate>Mon, 22  Aug 2016 18:21:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/visual-studio-code-and-hcl/</guid>
      <author></author>
      <description>&lt;p&gt;I sat down to setup Visual Studio Code for some Go coding. That is, #golang or “golang” on Google, because heaven forbid a language is named something that isn’t ubiquitous like the word “go”. But anyway, I digress, because this blog entry isn’t even about golang. It’s about HCL. You see, I sat down to toy about with golang but then I had to knock out a few tasks with Terraform, Packer, and such. To do that I needed the HCL support that Visual Studio Code has. I knew there was a plugin for Hashicorp Configuration Language (i.e. HCL). So I decided to do that work in Visual Studio Code and try out the HCL Plugin. Maybe next blog entry I’ll get around to writing some golang in Visual Studio Code?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-00.png&quot; alt=&quot;The Site&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The first thing I needed to do though, was download and get Visual Studio Code. I’d neglected to learn much about it or use Code (I’ll just call it that from now on, Visual Studio Code is way to much to write, plus it’s not really got much in familial relation to Visual Studio). That download, it all started &lt;a href=&quot;https://code.visualstudio.com&quot;&gt;here&lt;/a&gt;. I opened it upon finishing installation to a brand new Visual Studio Code Window.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-01.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;I toyed about a moment looking at the Visual Studio Code website, then toyed around with the editor, and noticed three things immediately.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;When I navigated to &lt;code&gt;https://code.visualstudio.com&lt;/code&gt; I noticed I was redirected or someway navigated to a link that immediately shoved some type of session mess into the URI. My link of &lt;code&gt;https://code.visualstudio.com&lt;/code&gt; turned into &lt;code&gt;https://code.visualstudio.com/b?utm_expid=101350005-27.GqBWbOBuSRqlazQC_nNSRg.1&lt;/code&gt;. Now I’m not sure about you but that type of behavior on a website actually pisses me off and makes me paranoid. I went through various things to determine what was going on, but suffice it to say I determined it was just an annoying contrivance that the site managers make the site do. Whatever…&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The second thing I noticed was that I had no idea what to do to install plugins. Was it the same as Atom as I’d heard? Was it some other command? I assumed since I’d used Code a few times before, it was likely the command line I tried a few based on other tooling. First &lt;code&gt;⌘ + space&lt;/code&gt;, nope, that was dumb. I have that mapped to &lt;a href=&quot;https://en.wikipedia.org/wiki/Spotlight_(software&quot;&gt;Spotlight&lt;/a&gt;). Ok, so then I tried &lt;code&gt;⌥ + space&lt;/code&gt;, nope. &lt;code&gt;⌘ + ⌥ + ^ + F12&lt;/code&gt;, naw. Ok, dammit, I guess it’s &lt;code&gt;⌘&lt;/code&gt; key plus something I’ll bet. Then I tried a whole slew and sure enough, &lt;strong&gt;&lt;code&gt;⌘ + p&lt;/code&gt;&lt;/strong&gt; was the magic sauce. But wait, it wasn’t. At this point I thought “maybe I should look this up” but I decide to stay stubborn and try some other things I &lt;em&gt;think&lt;/em&gt; I remember about Code. I try the &lt;code&gt;fn + F1&lt;/code&gt;, or what might be just &lt;code&gt;F1&lt;/code&gt; if you have your keyboard setup for function keys instead of the other OS-X uses. Sure enough, that was the command dialog I wanted.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I opened up another Code window so that I could also use the editor to write this very blog entry. I use &lt;a href=&quot;http://wintersmith.io/&quot;&gt;Wintersmith&lt;/a&gt; and have even written about it in the past &lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt; and &lt;a href=&quot;http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting&quot;&gt;Working in -34c Wintersmith Customization and Github Hosting&lt;/a&gt;. It’s a great Node.js static site generator. I immediately noticed as I started typing that Visual Stuido Code supports basic markdown on the basic installation! Holy shit, that’s super rad!&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Ok, on with the meat of all this.&lt;/p&gt;
&lt;p&gt;With the opened Code Window, I hit &lt;code&gt;fn + F1&lt;/code&gt; (again, that’s just &lt;code&gt;f1&lt;/code&gt; if you’ve got your function keys turned on for OS-X) and typed in &lt;code&gt;ext&lt;/code&gt;. That gave me the following dialog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-02.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;The list that displays, I then hit the down arrow key and selected &lt;em&gt;Extensions: Install Extensions&lt;/em&gt;. With that selected I hit enter and down the left hand side of Code I got the extensions list. The focus changes to that, so no need for the mouse still.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-03.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;I pressed the down arrow to select the HCL extension, but realized that was taking a minute, so shifted focus to the search box and just typed HCL. That immediately brought up the display of the extension once I hit the down arrow and then enter.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-04.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now I wasn’t sure how to install this, since I wanted to avoid using the mouse if possible. I just hit enter again and it worked! Since that worked, I hit enter again with the premise that it would now &lt;em&gt;enable&lt;/em&gt; the extension, which it did indeed do with a simple prompt to restart Code. I clicked on &lt;em&gt;ok&lt;/em&gt; and on to the restart of Code.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-05.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;When Code restarted and came back up, I had one Code Windows with the default empty document, with no directory opened, and I opened up another using &lt;em&gt;File -&amp;gt; New Window&lt;/em&gt; and then used it to open the directory in which I was editing this blog entry. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-06.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;To get the word wrap back (which I’d manually clicked before) I recalled the shortcut key is &lt;code&gt;⌥ + Z&lt;/code&gt;. This is super useful when editing markdown like this, so it’s a keyboard shortcut to set to memory.&lt;/p&gt;
&lt;p&gt;Now at this point I should have some HCL. I kick of my pulling down an existing project that I’m working on. I opened it by using the &lt;code&gt;⌘ + O&lt;/code&gt; keys. The project opened up and I immediately opened one of the /*.json files that I have for a Packer image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-07.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;That looked good so far. Let’s see about intellisense and Terraform. I used &lt;code&gt;ctrl + shift + E&lt;/code&gt; to get into the Explorer part of the editor. Then scrolled with the down arrow to the &lt;em&gt;dns-records.tf&lt;/em&gt; file. I atttempted to select the file with the &lt;code&gt;return&lt;/code&gt; button, but that invoked the &lt;em&gt;rename&lt;/em&gt; functionality. I tried a few other things, the &lt;em&gt;space bar&lt;/em&gt;, other unusable combinations, and then &lt;code&gt;ctrl + return&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Nothing&lt;/em&gt;. This was a bit frustrating, to get this far and stumble because I need to use the bloody mouse. Whatever, I clicked on the mouse to open the &lt;em&gt;dns-records.tf&lt;/em&gt; file. I then clicked into the file and tried out something around the intellisense (or is it autocomplete in Code?).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/visual-studio-code-and-hcl/code-go-08.png&quot; alt=&quot;Visual Studio Code&quot;&gt;&lt;/p&gt;
&lt;p&gt;This test I found rather interesting. The options, once I started typing &lt;em&gt;goog&lt;/em&gt; immediately showed as &lt;em&gt;google_compute_instance&lt;/em&gt;, &lt;em&gt;google_dns_managed_zone&lt;/em&gt;, and &lt;em&gt;google_dns_record_set&lt;/em&gt;. A somewhat odd selection indeed of these resources. You see, there are many other HCL resources for Google Compute Engine besides these three. But these specific three displayed in the dropdown. I looked throughout the file, and assumed that these three were retrieved from words in the file. Maybe the intellisense is more autocomplete then intellisense. Whatever the case however as I’m happy with just autocomplete. I don’t particularly need intellisense, especially since I haven’t used it now for about 6 years.&lt;/p&gt;
&lt;p&gt;So that’s my first tour of Visual Studio Code and HCL. My next tour and test is going to be finding some more of these bloody shortcuts I haven’t been able to find and to actually write some golang in the editor too.&lt;/p&gt;
&lt;p&gt;For now, I’ve got some HCL to put together for the coming &lt;a href=&quot;https://www.meetup.com/The-Portland-Elasticsearch-Meetup-Group/events/228010912/&quot;&gt;Monday night Elastic UG meetup&lt;/a&gt; on &lt;a href=&quot;http://blog.adron.me/talks/elastic-with-terraform-packer-and-immutability-magic/&quot;&gt;Elastic w/ Terraform, Packer, &amp;amp; That Immutability Magic&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>DevOps Thoughts, Fixing Culture Roadblocks, and Cultural Anti-Pattern Practices</title>
      <link>http://adron.github.io/articles/devops-thoughts/</link>
      <pubDate>Thu, 11  Aug 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/devops-thoughts/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/devops-thoughts/artisanal.jpg&quot; alt=&quot;Artisanal&quot;&gt;
&lt;/div&gt;

&lt;p&gt;DevOps Days PDX just wrapped up and I’m at home, working remotely today, digging into some deployment work around building Elasticsearch Clusters for monitoring with Beats. It’s a tricky beast at this point but I’m getting all the nuances figured out.&lt;/p&gt;
&lt;p&gt;I have a host of tools at my disposal that help tremendously with this endeavor. There is Packer, to help build the base images I need that have Elasticsearch, Beats, or whatever else needs to be on an image. There is Terraform that helps me to get the images deployed and start the final configuration process. Then there is the configuration process, which is a mix of bash, go, and other things to insure that the configuration of and services around Elasticsearch are started appropriately.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;devops-tooling-vs-culture&quot;&gt;DevOps Tooling vs. Culture&lt;/h2&gt;
&lt;p&gt;It’s a cool thing to have all this tooling at my disposal. For me to be able to whip together these solutions for myself and any clients or cohort that needs these solutions. But there’s so much more to the premise of &lt;em&gt;DevOps&lt;/em&gt; (or lack of premise, more on that in the future), or at least that of an efficient and forward thinking &lt;em&gt;DevOps&lt;/em&gt; culture that the tooling is almost irrelevant. Without effective cultural change in an organization all the fancy tooling is for naught.&lt;/p&gt;
&lt;p&gt;A momentary reflection I’ve had as I hack deeper into &lt;strong&gt;DevOps&lt;/strong&gt; idealism and ideas with these notions of &lt;a href=&quot;http://blog.adron.me/articles/immutable-infrastructure-some-reads-clarification-what-it-is/&quot;&gt;immutable infrastructure&lt;/a&gt;, &lt;a href=&quot;http://autopilotpattern.io/&quot;&gt;autopilot pattern applications&lt;/a&gt;, &lt;a href=&quot;http://12factor.net/&quot;&gt;12-factor apps&lt;/a&gt;, and related ideas, the more I find myself between a rock and a hard place with any existing system and existing development cultures.&lt;/p&gt;
&lt;p&gt;This is where I fight with the world, with existing cultures, and fight to make changes. You see, I grew up with more than a few dogs. Many people always said, “you can’t teach an old dog new tricks” to which I retort, “bullshit, you just suck at teaching your fellow dogs new tricks”. Ok, that’s my reactionary activist style response to someone saying I can’t do something, but it’s well founded. Because you see, every dog I ever grew up with would learn new tricks until the day that dog was laid to rest. I &lt;em&gt;respect&lt;/em&gt; dogs in that way and I &lt;em&gt;sure as hell expect more from humans&lt;/em&gt;, even though we humans can be such an enthusiastic let down sometimes.&lt;/p&gt;
&lt;h2 id=&quot;cultural-road-blocks-to-technology-solutions&quot;&gt;Cultural Road Blocks to Technology Solutions&lt;/h2&gt;
&lt;p&gt;So how does culture create an environment that makes all the tools for naught and encourages me to write articles where it takes me 3-5 paragraphs to get to the meat. Here’s a list of the key parts of culture that I’ve fought with over the years. These are greater roadblocks than any processor limit, bad code, or other simple technical limitation. The cultural roadblocks are far more of an issue than any code or technical roadblock in the vast majority of places. Suffice it to say, if you aren’t working on rockets and jets with Nasa, Space-X, or fighting some disease or cancer, it’s a cultural roadblock not a technical one that will stop you from progressing.&lt;/p&gt;
&lt;p&gt;With all that said, here’s my list of cultural problems along with a few suggestions on fixing them. These could also be called “cultural anti-pattern practices”.&lt;/p&gt;
&lt;h2 id=&quot;cultural-anti-pattern-practices&quot;&gt;Cultural Anti-Pattern Practices&lt;/h2&gt;
&lt;h3 id=&quot;-we-always-did-it-this-way-&quot;&gt;&lt;em&gt;“We always did it this way”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This practice basically defines the insanity of always repeating a practice without ever checking to see if it should still be done, if it’s still needed, or if there might be a better way to do things. Someone might respond with, “If it aint broke, don’t fix it!”, but this goes far beyond an refuses to even check it its broke, needs fixing, or otherwise. This cultural characteristic of an organization crosses into so many other ways of thinking and other practices it’s too hard to enumerate how damaging it truly is to any project or effort. It’s definitely a major anti-pattern in technology in general, and a massive cultural roadblock in any group that wants a more “DevOps” Culture of forward progress.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;-fire-fight-while-you-research-&quot;&gt;&lt;em&gt;“Fire Fight While you Research”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;We all know task-switching kills productivity (re: &lt;a href=&quot;https://blog.todoist.com/2014/05/13/how-multitasking-slows-your-brain-and-kills-your-productivity/&quot;&gt;this&lt;/a&gt;, &lt;a href=&quot;https://www.wrike.com/blog/high-cost-of-multitasking-for-productivity/&quot;&gt;this&lt;/a&gt;, &lt;a href=&quot;http://www.umich.edu/~bcalab/multitasking.html&quot;&gt;this&lt;/a&gt;, and &lt;a href=&quot;https://www.psychologytoday.com/blog/brain-wise/201209/the-true-cost-multi-tasking&quot;&gt;this&lt;/a&gt; for example) and the mother load of task switching is going from researching &amp;amp; testing out an idea to being thrown into the hot seat to fight a fire. In this type of task-switch, which is effectively the definition of opposing activities, the mental energy is more than merely exhausting. This type of task switch is a 10 foot thick brick wall of research &amp;amp; learn destruction. There is no way to recover after a fire-fight and immediately dive back into calm, thoughtful, and concentrated creative effort. This type of cultural characteristic will turn any week long project into something that has a delivery date somewhere next to infinity. You think I say that hyperbolically, but it’s basically true. Have regular fires and put a team on those that needs to develop a solution for tomorrow, and you’ll never have a solution for tomorrow. Simply put, DevOps shouldn’t be your “quick fire fight this emergency over here” or the “why is this unique artisanal, hand made, oven baked, organic, custom configured spice rack of a server on fire?” team. This should and needs to be handled in an entirely different way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;-always-silo-for-the-work-&quot;&gt;&lt;em&gt;“Always Silo for the Work”&lt;/em&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;This is not what Adam Smith meant by &lt;a href=&quot;https://en.wikipedia.org/wiki/Division_of_labour&quot;&gt;division of labor&lt;/a&gt;. This is a serious problem that I see continuing in so many places. If you want to get some more ideas about why not to silo work, go read up on the research and work of &lt;a href=&quot;https://en.wikipedia.org/wiki/W._Edwards_Deming&quot;&gt;W. Edwards Deming&lt;/a&gt; and for some semantic breakdown of the problem &lt;a href=&quot;https://www.infoq.com/articles/break-silos-ventilators&quot;&gt;Don’t Break Your Silos - Push Out the Silo Mentality&lt;/a&gt; is a great article. Creating a silo that creates walls around it and prevents communication or cross-training of necessary knowledge throughout an organization is a surefire way to squander any hopes of a DevOps Culture. The very words pulled together to for DevOps (ya know, Development and Operations) is the breaking down of barriers and silos and bringing together the skills and teamwork necessary.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These are the top three practices that I see and have experienced for a few years. In a subsequent article I’ll take these and others and write about some solutions. As discussed previously, the solutions are hard because it involves people changing their practices. At a core level that is difficult, but again, teaching old dogs new tricks isn’t so hard, it just takes persistence. Keep at it and happy hacking.&lt;/p&gt;
&lt;p&gt;Got comments, thoughts, or some other thing to ramble on about? Ping me via the Twitters &lt;a href=&quot;https://twitter.com/Adron&quot;&gt;@Adron&lt;/a&gt; or via wherever you saw this posted. Always happy to discuss, argue, chat, or otherwise work toward finding new solutions!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp; Packer - Part 2</title>
      <link>http://adron.github.io/articles/nginx-notes-from-the-url-redirect-part-two/</link>
      <pubDate>Mon, 01  Aug 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/nginx-notes-from-the-url-redirect-part-two/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/google-cloud-platform.png&quot; alt=&quot;Google Cloud Platform&quot;&gt;
&lt;/div&gt;

&lt;p&gt;In the &lt;a href=&quot;http://blog.adron.me/articles/nginx-notes-from-the-url-redirect/&quot;&gt;first blog entry, “NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp;amp; Packer - Part 1”&lt;/a&gt; I covered getting a basic Nginx URL Redirector setup and running. Now it’s time to dig into some of the next steps.&lt;/p&gt;
&lt;p&gt;Since we have an operative server running that we want to automate, I’ll actually just wipe out the server we built in the first part of this series. Albeit I will refer back to it when I get to the process of recreating this server with Packer and Terraform. So first things first, let’s actually setup the networking elements needed to put the server into action.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;infrastructure-the-first-terraform-resources&quot;&gt;Infrastructure : The first Terraform Resources&lt;/h2&gt;
&lt;p&gt;The first thing I need is an IP and an A Record in DNS to map to the server that’ll be in charge of the redirection. With Terraform, I can automate this, and for a quick review of how to get started with Google Cloud and Terraform, check out my post “&lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too)&lt;/a&gt;“. With that, I’ll add the following files to this project including the following Terraform resources. The way I do this is simply create a directory and run &lt;code&gt;git init&lt;/code&gt; to make that a repo, then just push it up to Github or wherever the remote needs to be stored. I’ll work based on that from here on out with this series. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;connections.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file will simply host the connection for the provider I’ll be building the infrastructure resources against. In this case, I’ll be working against Google Cloud. The &lt;code&gt;credentials&lt;/code&gt; section in the file has the interpolated local file &lt;code&gt;account.json&lt;/code&gt; that I have my secret key in. It’s one of the multiple ways you can setup your Google Cloud key to use with Packer, Terraform, or other tools. For more information or for specific directions on getting an account.json file just read my previous post on using &lt;a href=&quot;http://blog.adron.me/articles/working-with-google-compute-engine/&quot;&gt;Google Cloud &amp;amp; Terraform&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;../secrets/account.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;that-big-universe&amp;quot;
  region      = &amp;quot;us-central1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;addresses.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file will include the resources for the static IPs for use with the server and assigning a subdomain within the DNS Zone to redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_compute_address&amp;quot; &amp;quot;nginx-server&amp;quot; {
  name = &amp;quot;nginx-server&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;zone-adronme.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This file has more than the entries below, such as for this very blog. But I’ve just included the specifics of what are needed to provide the subdomain that will direct to the server, which will then provide the redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;resource &amp;quot;google_dns_managed_zone&amp;quot; &amp;quot;adronme&amp;quot; {
    name = &amp;quot;adronme&amp;quot;
    dns_name = &amp;quot;adron.me.&amp;quot;
    description = &amp;quot;Production http://adron.me Domain.&amp;quot;
}

resource &amp;quot;google_dns_record_set&amp;quot; &amp;quot;data&amp;quot; {
    managed_zone = &amp;quot;${google_dns_managed_zone.adronme.name}&amp;quot;
    name = &amp;quot;data.${google_dns_managed_zone.adronme.dns_name}&amp;quot;
    type = &amp;quot;CNAME&amp;quot;
    ttl = 5
    rrdatas = [&amp;quot;${google_compute_address.nginx-server.address}&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that the rrdatas value of &lt;code&gt;google_compute_address.nginx-server.address&lt;/code&gt; references whatever static IP is created in the &lt;code&gt;addresses.tf&lt;/code&gt; file resource.&lt;/p&gt;
&lt;p&gt;That will give me the DNS entries needed to get any requests sent to the actual server from within Google Cloud using their respective DNS Server &amp;amp; static IP assigned for their network.&lt;/p&gt;
&lt;p&gt;The next thing I want now is the actual server that Nginx will be installed on. I don’t want Terraform just to whimsically make this Nginx Server from scratch though (which it could through scripts, etc). I know what needs to be on the server, namely Nginx, but also how it should be configured by default. I already have my actual redirect, so I want to just have the data baked into the image. The easiest way to insure Terraform builds a Virtual Machine in a repeatable way is to simply create an image in Google Cloud first. That way I can use that as the base of the virtual machine whenever it needs created. The way I generally manage this, is I simply create a folder within the repository called &lt;em&gt;packer&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In the packer directory I’ll now have three specific files: install-nginx.sh, nginx.conf, and redirector.json. The install-nginx.sh will be for installing nginx, but will also include installing and opeing up the appropriate connections to the local firewall. The nginx.conf file will be the custom nginx file used for our nginx server that includes the URL redirection. This file will also be copied into the appropriate directory during creation of the image by the install-nginx.sh file. Last, the redirector.json file is the actual packer template that will be used to create the image. Below are the three files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;install-nginx.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This starts out by running the apt-get update, then installing UFW. UFW stands for &lt;strong&gt;U&lt;/strong&gt;ncomplicated &lt;strong&gt;F&lt;/strong&gt;ire&lt;strong&gt;W&lt;/strong&gt;all. After that is done, two allowances are added to the firewall for 22 (ssh) and 80 (http) traffic. Then it is enabled by passing in “y” to the command execution of &lt;code&gt;sudo ufw enable&lt;/code&gt;. After that is setup, nginx is installed and the service stopped. The service doesn’t really need stopped, but I’ll have to start it or restart it again in a moment so I stop it anyway. Then I’ve got the &lt;code&gt;sudo update-rc.d nginx defaults&lt;/code&gt; to set nginx to start upon reboots of the instance, finally the nginx.conf file from the repo is moved to replace the default nginx.conf file included with the original installation. Then finally a command to start nginx back up.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/usr/bin/env bash

# Install the UFW (Uncomplicated Firewall), setup tcp 22 and 80 for ssh and http. Then enable the firewall.
sudo apt-get update
sudo apt-get install ufw
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
echo &amp;quot;y&amp;quot; | sudo ufw enable

# Install nginx, stop, start, and restart the server for verification. Then set startup defaults.
sudo apt-get -y install nginx
sudo service nginx stop
sudo update-rc.d nginx defaults

sudo mv nginx.conf /etc/nginx/nginx.conf

sudo service nginx start
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;nginx.conf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the simple nginx.conf file, trimmed down to the bare necessities to accomplish the goal of redirecting this singular subdomain of &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; to the URL in the file. Everything else in the file is default from the original installation. The key part with the URL redirection is toward the bottom of the file in the &lt;code&gt;server&lt;/code&gt; block. For now, until I make the redirect permanent, I’ve set it up simply as a 302 redirect.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;user www-data;
worker_processes 4;
pid /run/nginx.pid;

events {
    worker_connections 768;
}

http {

    ##
    # Basic Settings
    ##

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # server_names_hash_bucket_size 64;
    # server_name_in_redirect off;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    ##
    # SSL Settings
    ##

    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
    ssl_prefer_server_ciphers on;

    ##
    # Logging Settings
    ##

    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    ##
    # Gzip Settings
    ##

    gzip on;
    gzip_disable &amp;quot;msie6&amp;quot;;

    ##
    # Virtual Host Configs
    ##

    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;

    server {
        server_name data.adron.me;
        return 302 http://api.compositecode.com/dataservices/information.html;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;redirector.json&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This final file, the redirector.json file, is the packer template itself. The first section holds two variables, which I didn’t technically need, but when I expand on usage it comes in handy. Also, this way any names or such that I might want to change are at the top of the file. It makes it a little simpler to find the parts I change regularly during troubleshooting and getting everything to work.&lt;/p&gt;
&lt;p&gt;After the two variables is the &lt;code&gt;builders&lt;/code&gt; section of the template. It includes what type of of builder it is (googlecompute), where that security file is (which I mentioned in the connection above for the terraform files, but this is connecting the packer template to the appropriate security key file), project id, zone, instance name, image name, and a few other values. A few of these values are very important to understand what they’re for and why I’ve put them here. The three I need to point out are &lt;code&gt;instance_name&lt;/code&gt;, &lt;code&gt;image_name&lt;/code&gt;, and &lt;code&gt;ssh_username&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The instance name is exactly what you might think, it’s the name of the instance that runs in Google Cloud Engine. However, this is the instance name of the instance that will be used temporarily to build the image from. That’s where the next value comes into place, the &lt;code&gt;image_name&lt;/code&gt;. The instance is deleted once it’s done being created, disconnected form the image that was created to build the instance, and that image is named whatever value is in the &lt;code&gt;image_name&lt;/code&gt;. So you’ll never really see the &lt;code&gt;instance_name&lt;/code&gt; except for a few moments during creation.&lt;/p&gt;
&lt;p&gt;The third value, the &lt;code&gt;ssh_username&lt;/code&gt; is actually the username of the account created to run the shell scripts and do the installations and such. For some of the operating system types, this is necessary and others it is not. For the debian-8-jessie-v20160803 image I’ve set as the &lt;code&gt;source_image&lt;/code&gt;, it seems to be necessary based on my testing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &amp;quot;variables&amp;quot;: {
    &amp;quot;instance_name&amp;quot;: &amp;quot;redirector-{{timestamp}}&amp;quot;,
    &amp;quot;image_name&amp;quot;: &amp;quot;redirector-{{timestamp}}&amp;quot;
  },
  &amp;quot;builders&amp;quot;: [
    {
      &amp;quot;type&amp;quot;: &amp;quot;googlecompute&amp;quot;,
      &amp;quot;account_file&amp;quot;: &amp;quot;../../secrets/account.json&amp;quot;,
      &amp;quot;project_id&amp;quot;: &amp;quot;that-big-universe&amp;quot;,
      &amp;quot;source_image&amp;quot;: &amp;quot;debian-8-jessie-v20160803&amp;quot;,
      &amp;quot;zone&amp;quot;: &amp;quot;us-central1-a&amp;quot;,
      &amp;quot;instance_name&amp;quot;: &amp;quot;{{user `instance_name`}}&amp;quot;,
      &amp;quot;image_name&amp;quot;: &amp;quot;{{user `image_name`}}&amp;quot;,
      &amp;quot;image_description&amp;quot;: &amp;quot;Nginx Server.&amp;quot;,
      &amp;quot;communicator&amp;quot;: &amp;quot;ssh&amp;quot;,
      &amp;quot;ssh_username&amp;quot;: &amp;quot;nginxadmin&amp;quot;
    }
  ],
  &amp;quot;provisioners&amp;quot;: [
    {
      &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;inline&amp;quot;: [
        &amp;quot;sleep 3&amp;quot;,
        &amp;quot;echo \&amp;quot;slept for 3 seconds.\&amp;quot;&amp;quot;
      ]
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;source&amp;quot;: &amp;quot;nginx.conf&amp;quot;,
      &amp;quot;destination&amp;quot;: &amp;quot;nginx.conf&amp;quot;
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;file&amp;quot;,
      &amp;quot;source&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;,
      &amp;quot;destination&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;
    },
    {
      &amp;quot;type&amp;quot;: &amp;quot;shell&amp;quot;,
      &amp;quot;script&amp;quot;: &amp;quot;install-nginx.sh&amp;quot;,
      &amp;quot;pause_before&amp;quot;: &amp;quot;10s&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;where-we-re-at-&quot;&gt;Where we’re at…&lt;/h2&gt;
&lt;p&gt;At this point I’ve got the key elements ready for deploy to Terraform and I’ve got the core pieces to build the image with my template for Packer. But I’ve got neither of these tools actually installed just yet. Well, I’m in luck, I’ve created two scripts just for this purpose for &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/adron-infrastructure/terraform-packer-install-scripts/install-terraform-packer-os-x.sh&quot;&gt;OS-X&lt;/a&gt; and &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/adron-infrastructure/terraform-packer-install-scripts/install-terraform-packer-ubuntu.sh&quot;&gt;Linux&lt;/a&gt;. Oh wait, I might have lied, I only have install files for OS-X and Linux. If you’re running Windows just navigate out and follow these instructions for &lt;a href=&quot;https://www.terraform.io/intro/getting-started/install.html&quot;&gt;Terraform on Windows&lt;/a&gt; and &lt;a href=&quot;https://www.packer.io/intro/getting-started/setup.html&quot;&gt;Packer on Windows&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Alright, with Packer and Terraform installed, I’m ready to build some networking infrastructure and a base image. The first thing I do is run the Packer command, from the directory in which I created the three files related to my Nginx Server. The following is an animated .gif recording (made with &lt;a href=&quot;http://www.cockos.com/licecap/&quot;&gt;licecap&lt;/a&gt;) of running &lt;code&gt;packer build redirector.json&lt;/code&gt;. Note, I paused over some of the parts that take a few seconds, so just the actual changes are shown without the long delays over things like deleting instance or creating image steps. So don’t freak out when you run a packer build and some things take a few seconds or minutes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/packer-build.gif&quot; alt=&quot;packer build&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now that we have the packer built image in Google Cloud I can build the Nginx server using this image. Here’s what I put together for the Terraform file to create the Nginx server. Note, I’ve placed this file in the root of the project repository (where I’ve placed all of my Terraform files that I mentioned previously in this article).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filename: &lt;code&gt;redirector.tf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this file I’ve declared a Terraform Compute Instance type, and named it redirector. For the disk, I’ve set it to the image name that Packer created for me, then the network_interface has an access_config that has the nat_ip set to the .address of the redirector static IP. Previously in the article I setup the DNS to point &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; to that IP address, so this is the final step here. The other information in the Terraform Template, suffice it to say, is a topic for another day. I will mention however, that the tags “http-server” and “https-server” are there to ensure that the Google Firewalls are appropriately opened up to these ports (80 and 443 respectively). Albeit I’m not using 443 at the moment, it’s open for subsequent material I may write on this topic.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    resource &amp;quot;google_compute_instance&amp;quot; &amp;quot;redirector&amp;quot; {
      name = &amp;quot;redirector&amp;quot;
      machine_type = &amp;quot;f1-micro&amp;quot;
      tags = [
        &amp;quot;http-server&amp;quot;,
        &amp;quot;https-server&amp;quot;]
      zone = &amp;quot;us-central1-b&amp;quot;

      disk {
        image = &amp;quot;redirector-1471307522&amp;quot;
      }

      network_interface {
        network = &amp;quot;default&amp;quot;
        access_config {
          nat_ip = &amp;quot;${google_compute_address.redirector.address}&amp;quot;
        }
      }

      service_account {
        scopes = [
          &amp;quot;userinfo-email&amp;quot;,
          &amp;quot;compute-ro&amp;quot;,
          &amp;quot;storage-ro&amp;quot;]
      }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, I can use the Terraform CLI and it’ll pull in the all the .tf files for processing and build out the static IP, DNS entry, and respective instance with the nginx.conf file already baked in. With a single command of &lt;code&gt;terraform apply&lt;/code&gt; and it will all be done!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect-part-two/terraform-apply.gif&quot; alt=&quot;terraform apply&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now, of course the first time this is applied, be sure to give the DNS Servers some time to propagate. When done, the URL redirection will be in place.&lt;/p&gt;
&lt;p&gt;If you see any errors or confusing parts of this article or &lt;a href=&quot;http://blog.adron.me/articles/nginx-notes-from-the-url-redirect/&quot;&gt;part 1&lt;/a&gt; let me know. You can even take it a step further and &lt;a href=&quot;https://github.com/Adron/adron.github.io&quot;&gt;fork my repo&lt;/a&gt; and, make the changes to the &lt;a href=&quot;https://github.com/Adron/adron.github.io/blob/master/_working/contents/articles/nginx-notes-from-the-url-redirect-part-two/index.md&quot;&gt;markdown file here&lt;/a&gt; and submit a pull request. I’ll review and get a new static site built with the edits ASAP! Thanks.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Speaking Trips, Tech, and Treks</title>
      <link>http://adron.github.io/articles/speaking-trips-tech-and-treks/</link>
      <pubDate>Mon, 25 Jul 2016 19:35:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/speaking-trips-tech-and-treks/</guid>
      <author></author>
      <description>&lt;p&gt;I’ll be off on some coding adventures in the coming months. I also hope to catch up with a lot of people and their respective projects, learn a few things, and if it’s possible maybe teach a few people a thing or three about immutable infrastructure, lessons I’ve learned, and how to avoid infrastructure catastrophes while building the next bad ass awesome application. This blog entry is about the details of my logistics, and I’ll follow up with more details of the coding adventure along the way. For now: details, details, and details.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://conferences.oreilly.com/software-architecture&quot;&gt;&lt;img src=&quot;/articles/speaking-trips-tech-and-treks/oreillyarchitectureconf.png&quot; alt=&quot;O&amp;#39;Reilly Architecture Conference 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;takes place in &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu&quot;&gt;London&lt;/a&gt; October 19-21, 2016 and &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-ca&quot;&gt;San Francisco&lt;/a&gt; November 14-16, 2016&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;moving-enterprise-practices-and-development-to-open-source&quot;&gt;Moving Enterprise Practices and Development to Open Source&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;in London&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Official Talk URI: &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52257&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52257&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My Talk URI: &lt;a href=&quot;http://blog.adron.me/talks/Moving-Enterprise-Practices-and-Development-to-Open-Source/&quot;&gt;http://blog.adron.me/talks/Moving-Enterprise-Practices-and-Development-to-Open-Source/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this talk I’ll tell the story of our efforts at Home Depot, and provide bullet points and suggestions for helping you to acheive the move to open source practices in your enterprise. The benefits are huge, and overall it’s a lot more fun to boot!&lt;/p&gt;
&lt;p&gt;Key Points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Steps we took to get into the open.&lt;/li&gt;
&lt;li&gt;Practices to take up and start using.&lt;/li&gt;
&lt;li&gt;Things to avoid when moving to open source models.&lt;/li&gt;
&lt;li&gt;How to make the most of things for the community and the enterprise.&lt;/li&gt;
&lt;li&gt;Tooling, interoperability, services, and how to get it done.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;building-immutably-to-continuous-delivery-with-minimal-inputs&quot;&gt;Building Immutably to Continuous Delivery with Minimal Inputs&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;in London and in San Francisco&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Official Talk URI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;London &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52254&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-eu/public/schedule/detail/52254&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;San Francisco &lt;a href=&quot;http://conferences.oreilly.com/software-architecture/engineering-business-ca/public/schedule/detail/52258&quot;&gt;http://conferences.oreilly.com/software-architecture/engineering-business-ca/public/schedule/detail/52258&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My Talk URI:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;London &lt;a href=&quot;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-London&quot;&gt;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-London&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;San Francisco &lt;a href=&quot;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-San-Francisco/&quot;&gt;http://blog.adron.me/talks/Building-Immutably-Continuous-Delivery-Minimal-Inputs-San-Francisco/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Prerequisite knowledge&lt;/p&gt;
&lt;p&gt;Basic understanding of web applications, architecture &amp;amp; design, and basic knowledge of windows &amp;amp; linux server systems.&lt;/p&gt;
&lt;p&gt;Materials or downloads needed in advance&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com&quot;&gt;Github Account&lt;/a&gt;, &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;AWS&lt;/a&gt; (or &lt;a href=&quot;https://cloud.google.com/&quot;&gt;GCE&lt;/a&gt;, &lt;a href=&quot;https://azure.microsoft.com&quot;&gt;Azure&lt;/a&gt;, etc) Account, and &lt;a href=&quot;https://codeship.com/&quot;&gt;CodeShip Account&lt;/a&gt;. Also a computer with OS-X, Windows, or Linux loaded with Node.js is also required.&lt;/p&gt;
&lt;p&gt;This workshop focuses on building a continuously delivered pipeline using Node.js (however easily transferable to Ruby/Rails/Java/Scala/.NET etc.). The workshop will trace the steps from inception to deployed application (with a domain pointed appropriately and all) that can then be developed against to continue whatever effort and intent of the developer(s)!&lt;/p&gt;
&lt;p&gt;Key Points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parts: Application, Domain Name, Infrastructure, Integration, &amp;amp; Delivery&lt;/li&gt;
&lt;li&gt;Build an Application: Steps for building &amp;amp; actually building a simple Node.js Application to deploy.&lt;/li&gt;
&lt;li&gt;Getting a domain name, determining name servers &amp;amp; DNS servers, setting it up and getting it pointed at our application.&lt;/li&gt;
&lt;li&gt;Setting up and determining the deployment scenario on AWS &amp;amp; discussion of other infrastructure choices.&lt;/li&gt;
&lt;li&gt;Deploying the application through the complete process of code, integrate, test, build, deploy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/articles/speaking-trips-tech-and-treks/hashiconf2016.png&quot; alt=&quot;Hashiconf 2016&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;h3 id=&quot;organizing-infrastructure-config-workflow&quot;&gt;Organizing Infrastructure Config &amp;amp; Workflow&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;September 7-8, 2016 @ Napa Valley, California&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Official Talk URI: &lt;a href=&quot;https://www.hashiconf.com/talks/organizing-infrastructure-config-workflow.html&quot;&gt;https://www.hashiconf.com/talks/organizing-infrastructure-config-workflow.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My Talk URI: &lt;a href=&quot;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&quot;&gt;http://blog.adron.me/talks/Organizing-Infrastructure-Config-and-Workflow/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m super stoked about this talk, as I’m getting to co-present with Evan Brown. Evan’s a friend of mine since I met him a whiel back while he worked at AWS, however he’s now a Senior Software Engineer at Google. We’re going to tag team style this talk to bring you as much information as we can about organzing your infrastructure configuration and workflow.&lt;/p&gt;
&lt;p&gt;My abstract for this talk goes something like this, “&lt;em&gt;When starting with the various products Terraform, Packer, Vagrant, and others, it isn’t always apparent where and in what way one should organize the actual project. In this talk I’d like to delve into what I’ve done to organize solutions for development, production, and related pipelines. I’ll talk from my point of view and what I’ve seen others do to keep their workloads organized and their infrastructure and application pipelines clean and well organized.&lt;/em&gt;“&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Portland Biketown Launches - Check out the API</title>
      <link>http://adron.github.io/articles/biketown-api/</link>
      <pubDate>Thu, 21 Jul 2016 08:13:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/biketown-api/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/logo.png&quot; alt=&quot;Biketown Logo&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Good morning Portland! After a few years of hiccups, the Portland Bike Share has finally gotten started! We can thank our corporate overlords over at Nike for kicking in that last chunk of millions to get a bike and station layout that is absolutely superb!&lt;/p&gt;
&lt;p&gt;For a little bit more about the opening day and metrics on uses check out &lt;a href=&quot;http://bikeportland.org/&quot;&gt;Bike Portland&lt;/a&gt; has posted &lt;a href=&quot;http://bikeportland.org/2016/07/20/over-2300-trips-taken-on-biketown-bike-share-in-first-24-hours-187922&quot;&gt;Over 2,300 trips taken on Biketown bike share in first 24 hours&lt;/a&gt;, &lt;a href=&quot;http://bikeportland.org/2016/07/19/bike-share-is-alive-photos-and-recap-from-the-launch-event-187867&quot;&gt;“This is awesome!” Photos and notes from the Biketown launch event&lt;/a&gt;, and others.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;biketown-pdx-&quot;&gt;Biketown PDX!&lt;/h2&gt;
&lt;p&gt;Alright, before diving into the API, let’s discuss the actual way the system works. There are several components to how things go, but it involves the &lt;strong&gt;&lt;em&gt;workflow&lt;/em&gt;&lt;/strong&gt; of &lt;strong&gt;&lt;em&gt;joining&lt;/em&gt;&lt;/strong&gt;, then &lt;strong&gt;&lt;em&gt;unlocking&lt;/em&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;em&gt;riding&lt;/em&gt;&lt;/strong&gt;, and then &lt;strong&gt;&lt;em&gt;locking&lt;/em&gt;&lt;/strong&gt; it back up. At least, that’s the basic workflow, but there’s obviously a bit more understanding needed to know what to actually do with the bike share. In the next few sections, I’ll break this into &lt;strong&gt;&lt;em&gt;Workflow&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Systemic Geographic Mapping and Stuff&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&quot;workflow&quot;&gt;Workflow&lt;/h3&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com/pricing&quot;&gt;&lt;img src=&quot;/articles/biketown-api/join.png&quot; alt=&quot;Join&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;The first step of the workflow is joining. There’s three ways to do this: single ride, day pass, or annual membership. The single ride is $2.50 per trip. The day pass is $12 a day and the annual membership is $12 per month. Now each of these prices are pretty straight forward, but there are indeed a few little gotchas here and there. Nothing that would break the bank, but let’s talk more about this first step.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Single Ride&lt;/em&gt; - The single ride is good if you’ve arrived somewhere but have a short distance to go. Like say you arrive at Pioneer Square on the MAX, and want to get over to the east side real quick around area Burnside. Obviously using transit to get back over the Burnside is an awkward mess, so jumping on a Biketown bike is a perfect solution. This is where the quick $2.50 ride comes into play. Now theoretically most human beings could clear Pioneer Square clear up to about 20th &amp;amp; Burnside in under 30 minutes. However, this is one of the gotchas - exceed 30 minutes and it is 10 cents a minute after that. Not a big deal, but if you didn’t read the fine print it’ll sneak up on ya. There’s one more note to this situation though, it isn’t all penalty fees. When you bring your bike back to the station you actually get a $1.00 account credit! So really, if you use the bike share even somewhat regularly, such as once or twice a month, your price really ends up being about a $1.50 per ride instead of $2.50.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Day Pass&lt;/em&gt; - This basically provides 180 minutes per day and an unlimited number of rides. Which this dual qualifier just doesn’t sound right. If I can have unlimited rides, but am limited to 180 minutes, it doesn’t sound like unlimited rides. Grumble grumble &lt;em&gt;nothing bugs me like poor logic applied in real world business&lt;/em&gt;. But anyway, that’s what is written. The other add, but benificial thing is that if you get a day pass, you can expand on that day pass to take out 4 additional bikes at a time, the first bike counts as the day pass purchaser’s bike, then the other 3 are only $6 per hour, nor do these bikes count toward the 180 minutes. Overall, sounds like a deal, but it’s also attached to that oddly worded logic of the day pass deal. I guess it works out. One the 180 minutes is exceed, it’s 10 cents a minute (so not unlimited rides, but just this…) and upon returning the bike to a rack station, a $1 is applied back to the account as credit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Annual Membership&lt;/em&gt; - This is the account I bought, partially to get into the founders 1000. Which I’m a proud member of. Basically I get extra benifits, but even purchasing one now, post the first founders round of purchasers gets you a good deal. The $12 a month cost gets you unlimited rides, with 90 minutes of ride time included per day. Over 90 minutes is 10 cents a minute. All the other specs are basically the same, but this is a great deal if you want to insure you have easy access at any time to the bike share.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Other Notes&lt;/em&gt; - It’s important to note also, that if you don’t park the bike back at a Biketown rack it’s $2.00 within the system area and $20 outside the system area. The later price can hit the piggy bank a bit. If you’re curious what the service area is, check out the &lt;em&gt;Systemic Geographic Mapping&lt;/em&gt; section below. If you somehow manage to &lt;strong&gt;&lt;em&gt;lose&lt;/em&gt;&lt;/strong&gt; a bike, heaven forbid, you’ll owe a  &lt;strong&gt;$1500.00&lt;/strong&gt; whopper, which they can and likely would nail your ass in small claims for that.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Alright, so that is the levels of joining you can partake upon, but what about actually joining? One way is to sign up on the &lt;a href=&quot;https://www.biketownpdx.com/&quot;&gt;Biketown site itself&lt;/a&gt;. Signing up on the site is likely the easiest of all the methods. Then you’ll get an account number and your passcode, then you can just use that to rent a bike wherever and whenever. The next way is to sign up with the little computer attached to the bike. I’ve seen one person do this, and I’m to fidgety to even attempt this, I did my registration via the site. Then the other way is via the mobile app (&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.biketownpdx&quot;&gt;Android&lt;/a&gt; or &lt;a href=&quot;https://itunes.apple.com/us/app/biketownpdx/id1132076989&quot;&gt;iOS&lt;/a&gt;, which is also really easy. Ok, that’s basically it for signing up. Now you’ll be in the system and able to work with the various aspects of the system, such as obviously the bikes themselves.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/unlock.png&quot; alt=&quot;Unlock&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Now comes the part where you go get a bike and unlock it. There are three absurdly easy ways to find the bikes. One, is to simply see the unbelievably orange things sitting about the area locked to whatever. Two, you can go out to the website and check out the &lt;a href=&quot;https://www.biketownpdx.com/map&quot;&gt;map and go to one of those locations&lt;/a&gt;. Third, you can use the mobile application, which is likely the most useful since you’d often be on the go when you get a bike. At least, for me that’s the way I generally use the system.&lt;/p&gt;
&lt;p&gt;The overall map looks a bit like this…&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.biketownpdx.com/map&quot;&gt;&lt;img src=&quot;/articles/biketown-api/maps.jpg&quot; alt=&quot;The Bike Map&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The other way to find and get a bike at the same time is to actually reserve a bike. This puts a hold on a particular bike as you travel toward the bike to pick it up. To learn more about reserving a bike download the app and give it a try.&lt;/p&gt;
&lt;p&gt;If you just go to where a bike or bikes are then you’ll click a button, the screen will come alive, then enter your account number and your account code. Once you’ve done that you’ve checked out the bike and are ready to ride. Also, feel free to enjoy a video on the matter of unlocking and locking.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/mPWZhknfI48?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;So moving right along…&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com&quot;&gt;&lt;img src=&quot;/articles/biketown-api/ride.png&quot; alt=&quot;ride&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Riding… ok, ummm, I think this is pretty self-explanatory. You ride the bicycle to where you intend to go. It’s really not complicated. But just in case here are a few tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ride at a steady speed in the bike lane, path, or if there isn’t a path or bike lane take the full lane as the law states in Oregon code.&lt;/li&gt;
&lt;li&gt;Don’t ride on the sidewalk unless you have to. It’s a pretty shitty thing to do in all seriousness, and also illegal in some circumstances.&lt;/li&gt;
&lt;li&gt;Enjoy the ride!&lt;/li&gt;
&lt;li&gt;Don’t ride into trees. They’re really hard.&lt;/li&gt;
&lt;li&gt;Enjoy the breeze flowing through your hair (or if you’re like me, flowing over your scalp!)&lt;/li&gt;
&lt;li&gt;Enjoy the fact you’re being super clean, responsible, you’re doing your body and everybody else some good by riding a bike, and getting things done at the same time!&lt;/li&gt;
&lt;li&gt;Just take your time and keep an eye out, you’ll get there just fine.&lt;/li&gt;
&lt;li&gt;You’re not reducing yourself to motor-vehicle usage, be proud of that.&lt;/li&gt;
&lt;li&gt;Also be glad you’re not some asshole in a car. Everybody, even me, when we drive we’re assholes. It’s just the law of physics and the rule of cages is all, don’t cry over it or anything.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ok, enough random rules, observations, and guidelines. You get the idea, ride the bike, have fun, get where you’re going. Smile, love one another. Koombayaaaa and stuff.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;https://www.biketownpdx.com/pricing&quot;&gt;&lt;img src=&quot;/articles/biketown-api/lock.png&quot; alt=&quot;lock&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Once you’re done with the bike lock it up to a bike kiosk. You can technically just lock it to a post or what not, it’s up to you, but note the costs above in the plans I described earlier. If out of zone it’s $20 bucks, if inside the zone and not in a kiosk it’ll cost you $2.00. So it’s usually best to just lock it to a standard bright orange rack kiosk.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Whew, done with the description. Let’s talk about the coding factor now…&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;systemic-geographic-mapping-api-stuff&quot;&gt;Systemic Geographic Mapping API Stuff&lt;/h3&gt;
&lt;p&gt;Ok, I don’t really know what “Systemic Geographic Mapping API Stuff” but it sounds like it encompasses the key aspects of what features the API has. So let’s talk data.&lt;/p&gt;
&lt;p&gt;The first bit of data that is useful is the GBFS. This is the General Bikeshare Feed Specification. This is available here: &lt;a href=&quot;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&quot;&gt;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;That’s a &lt;em&gt;little&lt;/em&gt; data, an overview of the system one could say. The real meat however is in the authenticate API. It’s available at &lt;a href=&quot;https://app.socialbicycles.com/developer&quot;&gt;https://app.socialbicycles.com/developer&lt;/a&gt;. Give it a try with a curl.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://biketownpdx.socialbicycles.com/opendata/gbfs.json
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The response is as shown. A pretty straight forward JSON data blurb. Showing the pricing, alerts, regions, calendar, hours, free bike status (??), station status, station information, and system information url references.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469237395&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;en&quot;&lt;/span&gt;: {
      &lt;span class=&quot;string&quot;&gt;&quot;feeds&quot;&lt;/span&gt;: [
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;gbfs&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/gbfs.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_information&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_information.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;station_information&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/station_information.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;station_status&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/station_status.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;free_bike_status&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/free_bike_status.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_hours&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_hours.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_calendar&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_calendar.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_regions&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_regions.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_pricing_plans&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_pricing_plans.json&quot;&lt;/span&gt;
        },
        {
          &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;system_alerts&quot;&lt;/span&gt;,
          &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.socialbicycles.com/opendata/system_alerts.json&quot;&lt;/span&gt;
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Any of the references you can do a simple curl against and get a good chunk of data. For instance.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl http://biketownpdx.socialbicycles.com/opendata/system_information.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result returns as such.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469290649&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;system_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;biketownpdx&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;language&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;en&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;BIKETOWNpdx&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.com/&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;purchase_url&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://biketownpdx.com/&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;timezone&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;America/Los_Angeles&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;phone_number&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;(866) 512-2453&quot;&lt;/span&gt;,
    &lt;span class=&quot;string&quot;&gt;&quot;email&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;customerservice@biketownpdx.com&quot;&lt;/span&gt;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I first looked at this list I got keenly interested in the &lt;code&gt;free_bike_status&lt;/code&gt;. I’d always want to know where the free bikes are when I want to rent one. A simple curl request and I knew what I could accrue from this end point. The blurb is sizably bigger than the previous two, so I actually cut out the mid section so it didn’t take until tomorrow to scroll to the end.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;last_updated&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1469290813&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;ttl&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;data&quot;&lt;/span&gt;: {
    &lt;span class=&quot;string&quot;&gt;&quot;bikes&quot;&lt;/span&gt;: [
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_6779&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0218 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.65348833333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.50477166666667&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_6265&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0188 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.70043833333334&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.535826666666665&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7160&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0131 BIKETOWN&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.674115&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.51180333333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      &lt;span class=&quot;string&quot;&gt;``&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…a whole bunch of entries cut out for brevity…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7308&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0984 AIR TRAINER&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.64039333333334&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.55905833333333&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      },
      {
        &lt;span class=&quot;string&quot;&gt;&quot;bike_id&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;bike_7301&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;0971 AIR TRAINER&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lon&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;-122.644855&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;lat&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;45.516286666666666&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_reserved&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;is_disabled&quot;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far this is purely the public facing, non-authentication based API for Biketown. You can get a host of information and do all sorts of useful things with just this information. But, I will be following up in the coming days with a review of the actual authenticated API for Biketown. I’m looking forward to hacking together some cool apps and interfaces myself, but I’m also really interested to see what others put together!&lt;/p&gt;
&lt;p&gt;Last thing for this post, if you’re curious about the oddly colored bikes that are clearly not orange. You can rent those two, they have a particular theme as detailed here. Something to do with Nike branding and Nike shoes of some sort, I’m not entirely sure as I don’t really wear any Nike gear. Ironically, since I bike I need tougher stuff that’s oriented toward biking. Nike doesn’t really seem to have any market play in that realm.&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qs6m9lQ9qRE?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Until that next API call, cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>NGinx Notes from URL Redirect Project on Google Cloud with Terraform &amp; Packer - Part 1</title>
      <link>http://adron.github.io/articles/nginx-notes-from-the-url-redirect/</link>
      <pubDate>Fri, 15 Jul 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/nginx-notes-from-the-url-redirect/</guid>
      <author></author>
      <description>&lt;p&gt;I set out on a mission yesterday to put together a URL Redirect Server. Before I even get into the nitty gritty of how I got this to work via Nginx, I’ll add two caveats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I don’t really know much about Nginx at all. I’ve written up and configured one reverse proxy and handed that off to some ops team. Theoretically it worked (in their testing). But other than that, I’ve barely done anything myself with Nginx.&lt;/li&gt;
&lt;li&gt;I’ve no idea really if this is even a good practice. URL Redirects of this sort actually seem like a hack. They work, but it seems like there really ought to be a better less onion layer like way to do this type of redirection.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With those two caveats I’ll add a few questions for you, dear reader.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If you have any suggestions for an easier way than spinning up a whole Nginx Server to do URL Redirects I’d love to hear them!&lt;/li&gt;
&lt;li&gt;Is this a best practice way to do subdomain to URL Redirects? If not, I’d probably like to be doing whatever is best practice.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, now that we’re past my caveats, questions, and requests for help, let’s roll on the how-to of all this.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This whole setup started when I realized while doing a migration from one DNS Provider to Google DNS. Google DNS doesn’t convolute their DNS Services with URL Redirect features or other non-DNS features. When I stumbled into the fact that there were some URL Redirects that had muddled themselves into Google DNS as actual CNAME DNS entries, I knew I’d need to get those migrated to something that could actually do URL redirects.&lt;/p&gt;
&lt;p&gt;The need was super simple in scope. Have a subdomain, like &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; redirect (302 and eventually 301, more on that in a minute) to something like &lt;a href=&quot;http://api.compositecode.com/dataservices/information.html&quot;&gt;http://api.compositecode.com/dataservices/information.html&lt;/a&gt;. I did some reading about &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations&quot;&gt;Apache vs. Nginx&lt;/a&gt;. I determined I’d go with Nginx as I knew it to be a solid server with minimal fuss.&lt;/p&gt;
&lt;h2 id=&quot;setting-up-nginx&quot;&gt;Setting up Nginx&lt;/h2&gt;
&lt;p&gt;Before getting into a smart way to setup Nginx, I just dove in to figure out how to setup a redirect.&lt;/p&gt;
&lt;p&gt;First I spun up an Ubuntu 16.04 Server on Google Cloud. Here’s the interface for creating a new instance on Google Compute Engine (GCE).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-01.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next setup the criteria for the instance. In my particular situation I’m assuming an almost non-existent need for resources so I’ve select the uber cheapo $4.49 instance. For that instance I named it url-redirector, stuck it in the us-central1-a zone, selected the micro (1 shared vCPU) with 0.6 GB Memory, using the Ubuntu 16.04 LTS image, gave it default access, selected HTTP traffic, and clicked create.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-02.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once created it displayed on the Compute Engine dashboard screen. There I have my IP and SSH options.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-03.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;Clicking on the SSH vertical elipsis I then selected the &lt;code&gt;View gcloud command&lt;/code&gt; option. A dialog appears with the gcloud command to connect to this new instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/nginx-notes-from-the-url-redirect/nginx-url-redirector-04.png&quot; alt=&quot;Google Cloud Instance Setup&quot;&gt;&lt;/p&gt;
&lt;p&gt;I copied the command to ssh into my Google Cloud server instance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcloud compute --project &amp;quot;that-big-universe&amp;quot; ssh --zone &amp;quot;us-central1-a&amp;quot; &amp;quot;url-redirector&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this point I went ahead and logged into this new instance and installed Nginx.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install -y nginx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On Ubuntu 16.04 a new firewall technology is used called Uncomplicated Firewall (UFW). To setup that firewall, open up the HTTP and SSH ports. Some instructions point to an Nginx HTTP so I added that too. Then I enabled the firewall.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo ufw allow http  #adds port 80
sudo ufw allow ssh  #adds port 22
sudo ufw allow &amp;#39;Nginx HTTP&amp;#39;
sudo ufw enable
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I noticed this prompted for a “&lt;code&gt;y|n&lt;/code&gt;“ as I enabled the firewall. So I’ll have to figure that out later as I work through automating and building out this server for deployment and prep with Packer and Terraform later. At this point however I have the server running, with Nginx, and am ready to test out a redirect.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Configuration File Structure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A lot of the samples I find all over the web are in little snippets like the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
    root /data/www;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    location / {
        root /data/www;
    }

    location /images/ {
        root /data;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;location / {
        fastcgi_pass  localhost:9000;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param QUERY_STRING    $query_string;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In these three examples I have location with a value for the root property in the top one, then in the next the server with two location sections and then finally a location. So many of these snippets are used and can be confusing without context for how and where things are structured within the configuration file itself.&lt;/p&gt;
&lt;p&gt;Let’s break this out real quick to the requisite parts of the file. Nginx has modules controlled by directives in the configuration file. A directive consistes of name and parameters separated by spaces and ending with a semicolon. A block directive or simple directive has the same overall structure. The difference being a block directive has a set of instructions surrounded by braces. A context is a block directive that has additional directives inside the braces. Directives placed in the configuration file outside of contexts is in the main context.&lt;/p&gt;
&lt;p&gt;Some of the key contexts to be familiar with in configuration of Nginx are the &lt;em&gt;events&lt;/em&gt;, &lt;em&gt;http&lt;/em&gt;, &lt;em&gt;main&lt;/em&gt;, &lt;em&gt;server&lt;/em&gt;, &lt;em&gt;http&lt;/em&gt;, and &lt;em&gt;location&lt;/em&gt; directives. Also, it’s good to know that the &lt;em&gt;events&lt;/em&gt; and &lt;em&gt;http&lt;/em&gt; directives reside int he &lt;em&gt;main&lt;/em&gt; context, &lt;em&gt;server&lt;/em&gt; in &lt;em&gt;http&lt;/em&gt;, and &lt;em&gt;location&lt;/em&gt; in &lt;em&gt;server&lt;/em&gt;. The most common one often edited, at least in my minor experience so far is the &lt;em&gt;server&lt;/em&gt; context. This &lt;em&gt;server&lt;/em&gt; context of course resides in the &lt;em&gt;http&lt;/em&gt; context which resides in the &lt;em&gt;main&lt;/em&gt; context. This looks something like what is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http {
    server {
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Check out a &lt;a href=&quot;http://adron.github.io/docs/nginx-default-config-file&quot;&gt;sample nginx.conf files&lt;/a&gt; to get an idea of what the default config file looks like after installation. For more information also check out this other &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts&quot;&gt;Digital Ocean blog entry “Understanding the Nginx Configuration File Structure and Configuration Contexts”&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another important thing to know, besides how the nginx.conf file is structured and formatted, is where the thing is actually located. Here are some of the file locations for it and related important files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/var/www/html&lt;/code&gt; is where the actual content that Nginx serves is located.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx&lt;/code&gt; is where the configuration files are. Including the nginx.conf file I’ll need to edit for the redirect.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/sites-available&lt;/code&gt; is the directory where per-site “server blocks” are stored. Typically server block config is done here and then enabled by linking to the other directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/sites-enabled&lt;/code&gt; is the directory where enabled per-site “server blocks” are stored linked by config files in the sites-available directory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/etc/nginx/snippets&lt;/code&gt; is where config fragments are included that are used elsewhere in Nginx configuration.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/nginx/access.log&lt;/code&gt; is where the web server records log files unless configured to do so elsewhere.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/nginx/error.log&lt;/code&gt; is where Nginx errors are recorded.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What I needed to do at this point was edit the nginx.conf, or some file, and ensure that it had the appropriate redirection in the file. My first take at this looked like the following edit. I opened up the nginx.conf file and added this to the &lt;code&gt;http {}&lt;/code&gt; context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http {
    server {
        server_name data.adron.me;
        return 302 http://api.compositecode.com/dataservices/information.html;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;At this juncture however, with this hack of the config file I had a working URL Redirection. Upon further reading I realized that maybe this wasn’t the most ideal place to put the redirection.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;I’ve got a solid redirect in place for &lt;a href=&quot;http://data.adron.me&quot;&gt;http://data.adron.me&lt;/a&gt; that is sending traffic to &lt;a href=&quot;http://api.compositecode.com/dataservices/information.html&quot;&gt;http://api.compositecode.com/dataservices/information.html&lt;/a&gt;. However I’m not sure I’ve set this up using an ideal practice. So I went back to reading more of the documentation. RTFMing, it’s important.&lt;/p&gt;
&lt;p&gt;Part 2, coming up soon, with more docs read for better insight! &amp;lt;- this line will eventually link, like a linked list, to the next part of this series.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nginx.com/&quot;&gt;Nginx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nginx.com/resources/wiki/&quot;&gt;Nginx Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-14-04-lts&quot;&gt;Installing Nginx on Ubuntu Server 14.04 LTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-nginx-on-ubuntu-16-04&quot;&gt;Installing Nginx on Ubuntu Server 16.04&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/apache-vs-nginx-practical-considerations&quot;&gt;Aapche vs. Nginx: Practice Considerations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts&quot;&gt;Understanding the Nginx Configuration File Structure and Configuration Contexts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>.NET Fringe and Node PDX Conference Retrospective</title>
      <link>http://adron.github.io/articles/net-fringe-retrospective/</link>
      <pubDate>Tue, 12 Jul 2016 13:37:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/net-fringe-retrospective/</guid>
      <author></author>
      <description>&lt;p&gt;Well, that’s a wrap - tied with a bow - for .NET Fringe 2016 and Node PDX 2016. That’s two years in a row for .NET Fringe and the 3rd year for Node PDX (2012, 2013, and 2016). All of the conferences have been very stressful, intense, and rewarding. I’ve learned a lot in the process and had a chance to work together with a lot of great people including Troy Howard, Glenn Block, Scott Hanselman, Phil Haack, Itamar Syn-Hersko, Alena Hall, and many others.&lt;/p&gt;
&lt;p&gt;At this point I’ve deemed it time for a solid retrospective on organizing, community, and related topics. I’m breaking this article into the following segments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conference Organizing - Taking a Break&lt;/li&gt;
&lt;li&gt;Community Organizing vs. Value Added&lt;/li&gt;
&lt;li&gt;Workshops - What’s valuable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;conference-organizing&quot;&gt;Conference Organizing&lt;/h2&gt;
&lt;p&gt;Conferences themselves are great experiences for the vast majority of people that attend the conferences. It’s also a great way to build a community that knows each other beyond the virtual space. Having these connections is invaluable - from the connections that Steve Jobs &amp;amp; Wozniak made at conferences that led to Apples creation to Microsoft at the same, to today with open source conferences like OSCON, Strangeloop, and other great community led conferences. These are the places where conversations start that build this industry and take us into the future.&lt;/p&gt;
&lt;p&gt;In that sense, I hope Node PDX and .NET Fringe have helped to grow the community in Portland and beyond. I hope it has helped people to expand on ideas, projects, and overall grow as individuals and build more cohesive organizations. I too, have grown and been able to expand and build on ideas and various projects because of these efforts. In many ways these conferences have helped me to build my future.&lt;/p&gt;
&lt;p&gt;I myself am going to take a break this coming dozen or more months, ma ybe permanantly, from conference organizing. I have however already started plotting some of the next big projects that I will contribute or build. Namely, I intend to start speaking and providing workshops on several key spaces within the tech industry that I see a horrid gap that needs filled. More on that real soon.&lt;/p&gt;
&lt;h2 id=&quot;community-organizing-vs-value-added&quot;&gt;Community Organizing vs. Value Added&lt;/h2&gt;
&lt;p&gt;I’ve always enjoyed organizing events of various types. From meetups like the Elastic Meetup that I’m currently helping to organize or conferences like .NET Fringe or Node PDX. Each tech stack, event type, and related slices of categorization have different &lt;em&gt;communities&lt;/em&gt; built around it. Some have inspiration, others networking options, some are great for project building or team building. Whatever the case they each have their positives. In the same light, each type of event has it’s various negatives too.&lt;/p&gt;
&lt;p&gt;Conferences are almost all organized around speakers speaking at an audience. Sometimes there is time for questions, but there is strong argument that questions for a speaker doesn’t add a lot and often derails the momentum of talks for the overall audience. Some conferences have workshops before the actual presentation sessions. Other conferences work around an unconference or open spaces style event setup. Each style has benefits for people and negatives, as an example, I myself love to attend open spaces conferences and feel that I gain the most value from conferences like that. &lt;/p&gt;
&lt;p&gt;I’ve always aimed to mix the elements together to find the best combination of value for people, along with Troy, Glenn, and the teams we’ve put together to organize these conferences. It’s actually an extremely difficult mix to get right. I think we’ve done a good job of getting that mix right, but I’m sure there are a number of things we can improve on to get even more value out of conferences for people.&lt;/p&gt;
&lt;p&gt;In an attempt to get more value out of social gatherings like conferences, meetups, and the like I’m going to work dilligently in the coming weeks to get new ideas together to build even better events. Some of the requests and demands of various audiences range widely. Here’s a few questions I’ve noted as of late, with a tweet that kicked off several of the conversations.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I&amp;#39;m kind of over conferences. The whole, &amp;quot;Speaker gets up and talks&amp;quot; mode of transferring information is busted. I learn by doing.&lt;/p&gt;&amp;mdash; Scott Koon (@lazycoder) &lt;a href=&quot;https://twitter.com/lazycoder/status/752002282498068481&quot;&gt;July 10, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;gathering-questions-for-ideas&quot;&gt;Gathering Questions for Ideas&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What do people enjoy in gatherings that help us attain the maximum learning?&lt;/li&gt;
&lt;li&gt;What makes gatherings interesting enough to attend?&lt;/li&gt;
&lt;li&gt;What negatives can we remove?&lt;/li&gt;
&lt;li&gt;What makes the environment good for meeting, talking, and working together on ideas to learn more?&lt;/li&gt;
&lt;li&gt;What are an ideal set of goals, specific goals, to actually work toward?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then some of the other goals that I aim to figure out, largely by testing out or building tools to do this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improve ability to communicate with specific members of the attendee audience when needed, with appropriate mediums, and reasonable expectations of information disseminate.&lt;/li&gt;
&lt;li&gt;Find ways to ticket by group, event, time, and related criteria that will allow communication and group association to simplify both things (ticketing and grouping).&lt;/li&gt;
&lt;li&gt;Find better ways to delegate payments and billing that aren’t hard linked to individual people and singular accounts.&lt;/li&gt;
&lt;li&gt;Find better ways to allocate work to volunteers and those interested in helping that has more globally viewable content to help give everybody involve better visibility into what we’re trying to get done.&lt;/li&gt;
&lt;li&gt;Study up on and work on my communication skills. This is, of course, something that has been an ongoing learning experience which I suspect will continue being an ongoing learning experience.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;workshops&quot;&gt;Workshops&lt;/h2&gt;
&lt;p&gt;I’ve got a ton of material that I’d like to break out into groupings for screencasts/video how-to or training content, blog entries, and hands on workshop training. After discussing space opportunities 
Mark at NedSpace (thanks again for helping with .NET Fringe Mark!) and have worked with Code Fellows (Marty rocked 2 Node PDX Workshops) and working with Mathias Brandewinder, Evelina Gabasova, Aaron Stannard, Beau Palmquist, and Jared Schaab. After gaining that experience I’m seriously working on determining how to provide more workshops, but with a bit more of a twist. I want to add new elements to workshops that can extend the entertaining value of the workshops but also the learnings of the various workshops I’d like to provide.&lt;/p&gt;
&lt;p&gt;One of the ideas that keeps rolling around in my head, which really is rooted in this question, “How do I combine the elements that I love providing in meetups, conferences, and existing workshops into a medium and mode of delivery that people would find valuable?” In summary, how can I do and teach the things I really enjoy so that people determine it is enough value to pay for? As in any business, it’s an interesting challenge. So in the coming weeks I’ll have more conversations and more ramblings on the blog here about what I’m determined to acheive with the delivery of workshops and gatherings related to learning lots of awesome things.&lt;/p&gt;
&lt;p&gt;Until then, I hope you’ve had a spectacular time at .NET Fringe AND Node PDX. I send thanks to all of the attendees and all involved - thanks and CHEERS!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Day 2 Multi-thinking-threads Smeared Around the Brainstorming at .NET Fringe</title>
      <link>http://adron.github.io/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/</link>
      <pubDate>Tue, 12 Jul 2016 09:04:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/day-2-multi-thinking-threads-smeared-around-brainstorming/logo.png&quot; alt=&quot;.NET Fringe Logo&quot;&gt;&lt;/p&gt;
&lt;p&gt;Sitting at .NET Fringe, day 2. Just introduced James Newton-King. Got a million conversations running through my mind. A lot of these conversations are worth noting, so I’ll just give a quick break out right here.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;docker-containers-windows&quot;&gt;Docker, Containers, &amp;amp; Windows&lt;/h2&gt;
&lt;p&gt;Started a conversation with Solomon Hykes (&lt;a href=&quot;https://twitter.com/solomonstre&quot;&gt;@solomonstre&lt;/a&gt;) regarding Windows and Docker Container technology use. I also started a lot of conversations yesterday and intend to have a few regarding these tech elements today.&lt;/p&gt;
&lt;h2 id=&quot;workshops-in-portland&quot;&gt;Workshops in Portland&lt;/h2&gt;
&lt;p&gt;I’ve had a conversation about future workshops, space, and the requisite needs around that to ensure I can deliver some awesome pending workshops to the Portland audience. Also started a conversation for people that would like to come into town for workshops, and have the assumed awesome time in Portland. We do have amazing beer, coffee, wine, food, and more. Thus any workshop in Portland will have appropriate things for any attendees. This is almost locked in, if you’re curious about these workshops, which will be seriously epic, &lt;a href=&quot;http://blog.adron.me/thrashingcodenews.html&quot;&gt;subscribe here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;hack-kubernetes-olympia&quot;&gt;Hack Kubernetes Olympia&lt;/h2&gt;
&lt;p&gt;Talked shortly with &lt;a href=&quot;https://twitter.com/NotMyself&quot;&gt;@NotMyself&lt;/a&gt;, and am plotting to take an Amtrak Cascades trip up to Olympia for a 1-2 day workshop on Kubernetes and related technologies. I’m thinking Docker + Swarm + Kubernetes + DevOps + how to make one’s life dramatically easier while delivering 10x what one could deliver just 5 years ago. This, I assure you will be a blast too.&lt;/p&gt;
&lt;h2 id=&quot;windows-server-vs-the-coders-universe&quot;&gt;Windows Server vs…  the coders Universe&lt;/h2&gt;
&lt;p&gt;So it seems that my assumption is safe. A large number of people in the .NET space love C#, F#, (even VB.NET), and other elements of .NET. There seems to be a resounding frustration around Windows OS itself, namely server not Windows 10. As a development OS it’s fine, albeit there are probably as many or more OS-X as Windows machines running and, dare I say at least 2 Linux machines at .NET Fringe right now. (Right &lt;a href=&quot;https://twitter.com/adymitruk&quot;&gt;@adymitruk&lt;/a&gt;) I’m very cool with this, as the pressure will grow to make Windows Server more, how should I put it, “Devopsified” or something like that might work.&lt;/p&gt;
&lt;h2 id=&quot;memetic-independence&quot;&gt;Memetic Independence&lt;/h2&gt;
&lt;p&gt;Ok, I almost started writing something about that in this blog entry, but it’ll get it’s own in the near future. &lt;a href=&quot;https://twitter.com/dsyme&quot;&gt;@dsyme&lt;/a&gt; hit on a dramatically important topic for the longevity and life of any open source software stack, and very applicative to .NET.&lt;/p&gt;
&lt;h2 id=&quot;the-9am-summary&quot;&gt;The 9am Summary&lt;/h2&gt;
&lt;p&gt;So it’s only 9:00am right now. I think that’ll be good for now. Will add more thoughts, observations, and other news bits later today. If you’re wanting help kicking off a project, connected to someone I might know, or otherwise talk tech, coding, and some devops universe topic - I’ll be around, just let me know!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>.NET Fringe Bike Ride</title>
      <link>http://adron.github.io/articles/Bike-Rides/</link>
      <pubDate>Fri, 08 Jul 2016 07:29:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/Bike-Rides/</guid>
      <author></author>
      <description>&lt;p&gt;In my &lt;strong&gt;&lt;em&gt;not so humble opinion&lt;/em&gt;&lt;/strong&gt; every conference should have a bike ride. But I realize it isn’t always possible. This is one of the ways conferences that Troy &amp;amp; I put on here in Portland are very different. We have a love for Portland; &lt;em&gt;the energy, the chill, vibrant yet relaxed, laid back, bike like, walking friendly city that it is&lt;/em&gt;. It’s a beautiful city that really can only be seen or felt by active transportation. If you walk, run, bike, skate board, dog sled, sled, cross country ski, or otherwise travel around Portland you get to actually see, feel, and hear this city. No other mode really works. Transit is fun, driving is like a cage, and with both you miss the vast majority of the life and blood of what makes Portland a great city!&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/Bike-Rides/nodepdx-bike-ride.jpg&quot; alt=&quot;Node PDX Bike Ride&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;-net-fringe-bike-ride&quot;&gt;.NET Fringe Bike Ride&lt;/h2&gt;
&lt;p&gt;With all that said, obviously we’re having a bike ride at .NET Fringe! I’ll be the lead, and give everybody a solid tour around some key parts of the city. I’ll show you all some odd things, weird stuff, probably some strange people, architecture and other elements and features of this place called Portland! Here’s the details:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Anybody can join the ride, even people that aren’t attending .NET Fringe. If we have 3 people ride or 500, it doesn’t matter, we’ll have a good roll about town.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;BYOB - Bring Your Own Bike AKA Bring Your Own Beer. For us, it means both. This might sound complicated, but I promise it’s not. There are a zillion places to rent a bike in about 20 seconds. Links below where to pick up a ride of your choice for the ride about the city.&lt;/li&gt;
&lt;li&gt;Show up at the designated location (also listed below) at the designated time (also listed below).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;That’s it!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ll summarize these simple steps to simply say “Just show up!” This isn’t a spandex crowd ride, this is a people chillin’ in Portland ride, so don’t worry nobody is getting left behind. We’ll enjoy some coffee, probably a beer, the city, and maybe a chat or three about the latest in tech, code patterns, and other miscellaneous hot topics like IoT not spamming your wifi and burning your muffins!&lt;/p&gt;
&lt;p&gt;Before renting a bike though, check out the options at the hotel you’re staying. Many if not most hotels in Portland have nice bikes that you can use for free. The Ace Hotel, Hotel Rose, and others all have a number that are freely available to guests of the hotel. &lt;/p&gt;
&lt;p&gt;So, in lieu of a bike access at hotel, home, friends, or otherwise, some great places to get bike rentals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.waterfrontbikes.com/&quot;&gt;Waterfront Bike&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Waterfront+Bicycle/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0xbed7f9780615f52d!8m2!3d45.5213399!4d-122.6709741&quot;&gt;10 SW Ash St #100, Portland, OR 97204&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.pedalbiketours.com/&quot;&gt;Pedal Bike Tours&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Pedal+Bike+Tours/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0x6c1861d1ea8716e0!8m2!3d45.5216706!4d-122.672739&quot;&gt;133 SW 2nd Ave, Portland, OR 97204&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://portlandbicycletours.com/&quot;&gt;Cycle Portland Bike Tours &amp;amp; Rentals&lt;/a&gt; - Located on &lt;a href=&quot;https://www.google.com/maps/place/Cycle+Portland+Bike+Tours+%26+Rentals/@45.522373,-122.6809235,15z/data=!4m8!1m2!2m1!1sbike+rentals!3m4!1s0x0:0xed9ef696a5172958!8m2!3d45.5241437!4d-122.672562&quot;&gt;117 NW 2nd Ave, Portland, OR 97209&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We’ll meet at the waterfront here @ &lt;a href=&quot;https://www.google.com/maps/@45.5213697,-122.6699997,19.25z&quot;&gt;100 SW Naito Parkway&lt;/a&gt; and depart at &lt;strong&gt;[[UPDATED &lt;code&gt;5:15pm&lt;/code&gt;]] &lt;/strong&gt; on Sunday.&lt;/p&gt;
&lt;p&gt;The ride path is a secret (mostly because we’ll be JIT via dynamic path finding along the route). However, I can say it’ll be low car volume, easy paths, and minimal hills (Portland is mostly flat by Cascadian standards).&lt;/p&gt;
&lt;p&gt;See all of ya out there!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Node PDX 2016 Photos</title>
      <link>http://adron.github.io/articles/Node-PDX-2016-Photos/</link>
      <pubDate>Wed, 29 Jun 2016 11:25:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/Node-PDX-2016-Photos/</guid>
      <author></author>
      <description>&lt;p&gt;Here’s a selection of photos from Node PDX. To check out all of the photos I’ve uploaded them on &lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Videos are available at &lt;a href=&quot;https://www.youtube.com/playlist?list=PLILnvQDgzULPSdF9Eppfl5MqQe0M3hhtx&quot;&gt;https://www.youtube.com/playlist?list=PLILnvQDgzULPSdF9Eppfl5MqQe0M3hhtx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/codes.jpg&quot; alt=&quot;Codes&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/liz.jpg&quot; alt=&quot;Liz&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/liz2.jpg&quot; alt=&quot;Liz&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/a1.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/azat4.jpg&quot; alt=&quot;Azat&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/b.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/computers.jpg&quot; alt=&quot;Computers&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben.jpg&quot; alt=&quot;Ben Michel&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/azat.jpg&quot; alt=&quot;Azat&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/chillin.jpg&quot; alt=&quot;Chillin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/elastic.jpg&quot; alt=&quot;Elastic&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hacking.jpg&quot; alt=&quot;Hacking&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hardware-hacking.jpg&quot; alt=&quot;Hardware&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/hardware-hacking2.jpg&quot; alt=&quot;Hardware&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/j3.jpg&quot; alt=&quot;&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jacob.jpg&quot; alt=&quot;Jacob&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/james3.jpg&quot; alt=&quot;James&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jamesh2.jpg&quot; alt=&quot;Jacob&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben1.jpg&quot; alt=&quot;Ben Michel&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jon.jpg&quot; alt=&quot;Jon&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/jon2.jpg&quot; alt=&quot;Jon&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/ben-music.jpg&quot; alt=&quot;Ben Michel &amp;amp; Band&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music2.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/music3.jpg&quot; alt=&quot;Music&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/matt.jpg&quot; alt=&quot;Matt&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/matt2.jpg&quot; alt=&quot;Matt&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/rethink.jpg&quot; alt=&quot;Rethink&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/reyes.jpg&quot; alt=&quot;Reyes&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/suchita.jpg&quot; alt=&quot;Suchita&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://photos.adron.me/Software/Meetups-N-Conferences/Conferences/Node-PDX-2016/&quot;&gt;&lt;img src=&quot;/articles/Node-PDX-2016-Photos/suchita1.jpg&quot; alt=&quot;Suchita&quot;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Node PDX 2016 Bike Ride, Photos, and More</title>
      <link>http://adron.github.io/articles/node-pdx-2016-bike-ride/</link>
      <pubDate>Wed, 29 Jun 2016 10:25:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-bike-ride/</guid>
      <author></author>
      <description>&lt;p&gt;Node PDX, at least for me, kicked off Saturday morning before the conference. This involved the Geek Train, which as always was a great ride. After returning everyone went off for the evening and I prepared more for the conference.&lt;/p&gt;
&lt;p&gt;The following day involved Sunday conference setup, workshops, and the Node PDX bike ride. Here’s a few photos of the ride and our break at Cup &amp;amp; Bar. In the next blog entry I’ll have more pictures &amp;amp; videos of the talks coming up.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/nodepdx-bike-ride.jpg&quot; alt=&quot;Node PDX Bike Ride&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar.jpg&quot; alt=&quot;Cup and Bar&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-1.jpg&quot; alt=&quot;Cup and Bar One&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-bikes.jpg&quot; alt=&quot;Cup and Bar Bikes&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/node-pdx-2016-bike-ride/cup-and-bar-chats.jpg&quot; alt=&quot;Cup and Bar Chats&quot;&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A Channel 9 Video on .NET Fringe 2016</title>
      <link>http://adron.github.io/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/</link>
      <pubDate>Thu, 16 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/A-Channel-9-Video-on-dotNET-Fringe-2016/chan9logo.png&quot; alt=&quot;Channel 9 Logo&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I was working on some code and related infrastructure configurations at &lt;a href=&quot;https://workfrom.co/albina-press&quot;&gt;Albina Press&lt;/a&gt; today. But took a short break to join &lt;a href=&quot;https://twitter.com/thoward37&quot;&gt;Troy Howard&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/&quot;&gt;Glenn Block&lt;/a&gt; to speak with &lt;a href=&quot;https://twitter.com/sethjuarez&quot;&gt;Seth Jaurez&lt;/a&gt; &lt;a href=&quot;https://twitter.com/Golnaz89&quot;&gt;Golnaz Alibeigi (even though she was hiding, she was there!&lt;/a&gt; to talk about &lt;a href=&quot;http://dotnetfringe.org/&quot;&gt;.NET Fringe&lt;/a&gt;.&lt;/p&gt;
&lt;iframe src=&quot;https://channel9.msdn.com/Events/NET-Fringe/NET-Fringe-2016/NET-Fringe-2016/player&quot; width=&quot;560&quot; height=&quot;315&quot; allowFullScreen frameBorder=&quot;0&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;For more info:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#speakers&quot;&gt;Speakers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#map&quot;&gt;Venue &amp;amp; Lodging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#lightningtalks&quot;&gt;Lightning Talks (submit one, still open)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#geektrain&quot;&gt;Geek Train&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://dotnetfringe.org/#tickets&quot;&gt;Tickets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Node.js Patterns - From Callbacks to Observer by Azat Mardan</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-azat-mardan/</link>
      <pubDate>Tue, 14 Jun 2016 19:35:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-azat-mardan/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-azat-mardan/azat.jpg&quot; alt=&quot;Azat Mardan&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Introducing Azat Mardan!&lt;/p&gt;
&lt;p&gt;Azat is author of many JavaScript and Node.js best sellers including &lt;em&gt;Practical Node.js&lt;/em&gt;, &lt;em&gt;Pro Express.js&lt;/em&gt; and &lt;em&gt;Rapid Prototyping with JS&lt;/em&gt;. He works as a Technology Fellow at Capital One Financial Corporation where he provides expertise in software engineering.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This presentation is for you, if you’re a JavaScript engineer who is interested in deepening your understanding of Node.js patterns so you can create and design Node.js applications intelligently. With the right pattern, applications will be more scalable and easier to maintain. If you aspire one day to become a Node.js architect (or maybe you’re already one and want to extend your knowledge), this presentation is for you.&lt;/p&gt;
&lt;p&gt;You will learn from this talk:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Starting with basic: what is event loop and callback: setTimeout(), setImmediate() and process.nextTick()&lt;/li&gt;
&lt;li&gt;The observer pattern with EventEmitter&lt;/li&gt;
&lt;li&gt;Middleware pattern&lt;/li&gt;
&lt;li&gt;Module patterns: module.exports et al&lt;/li&gt;
&lt;li&gt;Hacking object prototype and global refs&lt;/li&gt;
&lt;li&gt;Factory pattern and pseudo-classical inheritance&lt;/li&gt;
&lt;li&gt;Async patterns: Async, NeoAsync, async await, generators and Promises&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more work and links form Azat, check out these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://webapplog.com&quot;&gt;http://webapplog.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Company: &lt;a href=&quot;http://capitalone.io&quot;&gt;http://capitalone.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/azat-co&quot;&gt;http://github.com/azat-co&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Books: &lt;a href=&quot;http://webapplog.com/books&quot;&gt;http://webapplog.com/books&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Other links: &lt;a href=&quot;http://azat.co&quot;&gt;http://azat.co&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Working With Google Compute Engine (GCE) using Terraform (With a load of Bash Scripts too)</title>
      <link>http://adron.github.io/articles/working-with-google-compute-engine/</link>
      <pubDate>Sun, 12 Jun 2016 15:54:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/working-with-google-compute-engine/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;strong&gt;Mission:&lt;/strong&gt; I wanted to setup an instance, that I could install various things on and prepare it to act as a Terraformer or central server within GCE to spawn instances, setup networks, and generally manage the network autonomously of any local scripts or junk I have on my local computer. To set this up, I would of course have to launch it from my local computer, so there’s a whole range of things I’d need to have execute. To accomplish this, here’s what I did.&lt;/p&gt;
&lt;h2 id=&quot;first-steps-google-compute-engine&quot;&gt;First Steps: Google Compute Engine&lt;/h2&gt;
&lt;p&gt;First I logged in and setup a GCE Account (&lt;a href=&quot;https://cloud.google.com/compute/docs/quickstart&quot;&gt;read specifically about creating and getting started with a GCE account&lt;/a&gt;) and got &lt;em&gt;gcloud&lt;/em&gt; configured. The &lt;em&gt;gcloud&lt;/em&gt; is a cli to manage GCE. It’s actually a super powerful tool that comes in handy for all sorts of things. Besides managing GCE, it has a thin wrapper around &lt;a href=&quot;https://en.wikipedia.org/wiki/Secure_Shell&quot;&gt;ssh&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Secure_copy&quot;&gt;scp&lt;/a&gt;, and working with servers with those respective tools. I’ll use it a bit later to actually run some scripts against the instance I’ll be creating.&lt;/p&gt;
&lt;p&gt;Once you’ve signed up for GCE there’s a few things worth noting. One is the idea of the &lt;em&gt;project&lt;/em&gt; that Google uses within GCE. This is something you’re create, or rename the default, or in some way bring into existence to use. A &lt;em&gt;project&lt;/em&gt; is something that a host of instances, instance groups, load balancers, networks, networking, and more can be allocated against. It’s also something that can be setup for or inside a specific billing group. It might also be helpful to really get an understanding of what a &lt;em&gt;project&lt;/em&gt; is by reading the &lt;a href=&quot;https://cloud.google.com/compute/docs/projects&quot;&gt;Google documentation on &lt;em&gt;projects&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Once the project is ready, we can move forward with installing &lt;em&gt;gcloud&lt;/em&gt;. The way this is done is by installing the Google Cloud SDK. The curl below pulls down and executes the installation. Then the following command restarts the shell. Finally the gcloud init command kicks off the initialization of the gcloud cli.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;curl https://sdk.cloud.google.com | bash
exec -l $SHELL
gcloud init
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running gcloud init does several things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Authenticates the user (or allows re-use of saved credentials).&lt;/li&gt;
&lt;li&gt;Requests the user’s project &amp;amp; saves it in the gcloud configuration.&lt;/li&gt;
&lt;li&gt;Requests and sets a default zone based on the project in the gcloud configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point gcloud is setup for use, however upon connecting for the first time to an instance, gcloud will prompt to create a new ssh key set. This key set will be created and autonomous of the key set I have setup for git or other cli ssh tooling I’ll use. I’ll talk more about that later. NOTE: It is very important for subsequent steps to insure the gcloud ssh key is generated. I’ll get around to that in a moment under the “&lt;a href=&quot;#gcloudterraform&quot;&gt;&lt;em&gt;User gcloud w/ Terraform&lt;/em&gt;&lt;/a&gt;“ section.&lt;/p&gt;
&lt;p&gt;The specific instructions for setting up &lt;em&gt;gcloud&lt;/em&gt; are also available here in &lt;a href=&quot;https://cloud.google.com/sdk/&quot;&gt;getting started with the Google Cloud SDK&lt;/a&gt;. This includes a little more description of what is included and related information about the Google Cloud SDK.&lt;/p&gt;
&lt;h3 id=&quot;gcloudterraform&quot;&gt;Using gcloud w/ Terraform&lt;/h3&gt;

&lt;p&gt;When building Terraform configurations for Google Cloud there are a number of settings that &lt;em&gt;gcloud&lt;/em&gt; can pull up very easily. Here are some of the commands I’ve used most frequently when setting up google compute instances.&lt;/p&gt;
&lt;p&gt;List machine types in a project in table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List the URIs of all machine types in a project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list --uri
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all machine types in the us-central1-b and europe-west1-d zones.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list --zones us-central1-b europe-west1-d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all images in a project in table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List all the URI images in a project.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list --uri
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last thing is connecting to instances, with &lt;em&gt;gcloud&lt;/em&gt; looks like the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute --project &amp;quot;project-name&amp;quot; ssh --zone &amp;quot;us-central1-b&amp;quot; &amp;quot;instance-name&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’s some super useful ways to execute commands with the &lt;em&gt;gcloud&lt;/em&gt; cli, which provides a great way for bash scripting against instances.&lt;/p&gt;
&lt;p&gt;These all provide quick ways to get the specific GCE specific settings for the Terraform file. Which brings up a perfect point to get into a basic Terraform instance creation.&lt;/p&gt;
&lt;h2 id=&quot;next-terraforming-with-terraform&quot;&gt;Next: Terraforming with Terraform&lt;/h2&gt;
&lt;p&gt;If you don’t have &lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt; installed, the following bash commands will get you all setup on your machine. With this script below I can wrap this up as an installation script for the instance further along in this how-to. We’ll just have to tweak it specifically for Linux, as this script is focused around downloading and installing the Darwin (OS-X) version.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;cd /home/adron

# Create a move into directory.
mkdir terraform_0_6_14
cd terraform_0_6_14

# Download.
curl -O https://releases.hashicorp.com/terraform/0.6.14/terraform_0.6.14_darwin_amd64.zip
# Unzip and install
unzip terraform_0.6.14_darwin_amd64.zip

export PATH=/home/terraform_0_6_14:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To confirm that Terraform is installed correctly, just type terraform. The following should be displayed, which will let you know that the path variable is set to the correct path.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ terraform
usage: terraform [--version] [--help] &amp;lt;command&amp;gt; [&amp;lt;args&amp;gt;]

Available commands are:
    apply       Builds or changes infrastructure
    destroy     Destroy Terraform-managed infrastructure
    get         Download and install modules for the configuration
    graph       Create a visual graph of Terraform resources
    init        Initializes Terraform configuration from a module
    output      Read an output from a state file
    plan        Generate and show an execution plan
    push        Upload this Terraform module to Atlas to run
    refresh     Update local state file against real resources
    remote      Configure remote state storage
    show        Inspect Terraform state or plan
    taint       Manually mark a resource for recreation
    untaint     Manually unmark a resource as tainted
    validate    Validates the Terraform files
    version     Prints the Terraform version
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may also want to add the PATH to the ~/.bash_profile on your own OS-X machine, like I did. Instead of that last bit of script that just exports the PATH variable, I swapped it out with the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;echo &amp;quot;
export PATH=/home/terraform_0_6_14:$PATH
&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes, the odd spacing and new lines are important, because that will append the export to PATH in a way that provides space before and below the line. It just leaves the ~/.bash_profile file looking a little cleaner.&lt;/p&gt;
&lt;p&gt;Once you’ve added it to your ~/.bash_profile, remember to either restart the terminal or source the file to get the PATH variable updated.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next thing we’ll need for Terraform use with GCE is the &lt;em&gt;account.json&lt;/em&gt; file. This is the file that a service account sets up to secure our connection between GCE and Terraform.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/user_accountjson_001.png&quot; alt=&quot;Account JSON Permissions&quot;&gt;&lt;/p&gt;
&lt;p&gt;Navigate to the Permissions section of the GCE interface and add a service account. When you click to create a service account you’ll be prompted with the following.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/user_accountjson_002.png&quot; alt=&quot;Furnish Account JSON&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here check the “Furnish a new private key” and click on the JSON for the key type. Then create create. This will create the service account and the key will download locally. The key is not named account.json, but the file downloaded is what to use as the account.json file, it just needs renamed.&lt;/p&gt;
&lt;p&gt;Now we’re ready to get into actually putting together an infrastructure project. Let’s start with a basic setup. First I need the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;account.json&lt;/li&gt;
&lt;li&gt;theterraformfile.tf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are needed files and will get a terraform workflow started, but I break them out a bit more. Terraform files after all are all collected and then processed, so the configuration doesn’t have to all be in a single file.&lt;/p&gt;
&lt;p&gt;What I have been doing lately, is take the terraform file and break it out accordingly. For the connection I create a connection.tf file, for configuration around instances I create an instances.tf file, for network addresses (static IPs) that goes in an addresses.tf file. If any of those files get to big within a project I break those out further like instance-instancename1.tf and instance-instancename2.tf.&lt;/p&gt;
&lt;p&gt;With that practice applied, I end up with a project with the following files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;account.json&lt;/li&gt;
&lt;li&gt;instances.tf&lt;/li&gt;
&lt;li&gt;addresses.tf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I then run git init and add two more files.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;.gitignore&lt;/li&gt;
&lt;li&gt;README.md&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These have no relevance to the actual Terraform files, but they’re standard practice and come in very helpful once the project starts to grow. You’ll want a README.md for notes and documentation and you’ll definitely want to keep trash out of the project with the .gitignore, so even though they’re not required right now, if you’re following along add the files.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&quot;https://github.com/Adron/starting-with-gce/blob/master/README.md&quot;&gt;README.md&lt;/a&gt;, of course, we write our documentation! So anyway, it’ll be there in the &lt;a href=&quot;https://github.com/Adron/starting-with-gce&quot;&gt;repo&lt;/a&gt; I’ve created for this blog entry here.&lt;/p&gt;
&lt;p&gt;In the .gitignore file add the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;.DS_Store
account.json
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the connection.tf file I added the following connection information. The ${file(“../secrets/account.json”)} configuration interpolates the path of the file based on where the project is located and pulls in the appropriate values for GCE.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# Configure the Google Cloud provider
provider &amp;quot;google&amp;quot; {
  credentials = &amp;quot;${file(&amp;quot;account.json&amp;quot;)}&amp;quot;
  project     = &amp;quot;that-big-universe&amp;quot;
  region      = &amp;quot;us-central1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that in place, I added this to the instances.tf file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# Create a new instance
resource &amp;quot;google_compute_instance&amp;quot; &amp;quot;flirpderp&amp;quot; {
    name = &amp;quot;flirpderp&amp;quot;
    machine_type = &amp;quot;f1-micro&amp;quot;

    zone = &amp;quot;us-central1-b&amp;quot;

    disk {
        image = &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
    }

    network_interface {
        network = &amp;quot;default&amp;quot;
        access_config {}
    }

    service_account {
        scopes = [&amp;quot;userinfo-email&amp;quot;, &amp;quot;compute-ro&amp;quot;, &amp;quot;storage-ro&amp;quot;]
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the machine_type and disk image above I just used the following gcloud commands.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute machine-types list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;gcloud compute images list
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this first build, I just wanted to get a basic template with a small (and by association super cheap) instance. For this I went with &lt;em&gt;f1-micro&lt;/em&gt;. For the disk, I used the base disk image load of the &lt;em&gt;ubuntu-1404-trusty-v20160406&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;All configuration set, I opened up a bash terminal and typed in the following.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform plan
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command then displayed the following result.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Refreshing Terraform state prior to plan...

The Terraform execution plan has been generated and is shown below.
Resources are shown in alphabetical order for quick scanning. Green resources
will be created (or destroyed and then created if an existing resource
exists), yellow resources are being changed in-place, and red resources
will be destroyed.

Note: You didn&amp;#39;t specify an &amp;quot;-out&amp;quot; parameter to save this plan, so when
&amp;quot;apply&amp;quot; is called, Terraform can&amp;#39;t guarantee this is what will execute.

+ google_compute_instance.flirpderp
    can_ip_forward:                                      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;0&amp;quot;
    disk.#:                                              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    disk.0.auto_delete:                                  &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    disk.0.image:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
    machine_type:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;f1-micro&amp;quot;
    metadata_fingerprint:                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    name:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;flirpderp&amp;quot;
    network_interface.#:                                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    network_interface.0.access_config.#:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    network_interface.0.access_config.0.assigned_nat_ip: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.address:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.name:                            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    network_interface.0.network:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;default&amp;quot;
    self_link:                                           &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    service_account.#:                                   &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
    service_account.0.email:                             &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    service_account.0.scopes.#:                          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;3&amp;quot;
    service_account.0.scopes.1632638332:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;
    service_account.0.scopes.2428168921:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/userinfo.email&amp;quot;
    service_account.0.scopes.2862113455:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/compute.readonly&amp;quot;
    tags_fingerprint:                                    &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
    zone:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;us-central1-b&amp;quot;

Plan: 1 to add, 0 to change, 0 to destroy.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s walk through this result to get an idea of what just happened. Terraform has taken all of the Terraform files, which currently is only one file with actual configuration in it, and processed them to create a plan of changes. At the very bottom of the results the line “Plan: 1 to add, 0 to change, 0 to destroy.” simple shows what will occur if I were to apply these changes. Many of the values are also set as which simply means that when processed they’ll be calculated and set. Otherwise most of the other values are simply the settings I’ve put in via the actual Terraform configuration files.&lt;/p&gt;
&lt;p&gt;Now I applied the configuration.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform apply
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of this command will display as shown.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;google_compute_instance.flirpderp: Creating...
  can_ip_forward:                                      &amp;quot;&amp;quot; =&amp;gt; &amp;quot;0&amp;quot;
  disk.#:                                              &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  disk.0.auto_delete:                                  &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  disk.0.image:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;ubuntu-1404-trusty-v20160406&amp;quot;
  machine_type:                                        &amp;quot;&amp;quot; =&amp;gt; &amp;quot;f1-micro&amp;quot;
  metadata_fingerprint:                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  name:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;flirpderp&amp;quot;
  network_interface.#:                                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  network_interface.0.access_config.#:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  network_interface.0.access_config.0.assigned_nat_ip: &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.address:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.name:                            &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  network_interface.0.network:                         &amp;quot;&amp;quot; =&amp;gt; &amp;quot;default&amp;quot;
  self_link:                                           &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  service_account.#:                                   &amp;quot;&amp;quot; =&amp;gt; &amp;quot;1&amp;quot;
  service_account.0.email:                             &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  service_account.0.scopes.#:                          &amp;quot;&amp;quot; =&amp;gt; &amp;quot;3&amp;quot;
  service_account.0.scopes.1632638332:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/devstorage.read_only&amp;quot;
  service_account.0.scopes.2428168921:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/userinfo.email&amp;quot;
  service_account.0.scopes.2862113455:                 &amp;quot;&amp;quot; =&amp;gt; &amp;quot;https://www.googleapis.com/auth/compute.readonly&amp;quot;
  tags_fingerprint:                                    &amp;quot;&amp;quot; =&amp;gt; &amp;quot;&amp;lt;computed&amp;gt;&amp;quot;
  zone:                                                &amp;quot;&amp;quot; =&amp;gt; &amp;quot;us-central1-b&amp;quot;
google_compute_instance.flirpderp: Creation complete

Apply complete! Resources: 1 added, 0 changed, 0 destroyed.

The state of your infrastructure has been saved to the path
below. This state is required to modify and destroy your
infrastructure, so keep it safe. To inspect the complete state
use the `terraform show` command.

State path: terraform.tfstate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I logged in at this point to verify the creation of the instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/working-with-google-compute-engine/flirpderp.png&quot; alt=&quot;Google Cloud Interface&quot;&gt;&lt;/p&gt;
&lt;p&gt;In the interface the instance (or instances if I have multiple) shows up in a list underneath the fancy CPU utilization chart.&lt;/p&gt;
&lt;h3 id=&quot;cleanup&quot;&gt;Cleanup&lt;/h3&gt;
&lt;p&gt;Since I don’t actually want this instance to stay live currently, to destroy the instance I can use the terraform destroy command. If there were other instances in this set of Terraform configuraiton files, it would also destroy those too. Destroy, suffice to say is something that is very destructive and should be used carefully. For this example I’m going to destroy this instance now, but since I have the configuration I’ll add a little bit more to it and recreate it shortly.&lt;/p&gt;
&lt;p&gt;I issue this command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;terraform destroy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This displays…&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;Do you really want to destroy?
  Terraform will delete all your managed infrastructure.
  There is no undo. Only &amp;#39;yes&amp;#39; will be accepted to confirm.

  Enter a value: yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I confirm by typing ‘yes’ and then the following result of this acction is returned.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;google_compute_instance.flirpderp: Refreshing state... (ID: flirpderp)
google_compute_instance.flirpderp: Destroying...
google_compute_instance.flirpderp: Destruction complete

Apply complete! Resources: 0 added, 0 changed, 1 destroyed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, it’s pretty cool that I can build a single instance, but that’s of extremely limited use if I can’t get it deployed out into GCE in a usable state. The most common ways I’d want to wrap up configuration and installation of software on an instance is to issue some bash commands to the instance. Well, Terraform has ways that exactly that can be done. I’ll cover that in the follow up to this article.&lt;/p&gt;
&lt;h3 id=&quot;references-&quot;&gt;References:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/starting-with-gce/tree/blog-entry-01&quot;&gt;The Github Repository branch for this blog entry.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Startup Things - How Ya Linux Series - 0000</title>
      <link>http://adron.github.io/articles/how-ya-linux-0000-Startup-things/</link>
      <pubDate>Sat, 11 Jun 2016 15:35:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/how-ya-linux-0000-Startup-things/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/how-ya-linux-0000-Startup-things/penguinbash.jpg&quot; alt=&quot;Penguin Bash&quot;&gt;
&lt;/div&gt;

&lt;p&gt;When Linux starts up (or most Unix variants or OS-X for that matter, which is after all a kind of Unix variant) there are particular scrips that execute. The key two are ~/.bash_profile and ~./bashrc. When you log in the ~/.bash_profile executes and when you startup a shell then the ~/.bashrc executes.&lt;/p&gt;
&lt;p&gt;These two files are standard executable script files, so any bash will do. For instance, some of the bash script I end up in my ~/.bash_profile includes a git prompt, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if [ -f &amp;quot;$(brew --prefix)/opt/bash-git-prompt/share/gitprompt.sh&amp;quot; ]; then
    source &amp;quot;$(brew --prefix)/opt/bash-git-prompt/share/gitprompt.sh&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Another few lines of code actually load my nvm, which is my Node.js Version Manager.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export NVM_DIR=&amp;quot;/Users/axh6454/.nvm&amp;quot;
[ -s &amp;quot;$NVM_DIR/nvm.sh&amp;quot; ] &amp;amp;&amp;amp; . &amp;quot;$NVM_DIR/nvm.sh&amp;quot;  # This loads nvm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also have a few functions I’ve created, that load and are ready for my use at  any location I open the terminal at.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker() { if [ $1 ]; then
    docker-machine start $1
    docker-machine env $1
    eval $(docker-machine env $1)
    docker ps -a
fi };

cleandocker() {
    # Wipe out the images and containers.
    docker rm $(docker ps -a -q)
    docker rmi $(docker images -q)
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The first function executes simply by entering &lt;code&gt;gimme docker nameOfDockerVirtualMachineImage&lt;/code&gt;. It then checks for the virtual machine image parameter (the $1) and then executes various docker-machine commands against that image. Then ends with the evaluation and execution of the docker machine terminal connection.&lt;/p&gt;
&lt;p&gt;The second function deletes my docker containers and then deletes my images. This way I can start fresh without deleting an entire docker virtual machine (sometimes the later may actually be easier). It’s a quick way to start fresh with docker images and containers when working through a lot of minor changes.&lt;/p&gt;
&lt;p&gt;The last thing I’ll cover real quick that is commonly located in these startup scripts are some environment variables being set. For instance, I use Terraform to build out infrastructure. For that, sometimes I setup some Terraform variables, that are built to work specifically when prefaced with TF&lt;em&gt;VAR&lt;/em&gt;. So my variables look something like this when set in script.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export TF_VAR_username=&amp;quot;root&amp;quot;
export TF_VAR_password=&amp;quot;someSecretPassword&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So that’s some examples and the basic gist of things you might see, and what you might want to run with your ~/.bash_profile or ~/.bashrc files. Happy bash hacking!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Short Story of Node PDX, and Node PDX 2016</title>
      <link>http://adron.github.io/articles/node-pdx-2016/</link>
      <pubDate>Wed, 08 Jun 2016 14:30:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016/</guid>
      <author></author>
      <description>&lt;p&gt;Some of you may know the story, but I’ll tell it again for those that don’t. In 2012 Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37&quot;&gt;@thoward37&lt;/a&gt;) and I were sitting at the Side Door hacking on some project code. We started talking about where and what was up with the Node.js project, community, and asking ourselves what the future of that was. You see, we’d toyed about with the technology here and there but we hadn’t really done anything with it.&lt;/p&gt;
&lt;p&gt;We continued our coding, enjoying a tasty locally brewed beer, frothy and good. After a reasonable amount of said tasty beer, we started discussing a way to get up to speed faster on Node.js. In our infinitely wise and slightly intoxicated minds we both thought, “Hey, let’s throw a conference!”. We immediately started discussing this idea and a number of decisions were made…&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;inception-by-conversation&quot;&gt;Inception by Conversation&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Oh man, we should do exactly that, let’s have a conference! It’ll be super easy to ramp up if we just get a bunch of smart Node.js people together.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yeah, and it’d be a total blast. There are a number of smart people working in this space.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Let’s!”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yes.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Cheers!”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Cheers!”&lt;/p&gt;
&lt;p&gt;Beer drinking. So there we sat, and we began, the dilligent decision making at what was obviously the perfect time to make decisions about a conference!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Have you ever organized anything like this before?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Naw. You?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Ummm, nope.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “What seems like a reasonable timespan to get this put together?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; … sip, sip, sip, big drink. “Hmmm, I don’t know, 4 or 5 weeks, maybe 4?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Meh, sounds good.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Cool, so we’ll have it in about 5 weeks.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Yup.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “How many days, speakers and such?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Troy&lt;/strong&gt;&lt;/strong&gt; “Let’s go for two days and we’ll just do one track.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Done and done.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;(Ok, it might have been slightly different, but this is the gist of it.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In that moment of infinite wisdom we began the journey to create and organize our first conference. It thoroughly kicked our ass but was super fun.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/nodepdx-logo-2012.png&quot; alt=&quot;Node PDX 2012&quot;&gt;
&lt;/div&gt;

&lt;p&gt;We also learned some very key things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Organizing an inclusive conference is both easy and ridiculously stressful and difficult.&lt;/li&gt;
&lt;li&gt;Organizing a conference with 4-5 weeks before the date is batshit insane.&lt;/li&gt;
&lt;li&gt;Making decisions about organizing something one has never organized is probably not the best thing to do after coding for hours on end and maybe one to many beers.&lt;/li&gt;
&lt;li&gt;Community focused and grassroots organized conferences are really fun and arguably more educational than that corporate shit shill.&lt;/li&gt;
&lt;li&gt;Organizing volunteers and speakers is not actually easy at all.&lt;/li&gt;
&lt;li&gt;Non-profit incoroporation, actually any type of corporation is very poorly organized for this type of event. Either way, it adds a financial burden just for undertaking such an enterprise.&lt;/li&gt;
&lt;li&gt;One can actually learn a lot at a conference, but the people contacts are vastly more important.&lt;/li&gt;
&lt;li&gt;One can actually not learn a whole lot if actually organizing the conference, yet this first year we managed to do both learning and connecting with many of the great attendees of the conference.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/NodePDX-2012-site.png&quot; alt=&quot;Node PDX 2012 Site&quot;&gt;
&lt;/div&gt;

&lt;p&gt;So this basically summarizes year one of Node PDX. That was &lt;a href=&quot;http://2012.nodepdx.org/&quot;&gt;Node PDX 2012&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;node-pdx-2013&quot;&gt;Node PDX 2013&lt;/h2&gt;
&lt;p&gt;Node PDX 2013 started off a bit differently. We gave ourselves more runway to work with. I believe initially it was at least several months. We also gave ourselves plenty of resources to work with and incorporated anyway, which still is a complete discouragement from actually doing these things.&lt;/p&gt;
&lt;p&gt;Troy also did effectively all of the graphic design, which I might add, turned out pretty rad! Check it out for a trip down memory lane at the &lt;a href=&quot;http://2013.nodepdx.org/&quot;&gt;archive site&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/NodePDX-2013.png&quot; alt=&quot;Node PDX 2013&quot;&gt;
&lt;/div&gt;

&lt;p&gt;We got the ball rolling and Node PDX 2013 was a huge hit. We had involvement from all sorts of sponsors from great companies like &lt;a href=&quot;https://newrelic.com/&quot;&gt;New Relic&lt;/a&gt;, &lt;a href=&quot;https://www.urbanairship.com/&quot;&gt;Urban Airship&lt;/a&gt;, &lt;a href=&quot;https://liftsecurity.io/&quot;&gt;^lift&lt;/a&gt;, &lt;a href=&quot;https://www.mozilla.org/en-US/&quot;&gt;Mozilla&lt;/a&gt;, &lt;a href=&quot;https://www.jivesoftware.com/&quot;&gt;Jive&lt;/a&gt;, &lt;a href=&quot;http://www.janrain.com/&quot;&gt;Janrain&lt;/a&gt;, &lt;a href=&quot;http://www.walmartlabs.com/&quot;&gt;Walmart Labs&lt;/a&gt;, &lt;a href=&quot;http://www.piepdx.com/&quot;&gt;PIE PDX&lt;/a&gt;, &lt;a href=&quot;http://basho.com/&quot;&gt;Basho&lt;/a&gt;, &lt;a href=&quot;https://www.stickermule.com/&quot;&gt;Sticker Mule&lt;/a&gt;, &lt;a href=&quot;http://siliconflorist.com/&quot;&gt;Silicon Florist&lt;/a&gt;, and &lt;a href=&quot;http://devion.com/&quot;&gt;Devion&lt;/a&gt;. We also had a great speaker line up, had excellent local food, great freshly brewed &amp;amp; roasted coffee, and lots more. I even got hit in the head with a quad-copter! It was absolutely a superb time. &lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016/burnout.jpg&quot; alt=&quot;Conference Burnout&quot;&gt;
&lt;/div&gt;

&lt;h2 id=&quot;conference-burnout&quot;&gt;Conference Burnout&lt;/h2&gt;
&lt;p&gt;After 2013 Troy and I had a case of the burnouts kick us. He went the route of just organizing more conferences, I however went the route of not organizing any conferences, or much of anything for a while.&lt;/p&gt;
&lt;p&gt;This however lasted over a year for me, I started working on some projects, co-founded a startup, worked to raise capital with the team, built a product, ran out of money, spent most of 2015 not working, produced some training material and a lot more. Basically I was working on anything that involved not working on conference (or meetup) organizing.&lt;/p&gt;
&lt;h2 id=&quot;2016-hits-and-energy-returns&quot;&gt;2016 Hits and Energy Returns&lt;/h2&gt;
&lt;p&gt;At this point I’d had a significant amount of time off. I’d also managed to spend time in Europe, recover from my doldrums, get married to a most amazing an awesome person, and felt maybe I’d dive into some conference organizing again. I’d missed Node PDX &amp;amp; the comraderie and learning it brought. With that deduction I struck up another conversation to see if Troy was interested in organizing another Node PDX. I think it went something like this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Hey Troy, wanna run another Node PDX?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Maybe.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Let’s grab some coffee and discuss.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Alright. Should we meet at…” at this point we spend 45 minutes discussing where we should meet for coffee.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We then departed our respective locations to meet at a coffee shop somewhere in Portland. We then met and started talking about, as we often do, everything except what we were going to talk about. Then, as if spuriously interupted,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Adron&lt;/em&gt;&lt;/strong&gt; “Hey Troy, wanna run another Node PDX?”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Troy&lt;/em&gt;&lt;/strong&gt; “Ok.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So here we are now, with just 11 days to go before another Node PDX. We’re rounding up and finalizing the last steps of the effort right now. The speakers have been notified, we’ve gotten confirmations, and we’re getting the wheels on the bikes ready, the beer cooled off, the food prepared (ok, actually that’ll be prepared later), and psyched for the upcoming event. With that said, we’re definitely back in the groove and looking forward to this year’s event! We hope to see you there.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://nodepdx.org/#tickets&quot;&gt;Join us at Node PDX&lt;/a&gt;, enjoy a &lt;a href=&quot;http://nodepdx.org/lagniappe.html#bikes&quot;&gt;bike ride&lt;/a&gt; to see parts of Portland, and if you’re coming down from Seattle be sure to enjoy the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#geektrain&quot;&gt;$15 buck ride&lt;/a&gt; via the &lt;a href=&quot;http://www.amtrakcascades.com/&quot;&gt;Amtrak Cascades&lt;/a&gt; to Portland for the conference.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>How to Build a Bike Shed by David Manning &amp; Adam Ulvi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/</link>
      <pubDate>Tue, 07 Jun 2016 19:20:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-david-manning-adam-ulvi/davidadam.jpg&quot; alt=&quot;David Manning &amp;amp; Team&quot;&gt;
&lt;/div&gt;

&lt;p&gt;This is a very Portland, very unique to Node PDX talk, by Adam and David who work at ZHealth Documentation and have opinions about things.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Nuff’ said eh!&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Despite having no formal construction experience, Adam and David have been tasked with designing a new bike shed outside of the Olympic Mills Commerce Center. They have spent long hours in extensive research, and are excited to share their results with the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Attendees will receive plans and a Starter Kit of building materials.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For more important information about what a bike is, what a shed is, and how these two things combined make bike sheds, check out this useful links.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bikes: &lt;a href=&quot;https://en.wikipedia.org/wiki/Bicycle&quot;&gt;https://en.wikipedia.org/wiki/Bicycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Sheds: &lt;a href=&quot;https://en.wikipedia.org/wiki/Shed&quot;&gt;https://en.wikipedia.org/wiki/Shed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bike Sheds: &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_triviality&quot;&gt;https://en.wikipedia.org/wiki/Shed#Specific-use_sheds&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Get JavaScript Running on a $2 WiFi-Enabled Device by Andrew Chalkley</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-andrew-chalkley/</link>
      <pubDate>Tue, 07 Jun 2016 11:20:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-andrew-chalkley/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-andrew-chalkley/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-andrew-chalkley/andrew.jpg&quot; alt=&quot;Andrew Chalkley&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Andrew Chalkley is a full-time teacher at online education provider Treehouse. He’s a polyglot programmer with a passion for hardware. Andrew’s posts on the hardware platform Arduino have been featured in Hacker Monthly and used in higher educational institutions around the world. He’s also lectured at University on JavaScript and the Internet of Things.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The ESP8266 is a very popular Internet of Things device, because of it’s price and availability. You can program it with Arduino, Python and even JavaScript. Using JavaScript on a small device doesn’t have to be difficult. Andrew will show you the easiest way to install JavaScript on am Internet of Things device and how to run your JavaScript applications on it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://forefront.io&quot;&gt;http://forefront.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Company: &lt;a href=&quot;http://teamtreehouse.com&quot;&gt;http://teamtreehouse.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/chalkers&quot;&gt;http://github.com/chalkers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Flasher.js: &lt;a href=&quot;http://github.com/thingssdk/flasher.js&quot;&gt;http://github.com/thingssdk/flasher.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Demystifying TypeScript Decorators by James Churchill</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-james-churchill/</link>
      <pubDate>Mon, 06 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-james-churchill/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-james-churchill/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-james-churchill/james-churchill-nyc.jpg&quot; alt=&quot;James Churchill&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Portlander James has worked extensively with a variety of technologies, including ASP.NET MVC, SQL Server, JavaScript, TypeScript, Knockout.js, and AngularJS. James, a self-confessed geek, enjoys talking about programming and learning new technologies. He recently joined the Treehouse team as a teacher and is excited to have the opportunity to help beginners become developers.&lt;/p&gt;
&lt;p&gt;James also enjoys participating in the greater Cascadian Developer Community, presenting talks in Portland, Seattle, Salt Lake City, Boise, Eugene, Salem, and Hood River. Last April, James started and co-organized the Portland TypeScript Meetup (&lt;a href=&quot;http://typescriptpdx.com/&quot;&gt;http://typescriptpdx.com/&lt;/a&gt; which is an awesome meetup, come check it out sometime!).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When he is not working, he can be found skiing with his wife and kids, remodeling the house, playing music with his band, or hanging out in the yard with his chickens.&lt;/p&gt;
&lt;p&gt;In “Demystifying TypeScript Decorators” will show us TypeScript decorators, based on the ES2016 decorator proposal and introduced as part of TypeScript 1.5, provide developers with a way to modify a JavaScript class, property, method, or method parameter using a convenient declarative syntax. We’ll start this session by creating our own decorator, to see firsthand how they work. Then, we’ll take a look at how decorators can be used in a variety of settings.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Blog: &lt;a href=&quot;http://smashdev.com&quot;&gt;http://smashdev.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/smashdevcode&quot;&gt;http://github.com/smashdevcode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;http://twitter.com/SmashDev&quot;&gt;http://twitter.com/SmashDev&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>How to Electron by Blaine Schmeisser</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-blaine-schmeisser/</link>
      <pubDate>Mon, 06 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-blaine-schmeisser/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-blaine-schmeisser/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-blaine-schmeisser/blainesch.jpg&quot; alt=&quot;Blaine Schmeisser&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I’m happy to introduce Blaine Schmeisser. He’s a recent Portland transplant currently working as a Senior Software Engineer at New Relic. He has a passion for building and shipping software and an advocate for pair programming. Outside of tech, Blaine spends his free time with his dog and maintains a simplistic, eco-friendly lifestyle.&lt;/p&gt;
&lt;p&gt;Blaine’s “How to Electron” answers questions you have about building user interface applications with JavaScript. Have you ever wanted to build desktop apps with web technology you already know? If you’ve never heard of Electron or just want to learn more about it, this talk will cover what Electron is and how to utilize it to create powerful tools like Atom and Slack. You will learn the history of Electron, how to get started, the trade-offs of picking various boiler plates, and the unique Electron specific APIs that are vital to being a Electron developer.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&quot;https://github.com/blainesch&quot;&gt;https://github.com/blainesch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;https://twitter.com/blainesch&quot;&gt;https://twitter.com/blainesch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Website: &lt;a href=&quot;http://blainesch.com&quot;&gt;http://blainesch.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Modern Javascript Frameworks - Introduction to Ember.JS and Ember-CLI by Suchita Doshi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-suchita-doshi/</link>
      <pubDate>Sun, 05 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-suchita-doshi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-suchita-doshi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-suchita-doshi/suchita-doshi.jpg&quot; alt=&quot;Suchita Doshi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Suchita is UI Lead for the analytics module of Yahoo Admanager Plus team and Core member of Emberjs group @Yahoo, Speaker at Women Who code organization (Introduction To Emberjs/Ember CLI), Conducted Webinar for the TenXList members on EmberJS. She’s passionate about improving developers ergonomics and a hardcore “cricket” fan.&lt;/p&gt;
&lt;p&gt;In other Suchita news, she’s opening bats-woman for the Bay Area Cricket Association team! 😀&lt;/p&gt;
&lt;p&gt;Suchita describes her talk as “There will never be a “one size fits all” approach to web development. If you want your application to be minimally interactive, then server side rendered HTML would be the way to go, else, if it were a more interactive application, then client side framework would benefit you.
Why not use just JQuery instead of adopting these Modern Javascript Frameworks? Think about it! If your application has interactivity on the lighter side, then JQuery would work well, but as soon as you introduce more states in your application, it would then become messier and heavier on the DOM. You would need to use the ‘data-‘ attributes to store the data in your DOM and also remember how to map them with the triggered events.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here is where client side frameworks come to the rescue. I have worked on several client side frameworks like Backbone.js, Ember.js. Few of the many features I love about Ember.js are the two-way data binding, Computed Properties, the run loop, convention over configuration nature, ease of handling routing and many more.
In this talk I would be covering the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to Emberjs and why Ember&lt;/li&gt;
&lt;li&gt;How Ember js makes a difference&lt;/li&gt;
&lt;li&gt;Ember convention over configuration nature&lt;/li&gt;
&lt;li&gt;Introduction to Ember routes, components and templates&lt;/li&gt;
&lt;li&gt;Introduction to Ember CLI&lt;/li&gt;
&lt;li&gt;Computed Properties&lt;/li&gt;
&lt;li&gt;Live Demo on how it’s really intuitive in a couple of non-trivial scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So basically my goal is to attract more developers to adapt modern javascript frameworks and make a difference in the way complex apps are built.”&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The SAM Pattern - a distributed system view of Front-End architectures by Jean-Jacques Dubray</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jean-jacques-dubray/</link>
      <pubDate>Sun, 05 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jean-jacques-dubray/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jean-jacques-dubray/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jean-jacques-dubray/jj-sized.png&quot; alt=&quot;Jean-Jacques Dubray&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jean-Jacques Dubray is the founder of &lt;a href=&quot;http://xgen.io&quot;&gt;xgen.io&lt;/a&gt; and &lt;a href=&quot;http://www.gliiph.com&quot;&gt;gliiph&lt;/a&gt;. He has been building Service Oriented Architectures,
and API platforms for the last 15 years. He is a former member of the research staff at HRL and earned his Ph.D. from
the University of Provence (Luminy campus), home of the Prolog language. He is the inventor of the &lt;a href=&quot;http://www.xgenio.com/bolt-introduction.pdf&quot;&gt;BOLT methodology&lt;/a&gt; and the SAM pattern.&lt;/p&gt;
&lt;p&gt;In his talk Jean-Jacques Dubray presents that Web Applications are rapidly becoming sophisticated distributed systems. When you look at a Facebook page or a Netflix catalog,
the number of components interacting with each other requires complex synchronization and state management capabilities, reaching
the limits of the MVC pattern.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the last couple of years, several reactive architectures have started to get some interest (React, Cycle.js, ELM) without
generating significant traction (compared to established frameworks like Angular), while struggling to position effects in their
programming model. A new reactive, functional pattern, the State-Action-Model pattern (SAM) was introduced in early 2016 on the
foundation of TLA+ semantics.&lt;/p&gt;
&lt;p&gt;The pattern, which is unapologetically driven by simplicity, promotes a clear delineation between the business logic and the view
and challenges the complexity of frameworks like Google’s Angular or Facebook’s React/Redux.&lt;/p&gt;
&lt;p&gt;SAM’s unidirectional flow is also challenging interactive patterns like BFF (Back-End for Front-End) or the Vertical Slice Pattern
which suggest creating view-specific APIs, per platform, app, versions of an app…&lt;/p&gt;
&lt;p&gt;We’ll start by reviewing some of the key challenges of modern UX and Front-End Architectures. We will then present the
key concepts of SAM and walk the audience through some node.js code samples (including server-side TimeTravel).&lt;/p&gt;
</description>
    </item>
    <item>
      <title>MMOWAM - Build Server-less Games with a DSN by Josh Marinacci</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-josh-marinacci/</link>
      <pubDate>Sat, 04 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-josh-marinacci/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-josh-marinacci/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-josh-marinacci/josh-marinacci.jpg&quot; alt=&quot;Josh Marinacci&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Josh is an O’Reilly author, developer advocate, and recovering engineer. He is
currently head of the developer evangelism team at PubNub. Previously he worked
as a UI researcher at Nokia, and a developer advocate at Palm and Sun. He is
passionate about user interfaces and education. Josh lives in sunny Eugene,
Oregon.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Josh will be talking about building a multiplayer casual game for fun. Well, it’s fun until you have to write a server
component to run it. Now you have to implement game matching, keeping clients in
sync, in game chat, score tracking and more. In this Josh will show you how to
use a Data Stream Network (DSN) write a game without any server at all. The
network itself can connect users, load clients, and keep everything in sync
without having to learn distributed computing programming. Josh will build and
play a MMOWAM (Massively Multiplayer Online Whack-A-Mole) game to show how easy
it can be.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;game MMOWAM (whack-a-mole)&lt;/li&gt;
&lt;li&gt;show mini version of each player on dashboard&lt;/li&gt;
&lt;li&gt;show current score / level&lt;/li&gt;
&lt;li&gt;show how much is left&lt;/li&gt;
&lt;li&gt;random number syncing to ensure everyone has the same board&lt;/li&gt;
&lt;li&gt;use a random channel w/ tiny UID to let anyone join&lt;/li&gt;
&lt;li&gt;show number of players&lt;/li&gt;
&lt;li&gt;start when 4 players in? one player hit’s start? let all player see total count as well and status of the other players&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>WebSockets Bring Light at the End of the Tunnel by Joel Lord</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-joel-lord/</link>
      <pubDate>Sat, 04 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-joel-lord/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-joel-lord/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-joel-lord/joel-lord.jpg&quot; alt=&quot;Joel Lord&quot;&gt;
&lt;/div&gt;

&lt;p&gt;As a Development Manager, Joel’s motivation and proven technical prowess makes him a key member of Spiria’s software development team. With a degree in computational astrophysics, his interests eventually made their way to software and Web design. Today, his knowledge of JavaScript lets him to support a variety of projects on both the front end and back end. As we move into the age of the Internet of Things, Joel is ready with his passion for programming node bots and experimenting with gadgets.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Joel is going to speak on Web Sockets and tunnels of light… or to describe it more specifically more and more, people seem to be obsessed with real-time data.  But what does real-time mean in the world of REST servers and one-way communication?  Most modern web applications are now either displaying a snapshot of data at a given time or use a polling mechanism to update series of data at a given interval.
In this talk, you will learn about the power of WebSockets and how they can (and should!) be used in your modern web applications. In these 30 minutes, I will go through the process of building a Node server that can push data to multiple clients in real-time.  You will see how this can be easy using the socket.io library.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>I Play the JavaScript by Matt McKegg</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-matt-mckegg/</link>
      <pubDate>Fri, 03 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-matt-mckegg/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-matt-mckegg/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-matt-mckegg/mattmckegg.jpg&quot; alt=&quot;Matt McKegg&quot;&gt;
&lt;/div&gt;

&lt;p&gt;A JavaScript hacker and backyard musician and from Wellington, New Zealand. Lover of all things open and modular. I spend most of my time pressing buttons of various shapes, sizes and colours. Sometimes these buttons make sounds.&lt;/p&gt;
&lt;p&gt;Matt has been making music with computers for about 10 years, but once he tried to move from bedroom composing to live performance, he got incredibly frustrated at how hard it was to play computer music live. He decided to start working on his own live electronic performance software written in JavaScript that would let me play the way he wanted to play. 3 years later, it’s finally starting to become a reality.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here is one of the Matt’s recent performances, for your viewing pleasure. &lt;/p&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/L2BVDJWHdy0?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>The Web Platform is the Universal Instrument by Ben Michel</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-ben-michel/</link>
      <pubDate>Fri, 03 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-ben-michel/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-ben-michel/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-ben-michel/benmichel.jpg&quot; alt=&quot;Ben Michel&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Ben Michel has a pretty epic talk scheduled for Node PDX… if you don’t know Ben he’s a Musician–Developer. He composes &amp;amp; performs live soundtracks and cares a lot about community music.&lt;/p&gt;
&lt;p&gt;The talk he has planned for you all is described as, “Music as an idea, expression, commercial endeavor, and communal art is in its most volatile state since the European Renaissance. We’ve moved from the public adoption of recording technology, through the massive rise and fall of the recording industry, to a new age that was first seeded at Bell Labs during the Computer Science era.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Max Mathews encouraged a generation of computer musicians by declaring the Nyquist-Shannon “sampling theorem shows that there are really no limits to the sounds you can make…the computer is a universal musical instrument.”&lt;/p&gt;
&lt;p&gt;Now with a fuller understanding of what Mathews was implying, we can take it a step further and say that the Browser is the universal musical instrument. It’s the most accessible, cross-compatible runtime yet–and with the growth of Web Audio and Web MIDI standardization, we’re on the verge of a new renaissance in musical collaboration and interaction.&lt;/p&gt;
&lt;p&gt;Unfortunately, the promotion of individualism in our popular culture, and the divide between developers and working artists has kept us from realizing the potential of building useful tools for distributed music collaboration, even in the web platform.&lt;/p&gt;
&lt;p&gt;Still, I can see a world coming where community music and recorded works are not identified by regional boundaries, but distributed data regions and organic peer to peer networks. If the development of Web Audio and it’s supporting standards stabilize, music collaboration and exposition could be made available to everyone with no hinderances from age, class, or personal ability.&lt;/p&gt;
&lt;p&gt;The WebSound project is my iterative solution to this problem through long-term community engagement, and Audio/MIDI tool versioning.&lt;/p&gt;
&lt;p&gt;Our first endeavor is to build a few useful live performance tools enabling remote collaboration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Real-time Web MIDI performances streamed to a live-event, enabling the performer to lead songs or compositions remotely. Achieved through an optimized VPN and P2P WebRTC DataChannels.&lt;/li&gt;
&lt;li&gt;Communally performed live music making with MIDI controlled WebAudio and WebSocket broadcasting.&lt;/li&gt;
&lt;li&gt;Audience interaction with the exposed parameters of a live band’s instrumentation–via broadcast methods and microcontroller installations.”&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Code First Docs How we Threw Out The Book &amp; Put Code First With Twilio Documentation by Jarod Reyes</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jarod-reyes/</link>
      <pubDate>Thu, 02 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jarod-reyes/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jarod-reyes/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-left&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jarod-reyes/jarodreyes.jpg&quot; alt=&quot;Jarod Reyes&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jarod is alarmingly disinterested in “how things are done”. He spent much of his grade school years disrupting class, running social experiments and singing love ballads to his teachers. Nowadays he can be found working with an exceptional team of developers at Twilio who are laser-focused on improving the landscape of developer documentation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Jarod describes Code First Docs as&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“My job at Twilio is straightforward, write documentation that doesn’t suck. This may seem fairly straightforward, but it turns out to be harder than an &lt;a href=&quot;https://c1.staticflickr.com/5/4048/4353601145_5c12467871_b.jpg&quot;&gt;Atari 2600 cartridge&lt;/a&gt;. For the last 30 years we have asked developers to do their jobs by equipping them with essentially giant books that we have adapted to the internet age by simply putting them on the web. At Twilio we weren’t satisfied with this traditional approach so we threw out the book and challenged some basic assumptions about creating documentation for developers.&lt;/p&gt;
&lt;p&gt;What is the journey of the modern developer? How does documentation fit into their flow? Are there ways to create documentation that enables developers to work smarter, as opposed to interrupting their day? We’ll discuss these questions and more as I share how we got to the realization that we needed a documentation revolution; this is the story of how we raised up code to be the supreme leader of documentation.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Twitter: &lt;a href=&quot;https://twitter.com/jreyesdev&quot;&gt;@jreyesdev&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Github: &lt;a href=&quot;https://github.com/jarodreyes&quot;&gt;github.com/jarodreyes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>The House Is Not On Fire - Building a home automation robot with Arduino, Raspberry Pi and Node.js by Artur Paikin</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-artur-paikin/</link>
      <pubDate>Thu, 02 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-artur-paikin/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-artur-paikin/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-artur-paikin/art-stida.jpg&quot; alt=&quot;Artur Paikin&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Artur describes himself as, “I’m a web developer and traveler. I write stories about my adventures in Russian and English on my site: &lt;a href=&quot;http://arturpaikin.com&quot;&gt;http://arturpaikin.com&lt;/a&gt; and run a small technology cooperative called &lt;a href=&quot;http://unebaguette.com&quot;&gt;Baguette&lt;/a&gt;, where I work on cool projects, currently building an ambitious next generation file uploader with &lt;a href=&quot;https://transloadit.com/&quot;&gt;Transloadit&lt;/a&gt;. I ride a &lt;a href=&quot;https://www.instagram.com/p/xC0qC2SSYb&quot;&gt;foldable bicycle&lt;/a&gt;, &lt;a href=&quot;http://unebaguette.com/web-course/&quot;&gt;teach&lt;/a&gt; web development and sometimes &lt;a href=&quot;https://www.instagram.com/p/4_6LO8ySVL/&quot;&gt;garden&lt;/a&gt; on the balcony.”&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Artur has built an open source home automation system called &lt;a href=&quot;https://github.com/arturi/kotihome&quot;&gt;Koti Home&lt;/a&gt; (Koti means home in Finnish language). It’s powered by an Arduino connected to Raspberry Pi, MQTT protocol for messaging, Node.js on the client and server, web sockets. You can interact with Koti robot via a React (like the cool kids do) control panel, Telegram Chat Bot and even your own voice.&lt;/p&gt;
&lt;p&gt;Arthur will talk about how he’s turned this project into reality — the tech he used and the challenges he faced. From a blinking LED to a voice controlled home automation robot.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Ops for Devs by Adam Ulvi</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-adam-ulvi/</link>
      <pubDate>Wed, 01 Jun 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-adam-ulvi/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-adam-ulvi/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Node applications exist at the end of a long, somewhat magical series of tubes. What spells are being cast to make this all work? Let’s find out!&lt;/p&gt;
&lt;p&gt;In this talk Adam will explore the steps required to host a Node application on a small, affordable linux virtual private server (like a DigitalOcean droplet). This is not a tutorial, but rather, a walk-through of the configuration steps, background information the role each step plays, and the “why” behind the choices we are making.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-adam-ulvi/adamulvi.jpg&quot; alt=&quot;Adam Ulvi&quot;&gt;
&lt;/div&gt;

&lt;p&gt;The reference implementation is taken from the current production gruntjs.com server.&lt;/p&gt;
&lt;p&gt;By following the request lifecyle, we will touch on basic tcp/ip networking, DNS configuration and history, node application development, nginx proxy configuration, and basic linux system configuration.&lt;/p&gt;
&lt;p&gt;At the end of the presentation developers should have a better understanding of the simple application’s infrastructure requirements, external dependencies, and targets of opportunity for future improvement.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Github: &lt;a href=&quot;http://github.com/aulvi&quot;&gt;github.com/aulvi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;IRC: s5fs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’m looking forward to Adam’s talk, since I’ve been doing a lot of ops along with my dev work lately. Come check out Adam’s talk at &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;Node PDX&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Speakers and More For Node PDX 2016</title>
      <link>http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/</link>
      <pubDate>Wed, 25 May 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/</guid>
      <author></author>
      <description>&lt;p&gt;Spock and I are excited to announce our first set of speakers for &lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX 2016&lt;/a&gt;, which you’ve seen slowly coming out each day! I hope you’re ready and have your &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;tickets&lt;/a&gt; bought already. So far I’ve introduced &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-tomomi-imura/&quot;&gt;Tomomi&lt;/a&gt;, &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-jonny-oropeza/&quot;&gt;Jon&lt;/a&gt;, and &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-liz-abinante/&quot;&gt;Liz&lt;/a&gt;. Today I’ll introduce Adam Ulvi a bit later.&lt;/p&gt;
&lt;p&gt;We’ve also announced the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#geektrain&quot; target=&quot;_blank&quot;&gt;Geek Train for Node PDX&lt;/a&gt; and the &lt;a href=&quot;http://nodepdx.org/lagniappe.html#bikes&quot; target=&quot;_blank&quot;&gt;Node PDX Bike Ride&lt;/a&gt;. A little &lt;a href=&quot;http://www.merriam-webster.com/dictionary/lagniappe&quot; target=&quot;_blank&quot;&gt;lagniappe&lt;/a&gt; if you will.  ;)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-tomomi-imura/&quot;&gt;Tomomi&lt;/a&gt;, &lt;a href=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-jonny-oropeza/&quot;&gt;Jon&lt;/a&gt;, and &lt;a href=&quot;http://adron.github.io/articles/speakers-and-more-for-node-pdx-2016/&quot;&gt;Liz&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/speakers-and-more-for-node-pdx-2016/spock-horns.jpg&quot; alt=&quot;Spock&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX 2016&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Geek Train&lt;/strong&gt; provides super cheap $15 train fare from anywhere north of Portland along the Amtrak Cascades route. I’ll actually meet the train in Seattle and ride from Seattle back to Portland for the conference. How that works is if you’re in Bellingham, Everett, Seattle, Tacoma, or wherever along the northern stretch can &lt;a href=&quot;https://ti.to/nodepdx/nodepdx-2016/with/gl6purbdlmo&quot; target=&quot;_blank&quot;&gt;purchase a ticket from us here&lt;/a&gt;. Once you purchase a ticket we’ll all have tickets for a specific train and will board along the line and join up in a specific car on the train (which we’ll have assigned day of the trip).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;bike ride&lt;/strong&gt; will make a loop through west and east of the Willamette River with a chance to check out all sorts of parts of the city. We’ll stop and try some of the wicked tasty locally roasted coffee and roll into one of the local taprooms that has dozens of local brews on tap. Between those tasty beverages I’ll point out some of the most excellent architecture, bridge design (ya like bridges eh?), neighborhoods, and other things that are characteristic of Portland. This will be a slow ride, so no need to have alley cat like reflexes and riding skills, just come and enjoy a chill, casual, and fun slow ride through Portland.&lt;/p&gt;
&lt;h2&gt;&lt;a href=&quot;http://dotnetfringe.org/&quot; target=&quot;_blank&quot;&gt;.NET Fringe 2016&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;For .NET Fringe we’ll have the announcements for speakers coming very soon. We’ve taken a slightly different approach with a voting mechanism among organizers which we’ll be wrapping up and then will hurry up with the announcement, I know everybody needs to know ASAP!&lt;/p&gt;
&lt;p&gt;We’ll also be setting up a Geek Train &amp;amp; .NET Fringe bike ride too, we’ve just got to get everything posted. So keep an eye on the .NET Fringe site or &lt;a href=&quot;http://dotnetfringe.org/#signup&quot; target=&quot;_blank&quot;&gt;subscribe to updates&lt;/a&gt; and it’ll have updates popping up real soon.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A Foolish Quest Creating Knitting Patterns Using JavaScript by Liz Abinante</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-liz-abinante/</link>
      <pubDate>Tue, 24 May 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-liz-abinante/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-liz-abinante/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.adron.me/articles/node-pdx-2016-speaker-liz-abinante/knitting.png&quot; class=&quot;image float-left&quot; /&gt;Liz Abinante lives in Portland, Oregon and works as a Senior Software Engineer at &lt;a href=&quot;https://newrelic.com/&quot;&gt;New Relic&lt;/a&gt;. She is infectiously enthusiastic about web development, teaching, learning, and feminism. She used to write JavaScript, then walked up to the wrong desk one day and now she writes some Java too. She enjoys speaking at conferences, knitting, sewing, and a hacking away on interesting problems. She swears she’s a lot more interesting than this bio makes her sound. She’s often been compared to cartoon characters due to her enormous personality and penchant for singing and/or dancing her way through life.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;liz.jpg&quot; class=&quot;image float-right&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Liz’s presentation is &lt;strong&gt;&lt;em&gt;A Foolish Quest: Creating Knitting Patterns Using JavaScript&lt;/em&gt;&lt;/strong&gt;. The talk will show taking something real-world and math-based, like knitting, and turning into a program is actually super easy (no one is surprised here). But! What happens when you combine that with best practices and expected conventions, along with industry-wide standards for design and presentation? Things get a lot more complicated than just crunching numbers, especially when your output will result in lots of manual hours for people creating a real object. This is the story of how Liz built a customizable knitting pattern generator in JavaScript (after she’d built it in Ruby first, of course), and the lessons learned when you try and do math for more than just math’s sake.&lt;/p&gt;
&lt;p&gt;Join the Node PDX Conference by &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;buying a ticket&lt;/a&gt; and come check out Liz’s presentation!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Isomorphic Business Logic (Or How to convince even the most die-hard C#/Java/Rails-on-the-Backend boss that you need to run a node server) Jonny Oropeza</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-jonny-oropeza/</link>
      <pubDate>Thu, 19 May 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-jonny-oropeza/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-jonny-oropeza/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/node-pdx-2016-speaker-jonny-oropeza/jon.jpg&quot; alt=&quot;Jon Oropeza&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Jon Oropeza is a full-stack engineer at HD Quote Center, a post-aquisition startup solving tricky ecommerce problems for their parent company, The Home Depot. Prior to that, he designed and developed software for the insurance industry with his partners at LifePro Financial Services, and also co-founded a deep learning / computer vision oriented startup called Tilt Video.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Jon will be presenting “&lt;strong&gt;Isomorphic Business Logic (Or How to convince even the most die-hard C#/Java/Rails-on-the-Backend boss that you need to run a node server)&lt;/strong&gt;“ which might just be the talk with the longest title of the conference!&lt;/p&gt;
&lt;p&gt;Business logic is all the tricky calculations, rules and transformations that never seem to be in the hot new framework’s example ToDo app. Lately I’ve been finding it’s also the key to convincing clients and bosses that they NEED to run a node layer, no matter what other backend techs they happen to be rocking. In this talk I’ll dive into why and how, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An intro to isomorphic javascript&lt;/li&gt;
&lt;li&gt;Challenges that arise from wanting a performant client and server-side verification&lt;/li&gt;
&lt;li&gt;How this gets exacerbated if you happen to be using a microservices-based backend&lt;/li&gt;
&lt;li&gt;Business logic - that pesky stuff that isn’t in the ToDo App&lt;/li&gt;
&lt;li&gt;Story time: A real world example of an app trying to apply the same logic in 2 different languages&lt;/li&gt;
&lt;li&gt;Isomorphic business logic to the rescue!&lt;/li&gt;
&lt;li&gt;The close… How all of this translates to ‘you need to run a node server’ :)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Come check out Jon’s talk at &lt;a href=&quot;http://nodepdx.org/#tickets&quot; target=&quot;_blank&quot;&gt;Node PDX&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>From Software to Hardware How Do I Track My Cat with JavaScript Tomomi Imura</title>
      <link>http://adron.github.io/articles/node-pdx-2016-speaker-tomomi-imura/</link>
      <pubDate>Wed, 18 May 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/node-pdx-2016-speaker-tomomi-imura/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;a href=&quot;http://nodepdx.org&quot;&gt;&lt;img src=&quot;/articles/node-pdx-2016-speaker-tomomi-imura/nodepdx-2016-logo.png&quot; alt=&quot;Node PDX 2016&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I’m stoked to introduce Tomomi (&lt;a href=&quot;http://twitter.com/girlie_mac&quot;&gt;@girlie_mac&lt;/a&gt;). Tomomi is an avid open web &amp;amp; open technology advocate and creative technologist, who had been active in the mobile space for past 8+ years. Now she is working at PubNub in San Francisco. When she is not at work, she still geeks around and hacks some stuff like Amazon Dash to Rickroll people.&lt;/p&gt;
&lt;p&gt;Tomomi will be presenting “&lt;strong&gt;From Software to Hardware: How Do I Track My Cat with JavaScript&lt;/strong&gt;“.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;jamie-detected.png&quot; class=&quot;image float-right&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In the era of Internet of Things, connecting things to the mobile devices and web is becoming ubiquitous. You can control room light using your mobile phone. You can monitor your heart rate and weight on browser. JavaScript engineers like you already have skills to prototype ideas to build software, so why not hardware too?&lt;/p&gt;
&lt;p&gt;Tomomi, a front-end engineer with no background in electrical engineering, tells how she got started with hardware hacking with JavaScript, also talks about her recent fun project, &lt;a href=&quot;https://github.com/girliemac/RPi-KittyCam&quot;&gt;KittyCam&lt;/a&gt;, a Raspberry Pi camera with cat facial detection to see when her cat Jamie is eating while being away from home.&lt;/p&gt;
&lt;p&gt;If you’re interested in seeing Tomomi speak, get registered for &lt;a href=&quot;http://nodepdx.org/&quot; target=&quot;_blank&quot;&gt;Node PDX before the tickets are gone&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Dropping the Ball, GSD, and Staying Productive</title>
      <link>http://adron.github.io/articles/dropping-the-ball-gsd-and-staying-productive/</link>
      <pubDate>Fri, 13 May 2016 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/dropping-the-ball-gsd-and-staying-productive/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;em&gt;[&lt;strong&gt;NOTE:&lt;/strong&gt; This was actually written Thursday the 5th, things make more sense with that in mind.]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I sat here today, and several normal things happened that made me think of some seriously important things. The thoughts are presented very well by Scott Hanselman in a talk on &lt;em&gt;scaling oneself&lt;/em&gt;. He’s got a lot of gems in this presentation (links and video below), which he’s given a few times. In those presentations he makes a few very quotable statements that I had pop into my mind.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“It’s not what you read, it’s what you ignore.” - Scott Hanselman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The other really great gem is,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Sometimes &lt;em&gt;&lt;strong&gt;dropping the ball&lt;/strong&gt;&lt;/em&gt; is the right thing to do.”  - Scott Hanselman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Both of these are so true. It’s an important balancing act that one must perform to maintain a high level of productivity, especially in any complex work. Seriously, even digging a ditch can be complex, just look at Boston. They spent the years 1982 through 2002 to work on this project. They failed a dozen times on a dozen aspects of the project. It barely finished even a percentage of what was intended all for an initial estimate that was $2.8 Billion that ended up being $14.8 billion (only $8.08 Billion in 1982 dollars though :o ). In this situation, just to finish, the city had to actually drop the ball on a number of aspects of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Big_Dig&quot; target=&quot;_blank&quot;&gt;Big Dig&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But I digress, my problems I’m working on solutions for aren’t anywhere near the dilemma of the Big Dig. I do however find myself needing to chose between becoming swamped and living life, or dropping the ball. If I chose carefully I can still succeed even while dropping the ball on some things. Because sometimes it is indeed, the right thing to do.&lt;/p&gt;
&lt;p&gt;An alternative,&lt;strong&gt; delegate &lt;/strong&gt;and get help.&lt;/p&gt;
&lt;p&gt;Another solution to dropping the ball or not dropping the ball, is to simply delegate and pass the ball to others who can help out. Both &lt;em&gt;dropping the ball&lt;/em&gt; and &lt;em&gt;delegating&lt;/em&gt; are honestly great leadership skills that can be harnessed to effectively multiply your productivity levels. Both of them can seem almost like the same thing to those that have expectations upon your work, and both can be force multipliers for you, but their results can obviously be very different initially. In the end, both end up requiring someone to pick up the work or write off the work. I’ll leave you to guess which one results in which result. ;)&lt;/p&gt;
&lt;p&gt;As these things popped into my head I looked at my immediate to-do list of things. I knew I was rather bombarded with things I needed to do, so it was time to figure out what could be delegated and what could be dropped. This list, of course is only &lt;em&gt;tech related&lt;/em&gt; and &lt;em&gt;work&lt;/em&gt; related. It is also a list that has to be done before the end of the week, which is Sunday @ 6pm in time for Game of Thrones for this particular instance.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Infrastructure: DNS migration completion from provider X to Google Cloud DNS via Terraform &amp;amp; Atlas.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Resolve a firewall change.&lt;/li&gt;
&lt;li&gt;Determine Zookeeper working situation with Kubernetes &amp;amp; container tech vs. installed on VM. Prepare a seamless immutable infra deployment of said Zookeeper cluster.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Setup voting for proposals and get team to vote.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get bike ride event posted for day before conference.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get schedule put together for workshops.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Finalize curriculum, course topics, abstracts, and titles for workshops.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get Geek Train setup, scheduled, call Amtrak to confirm date and get a ticket block.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Get marketing done around Geek Train, Bike Ride, Workshops, etc.&lt;/li&gt;
&lt;li&gt;.NET Fringe - Update website w/ progress.&lt;/li&gt;
&lt;li&gt;Node PDX - Get bike ride event posted for day before conference.&lt;/li&gt;
&lt;li&gt;Node PDX - Get schedule put together for workshops.&lt;/li&gt;
&lt;li&gt;Node PDX - Meet with Code Fellows about partnership and workshop resources (space etc)&lt;/li&gt;
&lt;li&gt;Node PDX - Get proposals sorted and prepared for selection and make selection w/ team.&lt;/li&gt;
&lt;li&gt;Node PDX - Get Geek Train setup, scheduled, call Amtrak to confirm date and get a ticket block.&lt;/li&gt;
&lt;li&gt;PDX Node - (Not PDX Node and not Node PDX!) meetup tonight (Thursday) at Urban Airship to plan the future of the meetup and coordinate with organizers!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ok, that’s enough. You get the idea. I’m a bit underwater on things. But this is how it works. There are weeks where there isn’t a high priority on a single thing, and then BOOM, the deluge has come upon me and I have no hope of finishing things in a timely manner. Privatization, delegation, and dropping the ball are the options available during this time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question Things, Question Yourself, Always Ask Questions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I always ask several questions about things I need to get done during this time. For instance, how could I get help or even get someone to organize a bike ride or do the work of setting up logistics around the geek train? How could I make the amount of work I need to do to setup the DNS migration and complete it the absolute minimum while ensuring it’ll get done right, on time, and seamlessly without interruption? Could I just drop the Zookeeper and Kubernetes work for now? There is always a balance to be reached among things that provides the maximum return.&lt;/p&gt;
&lt;p&gt;Among all the questions there are two other things that are super important. Again, I’m going to pull a Hanselman quote.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Effectiveness is doing the right thing.
Efficiency is doing things right.  - &lt;em&gt;Scott Hanselman&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These two things are huge. If either falters, even in a small way, I’ve found it’s better to call a full stop and reflect on what I’m doing. I’ve also found, that when others start to give in and their efficiency and effectiveness drops, it’s time to call a full stop. This is something that’s hugely helpful when providing leadership for people too, help them help you help everybody move forward and don’t let them fall prey to be overworked and overwhelmed!&lt;/p&gt;
&lt;p&gt;These are a few things, largely focused around Scott’s blog entries and presentations. Absolutely great, well researched, and he practices what he preaches. Scott is a seriously kick ass, highly reliable, consistent guy.&lt;/p&gt;
&lt;p&gt;On to some other things that Scott might have said, but these are things I’ve come up with just from life. The following might actually seem counter-intuitive, but I promise you when these practices are mastered you will stand out strong while others falter around you. However they’re tricky, because if you have a “warm body in seat” type of boss, don’t have work flexibility around hours, schedule, remote or onsite all of these become extremely difficult. In spite of this they’re all wroth investing in to get them to work for you. I’ve easily quadrupled what I can do by doing the following.&lt;/p&gt;
&lt;p&gt;&lt;h1&gt;My Productivity List&lt;/h1&gt;
Remember one thing. Work is not your core focus and reason to exist in life. &lt;strong&gt;&lt;em&gt;You, your family, your love is why you work in order to live and to create and build&lt;/em&gt;&lt;/strong&gt;. Don’t get these things mixed up ever. If work takes to much toll, figure something out to reduce it’s damage to your life.&lt;/p&gt;
&lt;h2 id=&quot;coffee-without-work&quot;&gt;Coffee Without Work&lt;/h2&gt;
&lt;p&gt;Have your &lt;em&gt;&lt;strong&gt;coffee without work in the morning&lt;/strong&gt;&lt;/em&gt;. I can’t rave enough about getting one’s head in the game before actually starting on work tasks. Whatever your morning tradition is, mine being that wicked awesome coffee that Portland is famous for, this needs to be done without having work interfere. If someone is emailing you or calling you don’t let it interrupt. If you feel you need to be interrupted in the morning then you really need to find different work where this time will be respected.&lt;/p&gt;
&lt;p&gt;You might have another coffee with coffee folk at work, but whatever the case, have your first coffee in your own head space without interruptions. Better yet, have it with your wife, children, or loved ones so you remember why you are who you are and do what you do.&lt;/p&gt;
&lt;h2 id=&quot;cut-the-to-do-list-in-half&quot;&gt;Cut The To-do List in Half&lt;/h2&gt;
&lt;p&gt;Ever noticed the lies of to-do lists? It takes practice to create to-do lists that are actually able to be completed on a schedule. Don’t even lie about it, that’s what all of our first to-do lists do, is lie to us. There are tons of rules and thoughts around to-do lists. Keep em’ to three isn’t a bad one, but as you’ve seen I have a catastrophe in the making listed above. So I need to split that to-do list into manageable segments.&lt;/p&gt;
&lt;p&gt;The times to-do lists turn into a multidimensional array of to-do lists are to frequent to count. So cut them in half, stay focused on one list. ONE LIST, not anymore. If you have more delete them. They’re waste, total waste. I keep a single list and &lt;em&gt;notes&lt;/em&gt;. The notes are merely random thoughts and things that might one day end up one day on a list. That leads me to the next thing…&lt;/p&gt;
&lt;h2 id=&quot;write-note-and-think&quot;&gt;Write, Note, and Think&lt;/h2&gt;
&lt;p&gt;Write down things, not particularly lists, but just things that you think or ponder frequently. This helps one formalize what their thoughts are. Write these notes and think, think, and think some more. For me, this helps me refocus and insure I’m always working (or actively procrastinating at least) effectively and efficiently on things instead of getting hit with analysis paralysis or other such anti-pattern problems.&lt;/p&gt;
&lt;h2 id=&quot;take-a-break&quot;&gt;Take a Break&lt;/h2&gt;
&lt;p&gt;Take a break frequently. Taking a break frequently and move around. Walk around a space, the block, or whatever you can find. Walk for at least 15 minutes every 2-4 hours. I’m sure doctors say this too, but I’ve got this on my list of productivity helpers because it legitimately helps people keep that brain clear and helps in numerous other ways. This activity will also help knock out thinking road blocks, resolve errors that crop up, and generally keep you quick thinking. Otherwise we humans tend to fade at a dramatically faster rate during the day without a break, in spite of what we sometimes think we need to do. So take a break, walk around.&lt;/p&gt;
&lt;h2 id=&quot;be-active-stay-healthy-blagh-blagh-blagh-&quot;&gt;Be Active, Stay Healthy… Blagh Blagh Blagh…&lt;/h2&gt;
&lt;p&gt;I’m touchy about this one and I know a bunch of people are. But this is seriously pivotal to staying productive! There are more studies than I can count and might hit on the topic in a subsequent blog entry. For now, it’s safe to say I stay active and it is massive part of how I stay productive.&lt;/p&gt;
&lt;h2 id=&quot;don-t-work-hard-work-smart&quot;&gt;Don’t Work Hard, Work Smart&lt;/h2&gt;
&lt;p&gt;This is said by half the planet, but seriously take it to heart. If you’re working hard, then you’re likely getting behind. If you find yourself repeatedly doing some copy and pasting, or just cranking through typing line after line of some nonsense, or you’ve been delved into a problem for many hours, step back. Are you just working hard at the problem or actually trying to work smartly to resolve the problem? Far to often we work at the problem instead of trying to actually think our way through the problem or even around the problem!&lt;/p&gt;
&lt;p&gt;Another article I saw popup recently, which translates to the idea behind don’t work hard, work smart is &lt;a href=&quot;http://www.inc.com/will-yakowicz/stop-being-busy-and-start-being-productive.html&quot; target=&quot;_blank&quot;&gt;stop being busy, start being productive&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;don-t-meeting-&quot;&gt;Don’t &lt;em&gt;Meeting&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Does this need repeated? There’s a reason there are other options on meeting invites besides the &lt;em&gt;accept&lt;/em&gt; option. Use them readily, frequently, and with intent. Remove yourself from, and don’t let yourself fall into the trap of creating meetings that are unnecessary. &lt;a href=&quot;https://gettingreal.37signals.com/ch07_Meetings_Are_Toxic.php&quot; target=&quot;_blank&quot;&gt;Meetings are toxic&lt;/a&gt;, and seriously one of the biggest problems of going to &lt;em&gt;work&lt;/em&gt; is that far to often work doesn’t happen at work. Largely because of, as Jason Fried states, “&lt;em&gt;M &amp;amp; M&lt;/em&gt;“.&lt;/p&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/5XD2kNopsUs?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;For the last few, these are just a few things to NOT do. If you find yourself stuck in these anti-patterns of productivity start looking for a way out. These anti-patterns are basically indicators of a death march. You aren’t going to fix it, let it die.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;em&gt;&lt;strong&gt;requested&lt;/strong&gt;&lt;/em&gt; overtime happens more than once a month. I’d even say, if overtime requests happens more than once a year, get out. This is a sure indicator of being underfunded, understaffed, poorly managed, and a lack of project leadership that understand how to achieve the best results  for a project, product, service, or otherwise. The only time overtime is acceptable is if &lt;em&gt;&lt;strong&gt;YOU&lt;/strong&gt;&lt;/em&gt; choose for &lt;em&gt;&lt;strong&gt;YOU&lt;/strong&gt;&lt;/em&gt; or &lt;em&gt;&lt;strong&gt;YOUR COMPANY&lt;/strong&gt;&lt;/em&gt; to work overtime. In the same turn, don’t request of others this nonsensical thing, it’s a sure sign you’ve lost control of dictating your company’s future effectively.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;Do not lose sleep&lt;/strong&gt;&lt;/em&gt;. Unless it’s because you’re super excited, that happens sometimes. But if you do lose sleep, make absolutely sure that you regain it somehow. If you lose sleep to often you will absolutely, 100% land in a seriously flawed and troublesome failing state. This is not a good situation to be in.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;This next one might sound odd, but I do nto jest even lightly about this one. &lt;em&gt;&lt;strong&gt;Drink more water&lt;/strong&gt;&lt;/em&gt; than you do now. Statistically Americans are somewhere around 96-97% chronically dehydrated. That means we’re almost always operating under less than ideal personal physical condition. This is very bad… if you don’t buy this one, go read up on how dehydration works. Then think about it, I promise it’s far more important than you might thing and it’s ridiculously easy to actually fix. This isn’t the 10th century anymore, nobody is really walking down to the river for water, just grab a bottle and carry it on your person.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;A few more related references:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;First and foremost, check out Scott’s &lt;a href=&quot;http://www.hanselman.com/blog/ScottHanselmansCompleteListOfProductivityTips.aspx&quot; target=&quot;_blank&quot;&gt;list of tips&lt;/a&gt;.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;Here’s one Scaling Yourself from 2012 @ Dev Day&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/IWPgUn8tL8s?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;Also Scaling Yourself at goto; conf.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;1280&quot; height=&quot;720&quot; src=&quot;https://www.youtube.com/embed/FS1mnISoG7U?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    <item>
      <title>Immutable Infrastructure - Some Reads and Clarification of What It Is</title>
      <link>http://adron.github.io/articles/immutable-infrastructure-some-reads-clarification-what-it-is/</link>
      <pubDate>Tue, 12 Apr 2016 13:39:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/immutable-infrastructure-some-reads-clarification-what-it-is/</guid>
      <author></author>
      <description>&lt;p&gt;First let’s get these terms a little more defined with the help of some well written articles on the matter.&lt;/p&gt;
&lt;h2 id=&quot;an-introduction-to-immutable-infrastructure&quot;&gt;An Introduction to Immutable Infrastructure&lt;/h2&gt;
&lt;p&gt;A well written piece by &lt;a href=&quot;https://twitter.com/joshstella&quot; target=&quot;_blank&quot;&gt;@joshstella&lt;/a&gt; on O’Reilly Radar titled “&lt;a href=&quot;http://radar.oreilly.com/2015/06/an-introduction-to-immutable-infrastructure.html&quot; target=&quot;_blank&quot;&gt;An Introduction to Immutable Infrastructure&lt;/a&gt;“. Here are some key elements in Josh’s description of immutable infrastructure.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Immutable infrastructure (II) provides stability, efficiency, and fidelity to your applications through automation and the use of successful patterns from programming.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This provides a basic description, at a very high level, of what immutable infrastructure is. The keys to note are the idea of programming the infrastructure instead of tediously setting it up manually as has traditionally been done.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Immutable infrastructure requires full automation of your runtime environment. This is only possible in compute environments that have an API over all aspects of configuration and monitoring. Therefore, II can be fully realized only in true cloud environments. It is possible to realize some benefits of II with partial implementations, but the true benefits of efficiency and resiliency are realized with thorough implementation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this part another key point, from a functional perspective of what immutable infrastructure is, is brought up. The availability of APIs to control all aspects of the infrastructure and beyond are needed to truly implement this pattern of infrastructure use. Without APIs to programmatically enable this there is no way to truly create immutable infrastructure.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Historically, we’ve thought of machine uptime and maintenance as desirable because we associate the health of the overall service or application with them. In the data center, hardware is expensive and we need to carefully craft and maintain each individual server to preserve our investments over time. In the cloud, this is an anachronistic perspective and one we should give up on in order to create more resilient, simpler, and ultimately more secure services and applications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Paraphrased - kill your tediously and manually managed servers! &lt;em&gt;Woohoo!&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;why-you-should-build-an-immutable-infrastructure&quot;&gt;Why You Should Build an Immutable Infrastructure&lt;/h2&gt;
&lt;p&gt;“&lt;a href=&quot;https://blog.codeship.com/immutable-infrastructure/&quot; target=&quot;_blank&quot;&gt;Why You Should Build an Immutable Infrastructure&lt;/a&gt;“ by &lt;a href=&quot;http://Even though the  https://twitter.com/flomotlik&quot; target=&quot;_blank&quot;&gt;@flomotlik&lt;/a&gt; is an excellent write up with a bit more detail about how, where, and why to build out immutable infrastructure. The blog &lt;a href=&quot;https://twitter.com/codeship&quot; target=&quot;_blank&quot;&gt;@Codeship&lt;/a&gt; overall is an excellent place to find more implementation details about designing, uses, and ways to put together your own immutable infrastructure. In the article I’ve linked Florian draws some solid points about their experience with immutable infrastructure. Some of the key features Florian details include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;State Isolation&lt;/li&gt;
&lt;li&gt;Atomic Deployments and Validation&lt;/li&gt;
&lt;li&gt;Fast Recovery by Preserving History&lt;/li&gt;
&lt;li&gt;Simple Experimentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of these are valid reasons to go with an immutable infrastructure design practice. Florian also puts together some great links &amp;amp; reference material at the end of the article too.&lt;/p&gt;
&lt;h2 id=&quot;summary-&quot;&gt;Summary…&lt;/h2&gt;
&lt;p&gt;So these are reasonable good reads on immutable infrastructure, something, that if you’re in charge of any type of application deployment will benefit from in some significant ways. So learn up, and feel free to ping me for further discussion on twitter &lt;a href=&quot;https://twitter.com/adron&quot; target=&quot;_blank&quot;&gt;@Adron&lt;/a&gt;. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Difficult Open Source Path</title>
      <link>http://adron.github.io/articles/the-difficult-open-source-path/</link>
      <pubDate>Fri, 25 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/the-difficult-open-source-path/</guid>
      <author></author>
      <description>&lt;p&gt;Bringing a closed source, or just simply an internally managed code base, into the wild of open source software can be an arduous and surreal process. In this article I’m going to ramble on about exactly that, with a few learned lessons and key successes I’ve had.&lt;/p&gt;
&lt;p&gt;I’m currently helping the Home Depot Quote Center determine what is useful software to open source, and then helping them move toward open sourcing that software. In the past I’ve managed the open source development of .NET Extensions of Cloud Foundry, called Iron Foundry, which provided .NET support to the Cloud Foundry Platform. I’ve also helped organize and run open source efforts for plugins at New Relic, Basho, and a host of other smaller companies. Sometimes I’ve been a code contributor, sometimes I’m just interacting with contributors and managing pull requests. Either way it has been a lot of fun and every time it has been a seriously intense learning opportunity.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;lesson-1-open-source-amp-individual-freedom&quot;&gt;Lesson 1: Open Source &amp;amp; Individual Freedom&lt;/h2&gt;
&lt;p&gt;One thing to keep in mind, which I realize, but find myself being reminded of, is that people are truly free to either contribute, use, or completely disregard or ignore your open source project. The analogy of herding cats is often used to describe software development, and open source software development is like herding cats hopped up on a bunch of catnip that whimsically decide to do whatever they want.&lt;/p&gt;
&lt;p&gt;Of course, an open source project might have paid contributors. If a project has paid contributors we at least get back to a contained room of cat herding. But either way, never forget that someone may or may not build that feature, or close the issue, or submit a pull request the way you’ve set out to have the project run. Which brings me to the next lesson.&lt;/p&gt;
&lt;h2 id=&quot;lesson-2-write-up-roles-rules-process-guidelines&quot;&gt;Lesson 2: Write Up Roles, Rules, Process, &amp;amp; Guidelines&lt;/h2&gt;
&lt;p&gt;As soon as the team goes from one person to two, effort should immediately be put into creating roles, rules, and process for how contributions will be accepted, pull requests will be committed, how to submit or work on issues, and the whole host of work flow associated with getting things done for the project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Roles&lt;/strong&gt;, in this particular instance, can be broken down in different ways. Sometimes a project might have somebody managing the pull requests coming in, someone else or even several people are managing the product development issues for new features, another person might be handing bug issues that come up, and the possibilities continue. Some simple examples often look like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Project Leader - (Manager, Boss, Head Honcho, or whatever the title) would be in charge of and might even be the person who started the project.&lt;/li&gt;
&lt;li&gt;Contributor - Individual submitting features via pull request to the project.&lt;/li&gt;
&lt;li&gt;Feature Creator - Individual submitting feature requests and ideas via issues listings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Slightly more complex examples might be something like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Project Creator - Again, the person who created, started, and owns the project.&lt;/li&gt;
&lt;li&gt;Feature Architect - Some who specifically designs features from a technical stand point.&lt;/li&gt;
&lt;li&gt;Feature User Experience - Someone who works with users of the OSS project to determine how and in which ways the community is using the project and determine ways to make the experience better.&lt;/li&gt;
&lt;li&gt;Feature Contributor - Someone who contributes code for features, implementing based on contributor specs, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Beyond that, one just merely needs to detail the roles as much as necessary to help people determine what and how they’ll be contributing to the project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules&lt;/strong&gt; for a project can cover a wide range of things. One increasingly popular and sometimes useful thing to add, especially with a diverse group of people working on a project, is a basic code of conduct. This helps outline what is or is not appropriate behavior on the issue threads and general public conversation within the group. We have to remember that open source often has people involved that aren’t exactly employees or directly related to the person that started a project. Because of this individuals often come to a project without any particular guidelines about what is or isn’t appropriate behavior.&lt;/p&gt;
&lt;p&gt;Other rules that are dramatically simpler and easier to deal with, are breaking down and defining what is considered an acceptable pull request, how things should be documented, code standards, and other related technical rules.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt; for a project is often key to keeping people involved over time. Without a good process in which contributors really feel like they’re part of the team and getting their pull requests accepted, things can fall apart pretty quickly. Nothing like a bored programmer to go find something else to do that has nothing to do with your open source project!&lt;/p&gt;
&lt;p&gt;A good process helps to define the steps that a contributor would need to go through to contribute a piece of code to a feature, who they would need to communicate with, how to submit a pull request, and finally how to wrap up getting the pull request pulled from the latest code. This is as important to people and it is to defining the technical steps for the system itself to be sustaining from an ongoing continuous integration and deployment point of view.&lt;/p&gt;
&lt;p&gt;Once these core things are formalized it dramatically decreases tedious communication about working through the most basic of tasks while working on a project.&lt;/p&gt;
&lt;h2 id=&quot;lesson-3-branding-amp-marketing&quot;&gt;Lesson 3: Branding &amp;amp; Marketing&lt;/h2&gt;
&lt;p&gt;“Oh my god what are you talking about Adron, what’s that crap got to do with an open source project?” I can hear the naysayers immediately on this topic. But rest assured, branding and marketing will either make or break a project. If you’re repo is kind of clunky and cluttered it sends a bad message that you aren’t really paying attention to your project. If someone comes to your repo and immediately sees a reasonable logo, or some type of consistent README.md with useful information and messaging (that’s marketing by the way) about what, where, how, and why this project exists, you’re exponentially more likely to get people involved in contributing and even more dramatically more likely to get people using the project.&lt;/p&gt;
&lt;p&gt;In the OSS Manifesto a baseline of files are suggested for an OSS project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have a readme file&lt;/li&gt;
&lt;li&gt;Have a contributing file&lt;/li&gt;
&lt;li&gt;List all core team members in the readme file&lt;/li&gt;
&lt;li&gt;Have a license file&lt;/li&gt;
&lt;li&gt;Have a changelog&lt;/li&gt;
&lt;li&gt;Follow semantic versioning&lt;/li&gt;
&lt;li&gt;Tag all major releases&lt;/li&gt;
&lt;li&gt;Provide documentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ll add to this, throw in an &lt;em&gt;.svg or reasonably usable &lt;/em&gt;.png of a logo or some easily identifiable symbol for the project. Every major project has some sort of logo, it really doesn’t even matter if its a pretty lousy looking logo, it just needs to be there to make the project easily identifiable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/the-difficult-open-source-path/open-source-logos.png&quot; alt=&quot;Open Source logos&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;lesson-4-the-software-needs-to-work&quot;&gt;Lesson 4: The Software Needs to Work&lt;/h2&gt;
&lt;p&gt;Having the respective readme, contributing file, general doc, listing of all core members; these things I’ve listed so far are all nice but there’s one more thing I’ve not mentioned yet. That is having a working publicly accessible &lt;strong&gt;&lt;em&gt;continuous integration&lt;/em&gt;&lt;/strong&gt; build that is working. Any and every open source project should have a repository setup with a running build. Any new pull requests gets accepted or even the smallest commit should get a build started.&lt;/p&gt;
&lt;p&gt;There are many ways, more so for open source projects than probably any other kind, to get a continuous integration build going. Check out products and services like &lt;a href=&quot;https://codeship.com/&quot; target=&quot;_blank&quot;&gt;Codeship&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/teamcity/&quot; target=&quot;_blank&quot;&gt;TeamCity&lt;/a&gt;, &lt;a href=&quot;https://www.appveyor.com/&quot; target=&quot;_blank&quot;&gt;Appveyor&lt;/a&gt;, or &lt;a href=&quot;https://travis-ci.org/&quot; target=&quot;_blank&quot;&gt;Travis CI&lt;/a&gt;. These are just a few of the many options to get a continuous integration setup running for your open source project.&lt;/p&gt;
&lt;h2 id=&quot;lesson-5-there-will-be-other-lessons-to-learn&quot;&gt;Lesson 5: There will be other lessons to learn&lt;/h2&gt;
&lt;p&gt;An open source project is a pretty wild ride of code chops, organizational skills, and keep systemic development sustainable for a project. It can be tough, but a lot of fun, and very rewarding.&lt;/p&gt;
&lt;p&gt;With that, happy hacking and stay tuned, there’s more to come!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Quick Append to Text File with BASH</title>
      <link>http://adron.github.io/articles/quote-append-to-text-file-with-bash/</link>
      <pubDate>Mon, 14 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/quote-append-to-text-file-with-bash/</guid>
      <author></author>
      <description>&lt;p&gt;I commonly have the scenario where I want a bash script to throw in something at the tail end of the ~/.bash_profile or ~/.profile script or just append some results like a log file to some existing text file. Well here are two super easy ways to add text to a text file.&lt;/p&gt;
&lt;p&gt;Method one, using echo to append the text with the I/O redirection to the text file like this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo &amp;quot;line 1&amp;quot; &amp;gt;&amp;gt; greetings.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or even like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo &amp;quot;line 1
line 2
line 3&amp;quot; &amp;gt;&amp;gt; greetings.txt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Method two, using cat to read until EOT and redirect it to append to text file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOT &amp;gt;&amp;gt; greetings.txt
line 1
line 2
line 3
EOT
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That’s it, easy peasy. Enjoy your shell hacking!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Today I'm Using a Mac</title>
      <link>http://adron.github.io/articles/today-using-a-mac/</link>
      <pubDate>Sat, 12 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/today-using-a-mac/</guid>
      <author></author>
      <description>&lt;p&gt;Today I’m using a Mac (since 2011, but inspired to write this today in 2016) not because I have some profound love for Apple (I don’t really) or miss Steve Jobs (he was a dick, but I bet I’d have gotten along with him) only because I don’t want to spend excess time messing with Windows headaches and the games I generally play over the last 7-8 years have been things like SimCity, Civ 5, and Cities: Skylines. All run perfectly fine on Mac w/ Steam. If I played 1st Person shooters I’d probably still have a Windows machine stashed in the corner for that…&lt;/p&gt;
&lt;p&gt;…and…&lt;/p&gt;
&lt;p&gt;…as for Macs, I converted solely because of what I saw a few key coders acheive in seconds over a Windows machine. I’ve not seen a single person come close to what these people could accomplish on a *nix based platform vs Windows. I switched, my headaches went away blagh blagh blagh (you know the ads, I sound like that) and then between OS-X &amp;amp; VMware Fusion I found I had a machine I could do everything from a coding perspective on (I initially bought an MBA). Then when I got the Retina Pro 15” I realized not only did I have every programming platform in existence available to me (even .NET!) I also realized it was the only machine of it’s size, weight, and horsepower that would let me edit in screen full frame 1080p or even 4k video without choking on itself. Windows didn’t even have a viable option on the market at the time (and really, it still doesn’t).&lt;/p&gt;
&lt;p&gt;At this point I’ve given up trying to even use Windows to do work, primarily cuz it’s bad at video, bad at building code (most comparable machines just don’t build 1 to 1 code bases as fast), has weak POSIX compliance, Powershell is just a pain in the ass, it has poor SSH support (load 3rd party software? does it even internet) and security in general is completely bonkers, and Windows can never seem to find or maintain security integrity around any non-WINS/AD identified network (ok, in Windows defense, this is a Windows Server concern not Windows Desktop).&lt;/p&gt;
&lt;p&gt;Beyond that even the OS-X UI is preferable to the sluggish, strange multi-tasking awkwardness of Windows 2010 (and it’s dramatically improved over 8/8.1, 7, Vista, XP, &amp;amp; 2000). The fact I can launch a program and it doesn’t kill process &amp;amp; memory resources while I’m doing something has always fascinated me vs. Windows, which seems to hand over every available resource to whatever is attempting to launch. What is that nonsense even? Let it launch on a lower priority thread or something. I could go on…&lt;/p&gt;
&lt;p&gt;I’ve got plenty of complaints about OS-X, but it stays out of the way when I need to build code, automate infrastructure, sling dynamic code (re: Ruby, JavaScript, etc) and generally tears through Core CLR code &amp;amp; .NET Mono code dramatically better than suggish old VS on a box with more resources then this MBP. Honestly, it’s kind of sad how it seems to magically do better then Windows hardware. There aren’t a whole lot of specific reasons except that Macs are usually just integrated (motherboard/RAM/Proc/Video) better than most of the other junk that gets released to market. Of course if someone wants pure horsepower, yeah, got buy a desktop and get 4x-20x what comes in the best Mac, then run Linux. You’ll get stupid amounts of performance to build and process stuff with that. But in the consumer based world, if you want the maximum options with the minimal amount of bullshit in your life, you go and buy a MBP and get on with life. I could go on…&lt;/p&gt;
&lt;p&gt;I’m sure there’s a million other things where X device for Y niche is more perfect or perfectly acceptable, and I doubt I’d disagree, so go on, get yourself one of those. But again, for “the maximum options with the minimal amount of bullshit in your life, you go and buy a MBP and get on with life”. On that note, I’m off to sling some Core CLR code against a prospective Scala solution and test a micro-services idea of mine - using Docker and jazz on my OS-X box. I’ll be done in 20 minutes and will move on to probably a relaxing round of Cities: Skyline. ;)&lt;/p&gt;
&lt;p&gt;Thanks for reading my partial rant /&lt;em&gt;slash&lt;/em&gt;/ exploration of why I’ve ended up on Apple Hardware.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Docker Tips n' Tricks - Bash Things With Docker</title>
      <link>http://adron.github.io/articles/docker-tips-n-tricks-bash-things-with-docker/</link>
      <pubDate>Thu, 10 Mar 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/docker-tips-n-tricks-bash-things-with-docker/</guid>
      <author></author>
      <description>&lt;p&gt;If you use Docker frequently, you’ve likely memorized a few repetitive commands…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine start XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then you run…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine env XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;…and then you type…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;eval $(docker-machine env XyZvirtualMachine)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;One does this about a zillion times if there are multiple virtual machines or for other various reasons. I wanted to simplify this repetitive task so I wrote a bash function, thanks to a &lt;a href=&quot;http://stackoverflow.com/questions/35761480/scripting-docker-not-connected-after-running-script&quot; target=&quot;_blank&quot;&gt;fumble I posted on Stackoverflow&lt;/a&gt; and then an assist by my good friend Troy Howard (&lt;a href=&quot;https://twitter.com/thoward37&quot; target=&quot;_blank&quot;&gt;@thoward37&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This quick hack consisted of this &lt;a href=&quot;https://gist.github.com/Adron/8dc06eb398f403225daa&quot; target=&quot;_blank&quot;&gt;Github gist&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker() { if [ $1 ]; then
    docker-machine start $1
    docker-machine env $1
    eval $(docker-machine env $1)
    docker ps -a
fi }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Stick that in your ~/.bash_profile (or ~/.bashrc if you’re on *nix) and you’re good to go. Then at the bash prompt just type in this.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gimmedocker XyZvirtualMachine
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;BOOM! Less typing for the win!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Researching &amp; Learning About Zookeeper - A Guide</title>
      <link>http://adron.github.io/articles/research-learning-about-zookeeper/</link>
      <pubDate>Mon, 01 Feb 2016 16:30:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/research-learning-about-zookeeper/</guid>
      <author></author>
      <description>&lt;p&gt;I’ve started working with Zookeeper. Since I’ve started doing that I’ve put together this blog post. It’s aim is to provide a structured approach to learning Zookeeper and researching the elements that make its features tick. Along the way I have a few call outs to people that have also provided excellent talks, material, or contributions to learning about Zookeeper along the way. With that, let’s get started.&lt;/p&gt;
&lt;p&gt;Zookeeper is a consensus system written based on ideas presented via consensus algorithms. The idea is key value stores that keep all of their data in memory for read heavy workloads. The qualities in this context present a system that is highly consistent, with intent for access from distributed systems to data that won’t be lost.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;start-learning&quot;&gt;Start Learning&lt;/h3&gt;
&lt;p&gt;The starting point should be a complete read of the &lt;a href=&quot;https://zookeeper.apache.org/&quot;&gt;Apache Zookeeper Project Home Page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At this point I took an administrators’ angle on determining what I needed to know and do next. I knew that my situation would meet the basic assumptions of reliability around Zookeeper; First is that only a minority of servers in a deployment would fail at a particular time or become inaccessible from a crash, partition, or related issue, and second is that deployed machines would have correctly operating clocks, storage, and network components that perform consistently.&lt;/p&gt;
&lt;p&gt;I had also made an assumption that I would need &lt;em&gt;&lt;strong&gt;2 x F + 1&lt;/strong&gt; &lt;/em&gt;machines in order to maintain data consistency. The F here is the number of failed or inaccessible machines. This meant that if I wanted to have 2 failures, I’d need at least 5 machines. For a failure of up to 3 machines, that would be 7 machines. Pretty easy, just a little simple math.&lt;/p&gt;
&lt;p&gt;The other thing I was curious about, especially on a single machine, would be Zookeeper’s overall overhead. Would it come into contention with the services that are already running? Would it be ok to put Zookeeper on the machines that run the micro-services that Zookeeper is providing information to? Well, Zookeeper does indeed content with other application for CPU, network, memory, and storage. For this reason I have to balance the deployment of Zookeeper in relation to the other applications, as my server loads may not be super high, and thus I’d be able to have Zookeeper on some of the servers that have actual other services deployed. But YMMV depending on your services you’ve got deployed.&lt;/p&gt;
&lt;p&gt;While I was thinking through how I’d build out the architecture for my implementation of Zookeeper I came upon a very important note in the documentation,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“ZooKeeper’s transaction log must be on a dedicated device. (A dedicated partition is not enough.) ZooKeeper writes the log sequentially, without seeking Sharing your log device with other processes can cause seeks and contention, which in turn can cause multi-second delays.&lt;/p&gt;
&lt;p&gt;Do not put ZooKeeper in a situation that can cause a swap. In order for ZooKeeper to function with any sort of timeliness, it simply cannot be allowed to swap. Therefore, make certain that the maximum heap size given to ZooKeeper is not bigger than the amount of real memory available to ZooKeeper. For more on this, see Things to Avoid below.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After reading up on the following documentation it seemed like a good time to do a test deployment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html&quot; target=&quot;_blank&quot;&gt;Zookeeper Admin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zookeeper.apache.org/doc/trunk/zookeeperAdmin.html#sc_minimumConfiguration&quot; target=&quot;_blank&quot;&gt;Zookeeper Minimum Configuration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;BEGIN BUG DESCRIPTION - 1ST DOCKER ATTEMPT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;NOTE: If you just want to get to the Zookeeper installation &amp;amp; setup and skip this issue, GOTO &lt;a href=&quot;#awsInstallation&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My first go was to pull up a clean Ubuntu docker image and prep it as a container. Then start installing the necessary parts of Zookeeper. These steps consisted of the following. I made a video for it (see toward the bottom of this entry), so you can actually see the flow and I also wrote the commands I’m tying in bash below. Then you can pick your preferred use.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine start fusion-fire
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Docker machine starts my virtual machine on OS-X that runs the Docker daemon, which I’ve named fusion-fire, thus the command above. Then after that I pulled down an Ubuntu image, started a container from the image, connecting to the container and all set for installation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker pull ubuntu
docker run -it ubuntu
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To install the Zookeeper server and begin execution I then issued the following.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get -Y install default-jdk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While this was executing I also ran into a situation where the Java Development Kit was hanging on getting the certificates put into place.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;The last dozen or so &lt;a href=&quot;https://twitter.com/hashtag/Ubuntu?src=hash&quot;&gt;#Ubuntu&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/docker?src=hash&quot;&gt;#docker&lt;/a&gt; images I&amp;#39;ve tried to run &amp;quot;sudo apt-get install default-jre&amp;quot; on have all ended up spiking the CPU.&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/693219719441096704&quot;&gt;January 29, 2016&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;I began looking into this problem, and found currently on Ubuntu 14.04, running sudo-apt-get update and then running the install will trigger the bug. Two other points of reference are &lt;a href=&quot;https://github.com/docker/docker/issues/18180&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://bugs.launchpad.net/ubuntu/+source/ca-certificates-java/+bug/1396760&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, and there are other postings and issues related to the issue, just google. So what I did at that point to fix this issue was the following.&lt;/p&gt;
&lt;p&gt;First I forcefully killed the docker container by just restarting the whole docker VM.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine stop fusion-fire
docker-machine start fusion-fire
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once that stopped I then started the virtual machine again.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get -y install default-jre
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When it started I ran sudo apt-get install again. At that point apt-get attempted to recover but the install kept getting stuck on registering the certificates. So I gave up on this avenue for now. Hopefully a future Docker &amp;amp; Linux Kernal fixes the problem. So instead I went out and just spooled up some AWS instances for now, I’ll update this blog entry with a “Part II: Docker is Zookeeper Fixed” when the Java + Linux Kernal + Docker issue is remedied, until then, here’s the installation process on the AWS instances.&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;awsInstallation&quot;&gt;&lt;/a&gt;
&lt;strong&gt;END BUG DESCRIPTION - AWS Instance Zookeeper Installation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once this was setup I started 5 nano instances for Zookeeper (nano, since it’s just a test example for learning) and then logged in using broadcast with iTerm 2. From there each instance had the following commands executed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install -y default-jdk
cd /opt/
sudo mkdir zookeeper
cd zookeeper/
sudo wget http://mirror.tcpdiag.net/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
sudo tar -zxvf zookeeper-3.4.6.tar.gz
cd conf/
sudo nano zoo.cfg
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;NOTE: Nano is the text editor I used above for “sudo nano zoo.cfg”. If you don’t have it available just install it with “sudo apt-get install nano”.&lt;/p&gt;
&lt;p&gt;In that zoo.cfg I entered the following. For the IPs I actually used the AWS private IPs for the config file example below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;tickTime=2000
dataDir=/var/zookeeper
clientPort=2181
initLimit=5
syncLimit=2
server.1=172.31.19.66:2888:3888
server.2=172.31.19.67:2888:3888
server.3=172.31.19.68:2888:3888
server.4=172.31.19.69:2888:3888
server.5=172.31.19.70:2888:3888&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now I started the service using the zkServer.sh script file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo /opt/zookeeper/zookeeper-3.4.6/bin/zkServer.sh start-foreground
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When I booted up I ran into an error about the myid file, so I added the file with a sequential number for the byid in the /var/zookeeper directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo nano /var/zookeeper/myid
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In each of the files I added a number, respectively 1 through 5 for the id of each and saved those files. Upon attempting to start the zookeeper service with the following command I finally got to see the various nodes in the ensemble gain access to each other and start working. Which, I gotta admit, was a pretty damn cool feeling.&lt;/p&gt;
&lt;p&gt;After all that fussing it seemed good to note, especially since they’re hard to find in the documentation (which is kind of a bit hard to use), here are some of the switches for zkServer.sh.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;start
start-foreground (super useful for debugging)
stop
restart
status
upgrade
print-cmd&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once this is done, restart the service but this time instead of using the start-foreground command, just use the start command and that will start the service and return the bash back to you to issues commands or whatnot. An easy way to test out Zookeeper now that it is running is to use the Zookeeper CLI. This is the zkCli.sh shell script (or zkcli.bat file if you’re running it on windows - which I’d strongly suggest NOT to do).&lt;/p&gt;
&lt;p&gt;Ok, that’s it for this entry. More to come in the near future. Cheers!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Excellent Additional References&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a title=&quot;raft&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/raft.pdf&quot;&gt;In Search of an Understandable Consensus Algorithm (Extended Version)&lt;/a&gt; - Diego Ongaro &amp;amp; John Ousterhout @ Stanford University&lt;/li&gt;
&lt;li&gt;&lt;a title=&quot;paxos-simple&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/paxos-simple.pdf&quot;&gt;Paxos Made Simple&lt;/a&gt; by Leslie Lamport&lt;/li&gt;
&lt;li&gt;Camille Fournier (&lt;a href=&quot;https://twitter.com/skamille&quot; target=&quot;_blank&quot;&gt;@skamille&lt;/a&gt;) provided an excellent talk about &lt;a href=&quot;http://www.infoq.com/interviews/fournier-consensus&quot; target=&quot;_blank&quot;&gt;Zookeeper (Consensus Systems) on InfoQ&lt;/a&gt;. In this talk Camille also mentions the &lt;a title=&quot;chubby-osdi06&quot; href=&quot;https://compositecode.files.wordpress.com/2016/01/chubby-osdi06.pdf&quot;&gt;The Chubby Lock Service for Loosely Coupled Distributed Systems&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://youtu.be/j4uwKP7WJFk&quot; target=&quot;_blank&quot;&gt;Zookeeper for the Skeptical Architect by Camille Fournier&lt;/a&gt; - RICON East 2013
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/j4uwKP7WJFk?rel=0&amp;amp;showinfo=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
Talks about why Riak, Cassandra, and even the company Camille works at (Rent the Runway) doesn’t use Zookeeper. An interesting talk from the regard of why not to use it in some cases.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>All That Tech SitRep - Elastic Meetup and Quote Center Updates</title>
      <link>http://adron.github.io/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/</link>
      <pubDate>Tue, 26 Jan 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/all-that-tech-sitrep-elastic-meetup-quote-center-updates/qc_377x285.png&quot; alt=&quot;Quote Center&quot;&gt;
&lt;/div&gt;

&lt;p&gt;I started working with the Quote Center (QC) back in November, and wrote about it in “&lt;a href=&quot;http://compositecode.com/2015/10/31/after-816-days/&quot;&gt;After 816 Days I’m Taking a Job!&lt;/a&gt;“ Now that I’m a few months into the effort, it’s &lt;strong&gt;&lt;em&gt;sitrep&lt;/em&gt;&lt;/strong&gt; time. Sitrep, btw is military speak for&lt;/p&gt;
&lt;p&gt;&lt;em&gt;S&lt;/em&gt; ituational &lt;em&gt;R&lt;/em&gt; eport.&lt;/p&gt;
&lt;p&gt;The three core priorities I have at Quote Center in my role are: Community Contributions, Site Reliability, and Talent Recon.&lt;/p&gt;
&lt;h2 id=&quot;community-contributions-and-organizing-&quot;&gt;Community Contributions (and Organizing)&lt;/h2&gt;
&lt;p&gt;Some of the progress I’ve made, is direct and immediate involvement with some really interesting groups here in Portland. The first seemed a prime option, and that’s the &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Elastic User Group&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Myself and some of the QC Team traveled late last year to check out the &lt;a href=&quot;http://compositecode.com/2015/12/03/elasticon-tour-2015-in-seattle/&quot;&gt;Elasticon Tour stop in Seattle&lt;/a&gt;. It was an educational experience where I got some of my first introductions to &lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; and also a new product &lt;a href=&quot;https://www.elastic.co/&quot;&gt;Elastic&lt;/a&gt; had just released recently called &lt;a href=&quot;https://www.elastic.co/products/beats&quot;&gt;Beats&lt;/a&gt;. I was fairly impressed by what I saw and several other things aligned perfectly for follow up community involvement after that.&lt;/p&gt;
&lt;p&gt;I’ve since kept in touch with the Elastic Team and started coordinating the &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Elastic User Group in Portland&lt;/a&gt; (Join the group on &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/&quot;&gt;Meetup&lt;/a&gt; for future meetings &amp;amp; content). In March the group will be hosting a great meetup from Ward &amp;amp; Jason…&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot;&gt;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So be sure to &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot; target=&quot;_blank&quot;&gt;RSVP&lt;/a&gt; for that &lt;a href=&quot;http://www.meetup.com/The-Portland-ElasticSearch-Meetup-Group/events/228064228/&quot; target=&quot;_blank&quot;&gt;meetup&lt;/a&gt; as it’s looking to be a really interesting presentation.&lt;/p&gt;
&lt;p&gt;The second group I’ve stepped up to help out with is the &lt;a href=&quot;http://www.meetup.com/Docker-Portland-OR/&quot; target=&quot;_blank&quot;&gt;Docker Meetup&lt;/a&gt; here in Portland. The first meetup we have planned at this time is from Casey West.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.meetup.com/Docker-Portland-OR/events/228249211/&quot;&gt;http://www.meetup.com/Docker-Portland-OR/events/228249211/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;site-reliability&quot;&gt;Site Reliability&lt;/h2&gt;
&lt;p&gt;One of the other priorities I’ve been focusing on is standard site reliability. Everything from automation to continuous integration and deployment. I’ve been making progress, albeit at this stage going from zero to something, in the space of a site reliability practice takes time. I’ve achieved a few good milestones however, which will help build upon the next steps of the progress.&lt;/p&gt;
&lt;p&gt;We’ve started to slowly streamline and change our practice around Rackspace and AWS Usage. This is a very good thing as we move toward a faster paced continuous integration process around our various projects. At this time it’s a wide mixture of .NET Solutions that we’re moving toward .NET Core. At the same time there are some Node.js and other project stacks that we’re adding to our build server process.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Team City&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Our build server at this time is shaping up to be Team City. We have some build processes that are running in Jenkins, but those are being moved off and onto a TeamCity Server for a number of reasons. I’m going to outline these reasons and I’m happy to hear any reasons there may be other better options. So feel free to throw a tweet at me or leave a comment or three.&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Jetbrains has a pretty solid and reliable product in Team City. It tends to be cohesive in building the core types of applications that we would prospectively have: Java, .NET, Node.js, C/C++ and a few others. That makes it easy to get all projects onto one build server type.&lt;/li&gt;
    &lt;li&gt;TeamCity has intelligence about what is and isn’t available for Java &amp;amp; .NET, enabling various package management and other capabilities without extensive scripting or extra coding needed. There are numerous plugins to help with these capabilities also.&lt;/li&gt;
    &lt;li&gt;TeamCity has fairly solid, quick, and informative support.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Those are my top reasons at this point. Another reason, which isn’t really something I felt should be enumerated, because it’s a feeling versus something I’ve confirmed. That is, the Jenkins Community honestly feels a bit haphazard and disconnected. Maybe I’m just not asking or haven’t seen the right forums to read or something, but I’ve found it a frustrating experience to deal with the Jenkins Server and find information and help regarding getting a disparate and wide ranging set of tech stacks building on it. TeamCity has always just been easy, and getting some continuous integration going the easiest way possible is very appealing.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Monitoring&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We use a number of resources for monitoring of our systems. New Relic is one of them, and they’re great, however it’s a bit tough when things are locked down inside of a closed (physically closed) network. How does one monitor those systems and the respective network? Well, you get &lt;a href=&quot;http://compositecode.com/2015/11/25/nagios-and-ubuntu-64-bit-14-04-lts-setup-configuration/&quot;&gt;Nagios or something of the sort installed and running&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I installed it, but Nagios left me with another one of those dirty feelings like I just spilled a bunch of sour milk everywhere. I went about cleaning up the Nagios mess I’d made and, upon attending the aforementioned Elasticon Tour Stop in Seattle, decided to give Beats a try. After a solid couple weeks of testing and confirming the various things work well and would work well for our specific needs, I went about deploying Beats among our systems.&lt;/p&gt;
&lt;p&gt;So far, albeit only being a few weeks into using Beats (and still learning how to actually make reports in Kibana) Beats appears to have been a good decision. Dramatically more cohesive and not spastically splintered all over the place like Nagios. I’m already looking into adding additional Beats beyond the known three; Topbeats, Packetbeats, and Filebeats. There are a number of other beats that we could add specific to our needs, that would be good open source projects. Stay tuned for those, I’ll talk about them in this space and get a release out to all as soon as we lay a single line of code for those.&lt;/p&gt;
&lt;h2 id=&quot;talent-recon&quot;&gt;Talent Recon&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Currently, nothing to report, but more to come in the space of talent recon.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Elasticon Tour 2015 in Seattle</title>
      <link>http://adron.github.io/articles/elasticon-tour-2015-in-seattle/</link>
      <pubDate>Thu, 03 Dec 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/elasticon-tour-2015-in-seattle/</guid>
      <author></author>
      <description>&lt;p&gt;Today is the tour stop of the &lt;a href=&quot;https://www.elastic.co/elasticon/tour/2015&quot; target=&quot;_blank&quot;&gt;Elasticon Tour&lt;/a&gt; that swung into Seattle. Myself and some of the &lt;a href=&quot;http://hdquotecenter.com/&quot; target=&quot;_blank&quot;&gt;Home Depot Quote Center&lt;/a&gt; team headed up via the &lt;a href=&quot;http://www.amtrakcascades.com/&quot; target=&quot;_blank&quot;&gt;Geek Train&lt;/a&gt; for the event. We arrived the night before so we could get up and actually be awake and ready for the event.&lt;/p&gt;
&lt;p&gt;Just to note, a good clean place to stay, that isn’t overpriced like most of Seattle is the &lt;a href=&quot;https://www.google.com/search?q=Pioneer+Square+Hotel&amp;amp;oq=Pioneer+Square+Hotel&amp;amp;aqs=chrome..69i57j69i60l3.216j0j7&amp;amp;sourceid=chrome&amp;amp;es_sm=91&amp;amp;ie=UTF-8#safe=off&amp;amp;q=Pioneer+Square+Hotel&amp;amp;rflfq=1&amp;amp;tbm=lcl&amp;amp;rlfi=hd:;si:10477062606859836019&quot; target=&quot;_blank&quot;&gt;Pioneer Square Hotel&lt;/a&gt; - usually about $110-120 bucks. If you’re in town for a conference, sometimes it’s even worth skipping the “preferred hotels” and staying here. But I digress…&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When the team and I walked in we waited a little bit for registration to get started. We stood around and chatted with some of our other cohort. Once the registration did open, we strolled into the main public space and started checking out some demos.&lt;/p&gt;
&lt;h2 id=&quot;streamsets&quot;&gt;StreamSets&lt;/h2&gt;
&lt;p&gt;The first thing I noticed of the demos is something that’s catching a lot of attention. It’s a partner of &lt;a href=&quot;https://www.elastic.co/&quot; target=&quot;_blank&quot;&gt;Elastic’s&lt;/a&gt; called &lt;a href=&quot;http://streamsets.com/&quot; target=&quot;_blank&quot;&gt;StreamSets&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset1.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset2.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-responsive&quot; src=&quot;./streamset3.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;From what I could figure out from just watching the demo is that StreamSets is a ingest engine. That’s simple enough to determine just taking a look at their site. But being able to watch the demo also enlightened me to the way the interface IDE (the thing in the dark pictures above) worked.&lt;/p&gt;
&lt;p&gt;The IDE provided ways to connect to ingestion data with minimal schema and actually start to flow the ingestion of this data through the engine. One of the key things that caught my attention at this point was the tie in with &lt;a href=&quot;http://kafka.apache.org/&quot; target=&quot;_blank&quot;&gt;Kafka&lt;/a&gt; and &lt;a href=&quot;https://hadoop.apache.org/&quot; target=&quot;_blank&quot;&gt;Hadoop&lt;/a&gt; with the respective ingest and egress of data to sources ranging from AWS S3 to things like Elastic’s engine or other various sources that I’ll be working with in the coming months.&lt;/p&gt;
&lt;p&gt;For more information about StreamSets here are a few other solid articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/blog/elasticsearch-plus-streamsets-for-reliable-data-ingestion/&quot; target=&quot;_blank&quot;&gt;Elastic Search Plus StreamSets for Reliable Data Ingestion&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/blog/introducing-the-streamsets-data-collector/&quot; target=&quot;_blank&quot;&gt;Introducing the Streamsets Data Collector&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and connect to keep up with what StreamSets is doing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://twitter.com/streamsets&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and install instructions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/resources/installing-streamsets/&quot; target=&quot;_blank&quot;&gt;All The Installations&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://streamsets.com/resources/installing-streamsets/#install-docker&quot; target=&quot;_blank&quot;&gt;Run via Docker&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and most importantly, the code:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/streamsets&quot; target=&quot;_blank&quot;&gt;Github StreamSets&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;beats-not-http-lifehacker-com-are-beats-by-dre-headphones-any-good-1509805994-the-http-lmkprod-com-9-reasons-to-not-buy-beats-by-dre-headphones-lousy-http-forums-macrumors-com-threads-why-not-to-buy-the-beats-by-dre-1376663-target-_blank-dumb-a-a-href-http-www-viewpoints-com-expert-reviews-2013-11-08-why-i-will-never-buy-beats-by-dre-headphones-https-youtu-be-xkvzwj4pz7a-&quot;&gt;Beats (&lt;a href=&quot;http://lifehacker.com/are-beats-by-dre-headphones-any-good-1509805994&quot;&gt;Not&lt;/a&gt; &lt;a href=&quot;http://lmkprod.com/9-reasons-to-not-buy-beats-by-dre-headphones/&quot;&gt;the&lt;/a&gt; &lt;a href=&quot;http://forums.macrumors.com/threads/why-not-to-buy-the-beats-by-dre.1376663/&amp;quot; target=&amp;quot;_blank&amp;quot;&amp;gt;Dumb&amp;lt;/a&amp;gt; &amp;lt;a href=&amp;quot;http://www.viewpoints.com/expert-reviews/2013/11/08/why-i-will-never-buy-beats-by-dre/&quot;&gt;Lousy&lt;/a&gt; &lt;a href=&quot;https://youtu.be/XkVZwj4pZ7A&quot;&gt;Headphones&lt;/a&gt;)&lt;/h2&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;./packetbeat-fish-and-cluster.png&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Recently I &lt;a href=&quot;http://compositecode.com/2015/11/25/nagios-and-ubuntu-64-bit-14-04-lts-setup-configuration/&quot;&gt;installed Nagios&lt;/a&gt; as I will be doing a lot of systems monitoring, management, and general devops style work in the coming weeks to build out solid site reliability. Nagios will theoretically do a lot of the things I need it to do, but then I stumbled into the recently released &lt;a href=&quot;https://www.elastic.co/products/beats&quot; target=&quot;_blank&quot;&gt;Beats&lt;/a&gt; by &lt;a href=&quot;https://www.elastic.co/&quot; target=&quot;_blank&quot;&gt;Elastic Search&lt;/a&gt; (not by Dre, see above links in the title).&lt;/p&gt;
&lt;p&gt;I won’t even try to explain Beats, because it is super straight forward. I do suggest checking out the site if you’re even slightly interested, but if you just want the quick lowdown, here’s a quote that basically summarizes the tool.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Beats is the platform for building lightweight, open source data shippers for many types of operational data you want to enrich with Logstash, search and analyze in Elasticsearch, and visualize in Kibana. Whether you’re interested in log files, infrastructure metrics, network packets, or any other type of data, Beats serves as the foundation for keeping a beat on your data.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So there ya go, something that collects a ton - if not almost all of - the data that I need to manage and monitor the infrastructure, platforms, network, and more that I’m responsible for. I’m currently diving in, but here’s a few key good bits about Beats that I’m excited to check out.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;./packetbeat-fish-nodes-bkgd.png&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;1-packetbeat&quot;&gt;1 - PacketBeat&lt;/h3&gt;
&lt;p&gt;This is the real-time network packet analyzer that integrates with Elasticsearch and provides the respective analytics you’d expect. It gives a level of visibility with Beats between all the network servers and such that will prospectively give me insight to were our &lt;em&gt;&lt;a href=&quot;https://youtu.be/f99PcP0aFNE&quot; target=&quot;_blank&quot;&gt;series of tubes&lt;/a&gt; or getting clogged up&lt;/em&gt;. I’m looking forward to seeing our requests mapped up with our responses!  ;)&lt;/p&gt;
&lt;h3 id=&quot;2-filebeat&quot;&gt;2 - FileBeat&lt;/h3&gt;
&lt;p&gt;This is a log data shipper based on the Logstash-Forwarder. At least it was at one point, it appears to look like it is less and less based on it. This beat monitors log directories for log files, tails the fails, and forwards them to Logstash. This completes another important part of what I need to systemically monitor within our systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Random fascinating observations:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Did I mention Beats is written in Go? Furtherering Derek’s tweet from 2012!  ;)&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Prediction: Go will become the dominant language for systems work in IaaS, Orchestration, and PaaS in 24 months. &lt;a href=&quot;https://twitter.com/hashtag/golang?src=hash&quot;&gt;#golang&lt;/a&gt;&lt;/p&gt;&amp;mdash; Derek Collison (@derekcollison) &lt;a href=&quot;https://twitter.com/derekcollison/status/245522124666716160&quot;&gt;September 11, 2012&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;ul&gt;
&lt;li&gt;Beats has a cool logo, and the design of the tooling is actually solid, as if someone cared about how one would interact with the tools. I’ll see how this holds up as I implement a sample implementation of things with Beats &amp;amp; the various data collectors.&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;More References &amp;amp; Reading Material for Beats:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.elastic.co/blog/beats-1-0-0&quot; target=&quot;_blank&quot;&gt;Beats 1.0.0 Release&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/elastic/beats&quot; target=&quot;_blank&quot;&gt;Beats on Github&lt;/a&gt;&lt;/li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s it for the highlights so far. If anything else catches my eye this evening at the Elasticon Tour, I’ll get started rambling about it too!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Docker Tips n' Tricks - Delete All The Images &amp; Containers</title>
      <link>http://adron.github.io/articles/docker-tips-n-tricks-delete-all-the-images-containers/</link>
      <pubDate>Mon, 02 Nov 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/docker-tips-n-tricks-delete-all-the-images-containers/</guid>
      <author></author>
      <description>&lt;p&gt;Two simple commands that’ll wipe your installation clean of images and containers.&lt;/p&gt;
&lt;p&gt;Deletes all containers&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker rm $(docker ps -a -q)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Deletes all images&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker rmi $(docker images -q)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>After 816 Days I'm Taking a Job!</title>
      <link>http://adron.github.io/articles/after-816-days-taking-a-job/</link>
      <pubDate>Sat, 31 Oct 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/after-816-days-taking-a-job/</guid>
      <author></author>
      <description>&lt;p&gt;&lt;img src=&quot;/articles/after-816-days-taking-a-job/header.jpg&quot; alt=&quot;MAX Train&quot;&gt;&lt;/p&gt;
&lt;p&gt;The new mission, or as some may call it, a job! The context for those that might not be familiar with my adventures is that I’ve been working independently as a consultant, contractor, community builder, beer drinker, hacker, teacher, trainer, mentor, curriculum builder, and training content creator. The last time I held something that resembled a job was 560 business days ago, or more specifically 816 days ago. Honestly, I’m not even sure that &lt;a href=&quot;http://compositecode.wordpress.com/2012/11/21/sitrep-thor-iron-foundry-basho/&quot; target=&quot;_blank&quot;&gt;it could be considered a job, it was a strange gig to say the least&lt;/a&gt;. Recently after this long break I’m taking up a new job position with some interesting objectives and priorities.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s some of what I wrote to outline the specific objectives and priorities for the new team I’m joining and to insure I had clear priorities for myself. I do, after all, prize clear objectives very high on the “&lt;em&gt;things that are useful &amp;amp; cool&lt;/em&gt;“ list.&lt;/p&gt;
&lt;h2 id=&quot;objectives&quot;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Community Contributions&lt;/strong&gt; - Help launch and build the community around the release of a yet to be announced open source micro-services framework (we’re currently calling it the &lt;em&gt;Forge Framework&lt;/em&gt;) following an open source software model. I’ll also be telling you about all the work that has gone into this framework so far form Jesse, Beau, and the team. This will cover their various battles, from discussions to decisions, all leading up to the release of the framework. At this point, our time frame to release this is somewhere around the Feburary time frame. Currently it is in production, but we will need to make sure we have a reason repository of code we can release. We’re aiming for it to be in good shape for everybody to use when it’s released. &lt;em&gt;(I’ll be managing the overall effort, so ping me if you’re interested in jumping into the project)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site Reliability&lt;/strong&gt; - Help build infrastructure for site reliability, deployment, etc (immutable, container based, etc) to deliver the company’s key products, APIs, micro-services, and improve the back-end deployment and delivery options and capabilities. This is going to include a lot of cool technology including things like Docker, kafka, CoreCLR, and a host of other things that I’ll be blogging about on a regular basis. Along with this infrastructure and site reliability I’ll help set guidelines, approaches, and future objectives for delivery and deployment of software. When I implement things, I’ll aim to blog it, when I learn new tips and tricks, I’ll aim to blog it, and whenever I break a build, I’ll blog that too. Whatever it is, I’m aiming to increase my frequency a great deal in the coming days, weeks, and months.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Talent Recon&lt;/strong&gt; - I’m looking for, scouting around like force recon, and connecting talent to future work we will be having come open in early 2016. (Again, this is where I get to come and hack with you, help build awesome open source software, and let you my fellow coding cohort know about the company’s existing and upcoming awesome work we’ll be hiring for! For those that know me, you know I’m serious about making sure I line up the right people with the right types of gigs, I’m no recruiter, I’m a coder, so I fight against wildly innappropriate misalignment and related silliness!)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are my top priorities as I step into this role with the &lt;a href=&quot;http://hdquotecenter.com/&quot; target=&quot;_blank&quot;&gt;Quote Center&lt;/a&gt;, a kind of &lt;strong&gt;&lt;em&gt;laboratory of inventive ideas&lt;/em&gt;&lt;/strong&gt; for &lt;a href=&quot;http://www.homedepot.com/&quot; target=&quot;_blank&quot;&gt;Home Depot&lt;/a&gt;. You’ll be hearing a lot more about this in the coming days, and if you’re interested in working with me and an awesome group of people - reach out and let me know &lt;a href=&quot;https://twitter.com/adron&quot; target=&quot;_blank&quot;&gt;@Adron&lt;/a&gt; on Twitter or just email me. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>The Latest 5th Generation Dell XPS 13 Developer Edition</title>
      <link>http://adron.github.io/articles/latest-fifth-gen-dell-xps-13-developer-edition/</link>
      <pubDate>Wed, 22 Jul 2015 14:54:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/latest-fifth-gen-dell-xps-13-developer-edition/</guid>
      <author></author>
      <description>&lt;p&gt;Just about 4 weeks ago now I purchased a Dell XPS 13 Developer Edition directly from Dell. The reason I purchased this laptop is because of two needs I have while traveling and writing code.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I wanted something &lt;em&gt;small&lt;/em&gt;, &lt;em&gt;compact&lt;/em&gt;, that had &lt;em&gt;reasonable power&lt;/em&gt;, and…&lt;/li&gt;
&lt;li&gt;It needed to run &lt;em&gt;Linux&lt;/em&gt; (likely &lt;em&gt;Ubuntu&lt;/em&gt;, but I’d have taken whatever) from the factory and have active support.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s my experience with this machine so far. There are lots of good things, and some really lousy things about this laptop. This is the lowdown on all the plusses and minuses. But before I dive into the plusses and minuses, it is important to understand more of the context in which I’m doing this review.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dell didn’t send me a free laptop. I paid $1869 for the laptop. Nobody has paid me to review this laptop. I purchased it and am reviewing it purely out of my own interest.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;&lt;a href=&quot;http://www.dell.com/us/business/p/xps-13-linux/pd&quot; target=&quot;_blank&quot;&gt;XPS 13 Developer Edition&lt;/a&gt;&lt;/strong&gt; that I have has &lt;em&gt;8GB RAM&lt;/em&gt;, &lt;em&gt;512 GB SSD&lt;/em&gt;, and the stunningly beautiful 13.3-inch &lt;em&gt;UltraSharp™ QHD+ (3200 x 1800) InfinityEdge Touch Display&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exterior Chassis Materials&lt;/strong&gt; -&amp;gt; CNC machined aluminum w/ Edge-to-edge Corning® Gorilla® Glass NBT™ on QHD+ w/ Carbon fiber composite palm rest with soft touch paint.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Keyboard&lt;/strong&gt; -&amp;gt; Full size, backlit chiclet keyboard; 1.3mm travel&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Touchpad&lt;/strong&gt; -&amp;gt; Precision touchpad, seamless glass integrated button&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;negatives&quot;&gt;Negatives&lt;/h2&gt;
&lt;h3 id=&quot;the-freakin-keyboard-and-trackpad&quot;&gt;The Freakin’ Keyboard and Trackpad&lt;/h3&gt;
&lt;p&gt;Let’s talk about the negatives first. This way, if you’re looking into purchasing, this will be a faster way to go through the decision tree. The first and the LARGEST negative is the keyboard. Let’s just talk about the keyboard for a moment. When I first tweeted about this laptop, one of the first responses I got in relation to this machine was a complaint - and a legitimate one at that - is the blasted keyboard.&lt;/p&gt;
&lt;p&gt;There are plenty of complaints and issues listed &lt;a href=&quot;http://www.dell.com/support/article/us/en/19/SLN297563/EN&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;http://en.community.dell.com/techcenter/os-applications/f/4613/t/19470368&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;http://en.community.dell.com/techcenter/os-applications/f/4613/t/19627933&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; via the Dell Support site. Twitter is flowing with such too about the keyboard. To summarise, the keyboard sticks. The trackpad, by association, also has some sticky behavior.&lt;/p&gt;
&lt;p&gt;Now I’m going to say something that I’m sure some might fuss and hem and haw about. I don’t find the keyboard all that bad, considering it’s not an Apple chiclet keyboard and Apple trackpad, which basically make everything else on the market seem unresponsive and unable to deal with tactile response in a precise way. In that sense, the Dell keyboard is fine. I just have to be precise and understand how it behaves. So far, that seems to resolve the issue for me, same for the trackpad related issues. But if you’re someone who doesn’t type with distinct precision - just forget this laptop right now. It’s not even worth the effort. However, if you are precise, read on.&lt;/p&gt;
&lt;h3 id=&quot;the-sleeping-issue&quot;&gt;The Sleeping Issue&lt;/h3&gt;
&lt;p&gt;When I first received the laptop several weeks ago it had a sleeping issue. Approximately 1 out of every 3-5 times I’d put the computer to sleep it wouldn’t resume from sleep appropriately. It would either hang or not resume. This problem however, has a pretty clean fix available &lt;a href=&quot;http://www.dell.com/support/article/uk/en/ukdhs1/SLN297551/en&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;…issue with your XPS 13 (9343) system failing to  resume from suspend while running Ubuntu 14.04? See here: &lt;a href=&quot;http://t.co/EZDxp5wTct&quot;&gt;http://t.co/EZDxp5wTct&lt;/a&gt; &amp;lt;- THAT&lt;/p&gt;&amp;mdash; Λdrøn (@Adron) &lt;a href=&quot;https://twitter.com/Adron/status/621744827617669120&quot;&gt;July 16, 2015&lt;/a&gt;&lt;/blockquote&gt;&lt;/p&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;h3 id=&quot;not-performant&quot;&gt;Not Performant&lt;/h3&gt;
&lt;p&gt;Ok, so it has 8GB RAM, and SSD, and an i7 Proc. However it does not perform better than my 2 year old Mac Book Air (&lt;em&gt;i7, 8 GB RAM, 256 GB SSD&lt;/em&gt;). It’s horribly slow compared to my 15” Retina w/ 16GB RAM and i7 Proc. Matter of fact, it doesn’t measure up well against any of these Apple machines. Linux however has a dramatically smaller footprint and generally performs a lot of tasks as well or better than OS-X.&lt;/p&gt;
&lt;p&gt;When I loaded Steam and tried a few games out, the machine wasn’t even as performant as my Dell 17” from 2006. That’s right, I didn’t mistype that, my Dell from 2006. So WTF you might ask - I can only guess that it’s the embedded video card and shared video card memory or something. I’m still trying to figure out what the deal is with some of these performance issues.&lt;/p&gt;
&lt;p&gt;However…   on to the positives. Because there is also positives about the performance it does have.&lt;/p&gt;
&lt;h2 id=&quot;positives&quot;&gt;Positives&lt;/h2&gt;
&lt;h3 id=&quot;the-packaging&quot;&gt;The Packaging&lt;/h3&gt;
&lt;p&gt;Well the first thing you’ll notice, that I found to be a positive, albeit an insignificant one but it did make for a nice first experience is the packaging. Dell has really upped their game in this regard, instead of being the low-end game, Dell seems to have gotten some style and design put together for the packaging.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/01.jpg&quot; alt=&quot;Dell XPS 13 Developer Edition Box&quot;&gt;&lt;/p&gt;
&lt;p&gt;The box was smooth, and seamless in most ways. Giving a very elegant feel. When I opened up the box the entire laptop was in the cut plastic wrap to protect all the surfaces.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/02.jpg&quot; alt=&quot;Plastic Glimmer from protective plastics&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/03.jpg&quot; alt=&quot;Umm, what is this paper booklet stuff. :-/&quot;&gt;&lt;/p&gt;
&lt;p&gt;Removing the cut plastic is easy enough. It is held together with just some simple stickiness (some type of clean glue).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/04.jpg&quot; alt=&quot;Removing the Plastic&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once off the glimmer of the machine starts to really show. The aluminum surface material is really really nice.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/05.jpg&quot; alt=&quot;A Side View of the XPS 13&quot;&gt;&lt;/p&gt;
&lt;p&gt;The beauty of an untainted machine running Ubuntu Linux. Check out that slick carbon fiber mesh too.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/06.jpg&quot; alt=&quot;Carbon Fiber Mesh&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here it is opened and unwrapped, not turned on yet and the glimmer of that glossy screen can be seen already.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/07.jpg&quot; alt=&quot;A Glimmer of the Screen&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here’s a side by side comparison of the screens for the glossy hi res screen against the flat standard res screen. Both are absolutely gorgeous screens, regardless of which you get.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/08.jpg&quot; alt=&quot;XPS 13 Twins&quot;&gt;&lt;/p&gt;
&lt;p&gt;Booting up you can see the glimmer on my XPS 13.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/09.jpg&quot; alt=&quot;Glimmer on the Bootup&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;the-screen&quot;&gt;The Screen&lt;/h3&gt;
&lt;p&gt;The screen, even during simple bootup and first configuration of Ubuntu like this it is evident that the screen is stunning. The retina quality screen on such a small form factor is worth the laptop alone. The working resolution is 1920x1080, but of course the real resolution is 3200x1800. Now, if you want, you could run things at this resolution at your own risk to blindness and eye strain, but it is possible.&lt;/p&gt;
&lt;p&gt;The crispness of this screen is easily one of the best on the market today and rivals that of the retina screens on any of the 13” or 15” Apple machines. The other aspect of the screen, which isn’t super relevant when suing Ubuntu is that it is touch enabled. So you can poke things and certain things will happen, albeit Ubuntu isn’t exactly configured for touch display. In the end, it’s basically irrelevant that it is a touch screen too, except in the impressive idea that they got a touch screen of this depth on such a small machine!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/10.jpg&quot; alt=&quot;Booted Up&quot;&gt;&lt;/p&gt;
&lt;p&gt;Here’s a little more of the glimmer, as I download the necessary things to do some F# builds.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/11.jpg&quot; alt=&quot;Setting up F#&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;performance-and-boot-time&quot;&gt;Performance and Boot Time&lt;/h3&gt;
&lt;p&gt;Boot time is decent. I’m not going to go into the seconds it takes but it’s quick. Also when you get the update for sleep, that’s really quick too. So no issue there at all.&lt;/p&gt;
&lt;p&gt;On the performance front, as I mentioned in the negatives there are some issues with performance. However, for many - if not most - everyday developer tasks like building C#, F#, C++, C, Java, and a host of other languages the machine is actually fairly performant.&lt;/p&gt;
&lt;p&gt;In doing other tasks around Ruby, PHP (yes, I wrote a little bit of PHP just to check it out, but I did it safely and deleted it afterwards), JavaScript, Node.js, and related web tasks were also very smooth, quick, and performant. I installed Atom, Sublime 3, WebStorm, and Visual Studio Code and tried these out for most of the above web development. Everything loads really fast on the machine and after a few loads they even get more responsive, especially WebStorm since it seems to load Java plus the universe.&lt;/p&gt;
&lt;p&gt;Overall, if you do web development or some pretty standard compilable code work then you’ll be all set with this machine. I’ve been very happy with it’s performance in these areas, just don’t expect to play any cool games with the machine.&lt;/p&gt;
&lt;h3 id=&quot;weight-and-size&quot;&gt;Weight and Size&lt;/h3&gt;
&lt;p&gt;I’ll kick this positive feature off with some addition photos of the laptop compared to a Mac Book Pro 15” Retina and a Apple Air 13”.&lt;/p&gt;
&lt;p&gt;First the 13” Air.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/12.jpg&quot; alt=&quot;Stacked from the side.&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/13.jpg&quot; alt=&quot;USB, Power, Headphones and Related Ports up close.&quot;&gt;&lt;/p&gt;
&lt;p&gt;No the Mac Book Pro 15” Retina&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/14.jpg&quot; alt=&quot;MBP 15&amp;quot;. The XSP 13 is considerably smaller - as it obviously would be.&quot;&gt;&lt;/p&gt;
&lt;p&gt;…and then on top of the Mac Air 13”.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/15.jpg&quot; alt=&quot;On top of the MBA 13&amp;quot;&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/16.jpg&quot; alt=&quot;The 13&amp;quot; sitting on top of the 15&amp;quot; Retina&quot;&gt;&lt;/p&gt;
&lt;p&gt;Of course there are smaller Mac Book Pros and Mac Book Air Laptops, but these are the two I had on hand (and still use regularly) to do a quick comparison with. The 13” Dell is considerably smaller in overall footprint and is as light or lighter than both of these laptops. The XPS makes for a great laptop for carrying around all the time, and really not even noticing its presence.&lt;/p&gt;
&lt;h3 id=&quot;battery-life&quot;&gt;Battery Life&lt;/h3&gt;
&lt;p&gt;The new XPS 13 battery life, with Ubuntu, is a solid 6-12 hours depending on activity. I mention Ubuntu, because as anybody knows the Linux options on conserving battery life are a bit awkward. Namely, they don’t always do so well. But with managing the screen lighting, back light, and resource intensive applications it would be possible to even exceed the 12 hour lifespan of the batter with Ubuntu. I expect with Windows the lifespan is probably 10-15% better than under Ubuntu. That is, without any tweaks or manual management of Ubuntu.&lt;/p&gt;
&lt;p&gt;So if you’re looking for a long batter life, and Apple options aren’t on the table, this is definitely a great option for working long hours without needing to be plugged in.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/latest-fifth-gen-dell-xps-13-developer-edition/beer.png&quot; alt=&quot;Cheers!&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Overall, a spectacular laptop in MOST ways. However that keyboard is a serious problem for most people. I can imagine most people will NOT want to deal with the keyboard. I’m ok with it, but I don’t mind typing with hands up and off the resting points on the laptop. If Dell can fix this I’d give it a 100% buy suggestion, but with the keyboard as buggy and flaky as it is, I give the laptop at 60% buy suggestion. If you’re looking for a machine with Ubuntu out of the box, I’d probably aim for a Lenovo until Dell fixes the keyboard situation. Then I’d even suggest this machine over the Lenovo options.&lt;/p&gt;
&lt;p&gt;…and among all things, I’d still suggest running Linux on a MBA or MBP over any of these - the machines are just more solid in manufacturing quality, durability, and the tech (i.e. battery, screen, etc) are still tops in many ways. But if you don’t want to feed the Apple Nation’s Piggy Bank, dump them and go with this Dell or maybe a Lenovo option.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Happy hacking and cheers!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>AWS Beanstalk Worker with Node.js and SQS</title>
      <link>http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/</link>
      <pubDate>Wed, 19 Nov 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/amazon-sqs_200x200.png&quot; alt=&quot;Amazon SQS&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First I created a project for the node.js worker. The first steps for this are identical to that of creating the Hapi.js site that publishes messages to the queue. Go through these three steps for the worker and then I’ll continue from there.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish#webapplication&quot;&gt;create the web application&lt;/a&gt; which will act as our worker service. I gave mine the name of &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;testing-aws-sqs-worker&lt;/a&gt;, the site publishing to the queue I called &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;testing-aws-sqs-site&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Next &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/#mocha&quot;&gt;add dependencies needed&lt;/a&gt;, like mocha.&lt;/li&gt;
&lt;li&gt;Finally make sure the &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/#aws&quot;&gt;AWS environment variables&lt;/a&gt; are set appropriately.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;…and now on to the security, configuration and worker specific parts of this series…&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security Needs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before getting the actual worker setup I need to have a role setup in IAM (&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once here click on the Roles section of IAM. Then click on Create New Role.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next set the role name.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now select Amazon EC2 here. I noted this wasn’t immediately intuitive. But once I realized that the security item I’m looking for is a sub-item under Amazon EC2 things made more sense.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next next odd thing that occurred in this web wizard was that the number 3 step is skipped. Again, that took me a second to realize maybe that’s an optional step. Whatever the case, it shouldn’t be displayed unless it’s a step that might actually occur in all paths, otherwise just make it disappear. Anyway, step 4 is where the next step awaits.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next step I’ll add the JSON that defines this role. It looks like this in the wizard (and I’ve included the actual JSON just below the image of the wizard). NOTE: In this screen shot I’ve named the role one thing, but when I select it below I’ve actually renamed it to “serverComms”. These two are indeed the same role, I just didn’t want to go back and redo all the screenshots around a minor rename. :)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-07.png&quot; alt=&quot;Screen 7&quot;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;{
  &lt;span class=&quot;string&quot;&gt;&quot;Version&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;2012-10-17&quot;&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;Statement&quot;&lt;/span&gt;: [
    {
      &lt;span class=&quot;string&quot;&gt;&quot;Sid&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;QueueAccess&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Action&quot;&lt;/span&gt;: [
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:ChangeMessageVisibility&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:DeleteMessage&quot;&lt;/span&gt;,
        &lt;span class=&quot;string&quot;&gt;&quot;sqs:ReceiveMessage&quot;&lt;/span&gt;
      ],
      &lt;span class=&quot;string&quot;&gt;&quot;Effect&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Allow&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Resource&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;*&quot;&lt;/span&gt;
    },
    {
      &lt;span class=&quot;string&quot;&gt;&quot;Sid&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;MetricsAccess&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Action&quot;&lt;/span&gt;: [
        &lt;span class=&quot;string&quot;&gt;&quot;cloudwatch:PutMetricData&quot;&lt;/span&gt;
      ],
      &lt;span class=&quot;string&quot;&gt;&quot;Effect&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Allow&quot;&lt;/span&gt;,
      &lt;span class=&quot;string&quot;&gt;&quot;Resource&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;*&quot;&lt;/span&gt;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Click next and the summary is provided before final creation of the role.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-08.png&quot; alt=&quot;Screen 8&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Web Worker Application&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The first thing I need is to go ahead and get the worker setup in the AWS Management Console. I create a new environment by clicking on Launch New Environment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-09.png&quot; alt=&quot;Screen 9&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next up is setting the environment tier and type and the configuration. I set these to Worker, Node.js, and Load Balanced.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-10.png&quot; alt=&quot;Screen 10&quot;&gt;&lt;/p&gt;
&lt;p&gt;Then upload the project zip file. I zipped and uploaded this file &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/#upload&quot;&gt;similarly to the way I did the site for submitting messages to the queue&lt;/a&gt;. To see what code I’m uploading - the blog entry is kind of circular - so I added the code part toward the bottom of this entry. For the exact code, check out the later part of the entry and the finished code here in the &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-11.png&quot; alt=&quot;Screen 11&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now click next through environment info and additional resources. In configuration details the main thing I need is to select the IAM security role for the instance being created.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-12.png&quot; alt=&quot;Screen 12&quot;&gt;&lt;/p&gt;
&lt;p&gt;Click through the environment variables and on to Worker Details. Here I select the queue that I created in &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/&quot;&gt;part 1 of this series&lt;/a&gt;. Just below that enter the URI end point that the worker will provide the queue to send messages via POST. I’ll get to the code later in this article. But for now, I just selected /hi as the end point.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-13.png&quot; alt=&quot;Screen 13&quot;&gt;&lt;/p&gt;
&lt;p&gt;Finally, the last step is to review and Launch the worker instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/aws-beanstalk-worker-with-node-js-and-sqs/sqs-14.png&quot; alt=&quot;Screen 14&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Codes&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At this point I’ll still be using hapi.js and good.js, so I follow the installation of these libraries similar to the ones I used for the site app in &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/&quot;&gt;part 2 of this series&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install hapi --save
npm install good --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I’ve setup a &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker/blob/master/server.js&quot;&gt;server.js&lt;/a&gt; as shown below. This API end point provides an action, in this case a write to the log, and then just finishes. This will prove out a complete movement of message from publisher site to queue to answering worker service.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt;
  AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;),
  awsRegion = &lt;span class=&quot;string&quot;&gt;'us-west-2'&lt;/span&gt;,
  sqs = {},
  Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;),
  Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;),
  queueUri = &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/621392439615/sample'&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  method: &lt;span class=&quot;string&quot;&gt;'POST'&lt;/span&gt;,
  path: &lt;span class=&quot;string&quot;&gt;'/hi'&lt;/span&gt;,
  handler: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    AWS.config.update({
      accessKeyId: process.env.AWS_ACCESS_KEY_ID,
      secretAccessKey: process.env.AWS_SECRET_KEY,
      region: awsRegion
    });
    sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

    server.log(&lt;span class=&quot;string&quot;&gt;'response: '&lt;/span&gt;, request.payload.name);
    server.log(&lt;span class=&quot;string&quot;&gt;'Starting receive message.'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'...a 200 response should be received.'&lt;/span&gt;);

    reply();
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this code, note that Hapi.js takes the request (read more on &lt;a href=&quot;http://hapijs.com/&quot;&gt;Hapi.js here&lt;/a&gt;) and sticks the body of the request in the property payload. Since AWS SQS sends across JSON in the way I’ve set it up (see &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/&quot;&gt;part 1&lt;/a&gt; and &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/articles/hapijs-aws-worker-publish/&quot;&gt;part 2&lt;/a&gt;) the received message coming in looks like this.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;April&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above code, the request.payload.name code gives us the name April. Run this and when the SQS receives input to process it will immediately send the message to the worker which will then process the code. When the worker returns a 200, the message is marked complete and removed from the queue. When I navigate to the nodejs.log in the AWS Beanstalk logs section of the environment, I get the last few items that I submitted to the queue for processing. The code above responds as shown below in the log.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;-------------------------------------
/var/log/nodejs/nodejs.log
-------------------------------------
141119/011034.709, response: , Susan
141119/011034.709, Starting receive message., ...a 200 response should be received.
141119/011034.688, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (26ms)
141119/011039.927, response: , April
141119/011039.928, Starting receive message., ...a 200 response should be received.
141119/011039.925, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (6ms)
141119/011045.232, response: , Jessica
141119/011045.232, Starting receive message., ...a 200 response should be received.
141119/011045.229, request, http://ip-172-31-33-151:8081: [1;33mpost[0m /hi {} [32m200[0m (7ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;BOOM! All done. A few notes before I end this entry though. Note that with the worker feature being used for Beanstalk and SQS there really isn’t much code that is needed on the receipt end of the worker. I merely needed to respond 200, to complete the request from the point of view of the SQS worker service. Then whatever code I have that I want to act on the process with can work on the data received in the body from the queue. More than a few examples out there don’t really show this, but instead show the manual way of writing code that will poll and act upon the messages in the queue. The Beanstalk worker configuration is dramatically simpler in comparison to this practice. If you do want to read more about manually polling and acting on the data check out “&lt;a href=&quot;https://milesplit.wordpress.com/2013/11/07/using-sqs-with-node/&quot;&gt;Using SQS With Node&lt;/a&gt;“, it’s the only end-to-end example I’ve seen with Node.js being used. There is also of course the documentation, but it doesn’t provide clear cut examples of what exactly a good practice around working with the queue and requires a lot of RTFMing which quit frankly is a TLDR; scenario for doing something like this.&lt;/p&gt;
&lt;p&gt;Hope this blog post is helpful in getting Node.js working with the worker role. If you have any questions, comments or it appears I’ve missed a step, let me know and I’ll edit this and the related posts to make sure they’re as accurate and as simple to follow as I can get them.&lt;/p&gt;
&lt;p&gt;Cheers!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS</title>
      <link>http://adron.github.io/articles/hapijs-aws-worker-publish/</link>
      <pubDate>Fri, 07 Nov 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/hapijs-aws-worker-publish/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
  &lt;img src=&quot;/articles/hapijs-aws-worker-publish/SDKs-copy_nodeJS-200x2100.png&quot; alt=&quot;Node.js SDK&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name=&quot;webapplication&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;First I created a project for the node.js web application. This just used the simple &lt;code&gt;npm init&lt;/code&gt; command and I stepped through the prompts for name, version, description, entry point, and so on.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sane defaults.

See `npm help json` for definitive documentation on these fields
and exactly what they do.

Use `npm install &amp;amp;pkg&amp;amp; --save` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
name: (testing-aws-sqs-site)
version: (0.0.0) 0.0.1
description: This project that will feed data to the queue for the AWS SQS sample.
entry point: (index.js) server.js
test command: mocha
git repository: (https://github.com/Adron/testing-aws-sqs-site.git)
keywords: aws, sqs, elastic, elastic beanstalk, queue, worker
author: Adron Hall
license: (ISC) Apache 2.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;mocha&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installing Dependencies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Next I installed some dependencies like mocha and whatever else I’d need down the line and the next major dependency, the AWS SDK. To see a complete list of the dependencies just check out the &lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site/blob/master/package.json&quot;&gt;package.json&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install aws-sdk --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next step is to create a test directory which I’ll use to test out some of the services as I move forward. Some of these tests will not fit into the BDD, TDD, or any other style of tests, as I will write them in a way that they’ll test the SDK, system and related elements for future use in continuous delivery. So just follow me here and don’t freak out, they’re not as frivolous as they seem at first.&lt;/p&gt;
&lt;p&gt;I added mocha as my test framework, and since it uses a folder called test as the default to execute tests, I added a folder and placed a file in that folder called aws_sdk.js. I then added the following test just to have an example test to work from.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; should = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;'should'&lt;/span&gt;);

describe ( &lt;span class=&quot;string&quot;&gt;'When trying out this sample application in AWS you'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{

  it ( &lt;span class=&quot;string&quot;&gt;'should have an environment variable set for AWS_ACCESS_KEY_ID'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    process.env.AWS_ACCESS_KEY_ID.should.exist;
  });

  it ( &lt;span class=&quot;string&quot;&gt;'should have an environment variables set for AWS_SECRET_KEY'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    process.env.AWS_SECRET_KEY.should.exist;
  })

});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then execute that with a call to mocha, and the two tests will fail.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ mocha

  When trying out this sample application in AWS you
    1) should have an environment variable set for AWS_ACCESS_KEY_ID
    2) should have an environment variables set for AWS_SECRET_KEY

  0 passing (4ms)
  2 failing

  1) When trying out this sample application in AWS you should have an environment variable set for AWS_ACCESS_KEY_ID:
     TypeError: Cannot read property &amp;#39;should&amp;#39; of undefined
      at Context.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;anonymous&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp; (/Users/adron/Codez/testing-aws-sqs-site/test/aws_sdk.js:12:34)
      at callFn (/usr/local/lib/node_modules/mocha/lib/runnable.js:249:21)
      at Test.Runnable.run (/usr/local/lib/node_modules/mocha/lib/runnable.js:242:7)
      at Runner.runTest (/usr/local/lib/node_modules/mocha/lib/runner.js:373:10)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:451:12
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:298:14)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:308:7
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:246:23)
      at Object._onImmediate (/usr/local/lib/node_modules/mocha/lib/runner.js:275:5)
      at processImmediate [as _immediateCallback] (timers.js:336:15)

  2) When trying out this sample application in AWS you should have an environment variables set for AWS_SECRET_KEY:
     TypeError: Cannot read property &amp;#39;should&amp;#39; of undefined
      at Context.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;anonymous&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp; (/Users/adron/Codez/testing-aws-sqs-site/test/aws_sdk.js:16:30)
      at callFn (/usr/local/lib/node_modules/mocha/lib/runnable.js:249:21)
      at Test.Runnable.run (/usr/local/lib/node_modules/mocha/lib/runnable.js:242:7)
      at Runner.runTest (/usr/local/lib/node_modules/mocha/lib/runner.js:373:10)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:451:12
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:298:14)
      at /usr/local/lib/node_modules/mocha/lib/runner.js:308:7
      at next (/usr/local/lib/node_modules/mocha/lib/runner.js:246:23)
      at Object._onImmediate (/usr/local/lib/node_modules/mocha/lib/runner.js:275:5)
      at processImmediate [as _immediateCallback] (timers.js:336:15)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a name=&quot;aws&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At this point I’ll go ahead and set these environment variables in my ~/.bash_profile file. On other machines this may just be a .bashrc file or something else you’ve configured for your bash. Add the environment variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;# AWS Credentials
export AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY
export AWS_SECRET_KEY=YOUR_SUPER_SECRET_AWS_KEY
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you’ve added these to your bash, source the file to activate and set these new environment variables. My command is to source my local .bash_profile file, but you’d need to source whichever file you’ve set the variables in that starts up with your bash.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;source ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now executing the mocha tests I get a beautiful confirmation that I do have the environment variables in place and set.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ mocha

  When trying out this sample application in AWS you
    ✓ should have an environment variable set for AWS_ACCESS_KEY_ID
    ✓ should have an environment variables set for AWS_SECRET_KEY

  2 passing (4ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that I have these two passing I’ve added another that shows the SDK to have the settings have actually been set. The main reason here is also to just discover how it is set and where those values are stored on the AWS object. I discovered that to set the config, just issue a call to update({}) and pass in the respective configuration as name value pairs using JSON.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;before(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  AWS.config.update({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_KEY,
    region: awsRegion});
})

it(&lt;span class=&quot;string&quot;&gt;'should have the AWS Access Key set in the AWS config'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; config = AWS.config;
  config.credentials.accessKeyId.should.equal(process.env.AWS_ACCESS_KEY_ID);
  config.credentials.secretAccessKey.should.equal(process.env.AWS_SECRET_KEY);
})

it(&lt;span class=&quot;string&quot;&gt;'should have the AWS region set to us west 2'&lt;/span&gt;, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
  AWS.config.region.should.equal(awsRegion);
})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The configuration data is then stored in the config credentials for the access key and secret access key. The region is stored as a value on the config object. Those should pass and then let’s move straight on to setting up a basic site that can send the queue some data.&lt;/p&gt;
&lt;p&gt;For more information about the configuration and setup of the AWS SDK check out the &lt;a href=&quot;http://docs.aws.amazon.com/AWSJavaScriptSDK/guide/node-configuring.html&quot;&gt;SDK Documentation on the topic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Web Site Application&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To create this web site application I’m going to use hapi.js. You can of course use anything you want to for this part of the example such as express, geddy or whichever. The general premise of what I’m going to put together for the front end of this whole application is going to be extremely simple. By proxy it will then be easily applied to any of the other framework options.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install hapi --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that was done I installed the good library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;npm install good --save
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First part of the site I spooled up was to create a server.js file in the root of the project and add the following code.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;)

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(&lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  method: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  path: &lt;span class=&quot;string&quot;&gt;'/'&lt;/span&gt;,
  handler: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, world!'&lt;/span&gt;);
  }
});

server.route({
  method: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  path: &lt;span class=&quot;string&quot;&gt;'/{name}'&lt;/span&gt;,
  handler: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err; &lt;span class=&quot;comment&quot;&gt;// something bad happened loading the plugin&lt;/span&gt;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dependency I added, good, brings some logging features to the project now. So with this, when executing the server file to get the server running, I get the following response on the command line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ node server.js
141020/004110.009, info, Server running at: http://adrons-mbp:3000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next I issued some curl commands against the end points.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;17:42 $ curl localhost:3000
Hello, world!~
17:42 $ curl localhost:3000/Frank
Hello, Frank!~
17:42 $ curl localhost:3000/Sally
Hello, Sally!~
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the logging on, the following results proved out that everything was running ok.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-shell-script&quot;&gt;$ node server.js
141020/004219.213, info, Server running at: http://adrons-mbp:3000
141020/004230.236, request, http://adrons-mbp:3000: get / {} 200 (10ms)
141020/004236.850, request, http://adrons-mbp:3000: get /Frank {} 200 (2ms)
141020/004240.514, request, http://adrons-mbp:3000: get /Sally {} 200 (1ms)
141020/004254.937, request, http://adrons-mbp:3000: get /Cat {} 200 (0ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next thing I need to actually do is send a message to the queue to be processed. In the server.js file I added the following code, with the entire server.js file shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; should = AWS = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'aws-sdk'&lt;/span&gt;),
  awsRegion = &lt;span class=&quot;string&quot;&gt;'us-west-2'&lt;/span&gt;,
  sqs = {},
  Hapi = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'hapi'&lt;/span&gt;),
  Good = &lt;span class=&quot;built_in&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;'good'&lt;/span&gt;);

&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);

server.route({
  method: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  path: &lt;span class=&quot;string&quot;&gt;'/'&lt;/span&gt;,
  handler: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    reply(&lt;span class=&quot;string&quot;&gt;'Hello, world!'&lt;/span&gt;);
  }
});

&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sendSqsMessage&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
&lt;span class=&quot;meta&quot;&gt;  'use strict'&lt;/span&gt;;

  AWS.config.update({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_KEY,
    region: awsRegion
  });
  sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; params = {
    MessageBody: &lt;span class=&quot;string&quot;&gt;'The Message Body Goes Here'&lt;/span&gt;,
    QueueUrl: &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/588271471917/a_sample'&lt;/span&gt;,
    DelaySeconds: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
  };

  sqs.sendMessage(params, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, data&lt;/span&gt;) &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err, err.stack);
    } &lt;span class=&quot;comment&quot;&gt;// an error occurred&lt;/span&gt;
    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Victory, message sent for '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
    }
    ;
  });
}

server.route({
  method: &lt;span class=&quot;string&quot;&gt;'GET'&lt;/span&gt;,
  path: &lt;span class=&quot;string&quot;&gt;'/{name}'&lt;/span&gt;,
  handler: &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;request, reply&lt;/span&gt;) &lt;/span&gt;{
    sendSqsMessage(&lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name));
    reply(&lt;span class=&quot;string&quot;&gt;'Your message '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;' has been sent to queue!'&lt;/span&gt;);
  }
});

server.pack.register(Good, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err&lt;/span&gt;) &lt;/span&gt;{
  &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
    &lt;span class=&quot;keyword&quot;&gt;throw&lt;/span&gt; err; &lt;span class=&quot;comment&quot;&gt;// something bad happened loading the plugin&lt;/span&gt;
  }

  server.start(&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
    server.log(&lt;span class=&quot;string&quot;&gt;'info'&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;'Server running at: '&lt;/span&gt; + server.info.uri);
  });
});
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ll step through the key lines above to detail where and what the functionality is.&lt;/p&gt;
&lt;p&gt;The line below is important, as AWS Beanstalk assumes the PORT environment variable will be set and used.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; server = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Hapi.Server(process.env.PORT || &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I added the sendMessage function. In this function I update the configuration, which is required to get the appropriate variables set. On the AWS instance itself, which I’ll cover shortly, these are where the environment variables will be picked up to instantiate the AWS configuration for the SQS object.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-javascript&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;sendSqsMessage&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;&lt;/span&gt;) &lt;/span&gt;{
&lt;span class=&quot;meta&quot;&gt;  'use strict'&lt;/span&gt;;

  AWS.config.update({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_KEY,
    region: awsRegion
  });
  sqs = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; AWS.SQS();

  &lt;span class=&quot;keyword&quot;&gt;var&lt;/span&gt; params = {
    MessageBody: &lt;span class=&quot;string&quot;&gt;'The Message Body Goes Here'&lt;/span&gt;,
    QueueUrl: &lt;span class=&quot;string&quot;&gt;'https://sqs.us-west-2.amazonaws.com/588266671666/the_path_to_the_queue'&lt;/span&gt;,
    DelaySeconds: &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
  };

  sqs.sendMessage(params, &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;err, data&lt;/span&gt;) &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (err) {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(err, err.stack);
    } &lt;span class=&quot;comment&quot;&gt;// an error occurred&lt;/span&gt;
    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;built_in&quot;&gt;console&lt;/span&gt;.log(&lt;span class=&quot;string&quot;&gt;'Victory, message sent for '&lt;/span&gt; + &lt;span class=&quot;built_in&quot;&gt;encodeURIComponent&lt;/span&gt;(request.params.name) + &lt;span class=&quot;string&quot;&gt;'!'&lt;/span&gt;);
    };
  });
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So all in all, the code is kind of dirty, but it gets the point across. Whenever I send an HTTP GET request against domain/name a post to the queue with the /name part of the URI will be sent. Now it’s time to get the actual instance deployed in AWS and test this.&lt;/p&gt;
&lt;p&gt;In the example above, as a reminder where the URL for the queue is located, navigate to the SQS part of the AWS console and click on the actual queue itself. In the information section of the queue you’ll see the URL listed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;For more information on the queue and how to set it up check out the preview article here.&lt;/p&gt;
&lt;h2 id=&quot;setting-up-an-aws-beanstalk-instance&quot;&gt;Setting up an AWS Beanstalk Instance&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;If you’ve not used AWS Beanstalk the console interface will automatically show a display screen that only has options to create an application. If there are already applications running the Beanstalk Environment the create application button will be toward the top right of the console.&lt;/p&gt;
&lt;p&gt;It’s important to note I’ll be creating two environments within a single application within the Beanstalk environment. Both of them will be their own load balanced, environments acting just as if they were located in different geographical regions in AWS.&lt;/p&gt;
&lt;p&gt;The first step once I’ve clicked the create application button is to set the application name and description. The name, is required, the description is not.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Clicking on next then puts me on the environment creation screen. I’ve set the environment tier to web server, the predefined configuration is using Node.js, and the environment type is a load balanced with autoscaling environment. With these set, click next.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;upload&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the next step I’ll need to upload the application. I’ve got the cloned application repo navigated to in bash, execute ‘&lt;em&gt;open .&lt;/em&gt;‘ [1] against it to open the finder [2] to that location, right click and compress [3] the folder and all of the contents. I now have a ready to upload and deploy file package.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now select the file, make sure the radio button is selected also, as selecting a file doesn’t automatically select the radio button. Then click on next. The application deployment file will then upload.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_07.png&quot; alt=&quot;Screen 7&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next dialog will provide a form to set the environment name, URL, and description. Click on the &lt;em&gt;Check availability&lt;/em&gt; button to determine if the URL is available that is chosen.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_08.png&quot; alt=&quot;Screen 8&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next I click through the additional resources, configuration details and environment tags leaving the default settings. The on the final review information screen I’ll click the launch button and the status of deployment will show.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_09.png&quot; alt=&quot;Screen 9&quot;&gt;&lt;/p&gt;
&lt;p&gt;Once that spools up, click on the URL to navigate the browser to the URL that the site is now available publicly at and add a name to the URL. Here’s the default &lt;em&gt;Hello World!&lt;/em&gt; display.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_10.png&quot; alt=&quot;Screen 10&quot;&gt;&lt;/p&gt;
&lt;p&gt;The display when adding a name (or any set of strings) to the URL, in this particular case to this URL here &lt;em&gt;&lt;a href=&quot;http://awsqueuesampleapp-env.elasticbeanstalk.com/&quot;&gt;http://awsqueuesampleapp-env.elasticbeanstalk.com/&lt;/a&gt;&lt;/em&gt; with a name attached like this &lt;em&gt;&lt;a href=&quot;http://awsqueuesampleapp-env.elasticbeanstalk.com/April&quot;&gt;http://awsqueuesampleapp-env.elasticbeanstalk.com/April&lt;/a&gt;&lt;/em&gt; the following displays and sends the name to the AWS SQS Queue we have setup.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_11.png&quot; alt=&quot;Screen 11&quot;&gt;&lt;/p&gt;
&lt;p&gt;To determine if everything I’ve done has worked ok, I navigate back to the AWS console and then into the SQS section. On the queue list I pick the queue that is being used and there sits the queue items I’ve added by hitting the URL shown above.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/hapijs-aws-worker-publish/SQS_Worker_12.png&quot; alt=&quot;Screen 12&quot;&gt;&lt;/p&gt;
&lt;p&gt;Check under the Messages Available, which I’ve submitted 15 messages and they sit there in the queue, waiting for the next stage of this series - building the worker node. Keep reading, that’s up next. Cheers!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances</title>
      <link>http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/</guid>
      <author></author>
      <description>&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Amazon-SQS_200x200.png&quot; alt=&quot;Amazon SQS&quot;&gt;
&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before diving straight in, I’m going to outline the specific goals and what I am using to accomplish these goals. The goal is to have a simple web application, that will get some element of data posted to a queue. The queue will then have data that a worker service needs to then process. As I step through each of these requirements I’ll determine the actual push and pull mechanisms that will get the job done.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_Elastic-Beanstalk_200x200.png&quot; alt=&quot;Deployment &amp;amp; Management - Elastic Beanstalk&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/elasticbeanstalk/&quot;&gt;AWS Elastic Beanstalk Worker&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/elasticbeanstalk/&quot;&gt;AWS Elastic Beanstalk&lt;/a&gt; is a service used to deploy and scale web application and services. In this particular example I’ll be using Node.js for all the work, but other options are available such as Java, .NET, PHP, Python, Ruby and even anything you can stick in a Docker Container. Simply put, you can run whatever you need in Beanstalk and gain all the advantages of the virtualized services and scaling of the toolset.&lt;/p&gt;
&lt;p&gt;The worker feature that I’ll be using in this how-to, referred to by AWS as Worker Tiers, is setup to handle background tasks at scale. Think of things like doing database cleanup, setting action flags, events, firing triggers or simply sending an email notification. The worker tier that I’ll be using, again with Node.js, will simple be there to process messages that I’ll put into the queue.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Amazon-SQS_200x200.png&quot; alt=&quot;SQS&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;AWS Simple Queue Service (SQS)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;AWS Simple Queue Service&lt;/a&gt;, or &lt;a href=&quot;http://aws.amazon.com/sqs/&quot;&gt;SQS&lt;/a&gt; for short, is a distributed and scalable hosted queue service for storing messages that need to be reliably available between systems. By using SQS I can then create decoupled components of an application that are autonomous of each other in execution. This provides more options around scaling up or scaling down particular workloads, apps and services throughout the application ecosystem that I’ve built.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/cloudwatch/&quot;&gt;CloudWatch&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_CloudWatch-200x200.png&quot; alt=&quot;Cloudwatch&quot;&gt;
&lt;/div&gt;

&lt;p&gt;Even though the use of &lt;a href=&quot;http://aws.amazon.com/cloudwatch/&quot;&gt;CloudWatch&lt;/a&gt; is actually transparent to this project, I needed to bring it up, because without things being setup appropriately CloudWatch will definitely let you know that it is involved in this architecture.&lt;/p&gt;
&lt;p&gt;CloudWatch is a monitoring service for cloud resources. In this particular scenario that I’m detailing here it is setup automatically by Elastic Beanstalk to monitor and autoscale instances as demand dictates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/iam/&quot;&gt;Identity and Access Management (IAM)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/Deployment-&amp;amp;-Management_IAM-200x200.png&quot; alt=&quot;IAM&quot;&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/iam/&quot;&gt;AWS IAM&lt;/a&gt; provides security for individual AWS resources and also a way to manage users and administrators of those resources. In this particular scenario I won’t cover the default user that I have setup, but assume that I’m using a user with permissions to all resources. I will be adding some roles to enable CloudWatch and Elastic Beanstalk to interoperate appropriately with the SQS under the premise of an Elastic Beanstalk Worker environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://aws.amazon.com/sdk-for-node-js/&quot;&gt;AWS Node.js SDK&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;http://aws.amazon.com/sdk-for-node-js/&quot;&gt;Nodejs SDK&lt;/a&gt; that Amazon provides for the AWS Web Services is pretty extensive. I have noticed it suffers a little from the “&lt;em&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/God_object&quot;&gt;God Object&lt;/a&gt;&lt;/em&gt;“ type of context where it does everything in one giant library, &lt;em&gt;however&lt;/em&gt;, it really kind of makes sense for something like AWS’s Services.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/SDKs-copy_nodeJS-200x2100.png&quot; alt=&quot;Node.js SDK&quot;&gt;
&lt;/div&gt;

&lt;p&gt;The SDK provides JavaScript objects for AWS services including S3, EC2, and almost every other practical service they have. The package is available for download the standard npm way.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  npm install aws-sdk
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In the getting started section of the AWS documentation, the samples are generally given using a loadable json file with the secret key information for connecting to your AWS resources. In this scenario I’ll actually use a different way to setup that configuration, which I’ll elaborate on further into this series.&lt;/p&gt;
&lt;h2 id=&quot;back-to-business&quot;&gt;Back to Business&lt;/h2&gt;
&lt;p&gt;The first order of business is to get a queue created. Since everything I’m going to put together in this sample is primarily focused around processing a queue, it seems like the perfect place to start. First open up the AWS Console and navigate to the SQS admin page.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-01.png&quot; alt=&quot;Screen 1&quot;&gt;&lt;/p&gt;
&lt;p&gt;Next click on the Create New Queue button to launch the create queue dialog.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-02.png&quot; alt=&quot;Screen 2&quot;&gt;&lt;/p&gt;
&lt;p&gt;On the dialog enter the queue name and change any of the queue settings that you need to. In this particular situation I didn’t change any and just went with the defaults.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-03.png&quot; alt=&quot;Screen 3&quot;&gt;&lt;/p&gt;
&lt;p&gt;Now the queue is created. However I can’t really do anything with it at this point. I need to open up permissions to whatever I want to have access it. Clicking on the just created queue and then selecting the Permissions tab just below that will bring up the tab dialog that provides options for adding various permission levels for access.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-04.png&quot; alt=&quot;Screen 4&quot;&gt;&lt;/p&gt;
&lt;p&gt;Adding permissions…&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-05.png&quot; alt=&quot;Screen 5&quot;&gt;&lt;/p&gt;
&lt;p&gt;Add a Permission to sample&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances/screen-06.png&quot; alt=&quot;Screen 6&quot;&gt;&lt;/p&gt;
&lt;p&gt;The queue is now all setup. In the next entry I’ll setup a web application project that will send data to the queue. I’ll also update this article with the links to the subsequent articles at the very top - and the bottom of the article here.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Part 1&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/setting-up-an-aws-sqs-queue-for-use-with-node-js-beanstalk-worker-instances&quot;&gt;Setting up an AWS SQS Queue for Use With Node.js Beanstalk Worker Instances&lt;/a&gt; (This is the current article you’re reading now)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 2&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/hapijs-aws-worker-publish/&quot;&gt;Setting up a Hapi.js App that sends work to a Node.js AWS Worker via SQS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Part 3&lt;/em&gt; – &lt;a href=&quot;http://adron.github.io/articles/aws-beanstalk-worker-with-node-js-and-sqs/&quot;&gt;AWS Beanstalk Worker with Node.js and SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Reference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-worker&quot;&gt;Testing AWS SQS Web Worker Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Adron/testing-aws-sqs-site&quot;&gt;Testing AWS SQS Web App Github Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    <item>
      <title>Working in -34c Wintersmith Customization and Github Hosting</title>
      <link>http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting/</link>
      <pubDate>Wed, 19 Feb 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/working-in-34c-wintersmith-customization-and-github-hosting/</guid>
      <author></author>
      <description>&lt;p&gt;Getting Wintersmith customized, building and deployed to Github and a domain name pointed takes a few extra steps. So let’s roll…&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-01.png&quot; alt=&quot;Wintersmith Icon 1&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step #1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Setup &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt;. See my previous blog entry “&lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt;“ for this information.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-02.png&quot; alt=&quot;Wintersmith Icon 2&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step #2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now it’s time to get things deployed to Github. This takes a few interesting, non-intuitive steps, but once done things work extremely well. To get the appropriate git branch setup I worked with an existing git repo. This repo is the same repo that I’ve used for the public facing &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Deconstructed Site&lt;/a&gt;. The code repo is located @ &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Deconstructed Github Repo&lt;/a&gt;. I added a &lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;github pages branch&lt;/a&gt; to this repository, for more information on how to do this check out my Jekyll how-to “&lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;Bringing to Life an Open Source Project via Github &amp;amp; Jekyll - Part 1&lt;/a&gt;” which I detail at the beginning how to get a Github Pages site running.&lt;/p&gt;
&lt;p&gt;Once the site is up and running I switched over to it and cleared out that path. I kept a few things I’d need like the .gitignore, README.md and a few other files. I then put the repo directory that I detailed in “&lt;a href=&quot;http://adron.github.io/articles/wintersmith-creating-documentation&quot;&gt;Wintersmith Creating Documentation&lt;/a&gt;” right here in the gh-pages branch. With that in place I then just committed and pushed this code to the gh-pages repository. That gave me the initial baseline for the site.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/wintersmith-03.png&quot; alt=&quot;Wintersmith Icon 3&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Step #3&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Get the customizations done and site domain/subdomain redirected. The steps to get the domain setup to have a custom domain pointed at your gh-pages github site is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a file named CNAME in the root of your gh-pages branch and in that CNAME file add one line with the domain that is being directed to this gh-pages site. My &lt;a href=&quot;https://github.com/Adron/deconstructed/blob/gh-pages/CNAME&quot; target=&quot;_blank&quot;&gt;CNAME file&lt;/a&gt; looks simply like this: &lt;code&gt;docs.deconstructed.io&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next setup either an DNS A record or cname record. The cname will give you the advantage of having Github manage which IPs are in use in their system, so if there is any failover, DDOS or IP changes then you’re protected from that. To setup an A record add the A record to point to 204.232.175.78 or setup a cname to point to your github .io account, which in my case is &lt;a href=&quot;http://adron.github.io/&quot;&gt;http://adron.github.io/&lt;/a&gt;. The following is what the record looked like in my Route 53 settings.&lt;img src=&quot;/articles/working-in-34c-wintersmith-customization-and-github-hosting/dns-deconstructed.png&quot; alt=&quot;DNS Setting&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Last but not least the configuration settings that need to be made in Wintersmith.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First set the locals url setting to the appropriate domain or subdomain. In my case that meant changing the value from &lt;em&gt;&lt;a href=&quot;http://localhost:8080/&quot;&gt;http://localhost:8080/&lt;/a&gt;&lt;/em&gt; to &lt;em&gt;&lt;a href=&quot;http://adron.github.io/docs/deconstructed-once-upon-a-time&quot;&gt;http://docs.deconstructed.io/&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;  “locals”: {&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  &amp;quot;url&amp;quot;: &amp;quot;http://docs.deconstructed.io&amp;quot;,
  &amp;quot;name&amp;quot;: &amp;quot;Deconstructed Docs&amp;quot;,
  &amp;quot;owner&amp;quot;: &amp;quot;Adron Hall&amp;quot;,
  &amp;quot;description&amp;quot;: &amp;quot;This site provides the documentation around the Deconstructed API Services.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;  }&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In the root of the project (where the Wintersmith build ends up) add a .nojekyll file so that Jekyll won’t be used unnecessarily to try and build the Wintersmith project.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;…and with that, I’ve covered the bases for getting a Wintersmith site (blog or whatever you’re like to use it for) up and running. Feel free to ask any questions in the comments and I’ll help work through any issues you’ve encountered. Cheers!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Wintersmith Creating Documentation</title>
      <link>http://adron.github.io/articles/wintersmith-creating-documentation/</link>
      <pubDate>Mon, 17 Feb 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/wintersmith-creating-documentation/</guid>
      <author></author>
      <description>&lt;p&gt;I set out a few days ago to put together a documentation site. I had a few criteria for this site:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;A static site that I could push to Github to use with their github pages feature.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The static site is generated from markdown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It just works. It’s easy to get it into a workflow without breaking the tool or breaking a solid workflow.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That was it, what I’d consider some pretty straight forward criteria. However it wasn’t that easy, until it was. Here’s a few of the issues I ran through on the way to getting a solid tool with a solid workflow working together. Beware however if you have fickle reading eyes, the following is a rant about what does and does not work.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;[rant on]&lt;/h2&gt;
&lt;strong&gt;Middleman Broken Ruby and Broken Gems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I have a Mac Book Pro Retina 15”. The machine runs OS-X Mavericks. I’ve had zero issue with this OS. It comes with Ruby 2 and some version of gems. My first attempt was to take a stab with &lt;a href=&quot;http://middlemanapp.com/&quot; target=&quot;_blank&quot;&gt;middleman&lt;/a&gt;, the same static site builder used by many companies including Basho. Even though I ran into problems which I detailed in “&lt;a href=&quot;http://compositecode.com/2012/12/09/basho-first-week-coding-research-adventures/&quot; target=&quot;_blank&quot;&gt;Basho – First Week Coding &amp;amp; Research Adventures…&lt;/a&gt;“ and “&lt;a href=&quot;http://compositecode.com/2012/12/14/un-breaking-mountain-lion-os-x/&quot; target=&quot;_blank&quot;&gt;Un-breaking OS-X Mountain Lion&lt;/a&gt;“ eventually middleman &lt;em&gt;mostly&lt;/em&gt; worked.&lt;/p&gt;
&lt;p&gt;Well, I didn’t get to a working app very fast. Immediately Ruby 2 had issues and gemsets puked middleman everywhere. I then ran into some confusing permissions errors. About 15 minutes into this process of troubleshooting middleman I had flashbacks of the first few days at Basho and thought, “&lt;em&gt;this is bullshit, something has to work better than this catastrofuck of software version conflicts&lt;/em&gt;“. So I dropped middleman dead.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assemble, Assemble, Assemble…    ??!?#@$%! WTF!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I attempted &lt;a href=&quot;http://assemble.io/&quot; target=&quot;_blank&quot;&gt;assemble&lt;/a&gt; next for the node.js stack. It &lt;em&gt;looked&lt;/em&gt; to have a lot of promise. It uses grunt.js and a bunch of other tools to manage a static site generating, bootstrap using stack. The more I looked at it however it seemed busy. Busy as in “&lt;em&gt;I’m going to do more than three things so I’ll maybe do none of them right&lt;/em&gt;“.&lt;/p&gt;
&lt;p&gt;Reading about assemble I turned to another hacker slinging some code at the bar I sat at. She looked at the project and asked, “&lt;em&gt;what’s it supposed to do exactly? I get that it’s a framework of tools but it doesn’t’ exactly lay out what it is supposed to be doing besides arbitrarily managing some parts of the stack.&lt;/em&gt;“ That seemed reasonable to me.&lt;/p&gt;
&lt;p&gt;Before I just tossed assemble.io to the trash heap of options I wanted to ask at least one more person. So the next day I asked my good friend and super genius Troy Howard. It was a short verdict, “drop that shit”.&lt;/p&gt;
&lt;p&gt;That was enough for me, assemble was officially dead for this project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slate, This Seems Slick But…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I then took a stab at &lt;a href=&quot;http://tripit.github.io/slate/&quot; target=&quot;_blank&quot;&gt;Slate&lt;/a&gt;. &lt;a href=&quot;http://tripit.github.io/slate/&quot; target=&quot;_blank&quot;&gt;Orchestrate.io just created some excellent documentation&lt;/a&gt; using the Slate solution. So I dove into this, getting a test site up and running rapidly. It seemed like a mostly viable solution until I started running into issues with how and where I wanted things displayed for the code samples and other material. It appeared, if I were going to use Slate, I’d be using it almost exactly as is. I might borrow pieces of it in the future, even the layout to some degree, but for now I wanted something else that I could incorporate my themes as needed. Alas, I was super happy with Slate, it just wasn’t a great fit for now.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where The Hell Are My Options, Jekyll?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At this point I was getting a little frustrated. I then went to a tried and true solution in &lt;a href=&quot;http://jekyllrb.com/&quot; target=&quot;_blank&quot;&gt;jekyll&lt;/a&gt;. Jekyll is a pretty solid solution, with some bugs and oddball issues but nothing major. I started working with it and even transitioning a jekyll project into my theme. Hacking a jekyll blog into a reasonable documentation solution this seemed like the way to go.&lt;/p&gt;
&lt;p&gt;But then I got a wild urge to see if there was anything else in Node.js land that I was missing. I really didn’t want to sling a Ruby project if I didn’t have to. I’d rather keep all the stacks around JavaScript for this particular set of projects. No reason to diverge when I’m just dealing with such simple straight forward web projects. I’ll diverge when something truly validate diverging, like doing some real math with a real functional language or something. Trading Node.js for one single project to go with a pseudo Ruby project for static site generation just didn’t seem appealing. So I started looking around one more time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Made in -34°C&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;img src=&quot;/articles/wintersmith-creating-documentation/temp.png&quot; alt=&quot;-34° Celsius&quot;&gt;
    Yup, -34 Celsius. That’s about as cold as it gets. Click for the full size chart!
&lt;/div&gt;

&lt;p&gt;The next solution I tried was &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt;. This solution appeared to have everything that I’d been looking for feature wise. It was a node.js project, it generated static content, could generate blogs but other things too, was simple, had plugins, was straight forward and more. I was a little paranoid after the solutions I’d fought my way through earlier so I went to the only place that would insure that I’d have a solution I could be confident in. I went straight to the &lt;a href=&quot;https://github.com/jnordberg/wintersmith&quot; target=&quot;_blank&quot;&gt;source&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;I’ll admit I took a peak at the package.json file before going head long into the source. A quick perusal of the dependencies list looked ok.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  dependencies: {
    marked: ~0.3.0,
    coffee-script: ~1.6.3,
    async: ~0.2.9,
    highlight.js: ~8.0.0,
    jade: ~1.1.5,
    ncp: ~0.5.0,
    rimraf: ~2.2.6,
    winston: ~0.7.2,
    colors: ~0.6.2,
    optimist: ~0.6.0,
    minimatch: ~0.2.14,
    mime: ~1.2.11,
    js-yaml: ~3.0.1,
    mkdirp: ~0.3.5,
    chokidar: ~0.8.1,
    server-destroy: ~1.0.0,
    npm: ~1.3.24,
    slugg: ~0.1.2
  },
  devDependencies: {
    shelljs: 0.1.x
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I immediately took note of a few things. The first was that there was actually a breakout of dev dependencies versus actual project dependencies. That’s a good first sign. The second thing I just went through the list and checked the various library dependencies, there were a few that I’ve played around with before that I trusted; highlight.js, coffee-script, async, js-yaml and npm were all cool by me. It didn’t seem to crazy out of whack. With that I went forth into the code with zero expectations…&lt;/p&gt;
&lt;p&gt;The first files I dug into were the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/config.coffee&quot; target=&quot;_blank&quot;&gt;config.coffee file&lt;/a&gt;, which pointed out a few things I’d want to possibly tweak a little later such as the port number and other things the wintersmith server would use when running the preview server.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class Config
  ### The configuration object ###

  @defaults =
    # path to the directory containing content&amp;#39;s to be scanned
    contents: &amp;#39;./contents&amp;#39;
    # list of glob patterns to ignore
    ignore: []
    # context variables, passed to views/templates
    locals: {}
    # list of modules/files to load as plugins
    plugins: []
    # modules/files loaded and added to locals, name: module
    require: {}
    # path to the directory containing the templates
    templates: &amp;#39;./templates&amp;#39;
    # directory to load custom views from
    views: null
    # built product goes here
    output: &amp;#39;./build&amp;#39;
    # base url that site lives on, e.g. &amp;#39;/blog/&amp;#39;
    baseUrl: &amp;#39;/&amp;#39;
    # preview server settings
    hostname: null # INADDR_ANY
    port: 8080
    # options prefixed with _ are undocumented and should generally not be modified
    _fileLimit: 40 # max files to keep open at once
    _restartOnConfChange: true # restart preview server on config change
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Second code file that looked interesting, the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/renderer.coffee&quot; target=&quot;_blank&quot;&gt;renderer.coffee&lt;/a&gt; code file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fs = require &amp;#39;fs&amp;#39;
util = require &amp;#39;util&amp;#39;
async = require &amp;#39;async&amp;#39;
path = require &amp;#39;path&amp;#39;
mkdirp = require &amp;#39;mkdirp&amp;#39;
{Stream} = require &amp;#39;stream&amp;#39;

{ContentTree} = require &amp;#39;./content&amp;#39;
{pump, extend} = require &amp;#39;./utils&amp;#39;

if not setImmediate?
  setImmediate = process.nextTick

renderView = (env, content, locals, contents, templates, callback) -&amp;amp;gt;
  setImmediate -&amp;amp;gt;
    # add env and contents to view locals
    _locals = {env, contents}
    extend _locals, locals

    # lookup view function if needed
    view = content.view
    if typeof view is &amp;#39;string&amp;#39;
      name = view
      view = env.views[view]
      if not view?
        callback new Error &amp;amp;quot;content &amp;#39;#{ content.filename }&amp;#39; specifies unknown view &amp;#39;#{ name }&amp;#39;&amp;amp;quot;
        return

    # run view
    view.call content, env, _locals, contents, templates, (error, result) -&amp;amp;gt;
      error.message = &amp;amp;quot;#{ content.filename }: #{ error.message }&amp;amp;quot; if error?
      callback error, result

render = (env, outputDir, contents, templates, locals, callback) -&amp;amp;gt;
  ### Render *contents* and *templates* using environment *env* to *outputDir*.
      The output directory will be created if it does not exist. ###

  env.logger.info &amp;amp;quot;rendering tree:\n#{ ContentTree.inspect(contents, 1) }\n&amp;amp;quot;
  env.logger.verbose &amp;amp;quot;render output directory: #{ outputDir }&amp;amp;quot;

  renderPlugin = (content, callback) -&amp;amp;gt;
    ### render *content* plugin, calls *callback* with true if a file is written; otherwise false. ###
    renderView env, content, locals, contents, templates, (error, result) -&amp;amp;gt;
      if error
        callback error
      else if result instanceof Stream or result instanceof Buffer
        destination = path.join outputDir, content.filename
        env.logger.verbose &amp;amp;quot;writing content #{ content.url } to #{ destination }&amp;amp;quot;
        mkdirp.sync path.dirname destination
        writeStream = fs.createWriteStream destination
        if result instanceof Stream
          pump result, writeStream, callback
        else
          writeStream.end result, callback
      else
        env.logger.verbose &amp;amp;quot;skipping #{ content.url }&amp;amp;quot;
        callback()

  items = ContentTree.flatten contents
  async.forEachLimit items, env.config._fileLimit, renderPlugin, callback

module.exports = {render, renderView}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Fairly straight forward code. Puts together the rendered content and I noted a few key things. There was a solid process order that was repeated; env, content, locals, contents, templates, callback. Because of this it looked like local variables were set to statically set certain things based on configuration instead of dynamic location. This could bite me, but with this quick glance, at least I knew where and what was happening with the order of generation.&lt;/p&gt;
&lt;p&gt;I then did a scan of the &lt;a href=&quot;https://github.com/jnordberg/wintersmith/blob/master/src/core/templates.coffee&quot; target=&quot;_blank&quot;&gt;templates.coffee&lt;/a&gt; and a few other code files. Having gotten a fair idea of where and what was being done, I went looking for a quick start. Things looked pretty good, so I crossed my fingers and my rant ends here…&lt;/p&gt;
&lt;p&gt;&lt;h2&gt;[/rant off]&lt;/h2&gt;
So now that the rant mode was over, here’s what I did to make wintersmith my documentation solution. Most of this is in a state of flux as I automate and put more into the project to simplify the workflow.&lt;/p&gt;
&lt;p&gt;Here’s how I got started super fast.&lt;/p&gt;
&lt;div class=&quot;image float-right&quot;&gt;
    &lt;a href=&quot;http://wintersmith.io/&quot;&gt;&lt;img src=&quot;/articles/wintersmith-creating-documentation/wintersmith-04.png&quot; alt=&quot;Wintersmith Icon 4&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;First step is get &lt;a href=&quot;http://wintersmith.io/&quot; target=&quot;_blank&quot;&gt;Wintersmith&lt;/a&gt; running.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;npm install wintersmith -g
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that you’ll need to install it globally (thus the -g) and may need to install Wintersmith with sudo prepended to that command.&lt;/p&gt;
&lt;p&gt;The next thing that I did was create a directory that I’d use to build the static generated contents. This material I’d put into a git repository on github (namely the &lt;a href=&quot;https://github.com/Deconstructed/deconstructed/tree/gh-pages&quot; target=&quot;_blank&quot;&gt;deconstructed gh-pages repo&lt;/a&gt;). I’ll call this generically the root directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir rootDirectory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that I navigated into the rootDirectory and created a new Wintersmith Application.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wintersmith new myAppName
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That now gives me a directory structure like this&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rootDirectory&lt;/li&gt;
&lt;li&gt;myAppName&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now that I have this, the app content, markdown, views and related templates are in myAppName. To view the app, I changed directories into myAppName and ran wintersmith preview like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wintersmith preview
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Opening up a browser I can navigate to &lt;a href=&quot;http://localhost:8080&quot; target=&quot;_blank&quot;&gt;http://localhost:8080&lt;/a&gt; and see the fully rendered site. To publish the site however one needs to run wintersmith build, however there’s one problem. I want the site to publish to the rootDirectory where the application content currently sites. To do this I have to edit the &lt;em&gt;config.json&lt;/em&gt; file. Just above the locals code settings shown below…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  locals: {
    url: http://localhost:8080,
    name: The Wintersmith&amp;#39;s blog,
    owner: Someone,
    description: Ramblings of an immor(t)al demigod
}
[/sourcecode]

I added an output key value property to the file as shown. It merely takes the results and shifts them back a directory so they end up in the rootDirectory.

[sourcecode language=&amp;quot;javascript&amp;quot;]
{
  output:../,
  locals: {
    url: http://docs.deconstructed.io,
    name: Deconstructed Docs,
    owner: Adron Hall,
    description: This site provides the documentation around the Deconstructed API Services.
  },
  plugins: [
    ./plugins/paginator.coffee
  ],
  require: {
    moment: moment,
    _: underscore,
    typogr: typogr
  },
  jade: {
    pretty: true
  },
  markdown: {
    smartLists: true,
    smartypants: true
  },
  paginator: {
    perPage: 6
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also changed the perPage setting to 6, just so I could get a little more content on the main page eventually. There is also the change for the domain name and a few other parameters that I’ll catch up on with the next blog entry.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In my next blog entry I’ll cover a quick how-to on how to setup the CNAME in github pages to get the static wintersmith site up at a subdomain/domain name. I’ll also dive into setup with AWS Route 53, which generically applies to setting a gh-pages site up with any DNS provider. So subscribe and I’ll have that post in the next 1-2 days.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>my top 4 ideal dev shop product characteristics yours</title>
      <link>http://adron.github.io/articles/my-top-4-ideal-dev-shop-product-characteristics-yours/</link>
      <pubDate>Sat, 22 Oct 2011 01:00:00 +0100</pubDate>
      <guid isPermaLink="true">http://adron.github.io/articles/my-top-4-ideal-dev-shop-product-characteristics-yours/</guid>
      <author></author>
      <description>&lt;p&gt;What is an ideal software project? What is an ideal delivery cycle? What is an ideal culture? From a client’s perspective do they see the team as a sluggish liability or is the development team proactive and looking for the next strategic or tactical step to take?&lt;/p&gt;
&lt;p&gt;Ideally, I see the development team as a group that should be leading a company with technology. If a team isn’t doing that, they’re likely to be running the risk of appearing as a liability and risk. Often these are the types of teams that are often outsourced or off-shored because it seems easier to the clients or management.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I don’t like the idea of getting stuck in a team like that. However, I’d do everything in my power to change that situation. In the past I’ve done just that. It is hard, but it is worth it. It boils down, unfortunately, to a perception and practice problem most of the time. A little like herding cats. Once you get them all together… well, you can read the picture. ;)&lt;/p&gt;
&lt;p&gt;[caption id=”” align=”alignright” width=”225” caption=”Herding Cats, ain&amp;#039;t a feeling like it in the world!”]&lt;img class=&quot; &quot; title=&quot;Herding Cats, Oh yeah!&quot; src=&quot;http://adronhall.smugmug.com/Software/Misc-Images/Bad-Resume/i-xPhHdVB/0/S/cat-herding-S.png&quot; alt=&quot;Herding Cats, Oh yeah!&quot; width=&quot;225&quot; height=&quot;180&quot; /&gt;[/caption]&lt;/p&gt;
&lt;p&gt;So what is my ideal team, product, and environment look like? That’s simple to answer.&lt;/p&gt;
&lt;p&gt;&lt;ol&gt;
    &lt;li&gt;Team cohesion through pairing, eating lunch together, having a beer once in a while, easy conversations, hallway troubleshooting, and other social interactions. These interactions should be easy, comfortable, almost as if everybody were friends. Better yet, the ideal situation is simply that people working on a project actually be friends. No reason, in and ideal situation, for everyone not to be.&lt;/li&gt;
    &lt;li&gt;Frequent delivery of product. Weekly, maybe every two weeks, but not much longer than that. The customer or client needs to be kept informed. If it is difficult to deliver something every week or two, that should be the top fix it item on the list of things to do. In this ideal environment of mine, I’d like to keep conversation and delivery on a weekly basis. Two weeks, often is a long time between delivery points.&lt;/li&gt;
    &lt;li&gt;Communication among all lines of the company. There should be zero resistance to talking to any part of the company, developer directly to whoever is involved in the product. If there is a user, the developers should have access to them.&lt;/li&gt;
    &lt;li&gt;Casual work environments are important. Generation Y especially, but X and others also don’t particularly like an environment to be socially stuffy because of forced attire. Dress comfortably, yet respectfully.&lt;/li&gt;
&lt;/ol&gt;
Usually with three out of four of these I’m a happy developer. If I get lucky enough to actually find 4 of 4, I’m happier than a kid in a toy store!&lt;/p&gt;
&lt;p&gt;What other characteristics draw you into a team or a product to work on? What gets you excited about the software you’re going to build or the team you’re going to work with?&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;
    &lt;li&gt;&lt;em&gt;&lt;strong&gt;Bobby&lt;/strong&gt;&lt;/em&gt; (&lt;a href=&quot;https://twitter.com/#!/NotMyself&quot; target=&quot;_blank&quot;&gt;@NotMyself&lt;/a&gt;) followed up on &lt;a href=&quot;http://iamnotmyself.com/2011/10/25/my-ideal-development-shop/&quot; target=&quot;_blank&quot;&gt;his blog here&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;Even though she didn’t write it in response to my blog entry, &lt;a href=&quot;http://katemats.com/&quot; target=&quot;_blank&quot;&gt;Kate’s blog entries&lt;/a&gt; on how to be awesome, reflects a lot of a great team member. &lt;a href=&quot;http://katemats.com/2011/10/09/manage-your-career-being-awesome-part-1/&quot; target=&quot;_blank&quot;&gt;Part 1&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/16/being-a-great-teammate-being-awesome-part-2/&quot; target=&quot;_blank&quot;&gt;part 2&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/21/improve-your-communication-skills-listening-being-awesome-part-3a/&quot; target=&quot;_blank&quot;&gt;Part 3a&lt;/a&gt;, &lt;a href=&quot;http://katemats.com/2011/10/22/improve-your-communication-skills-being-awesome-part-3b/&quot; target=&quot;_blank&quot;&gt;Part 3b&lt;/a&gt;, and &lt;a href=&quot;http://katemats.com/2011/10/23/keep-improving-being-awesome-part-4/&quot; target=&quot;_blank&quot;&gt;Part 4&lt;/a&gt;. All good reads.&lt;/li&gt;
&lt;/ul&gt;
If you write up your thoughts or ideas on an ideal dev shop or ideal product, let me know and I’ll provide a link to your blog as well!  :)&lt;/p&gt;
</description>
    </item>
  </channel>
</rss>